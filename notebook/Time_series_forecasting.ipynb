{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "# slice [start:stop:step], starting from index 5 take every 6th record.\n",
    "df = df[5::6]\n",
    "#print(\"df\", df)\n",
    "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
    "#print(\"date_time\", date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>996.50</td>\n",
       "      <td>-8.05</td>\n",
       "      <td>265.38</td>\n",
       "      <td>-8.78</td>\n",
       "      <td>94.4</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.96</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1307.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.63</td>\n",
       "      <td>192.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>996.62</td>\n",
       "      <td>-8.88</td>\n",
       "      <td>264.54</td>\n",
       "      <td>-9.77</td>\n",
       "      <td>93.2</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.91</td>\n",
       "      <td>1312.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>190.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>996.84</td>\n",
       "      <td>-8.81</td>\n",
       "      <td>264.59</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>93.5</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1312.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.63</td>\n",
       "      <td>167.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>996.99</td>\n",
       "      <td>-9.05</td>\n",
       "      <td>264.34</td>\n",
       "      <td>-10.02</td>\n",
       "      <td>92.6</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1313.61</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>997.46</td>\n",
       "      <td>-9.63</td>\n",
       "      <td>263.72</td>\n",
       "      <td>-10.65</td>\n",
       "      <td>92.2</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1317.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.88</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  VPmax (mbar)  \\\n",
       "5     996.50     -8.05    265.38        -8.78    94.4          3.33   \n",
       "11    996.62     -8.88    264.54        -9.77    93.2          3.12   \n",
       "17    996.84     -8.81    264.59        -9.66    93.5          3.13   \n",
       "23    996.99     -9.05    264.34       -10.02    92.6          3.07   \n",
       "29    997.46     -9.63    263.72       -10.65    92.2          2.94   \n",
       "\n",
       "    VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  rho (g/m**3)  \\\n",
       "5           3.14          0.19       1.96             3.15       1307.86   \n",
       "11          2.90          0.21       1.81             2.91       1312.25   \n",
       "17          2.93          0.20       1.83             2.94       1312.18   \n",
       "23          2.85          0.23       1.78             2.85       1313.61   \n",
       "29          2.71          0.23       1.69             2.71       1317.19   \n",
       "\n",
       "    wv (m/s)  max. wv (m/s)  wd (deg)  \n",
       "5       0.21           0.63     192.7  \n",
       "11      0.25           0.63     190.3  \n",
       "17      0.18           0.63     167.2  \n",
       "23      0.10           0.38     240.0  \n",
       "29      0.40           0.88     157.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFxCAYAAABeEPDDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAACguUlEQVR4nOzdd1yV5fvA8c9z2HuDCMgSEcWNe++VmqM0y4YN27Ys2+tb2a+9rCyzMke5UnPk3hMVFTfI3nvPc57fHw+QyDrAgQN6v18vX8k5z7nPDeG5nntdlyTLMoIgCIIgtHwqfXdAEARBEATtiKAtCIIgCK2ECNqCIAiC0EqIoC0IgiAIrYQI2oIgCILQSoigLQiCIAithKG+O1AXR0dH2cvLS9/dEARBEIRmcerUqVRZlp2qe67FB20vLy+Cg4P13Q1BEARBaBaSJEXV9JyYHhcEQRCEVkIEbUEQBEFooJzCEt74+zxxmQXN8n4iaAuCIAhCA+27ksIfx6KZ8NVBcotKm/z9WvyadnVKSkqIjY2lsLBQ311pNUxNTXF3d8fIyEjfXREEQbhlnI3JBCCroIS7fjjKmsf7Y2nSdKG1VQbt2NhYrKys8PLyQpIkfXenxZNlmbS0NGJjY/H29tZ3dwRBEG4ZZ2Iy6eVpx5PDfHn4t2C+3RPGwvEdm+z9WuX0eGFhIQ4ODiJga0mSJBwcHMTMhCAIrV5uUSlhybn67gYAxaUaQuOy6OFhy8gAF6b1dOOXQxFEpuY12Xu2yqANiIBdT+LnJQiVFRSreX3DeV74K0TfXRHq4a2/Qxn1+X7+vZCo766w9XwCRaUa+njbA7BwXEeMDCRe23Ce6LT8JnnPVhu09SktLY3u3bvTvXt32rRpg5ubW8XXxcXFFdfJssyIESPIzs6u0sY777zDp59+2uA+XL16lQkTJtC+fXsCAgK4++67SUpK4vz58zz44IMNblcQbhcfb7/MiuPRrD8dR3Zhib67o7UX/zrLb0ci9d0NvTkUlgrAS3+dJSOvuI6rdS8+s4DcolLScov4aNslurrbMCrABQBna1MWju/IkfA0Jn17iLyyjWnRafnMWXqcPh/s4qNtl1Br5Aa/f6tc09Y3BwcHQkJCACX4Wlpa8tJLL1W5buvWrXTr1g1ra2udvn9hYSETJ07k888/Z9KkSQDs3buXlJQUunTpQmxsLNHR0bRr106n7ysIt4r84lLWnYrF0dKE1NwizsVkMcjPUd/dqlOJWsOms3HEZOTzwAAvfXen2SVnF5KcU8SMXu6sOx3LV7uv8c7kzk3+vmm5ReQXqwmOSueVdefxtDfHyEBFZn4JP9/fG5Xqv5nMOf298HW2ZPZPx+n9wS56edpxLjYLjSzTx8ueH/dfx8zIgOdGdWhQX8RIuwmtWLGCKVOmVHz9wQcf4O/vz6hRo7hy5UrF4+Hh4YwbN45evXoxePBgLl++XPF4v3796N27N2+99RaWlpYArFy5kv79+1cEbIDhw4cTGBgIwKRJk1i9enVzfIuC0CptO59ITlEpH03rAkBITIaee6SdqLR8StQy15JykOWGj9ZaqxOR6QDc18+TWb3b8euRSL7cdRVQZjZ/PxrJwWspDf7ZZOWX8Mm/l/lm9zVScoq4nJjN17uvMfqLAwz7dB/P/3mWAFdrotPzScwu5Pv7etLF3aZKO/19HDA3NiC/WM3pqAwcLIzZ8sxglj7Ymwld2vDTgeuk5RY1qI9ipN2EDh8+zI8//gjAqVOnWL16NWfOnKG0tJSePXvSq1cvAB577DF++OEH/Pz8OH78OE8++SR79uxh/vz5zJ8/n3vuuYcffvihot3Q0NCK11YnKCiIRYsW8fLLLzftNygIrdT2C4m0tTFlVIAzPk4WhMRk6btLWglLzgEgI7+ElNwinK1M9dyj5rX1fAI2ZkZ0bmvN/+4MJLughO/3hXNfP0/2X0nhrY0XAOjgYsndQR5YmhgytacbJoYGWrX/5sZQNp+LB+CznVcrHu/c1pqJXVwxNzHgpTH+pOQUYWNmhEUNR7skSeK3uX24kpjDjF7uSBIVfXhhtD/bQxP5bm84b03qVO+fQasP2u9uvsDF+Kprxo3Rqa01b09q/JRLeno6VlZWABw8eJCpU6dibm4OwOTJkwHIzc3lyJEj3HXXXRWvKypS7sCOHj3K33//DcDs2bOrnYKvjrOzM/Hx8Y3uvyDcigpL1By6llr2YSoR2NaG09GtY6R9Lem/XdNXE3Nvq6Adk57P9tBE5g31xchAmSR+fnQHtpxP4Pk/QwiJyaRnO1vu7evJ0kMR/G/LJUC5QVv6QG8MVLVvxj0TncGms/E8P6oDd3RzZeu5BEyMVNzVywM7C+NK17a1Nauzv7297OntZV/l8fbOlkzv6c4fx6J4ZLC3Vm3dqNUH7ZbM0NAQjUaDSqX8glW3g1uj0WBra1uxRq6Nzp07s3///hqfLywsxMysfr8IgtCSlU936uIUxLHraRSUqBkR4AyAh70ZW88nUKrWYGjQslcMryXnYm1qSHZhKVeSclrFOnxddlxIJDmniPv6edZ63coT0UiSxAP9vSoea+9syZPDfPn5YAQdXa34alYPPOzNmdbTjdiMAv69kMj/tlziwNUUhnd0rrX9v8/EYWKo4uHB3liaGPLMSD9dfHvVenpEe9acimXr+QQeGexTr9e2+qCtixFxU/H39+f69eu0b9+eIUOG8OCDD7Jw4UJKS0vZvHkz8+bNw9raGm9vb9asWcNdd92FLMucO3eObt260a9fP9atW8fMmTMrrVHPnj2bjz76iC1btjBx4kQAtm/fjpubG126dOHq1asV69uC0NoVl2oY+fk+7u3ryeNDfRvd3oGrqZgYqujv4wCAm605pRqZpJwi3Oo56mkuxaUaDoelsu9KMn19HDgdlcHVxBx9d0srJWoNa4JjMTKQmNStLaZG/01Vl6o1vLkxlJScInq2s6NT2+o37Wo0MptC4hns50gbm8qzCy+P68hzozpgZCBV3NRJkoSHvTn39/di8b5w1p6KrTVol6o1bDmfwMgA5ybNZlbO08ECH0cLjoSn1Ttot+zbylZu4sSJ7Nu3D4CePXsyc+ZMunfvzvTp0xk8eHDFdStWrGDp0qV069aNzp07s3HjRgC+/PJLPv/8c/r06UNCQgI2NsqGBzMzM/755x+++eYb/Pz86NSpE7/++ivOzsov5d69eyuCuSC0dofCUohJL+CnA9cpLFE3ur0j4akEedlVBA93OyVQx2U0T8GHhnj8j1M89OtJLEwMeXNiJzq4WHElqeUH7VK1hidXnOa1DedZsPYcs386xoYzsRVHnvZeSSEpuwhJkrjnp2O8u/lCtce4tpxPIC6zgDu7u1X7PsaGqmpnYYwNVUzp3padF5Nq3fh1NjaT1NxiJnRxbeB3Wn8D2jtw/HoaJWpNvV7X6kfa+vbOO+/U+NwjjzzC/fffzyOPPALA66+/zuuvv17lOm9vb7Zv317lcTc3N44dO4YkSaxevZqgoKCK5zp27Fjta4qKiggODubLL7+s/zcjCC3QP2cTMFBJpOUVsz00kTt7VP/BrY3U3CIuJ+awYKx/xWNuZUE7NiO/IklGS3IkPJU9l5N5YpgvTwzzxdrUCP82VqwJjkGW5RadOOnDrZfZeTGJtyd1wt7CmDf/DuX5P8+y7XwiX83qwY/7w3GxNuG72T357WgUvx+NYt+VFFY80rdirTckJpNnV5+hc1trxnZuU+8+3NvXk2WHI1lxPJq5g7zJLy7l8x1XKSrV8MHUQMyNDTkSlgbAQN/mW24Y6OvIH8eiCY7MoL+vg9ava/agLUnSOOArwAD4WZblRc3dh+bi6urKo48+SnZ2doPOap86dYqnn34aWZaxtbXll19+qfM10dHRLFq0CENDcT8mtH6yLLP7cjJTurdl89l4LjdySjg4UtlwduOHZPmUeEsdaf9yKAJnKxPmj/SrmB3o4GJFXrGauMwC3O3MdfI+uy8l8efJGL67t2fFRq/GOBOdwS+HI3igvycPDVRqHkzq2pbfjkby3j8XGfnZPuKzCvloWheCvOwJ8rJXrl12krt+OMrqx/rhYW/O7ktJSMDKR/phZqzdLvAbtXe2ZJi/E78cjmDDmTiSsgvJL1ZmbOIyC3hpjD/bQhMJcLWusuGsKQ31d8LSxJA1p2LqFbSbdXpckiQD4DtgPNAJuEeSpPrveW9F7r777gYnVxk8eDBnz57l3LlzHDhwgPbt29f5Gj8/P4YNG9ag9xOEliY2o4CsghKCPO1xtjIlKbtx+fMj05Sc0H7OlhWPmRoZ4GhpQmwzB+3yderErJq/p6yCEg5cTWXyTWvB/m2U/l/V4RT5r0ci2XExiX/ONf7kiUYj88GWSzhamrBg3H/FM1QqiYcGerNkThDu9uaMD2zD3UEeFc8Hedmz8tF+ZOYXs2ibkq/i+PV0At1ssDFveIXCNyZ2wtLEkISsAkyNDGhjbcr/zejKych07v7xKBcTsiv2ODQXc2NDJndvy9bzCWQVaJ+Rr7mHY32AMFmWrwNIkrQamAJcbOZ+CILQCoTGKeenA92saWNjWmuA00ZMej625kZYmVYOAO52ZkSnN02u6JuV5zzfGppAYYkGGzMjXhzTgbuDPCoFZoB1p2IpVmuY2LXyWqufi3KU9HxsNiM6ujS6T9mFJRy7rkwR/7j/Ond2d2vUtPvSQxEER2Xwf9O7Vruxa3QnF0Z3qr7fXdxtuH+AFz/sD+f49TRCYjJ5YEDtO8vr0t7Zku3PDSEzvxhDlYpSjQZ3O3M6uFiRlF3I6egMZvdp/gyS03u6s/J4NHsvJ2u97NPcQdsNiLnh61igb0MaaulrOS3N7Zg9SWj9QuOzMFRJdHCxoo21KZcSGpeTISajAI9qppO7e9iy6kQ0hSXqKoFT1xauP8ems/HM7tOOPt72LDscyVsbL3AmOpNh/k58sOUSLtampOcVE5dZQC9PO7p72FZqw9rUiN5edmw8G8ezI9s3+rNw35UUStQy03q6sf50HBcTsunctmqmL22k5hbx+c6rjApw4a4g9wa1MXegN3+ejGHmkmMADOng1KB2bmRpYljlBqL859qQtXJd6OFhi5OVCTsuar9Xo7l3j1f3m1UlmkiS9JgkScGSJAWnpKRUeYGpqSlpaWkiEGmpvJ62qentk4hB0I/NZ+Pp++EuCoobv8sb4EJ8Nn4uVpgaGeBibUpidmGj/t3HZuTjYV/1WNcwfyeKSjUVo82mUliiZseFJO7t244PpnZhSnc3/n5qIM+MaM+GM3HMXx2Co6UJVqaG9PG2542JAax8tG+1QfmuXh5cT8njdHRmo/u182ISDhbGvDYhAEOVxMaQhk+RLzlwnaJSNa9O6NjgmwknKxN2Pj+ENyYG8PvcPgz2a3zQbolUKolRAS7sv5JCjpZFa5p7pB0LeNzwtTtQ5bdDluUlwBKAoKCgKv9C3d3diY2NpbqA3tpoNDLZhaVYmxmiasAveKlaQ3ZhKaUaGUdLY1SShEYjk1lQQlGJGlNjA+zMjTE1NcXdvWF3vYKgrWdWnQEgOj0f/zZWjW7vWlIuvb3sAHC1MSW/WE1OUSnWpvVf39RoZGIzChgdUHVatp+PAyaGKvZdSWGYf+1JOGpTWKLm/l9O8OLoDvStZo30aFlil1E39eHZkX4YG6iwNTdiRi8PrTZcTejqyhsbQ9l2PoFennYN7nNxqYZ9l5MZ36UNjpYmDPN3YsmB6yRmFfL1PT3q1db1lFx+PRzJnT3c8HWyrPsFtXCwNKn3GebW6O4gd9YExzBv+Sn+eLhvpeIj1WnuoH0S8JMkyRuIA2YBs+vbiJGREd7e3rrum14sPxbFm3+H8sN9vRgXWPMUjVojV0nD99fJGF7bcB4DlURRqYaOZR+SidmF5BepGeznyO7LCczq7cFH0yrf9RaWqDGp4WyjIDRESs5/52BTc4vwp3FBW6ORScourDj641KWVCMpq7BBQTslt4jiUg3u9lWnx02NDOjv68D+q40bCESm5XEiIp2Hfwvmz3n9eOPvUPp42/PMCD8sTQzZei4Bc2MD+t0U0I0MVPXOwGVpYkg/Hwf2XknmjTsavp/3REQ6OUWljO6kfP58MqMbn+64worj0czo5a711PTey8m8vekCJkYqFo7vWPcLBAB6tLPjrUmdeGvjBY5dT2NA+9qPnTVr0JZluVSSpKeBf1GOfP0iy/KF5uxDS3P4mlIb9lJCdo1BOzmnkOnfH2FmkAdPj/Ajr6iUz3de5ZfDEQxq78hnd3Xjjb9D2XUpiV6ednjY2/PimA50bGPN/22/zOJ94RwOT6VXOzvS8oq5lJBDam4RKgnaWJvSw9OOzPxiXKxMeXiwN8YGKrwdLVp8SkehZdl9Kani78k5jdswBpCaV0SpRsa1LFi3sVb+m5hdWLERqz4iUpWd4x521Wc9G9bBiXc2X+TltWeZ3dezyjqyNtLLEoPkFpXy8tpzRKbmcTYmk50Xk3igvxfrTscyp5+nztbNh/s78e7mi0Sn5dPOoWFHv4Kj0lFJMKDs2JGdhTFvTerEgWspvPF3KH8/NRD7Oo5CrToRzavrz+PnbMmSOUG3VU50Xbg7yINP/73CmlOxLStoA8iyvBXY2tzv21glag35xWpszBp+7OBmao3M0bI1tMuJNW+weXntOWLSC1hy4Dr9fR15dtUZ4rMKuLdvO96Y2AlTIwO+mNmdpOxCfG6aknppjD9OViYcv57OobBUXKxNGebvhKe9OYWlaiJS8wiNy8LMyIATEemsPxMHQI92tix7sDe25s13blFo3Y5dT8PMyICCEjXJ2Q0rO3ijhEwl8LvamJX9VwkEUWn5DG5AWug9l5MxMpDo4VH9VPIwf2fYfJG/gmO5lpzLhicH1vs90nL/y+Z1IT6bxff2xNbciJfXnuPtTRdwsTbhhdH+tbRQP8P9nXl380X2XU3m/htyctfHudgs2jtbVqpYZWJowFezejBryTFm/niUz+7uRld324rnU3KKWHk8GnNjA+wtjHn/n4sMau/Izw8ENflGvluRqZEBU7q78VdwDO9OqT01t8jAUQeNRiY1t4jHlp8iKbuQXS8MrbEcW30dj0gjq6AEc2ODGpNGHAlLZd+VFCZ1U5JLTP/+CK42pqx9vD+9PP/L3mRhYlglYMN/5yLLkxvUJjwll8sJOSRlF7Jo22Xe2nih3mtaQsu3eF8YqTnFDSoLWBNZljkekc6Ijs7suZxMco4OgnbZ8a7yXNPudmZ4OpizLTShzuISN9NoZP45G88QP6caz/t6OVrQzd2GuMxCzkRnciUxp97r8qllqTLdbM14ekT7irSYu14YSlhyLp4O5lWOmzWGl6MF3o4W7L3csKAtyzLnYjMZ2qHqOn7Pdnb88kBvnv8rhMnfHmZClzaYGBowpIMji/eGcy35v4pjpkYqPpzaRQTsRrgryJ3lx6LYfLb2TYAiaNfhkx1X+H5feMXXi7ZdZsE4/watqd1IlmW+3HkNJysT7urlzuJ94eQVlVa6IThwNYXXNpzH1caUT2Z0pWc7WzLzS5jZ26Pe5dy04etkWbF5JC2viO/2hvPgQC96tmv4Jheh5Vl1Ipq4jAIeG+JTpfhCQ8WkF5CQVUg/H3tC47MqrW83VEKWkuyk/HddkiTu7O7G13uuEZGah7ejhdZtnY3NJD6rkJfG1j7K/fupgWTkl9D7g11sPhuPf5v6jYpTc4swUEkcfHl4pQ1FpkYGBLo17AhVXYb5O7HyeDQFxep6ZwyLzyokNbeYbh7V922QnyN7XhzKj/uvs/RQBAAbzsRhZWLIqkf70amtNUnZhZgZGeBRzV4BQXtd3Gzo2MaK5Uejar1OLFrWIiw5h58OXGeYvxO/PtSb6T2VO6FBi/aw4ngUxaX1S/R+o6i0fE5EpjNviA89yoLijQUAjoSn8vBvJzE2VPHVrB6YGhnw0EBvnh/doUkC9s3mDfXF1caUx5ef4kwrqTUs1C0lp4iY9AI0Mqw/E6uzds/EKL8jQV72OFuZ6GRNOzGrEGNDFXY3jIxn9HLHzMiAyd8eqteZ7f1XU5Ak6twZLkkS9hbGdHK15lRU/X/vU3OKsbcwrnMHsC6N7OhCUamGT3dcobSexSfK/23fOPV9MytTI14a68+Fd8dy6s1RvH9nILteHEp/XwdszIzo4GIlArYOSJLEc6P8Ks1gVEcE7RqUqDW8+NdZLEwM+fSubgzzd+bTu7ry91MD6epuy+sbQunwxjZmfH+EqLLUiPURl6mMIjq3tanY9V3+IVSi1rBw3Xk87M3Z8MRAvRQxsDY14teH+qCRZaYuPsLCdeca9H0KLUv5h7SZkQH7r+juyOSF+GyMDVW0d7bE2cpUZ9PjrjamlU44eNibs/XZwZgYGvDUytO8+XcoRaW1nwkvKFZz4GoKXdxs6txQVa6Xpx0hMZn1DoJpeUU4WprU6zWNNbC9A3P6ebL0UARjvjjAlnMJWr/2SHgaliaGBNZQEvNGKpWEubEhc/p54mItNpo1hXGBrvzyYO9arxFBuxp5RaU8tzqEs7FZfDi1S8U/QkmS6O5hy+9z+/Dx9C48McyXq0k5PLvqTL3/ccdnlk/9meJuZ4aliSGXE3JYfSKau344SnR6Pq+ND2hUvt3G8m9jxb4Fw5k3xIe/gmMY+dl+joSn6q0/t5OcwhIGLtrDtvPafwBr43R0JoYqiYHtHXUSWMtdiM/C38UKIwMVTlYmpOhgI1p8ZkHF5rMbeTla8L87A7meksfyY1HsuJBUzasVMen59Hh/B6ejMxlSjwQdPdrZUlCirneBkpTcYhwtm3fzpiRJvDelM0vm9MLYUMVTK0+zMSROq9ceDU+jr7e9OCnSggyt44jdbfl/SpZljoSnciQ8FU1ZXdesghL+Co7h54PXGfbpPracT+CNiQFVcv6Ccsc5s3c7XhnXkQ+ndeFsbBZvb7pQ0ZY2ynMou1grI4mObaxYfiyKhevPk5ZXxMQurowMaHiSB12xNDHk1QkBHHplBO3szXnpr7MVx1puZ4UlatadiiUpu5AdFxJ1np3v0LVU4jILWHkiWqftHglPpZuHLZ4O5iQ1MrtYOVmWuRCfTeey0VpbW1Nyikobva4dnpKLt2P1CTrGBbbh2gfjcbM146/gmGqvAXh380VUksQ9fdoxq49HjdfdLMhLmd3afC6+XstgqTnNP9IGJXCP6dyGzc8MopenHfNXhzD9+yNVMtMdv57G0kMRRKXlcSQ8lYjUvDqPGAkty22xEU2WZX47EslPByOQZRmNrJz1BPB2tOCxIT58+u8V0sqCUXcPW36c00urDVgTu7gSOjSbH/aHo5HhgzsDtVrPis8qxMHCuGK3ZXniiAG+Dix/uG+VRCr61tbWjK9m9WD6D0d44o9TrHy0X4vrY3P690IiL645W/H1ikf6MlCHH377yqauj4SnkZFXrJOSgck5hZyLzeKlMR0wNlSRX6wmt6i00buZ47MKycwvqQja5T+HfVeSuStI+0B5o7TcIjLyS2jvXHNWLSMDFXcFufPV7mtcTszGx9GSnw5eJ7+4lMeG+HI6KoNdl5JYOL4jjw/1rdf7u9maMaOXOz/uv86P+6+z4ckBFXtPaiLLykmT5h5p38jIQMXSB4L4/WgUn++8yrubL/DB1C4YqCT2X03hwWUnkGX4cOsl1BoZF2sTJnTRT95toWFu6aBdqtaw4Uwc3+8P53pKHn297WljY0qpWq6oMPPD/nBeXX8eE0MVf83rj7OVCZ4O5lpnCpMkiVfG+WOggu/2htOprTVztDiOkphVUGnn7gh/Z7acS+CNiZ1abDDs4m7DB3cGsmDtOVadiK73sZtbyY1lHC1NDPlq1zWdBW1Zltl/NQVvRwsiUvM4GKaUZmys8jXs4R2dCSvb7JKUXdTooF3eVoeyhCedXK1pY23KnssND9rlbdYWtAEeHODFL4cieG/zRWXXdlmyomWHI5EAHycL5mpx3LE6b97RiayCEnZeTOLA1dQ6g3ZaXjFFpRq9r/famhvz7Eg/8opL+XH/dSJS83hhdAeeW32GDs5WfDu7B6tOxODpYM6MXu46O8IqNI9b7v+WWiOz7nQsF+Ky2BqaSEpOEd3cbfhwahdm9faoMgoe3tGZF/4MYVxgmwZv+JIkiZfG+HMmOpP/236ZO7q41jkySsgqrFS8flpPN8Z0dtHpGc6mMKOXO2tPxfLJv1eY0MVV6409t5qotDwcLY3Z8ORA1p2O5ctd16oc2Wt42/kkZhfy+oQAPth6qWL/Q2OdisrAztyITq7WZBeUApCcXVhnYKxLeUlLTwflCJYkSQzv6Mzms/FoNHKDdlKHpWgXtG3NjVkwriNv/h0KwKJpXejqbsvKE1GUqmUeHuSNsWHDVgFtzIz46f4gxn5xgNNanKA4U1a4o1sDMqk1hYXjOtLeyZK3N11g5pJjWJoY8v19PfFxstTpGX2hed0yQTuvbA3t9b/PczgsDWNDFcM6ODGjlzujAlxq/OCwMTNiaR279bQhSRKvTwxg4teH2BgSx4N13N0nZBXS2+u/mwRJklp8wIbyTS+BTPj6IJ/8e5mPpnXVd5f0IiotH08HCzzszSuS2sRlFlSMNhsjuOyo0VB/J77YdVUn2cVASePp62SJJEm4WCvrrkk6OJoVnZaHiaEKZ6v/1nJ7lJW6jE7Px6se56nLhSXnYm5sQFstzpHP6edJYFtrUnKKGFNWYvF/d3ap93vWpKenLVvOJdR5A3ImOgNDlUSXJjqPXV+SJHFXkAcD2zuyPTSRzm2tq03AJLQut0TQ1mhkJn1ziOupyofH/03vyl1B7s1eDKNzWxs6uVrzzuaLFKs1DOngRMc2VY9S5BWVklVQgqtt6zw24d/Gigf6e7HsSAQPDPCq9nu81UWn59O/rOiDe1ku69iMfJ0E7VNR6VibGtLeyRIXa1OdnHkG5UajfArfuWwKN0kHNwRRafm0szevFNACXJXfiYsJ2Q0O2uU3GNqoa+q6MXq0s2PViRjCU3JrzXl+OjqDTm2tW1xWsLa2ZswddGsUWBJukd3jwVEZXE/No4+3PZueHsTdvT30Vr3q7rKi7x9uvcyUbw9X+4Fbfnjep4adsa3BsyPbY2ViyP/+uVSvXfOtnSzLbDufQEJWYUWBhv+Ctu6msXt62qFSSThZmehkpF1QrCYxuxBvR6XPliaGWJoYkpStg5F2ej6eNxWr8HOxxEAl1SsByo3Ck3MbPW2vK+VlL2ubItdoZM7FZtGjhUyNC7euVh20NRoZjUbm75A4zIwMWPZgb53U8G2MOf292PLsILY+O5iiUg0rj1c9slP+QdbJtfWOUMvXEg+FpfLL4Qh9d6fZnI7O5IkVpwFoV5YFysnSBBNDlU6CtizLRKTmVcxe6Cq7WFS6khinfN0ZlKNZ4SmNS5gjyzLR6flVMmKZGhng62TBxfj6B+3colLisxq/1q4rPo4W2Job8fXuMKZ/f4TCkqrJXKLT88kvVtNJiyQlgtAYrTpov/BXCCM/38/a4Fju6OraInZBGqgkZZq8rTXD/J1YdSK6ykj0UkI2liaGFSO01uq+vu0Y7OfID/uvo75NRtunotIB8HWyoH9ZKUNJknCzMyM2I7/R7WcXllKiliuODblYm5KUXdTo89SRqUrfbszXPdjPiWPhaeQWlTa43ZScIvKL1XhWk8ayc1sbzsdl1bvv4WUzUb4tZP1VkiR6eNgSl1nAqagMQuOyqlxTnoLY/zZcKhKaV6sN2seup/F3SDwRqXmYGRvw8riWV3R9cre2JGUXERpf+R/5pYRs/NtYNWt+4qYgSRJ3B3mQmlvEych0fXenXlJyiupMf1md4MgMvBzM2f3isIqSkQDuduY6GWmnlVWJKk/Q4WxlQkGJulGBFSCyLAXtjTWXx3RyoVitYd+V5Aa3u++qcoysp2fVNeV+PvYk5xRxNan2XMo30/a4V3Nyu+EG+2xsNUE7MQdJgg4uLafPwq2pxQft6rIRZeQV89Kas7jZmvHPM4NY83h/nKyaPwtRXYb5OyNJsPvSfx+KRaVqLifkEOCq32l8XRnR0RkTQxVbdZxus6nIssxHWy/R58Nd9Hp/V73SssqyzOnojGoDlIedGREpeY0qIgOQWlaP2aFspO1ctsu7sSlHo9LysbcwrlSdLsjLHltzo0blIN92PgF3O7Nqd0wPKUvHeOBq/doPS8nFUCVVWSfXp3lDfJkZ5IGVqSHnYzOrPH8lMYd29uaYG+t/tk+4tbX4oF1en/ZG3+wJIym7kO/u7Umgm41Oduw2BXsLY3q2s2PtqdiKYhurjkeTU1TK2M63RhYiCxNDBvs5sftSss5TeTaFLecT+PHAdab1cMfR0pjXN9RdcKJcbEYBqbnF1e5UHt3JhZyiUnZerDkPtjZuHmm7WCm7vMvT3jZUTHp+xRp8OQOVRFd3W0IbsO4MkF9cyqGwVMYHtql246erjRl+zpZsC01gx4VEzpUFu/ziUl5df46QmMwqrylRa9h2PoHObjYYtaB82B725nw8oyv9fBw4V81I+3JiNv4t9HNIuLW0nH8VNUjLK2bz2fiKzR8ajczW8wkM93emeyvYqfnq+I7kFZfy6O/BFJdq+G5fOP187Bl0C+X7HebvRFxmQaM3NTU1tUbmgy2XCHSz5v9mdOXtSZ2JSM3jn7PazRKUF4+obgPhYD8n3GzNWH2ycbnCU/Mqj7QDXK0xNlA1+mYgupqgDRDY1pprSTkNWiq4mpRLiVquyNNdnfsHeHE6OpPHlp9i7q/BlKg1vLvpIqtOxPDY78FVbsrXnYolMi2fp4e3r3d/mkM3dxuup+aRVVBS8Vh+cSnXU/PEJjShWeg8aEuSdJckSRckSdJIkhR003OvSpIUJknSFUmSxmrb5jOrzjDx64MkZxdyJiaTxOxCJnSpWsijJQrysuetOzpxNSmX/225SEpOEY8M8tHbkbSmUF6VpjFro83h2PU0ErIKeXJYewxUEsP8nfCwN2PDGe0qIl1JVEak1Z1QMFBJTOjShuMR6Q0KgOXKR9r25krQtrMwZlxgG9afjq1217I2StUa4jILqg/abjaUamSuJtZv3RngatlNTG0jzPv6tuOlMR0wNzYgNbeIzm//y5/BMUzs6kpqbhFLD/138qCwRM3Xu6/R3cOWUS2gWE51upTVnb5xM9rF+GxkmRaTVEW4tTXFSDsUmAYcuPFBSZI6AbOAzsA4YLEkSXVmIfB1suC72T2JySjg3c0X+XLXVcyMDBjRQv9RV2diV1ecrEz4/WgU1qaGDPXXvkRga+Bhb46fs2WjR4NNbVNIPJYmhozoqPzuSJLE1O5uHA5P1eq88uXEHDzslTKq1enZzo7iUk2DjjmVS8stxs7cqFKpxLuC3MkuLOXQtYaVRU3IKkStkWsYaSuBZvr3R+rd76tJOZgYqqoc97qRJEk8PcKPnS8MBZQ9Kt/c04Nv7+nBmE5tWHUimoJiNbIs88m/V4jPKmTBWP8We1PbtSwwf7j1Eh9suYhGI3O+LIAHiqAtNAOdB21Zli/JsnylmqemAKtlWS6SZTkCCAP61NWeubEhE7u68sRQX7acT+DgtVTeuCOg0oaals7E0ICf7w9isJ8jL47xb1FrdboyvosrJyLTdZa9S9eKSzVsC01gTCeXShmrJnZtiyzXPUuQmV/MkfA0/F1qngIt36BWnoO6IdLyinC4qbRjby97jA1VHLue1qA2y3ODVxdcPezNCHSzplit4avdV+vV7tWyBCjaFLhxszXj/v6evDelM5O6tUWSJB4a6EVmfgkbQ+JYExzL0kMR3NevnU6rpemanYUxjpbGXIjP5qeDESw9FMH5uCycrEz0XihEuD0051ZHN+DYDV/Hlj2mlWdH+lWsGY0pq9DVmnTzsGX5w3313Y0mM7GLK1/vvsamkHgeGeyj7+5UceBqCtmFpUy6qVpWBxdLXKxNOHA1lZm921X72vziUoZ/uo+M/BI61bLr38XaFDdbM05FZTQ4bWRqbjEONxVhMTUyoGc7W45FNCxoR6UpQbtdNbuxJUnin2cG8+HWS/xyKILknEKcrbQLPteScuhXlspVG+9NCaz0dR9vewJcrVl2OBJHK2N8nCx4/6ZrWiIzY+Wmr5uHLR9svYSpkYrBfrfW7JnQcjVoyCdJ0i5JkkKr+TOltpdV81i1240lSXpMkqRgSZKCU1KU4yIGKomxndswtnP1O1UF/ergYklfb3s+3XGlUdPDTWXzuXjszI0Y5Fd5FCdJEoP9nDgUllrtSQWALecSyMgv4Z4+HnUWghne0YltoQkNnspW6jFXPb7Yz8eBC/HZlTZAaSs6PR9jAxVtahkJ3h3kQalGZt0pZX0/pY4jZknZhSRkFTYqq1/5aPtKUg6Hw9IY10r+bX97T0/evKMTf83rx7Sebgzr4MzbomqW0EwaFLRlWR4ly3JgNX821vKyWODG4rruQHwN7S+RZTlIluUgJydxB9saSJLEd/f2xNhAVWlzkbaWHY4gOq3xGcWqI8syh66lMryjc7VLExO7uJJVUMLIz/ZXbAQrp9HI/HE8Gh8nCz6c2qXOUqSvjg/Ay9GCdzdfqPcROI1GJjajoNpMef19HJBlOBlR/yQ2Men5uNuZ1TqN3d7Zkj5e9vx5Mpr1p2Pp++EuLsRXPdpUrvymZEB77Ufa1Zne050e7WwBGB/YOjaXdvOw5eFB3pgYGvD53d35YU6vSmV2BaEpNefi6iZgliRJJpIkeQN+wIlmfH+hiTlamjAywIXdl5MoVWufZCQjr5h3N19k7JcH6r64AaLT80nLKybIs/qjScM7OvPrQ73JKihh9+XKa9u/HY3kbEwm84Zot+PfwsSQRwb5cC05t9rMWbWJzyqguFRTbVWsbh62mBiqONqAde3qcoNXZ2ZvDyLT8nnhr7NoZPi7ll31h8JScbAwJqCRaTsNVBKrH+vHP88Moou72MglCHVpiiNfUyVJigX6A1skSfoXQJblC8BfwEVgO/CULMsNPxsjtEhjOrmQmV/CiXqkNS2v6VxQoia7sP7Tv3Upr85UPqKrztAOTrjamPLy2nO8vTEUUEqofr7zKkM7OHF3kEeNr73ZHd1cMTVS8fuRyHr1MyJVOefuXU3QVta17Vh6KILfjkTWaxRf0xntm93RzZXJ3dqikpTKZZvOxrN4Xxg/H7xe5doj4an093XQSSpeE0MDsfNaELTUFLvHN8iy7C7Lsoksyy6yLI+94bkPZFn2lWXZX5blbbp+b0H/hnRwwszIgM1nq135qNaNpSdn/nhMJ+Uib3QmOhMLY4NaM+dJksTwsqNgvx2NIjYjn+XHosgpLGX+KL96rbVamxrx4ABv1p+JY289zq5H1hK0gYoCJW9vusD609qdLc/KLyGroESroG1iaMDX9/Tg/DtjefOOTiTnFPF/26/wvy2XKp0KSM4pJCm7iJ5NWMNaEITq3XpnjwS9sjBRjuhtPptAfrF2RS7K82rPH+nHpYTsWqdlG+J8XBaBbjZ1Hk16ZWxHXikrPDPo470s2naZ3l52DQpOz4/2w93OjGWHI7V+zfXUPMyNDXCuIY/+QwO9+GJmN4I87Xhn8wXCknPqbLO24141sTAxZGznNoS+M5ZlD/YGlEIpG0Pi2HAmlgtlGw1FBjBBaH4iaAs6N7O3B7lFpVpnGisfxc0b6oOPo4VOK4bJskxYUq5W+eltzI14fOh/x9Xu7duOX8qCVn2ZGBowPrANR8NTydFyyj8iNQ8vB4saR/VWpkZM7eHOFzO7Y2JowCO/BdeZJa08aGsz0r6ZhYkhA9s7Ymqk4oudV5m/OoSX1pzjzxMxgAjagqAPImgLOhfkaUc3D1u+3xdOiRYb0pKzi7AyMcTc2JAgLzuCozKq1CBvqOScInKKSrUu8yhJEmM7K3kAXp0QgFUjkviMCnChRC1z4Kp2x78iU/Pwdqp+avxGHvbmfDmzO5Fp+dWuN1dqs6xQTUMrZhkbqujhYce15FyGdnDCydKE7RcSsTY1bFUJjgThViGCtqBzkiTx3Eg/YjMKeOGvs3WWq0zOKcSprARlby97MvNLCE+pfy7s6oQ3oDbzlzN7cPrN0TWmK9VWL087nK1MtNo4VqLWEJNRgE8N69k3G+TnyLjObfhubzjxmTXX8b6ekoeLtQkWjfheHh7kzey+7fhxTi++nd0DgI6N3DUuCELDiKAtNInhHZ15ZVxHNp+NZ+6vJ8ktqnl9Ozm7qGIdt3dZxaj67D6vTVhK/YO2mbFBneextWFooOKZEe05EZnOnsu1b0iLSc9HrZHxctAuaAO8PjEAjSyzaNvlGq+JTMurcWObtkZ1cuHDqV0wNTIgyMuezU8P4otZ3RvVpiAIDSOCttBknhjmy//N6MrR62nc+9OxGkfcyTlFFakzPR3McbIyITgyQyd9CEvOxcrEsMbNXU1tZu92+DhZ8PamC7VuzKs47qXF9Hg5D3tzHhnszaaz8ZWqTt3crrej9jcs2ujiboObbdUEMIIgND0RtIUmdXeQB5/e1ZWzsVn8eyGxyvNJ2YUkZhXiaqMEbUmS6O1lx4kGZP6qTlhyLj7OlnpLj2lsqOKjqV2IzSjg54M1Z4qrCNr1GGkDzBvqi625EdMWH6HX+ztZfiyq4rms/BLS84rxdhTZugThViGCttDkpnRzo529OcsOR1TamBabkc/81WeQJJjV579iHUGe9sRlFtS6VqutsORc2jvpdqRZX319HBjdyYWfD16vMXd4RGoetuZG2NVzWt7a1IhVj/bjoYFe2FsY88XOq5yOziC3qJSwFOVImK5H2oIg6I8I2kKTU6kkHhviw+noTOb+ehJQClLc+d0RzkRn8v6UwErrrn28lXXtxh79yi4sITmnqF7r2U3l+VEdyCkq5ctd1Ze/DI3PxreBNxcBrta8OiGA96YEkp5XXDHqfvyP01iaGNJNpAcVhFuGCNpCs7ivnyfPjGjPwWupJGYV8u7mC+QUlvD3UwO5u3flFKEd21hhYWzQ6HXtsAbsHG8qndpac2/fdvx2JLJKIY6I1DzOxmQ2uuRsPx973p3cmf+b3pVZvT1wsDBm6QNBOIs6z4Jwy2jOetrCbW50Jxe+2RPGobBUdl5MYlZvDwKqKe1oaKCip6ddo0faLSloAywY05HtoYm8viGUdU8MID2vmOj0fPZdSUYlwZ09tC4vXy1JknhggFfZV9rnShcEofUQQVtoNp1crTE3NuCbPdcoKtUwIqDmkWVvL3u+2HWVtNwiHKqpL62N8ORcjA1UeFRT6lIfbMyNeGNiJ577M4SnV54mND6LuIwCbMyMGNLBCRcxIhYEoQ5ielxoNoYGKnq0syUqLR9jAxV9vasvlQkwPrANsgy/1bNS1o3CknPxdrTAsJoa2vpyZw83nh/Vge0XEikoVmNooCIjv4Q5/Tz13TVBEFoBMdIWmtXTw/0wMzKgRzs7TI0MarzOz8WK8YFtWHYkkieGtcfMuOZraxKekkvnti1vE9b8UX7MG+qDoUrikx1X2H8lhWH+zvruliAIrYAI2kKz6u/rUFFisi739vVkW2gih8JSGV3PTVqFJWqi0/OZ3K1tQ7rZ5MpvWF4dH8Cr4wP03BtBEFqLljNvKAg36etjj5WpIbsuJtX7tZFpeWhk8G0hm9AEQRB0QQRtocUyMlAxzN+Zfy8mciWx7trRN2ppO8cFQRB0QedBW5KkTyRJuixJ0jlJkjZIkmR7w3OvSpIUJknSFUmSxur6vYVbzxNDfTEyUDH7p2O15u6+2bWkXCQJfEQ2MEEQbiFNMdLeCQTKstwVuAq8CiBJUidgFtAZGAcsliSp/ruLhNtKp7bWfH9vT9Lyill7Klbr14XGZeHrZNmgDWyCIAgtlc6DtizLO2RZLh8SHQPcy/4+BVgty3KRLMsRQBjQR9fvL9x6enna0d3DluVHo+q+GJBlmZCYTLp72DZtxwRBEJpZU69pzwW2lf3dDYi54bnYsscEoVaSJDEusA3XknNJySmq8/rYjALS8opF0BYE4ZbToKAtSdIuSZJCq/kz5YZrXgdKgRXlD1XTlFxD+49JkhQsSVJwSkpKQ7oo3GJ6eymJWIK1SG16JiYTQARtQRBuOQ06py3L8qjanpck6QHgDmCkLMvlgTmWygmR3YH4GtpfAiwBCAoKqjawC7eXLm42mBqpOBGZzvgurrVeu+18AnbmRvi3sWqm3gmCIDSPptg9Pg54BZgsy3L+DU9tAmZJkmQiSZI34Aec0PX7C7cmY0MVvb3s+fNkDBtD4nhq5Wn+PhNX5br4zAJ2XExiZu92GLWg9KWCIAi60BQZ0b4FTICdkiQBHJNl+XFZli9IkvQXcBFl2vwpWZbVTfD+wi3q4+ldeWbVGeavDgHgaHhaRWWs5JxCPv33Cg6WJqg1Mvf2bafHngqCIDQNnQdtWZbb1/LcB8AHun5P4fbQ1taMn+4PYtI3h4jLLEBC2SkuSRLf7gnjr+BYDFQSfs6WeNib67u7giAIOifmD4VWxd7CmF0vDOWtOzqRlldMeEouJyPTWX1SOZig1sgMbO+o514KgiA0DVEwRGh1zIwN6Fa2M3zU5wcAcLM1Y2B7B/4KjmWAlgVJBEEQWhsRtIVWqZOrdcXf/3dnIOMD26CWZaxMjRjSwUmPPRMEQWg6ImgLrZKZsQHrnxyAj6MFtubGFY+/eUcnPfZKEAShaYmgLbRaPdvZ6bsLgiAIzUpsRBMEQRCEVkIEbUEQBEFoJaT/soy2TJIk5QBXdNysDZCl4zabuu3W1m5Ttt3a2m3Ktltbu03Ztuhz07fblG23tnabsm1/WZarz8Msy3KL/gMEN0GbS5qwv03SdmtrtzX2WfwsxM/iVumz+Fm0+p9FjXHvdp0e39wK225t7TZl262t3aZsu7W125Rtiz43fbtN2XZra7ep265Wa5geD5ZlOUjf/RAEQRCE5lBb3GsNI+0l+u6AIAiCIDSjGuNeix9pC4IgCIKgaA0jbUEQBEEQEEFbEARBEFoNEbQFQRAEoZUQQVsQBEEQWgkRtAVBEAShlRBBWxAEQRBaCRG0BUEQBKGVEEFbEARBEFoJEbQFQRAEoZUQQVsQBEEQWgkRtAVBEAShlTDUdwfq4ujoKHt5eem7G4IgCILQLE6dOpUqy7JTdc+1+KDt5eVFcHCwvrshCIIgCM1CkqSomp4T0+OCIAiC0EqIoC0IQv3JMuz/P/jYGw59oe/eCMJtQwRtQagvdYm+e6B/V7bB3g/AxAp2vQOh6/XdI0G4LbT4NW1BaDHUJXDwczjwCfiPg8AZEDAZVNXc+xblQmEmWLmCyqDZu9qksmJh28vg1BEe2we/3gFbXgSvQWDpDEU5cH4tZEaDkz/4jQFJAlNb5b/CLaekpITY2FgKCwv13ZVWxdTUFHd3d4yMjLR+jQjagqCNolxYfifEngTvoRC+Dy5thj6PwbhFUFoEoesg6gikXoH4EJDV4NAehr8GnaZWH9zLXdwEV7ZCxzsg4I7a+6IuhZhjUJgFLoFgaApnV0FuEvhPAO/BynUxJ+DkUjCxBDtv6PdE/W8gUq8pATonEXrcB74jYOXdUJgNd/8ORmZw52L4YTD88zxM/QF+vxPigkFSgaz5r622PWDSV+DarX59EFq82NhYrKys8PLyQhI3ZlqRZZm0tDRiY2Px9vbW+nWSLMtN2K3GCwoKksXucUHv1j2iBOVpP0GXGUrg3PkWHPsOzOyhIAOQwbIN2HuXjTpdIPgXSL4Ijh2UkbqmFLrdA36jlRFpfhoUZCqB0dAU1MVw/8b/Au/NMmNgzQMQd6rqc4ZmUFoAnaYoQfrwV2BirYxuCzNh5Nsw+AXtv2dZhmUTIPkCOAUoNwqgjJjv/1sJwuUOfQm73gZTG+UGZ8YvSj+u7YSUS6BRw4klSrC/by14DtC+H0KLd+nSJTp27CgCdj3Jsszly5cJCAio9LgkSadkWQ6q7jUiaAtCXa7tghXTYdhrMOyV/x6XZbiwHq5sBwdfaNdPGYXf+MGlUSvB/sRPYO0KJQVwbUfV9/AaDNOXwm93QHaCErjdeynP5abAmeWQfh0ub1GC//iPlRuBpPPKKN9zIDj6wZFv4dDnUJIPnafCpK+Vdee1Dymj+Yd3gHu1nwVl/dVAzHHlRiPxPJxaBuM/gb6PKT+HtDDoMFa5Mbn5dccWK9/r6HfBe0jVtnMS4deJSlB/4ghYOGj//0Bo0S5dulQl8Ajaqe5nJ4J2U5FlCFmpfHDHnAC3XqAyVP7rPUT5cDQ00XcvhcZIOAer7gEjU3jiKBgaN77NrDhIPAcGxmBmC6XFSsCXJOW5ZeOVQDzlW0gKVdbRi7KVkbtLZyWIOravuf2SAshLARuP/24gCjKVKWxNKYx6WxnlyzJYuUB6hDJtnp0AEfuV9wQwMldmDO5ernz/upB4Hn4aodxwjFuktC9GZ61eawrazz33HNOmTWPIkGpuLKuxb98+Pv30U/75558Gv+dLL73EhAkTGDFiRJXn6hu0xZp2Q6lL4e/H4fwasPdR1hLjTytBO3w37F8EFs4w/SfwGabv3goNEXEAVs1WRqrTl+omYAPYuCl/anpu1kpYOgZWzFAe8x2pBDinDtq1b2QGtu0qP2ZmC/eshD/vgw3zqn+doRm4dIIp3ym/s1Zta1+Hb4g2XWD2n/DXg8qsgluQsibu5K/b9xGEaqSnp3Ps2DG+/PLLZntPtVrNM888w6OPPlpt0K6vOoO2JEm/AHcAybIsB5Y9Zg/8CXgBkcDdsixnlD33KvAwoAaelWX537LHewG/AmbAVmC+3NKH+TWRZdj6khKwR7wJg1+sPFooyITIQ7DnfWVTTp/HwH88ePQFY3N99VrQlroE/n4Szv+l3JA9uAWs2zbf+7cJhOfOQcplZfe5vY9uRqNtusCTxyH1qhLEVUaQnwrWbkr7JtbNs9PddwS8eEmZSt/1LiwZDnd8Ad1mNv17C7ekyMhIxo0bR9++fTlz5gwdOnTg999/x9y88uft2rVrGTduXMXXXl5ezJ49m71791JSUsKSJUt49dVXCQsLY8GCBTz++OMAZGdnM3XqVK5cucKQIUNYvHgxKpWKJ554gpMnT1JQUMCMGTN49913K9qdO3cuO3bs4Omnn2bWrFmkpaWRmJhImzZtGvW9ajPS/hX4Fvj9hscWArtlWV4kSdLCsq9fkSSpEzAL6Ay0BXZJktRBlmU18D3wGHAMJWiPA7Y1qvegbIApLYShrzTfNNuhz5W1voHPwZCXqj5vZqvsAPYZBlsXQPBSOPGjMh0aMAlGvwc27s3TV6H+dr6lBOwhC2DAs2Bq3fx9sHAEi0G6b9fIFFy7/ve1tavu30MbxhbQ835oPxrWzoUNj8G1f8FvLAROBwMxCdhqbVuoLIPoUpsuMH5RrZdcuXKFpUuXMnDgQObOncvixYt56aXKn8+HDx9mxowZlR7z8PDg6NGjPP/88zz44IMcPnyYwsJCOnfuXBG0T5w4wcWLF/H09GTcuHGsX7+eGTNm8MEHH2Bvb49arWbkyJGcO3eOrl2Vf1+mpqYcOnSo4n169uzJ4cOHmT59eqN+FHXOfcmyfABIv+nhKcBvZX//DbjzhsdXy7JcJMtyBBAG9JEkyRWwlmX5aNno+vcbXtNwIauUHav7PoKdbyrrdADFeXD2T2Xzz75FcOBTCF4G+Td/Gw1w9k/Y/R50uUvZjVsbE0uY+j28Egmz10DQXCUpxR8zlD4KLU9WHJz8WQkoI97QT8C+nVi7wgObYdALyia7DY/BkqHK34ty9d07oRXx8PBg4MCBANx3332VAma5hIQEnJwq1+GYPHkyAF26dKFv375YWVnh5OSEqakpmZmZAPTp0wcfHx8MDAy45557Ktr+66+/6NmzJz169ODChQtcvHixot2ZMyvPHDk7OxMfH9/o77Oht7MusiwnAMiynCBJknPZ424oI+lysWWPlZT9/ebHGy7yEGx+Vtl1a+sJR75RNoVZtYX0cGX37M22L1SCbd/HlSnI+kq5Apvng+cgZd1P2/U+EyvoMKbsz1hYPk1JATn63fr3QWhaB/5POVs8uJoZFKFpGBgqm+NGvgWXNsH212D1bGVD5yO7xUa11qaOEXFTufm4WXXHz8zMzKokgDExUTYLq1Sqir+Xf11aWlpj2xEREXz66aecPHkSOzs7HnzwwUptW1hYVHpNYWEhZmZmDfjOKtN1GtPq/nXJtTxefSOS9JgkScGSJAWnpKRUvSD1Gqy+F+y8YOZyuPM7eGSPcvbT2lUZJT20DV68Cm+mwZupMO8gdJulrKP9MBD+fgpK6sjeU5yvrF+Dspt33cPKJp8ZSxu+K9x3BAROU5JeFGQ2rA2haSSchVO/KXsQ7Dz13ZvbjyQpZ7ufCVZmOeJOKcfPBN0rzofwvXDs+1tmRiM6OpqjR48CsGrVKgYNqrq8FBAQQFhYWL3bPnHiBBEREWg0Gv78808GDRpEdnY2FhYW2NjYkJSUxLZtta/2Xr16lcDABgwWb9LQoJ1UNuVN2X+Tyx6PBTxuuM4diC973L2ax6sly/ISWZaDZFkOunkqA1mGTc8o2ZbuXQNmdmUt9oKZfyiPjf9YCeBWLspdvIGRso436St44SIMnA8hfyjTcGG7q3YgL1VZZ/vQFb4IhL0fwW+TlHWaKd+BVeM2EjDwOSjOgYOfNa6d1k5dopzvbQlKCmDD48pa8tBX6r5eaDpGZtDvSWVjXPAv+u7NraMoB86sUNLOLmqnZPjbvlA5TdBS/h02QkBAAL/99htdu3YlPT2dJ554oso1EydOZN++ffVuu3///ixcuJDAwEC8vb2ZOnUq3bp1o0ePHnTu3Jm5c+dWTM1Xp6SkhLCwMIKCasmRoCWtzmlLkuQF/HPD7vFPgLQbNqLZy7L8siRJnYGVQB+UjWi7AT9ZltWSJJ0EngGOo2xE+0aW5a11vXeVc9rn1sD6R5TdpkFz6/fd3ujKdvj3NSVhRdBDSg7pxHNKXuXza5Vf8N4PQ9RhJVg7doCgh6Hf4w1/zxttegbO/AFz/wWPPrppsyWKPq6k2JTVyk7ozGjlZ56fpmT3MrOFUe9A99n67eeWl+DkT3DvOvAbpd++CIqtC+DUr/DCZZGIpaFkWUm9u+PN/zLaObRX0uV6DVLO5O96p2rioHrS9zntyMhI7rjjDkJDQ+u8dtCgQfzzzz/Y2to2fcfKbNiwgdOnT/P+++9XeU7n57QlSVoFDAMcJUmKBd4GFgF/SZL0MBAN3AUgy/IFSZL+Ai4CpcBTZTvHAZ7gvyNf22jIzvHr+5X8xu69ocf99X55Jf7jlAQoO9+C07/9d0dvaAo+w5X1NZdOSkar/HSwdKq9vfoa84GSv3rD4/D4oVvrKJi6RLnxubBB2RFsYq2cXy9IV44X2Xkru0E7jIPYYOV4lZE5dL5TP/29tlMJ2P2eEgG7JQmaq6Q+DflDmR0TtJObotwox51SckdkRoN52QySz/D/EvkAtB+l7NXZ96ESxL1qHi3eKj777DOio6ObNWiXlpby4osv6qSt1pER7cTxsl3g/wc27WDuNt0emcpPh/gzStWimpJeNIWIA8q0e9/HlSn9W0H8Gdj4jJJe09xRKVLR7wklKKtLqiYoKSlUUlumh8NTJ3V/c1SX4nxY3Fe5WXv8kMhg19L8eocSVJ49o5zGEGqmUSupZPd8oOSgt/cBBz/oNFk5ampqU/3rivNgcT/l3P59ayE1TMlV3+lOrRMK6Xuk3ZrdehnRchLgs46Ql6xUGZrwme5SKpYzt4f2I3Xbpja8h0CfeXD8B2XU6Tu8+fugS1FH4ffJSgGNmX8oU3A37rqs7gPAyFTZJ/DjYKVoxl3Lmq+/oMywZEbDA/+IgN0SjXwLlo6G/R/DmKpTiwJK0D39OxxdDFnR4D9RWXLSNoOesQVMWQyrZsHXNxSB2bdIyVbXrl+TdFtomFYQtBOh7XRlzbOm2sWt2ah34Po+ZZr80T3NO9LXpcIs+GuOkj7z4Z3KjZC2nDvCkJdh7/+U9W47L6UAR9eZTZvesrQIjn6rHBusqaqWoF8efaDXg3Dka6X0aLdZyhSvOAamyIhSbmpyk6Bdfxj7gTKqru/Px3swPH5QySNh3VaZGdv6EvwyTtkUOOKNOpfwZFkWVb7qqSEz3S1/erxndzn4dIi+u9G0EkOVIhHmDjDuI3Dv0/o23ux+T9kN/9i+yiUbtaUugb0fQkKIMvLNiFSKW3gPUYJ3257KHgNdOr0cNj0N961T1vaElkldoszChK5Xpm273KUEkrY9bu/gXVIAK2cqa9ez/9L9enRRrpK86uTPylT70IXKvpNqZqQiIiKwsrLCwcFBBG4tldfTzsnJqVJPW1T5ag1iTsKaByE7FowtYc7f4NFb373STlYcfNNTmQmZ/pNu2sxLVab8gn+BrBjlsV4PwcTPdTPbotHAd32U6fl5B2/vD//WorQIDn2hZEAE6P+0kkmttd3g6kJ+OvwyVskjf8eXygmYphJxQEkqlX4dnDvDxE+VUf0N/2ZKSkqIjY2tkrhEqJ2pqSnu7u4YGRlVelwE7daiOB+ijsC2BUrilccPtfzpco1GSTpz+R94Olj3SUk0aqWG86lflU02Xe6GoS8rtaMb4+h3ypG/u35V6k4LrUf6dTj8lfI7oTJUstcNfeXWWzorl3xJyfioUSvHUJ38leRSMcfhnlXNM0uk0cDV7crpndxE5RSIlauyH8W5Y9O//21GBO3WJjUMfhyiBOw7vlCOYrRUWxcox3KGvwFDFzTd+8iycjzv2PfKB/WY95WRd0MKS6RHwHd9lc2Hs1aKUXZrJMvKDe6pZUq1vS53w9Qfb73AnZusfBYU5ym/p4VZynpzaZGySazbrObtT3G+Ukwn4oDyR2UIM35RklkJOiOCdmsUvgc2P6es4T0dDJbOdb2i+cWHKFnl+jwG4/+veYJfThKsfxQi9oOxlXKjMODZ+r33Xw/AtR3wzKnmLbkp6J4sKwWB9v5PKZE78i1990h3Lm6ELS8qiZ4e2aWsK5/4STlREzhD/8tnSReUHPEZUdD/KegxRxn923kqFQ6FBhNBu7VKuQrfD1COXNz1q5Jis6XQqJXNc2lhyhnams6ANgVZVoJu8C/KlF3Qw8pNgzaj7rDd8Mc0GPYqDFvY9H0Vmp4sK8WDTv8O05dClxl1v6YlK8qBba9AyApw7Q6TvwbXbvruVfWKcpUZsOCllR83tVH2uEz6qnlqtN9iWvc57duZUwfll/6f5+HP++DBrS1n+u/kUuWueuqPzRuwQRlVdxir1GLe/S4c/hI0JTDpa+W5gkyIOaEcG3Pw/e91eanKhhoHPyX/u3BrkCQlf0NqGGx8Cuy9lQphrVFGlJLrIDNaWasftlCpndBSmVjCHZ8ru8qTLoDvSOVGOvYEnFmubKrVU9WvW5UI2i1dj3uV/258Eg59DkNaQMnIggzY+4EyBdZ1Zp2XNxmVSilvqjKEg58qVboMTCAjAvJSQDJQSj4OeFY57//nfcoa4dxtuk/QI+iXobFS8e+n4bBqtnL00NpV372qn/JKgvnpyg26Z39990h73kOUP/BfUpdtC+H49+DWE7rerb++3WJayLBNqFX32coO5z3vw/5P/isXqi/7FikbYsb8r2Vs4hrxhnIUDJRg3LYn3LtWSTKx8y1YPlXZeJZ8USmr2lpHYULtLBzhntVQnAs/j4RL/+i7R9q7ugN+m6wU95j8desK2DUZ8z54DoRNzyozX4JOiDXt1kJdqiQCObtKKZ4w6t3mD5iyrOzUXf8Y9H5EOa/Zkmk0ygalCxvAKUAZlTf2qJjQ8sUGwz/PKdX5BjwDPR8AU1vlWGLoOuXfjnsLuXGTZeXo4bHFSh8nfHJrjUpzk5WMbdnxyrn6oS8rpVeFWomNaLcKjUZJLRi8FHo/qmy+aq417tJipZzoudXKppgHt4oCDkLLVVoE21+tukHK0FRZNpm1Qv+5/jVqJVHMgU+UGgRjP2zYEcaWLj9dyWh3fq2ypDbhE3HzXAcRtG8lsgw731SSLfiNhU5TQF0EkkpJf6rrVJ+gnM1cPRuu74XhrytHa8SOUKE1iDwMWbFKQhC3IOXY1B/TIe0azN2uv6WStHDl6GLcKeg6C6b+0DKWmprSmT+UqXJZrXx2Tf2hfjUKbiMiaN9qZBmO/6jkBS69KW1g4HSY9rNuR+C73lHSR075Tqm0JgitWX66krAESTn/bOXSvO9/fq2Sg0FlABM+VY6o3eoBu1x2glIfff//KaWQH9oKJlb67lWLI4L2raq0SBlFGJkro+3gZcrxp/H/B33n6eY9Uq/B4v5KkYap3+umTUHQt7jTSh13Gw8Y+KxyAsG5EzgH/HfEKj9dWWfW1Q1w3Cml1nX4bvDoB9N/BlsP3bTd2lzdoZQCtXGHtt2VgYaWtbtvByJo3y5kWZn6izkB80Man4xFlpVEJLHBSvawlpiVTRAa6vp+ZYo6N+m/x2zagf84iD4GieeUkwjTf6583r8h4s8ou8ONzJQb6gHzb8316/o49asy0EgIgaC5SspmARBB+/aSchUW94Pu98Dkbxs37XZps3K2edwi6PeE7vooCC1FUW5ZFTlJCdInlypJQpz8wWeoElSMzGDuvw0fFSdfgmUTlEQjc7e3/CJAzW3nW0oBGL8xSv30fk/VWbv7VieC9u1m59vKNPnIt5RNYw1RnK+cbTaxgnkHxKhAuD0lnlcCrp0nPLAZzOz+e660WMnEZ2xR8+uTLigjbJWhsn7b2BH7rUijVjLZXd8POfHQYbxSvex2WeevhkhjersZ+bZyLnL3e8qu8gHz678ud+gLyIpWjnaJgC3crtp0UapYrboHvu4Bdl5KRTFTayX3fcJZcO+trH/nJChLSkNfVs6HX90Ofz8JhibwwD8iYNdEZaDsJAc49KWywfbKVug4Ua/daqnESPtWpS5RUiJe3Kis0416W/tCCunX4bt+0Gmysp4nCLe7mJNw/AclSKddUx6TVEriloSzShB37qRMhV/fq9Sbzo4DR39l1CgCtnbUJUqRJMkAnjjScmotNDMxPX67kmW4sB6OfqfsXO14hzIKqK1iUGmRsqsz5oRSErS15W8WhKakLlWCcU4iqIvBe/BNz5coo8XEc+A3Grrd07ILfrRE59cqA467f1fyUNyGRNC+3ZUWK8VGji6GoizwHqqMCjpNUcp+SpLyYXToCzi7Uhlp3/GFsqNTEAShOWnU8FV3JWvanPX67o1eiDXt252hsVLir98TcGIJnP1TGUkf/14J3v2eVGoRx54Ar8FKbuZOk/Xda0EQbkcqAyX/+qHPlRkNqzb67lGLcnsuGNyuTG1gyAJ4JhgWhCkZzgqzlEIk6ddh2k/w4D8iYAuCoF/dZoGsgRM/6bsnLY4Yad+uTCyVlKSd7lTqTzv4iRrTgiC0DI5+ShbGI98on1P23vruUYshRtq3OxNL5ViLCNiCILQko99T/nvoc/32o4URQVsQBEFoeazbQs85ELIKsuL03ZsWQwRtQRAEoWUa8Kyytn30W333pMUQQVsQBEFomew8lZ3kp36FvFR996ZFaFTQliRpviRJoZIkXZAk6bmyx7pLknRMkqQQSZKCJUnqc8P1r0qSFCZJ0hVJksY2su+CIAjCrW7Q81BSoGSkExoetCVJCgQeBfoA3YA7JEnyA/4PeFeW5e7AW2VfI0lSJ2AW0BkYByyWJMmgUb0XBEEQbm1O/hAwCY4vgcJsffdG7xoz0g4AjsmynC/LcimwH5gKyIB12TU2QHzZ36cAq2VZLpJlOQIIQwn4giAIglCzwS8o2RyDl+q7J3rXmKAdCgyRJMlBkiRzYALgATwHfCJJUgzwKfBq2fVuQMwNr48te0wQBEEQata2B/iOVOoolBbV//X56fDXA/DTiFY/Wm9w0JZl+RLwMbAT2A6cBUqBJ4DnZVn2AJ4Hym+NqiuOWm3ic0mSHitbDw9OSUlpaBcFQRCEW0XfeZCXAtf31e91uSmwbLxS7jM+BJYMg22vQF5aE3Sy6TVqI5osy0tlWe4py/IQIB24BjwAlGd5X8N/U+CxKCPxcu78N3V+c7tLZFkOkmU5yMnJqTFdFARBEG4FPsPAxBoubarf63a+BekRcN96mPqjcv77xE/w+xSlmFIr09jd485l/20HTANWoQTioWWXjEAJ5ACbgFmSJJlIkuQN+AEnGvP+giAIwm3C0AQ6jIXLW5WqhNpIDYNzq6HPo0oZ1a53KfUV7v4dks63ymxrjc09vk6SJAegBHhKluUMSZIeBb6SJMkQKAQeA5Bl+YIkSX8BF1Gm0Z+SZVndyPcXBEEQbhcBk+H8Gog6DD5D675+/8dgaAoD59/Uzh1KbvMDn0DHiUoq55aijnLZjZ0eHyzLcidZlrvJsry77LFDsiz3KnusryzLp264/gNZln1lWfaXZXlbY95bEARBuM20HwVG5tpNkadeUwJ8n0fB0rnq8+P/D8zs4O8nQV2i+742RGY0LL+z1ktERjRBEAShdTA2VwL3pX9Ao6n92tO/K7W5+z9T/fPm9nDHF5B4Dk62gKNk2QmwbCLEnqr1MhG0BUEQhNYjYDLkJkLsyZqv0WggdJ1yTMyyls3MAZPArReErNB9P+ujIAP+mAYF6fDg5lovFUFbEARBaD06jAUD49qnyKOPQHackre8LoEzlNF2ylXd9bE+Sgpg1T2QFgazVihn0mshgrYgCILQephag+8IOLO85qnkc3+BkQX4j6+7vc5TAQlC1+q0m1pRl8KahyD6GExbohxrq4MI2oIgCELrMm4RmNrCmgeqHv8qLYKLG5Vd4cYWdbdl7aocBzu/ts6d2zoly7B5PlzdBhM+Kbt5qJsI2oIgCELrYu8N4z6CrBi4/E/l5y7/A4WZ0HWm9u0FzoD0cEgI0WUva1ZaBDvfhJA/YOgryg53LYmgLQiCILQ+HcaBnRcc/Aw0N6T8OPGz8rjvCO3bCpgESHBtp447WY30CPiiMxz5BoLmwrBX637NDUTQFgRBEFoflQGMfEvZRHbwc2W6OWy3sgmt9yOgqkd4M7cHl0CIPNR0/QVlKn/j08pI+57VMOEzkKory1GzxmZEEwRBEAT96DwNLvwNe/8HiWch5iQ4doDe2k83V/AaCKd+U/KRGxrrvKsA/DMfog7Bnd9rt0muGmKkLQiCILROkgR3/QYj3oDLW5RgO+MXMDKtf1teg6C0AGJ1XBJDluHY97DjTTjzBwx+EbrPbnBzYqQtCIIgtF4qFQxZoOQSt3BWsqY1hM8wMLZSRtteg3TXvx1vwNFvlb/btlM2njWCGGkLgiAIrZ+dV8MDNoCJFfS4Dy6sh5xE3fSptFi5Ceg8FSZ8CjN+VaqVNYII2oIgCIIA0PN+0JTCtR26aS/6CBTnKLMAfR4F916NblIEbUEQBEEAcA4ASxe4vr/xbYWuh9+ngMoIvLUoI6olsaYtCIIgCKBsbPMZphwd02jqd2zsRnlpsPk5MHeE7veAiaXOuihG2oIgCIJQzmcY5KdCwpmGt3HgEyjOhQe3wJj/6axrIIK2IAiCIPzHfzwYmChFRxoiJwlOLYNu94BzR932DRG0BUEQBOE/ZnbgPw7Or4GSwvq9NuIgfNcH1MUw+IUm6Z4I2oIgCIJwo96PQn4a7PtQ+9fIMux4XSkd+uAWcPBtkq6JoC0IgiAIN/IeDD0fUIp6xGiZIS1sFySchSEvg+eAJuua2D0uCIIgCDcb8z8I3wMrZ4J1WzA0hbbdITsBnPyh3xNg6axcK8tw4FOwdq9fSdAGECNtQRAEQbiZqTXMWqEUErF0gZJ8OLcG0q7B4S/h+wFKgZLcZFj7EMQcg4Hzm67YSBkx0hYEQRCE6rh2g5l/VH08+RKsmgWrZyvFSXJTYMAz0OvBJu+SGGkLgiAIQn04B8CsVaAuAjN7ePAfZTq9iUfZIEbagiAIglB/Lp3glSgli1ozEiNtQRAEQWiIZg7YIIK2IAiCILQakizL+u5DrSRJygGu6LhZGyBLx202ddutrd2mbLu1tduUbbe2dpuybdHnpm+3Kdtube02Zdv+sixbVfuMLMst+g8Q3ARtLmnC/jZJ262t3dbYZ/GzED+LW6XP4mfR6n8WNca923V6fHMrbLu1tduUbbe2dpuy7dbWblO2Lfrc9O02Zdutrd2mbrtarWF6PFiW5SB990MQBEEQmkNtca81jLSX6LsDgiAIgtCMaox7LX6kLQiCIAiCojWMtAVBEARBQARtQRAEQWg1RNAWBEEQhFZCBG1BEARBaCVE0BYEQRCEVkIEbUEQBEFoJUTQFgRBEIRWQgRtQRAEQWglRNAWBEEQhFZCBG1BEARBaCVE0BYEQRCEVsJQ3x2oi6Ojo+zl5aXvbgiCIAhCszh16lSqLMtO1T3X4oO2l5cXwcHB+u6GIAiCIDQLSZKianpOTI8LgiAIQishgrbQal1Ov0xuca6+uyEIgtBsRNAWWqX8knzu2nwXY9aNIasoS9/dEQRBaBYtfk1bEKpzIe0CADnFOQz5cwiv9H6Fwe6D+fr017zd/20sjS313ENBaLlKSkqIjY2lsLBQ3125rZmamuLu7o6RkZHWrxFBW2hV1Bo1S84vYV/MPgC+H/U9qy6v4qMTH7ElYgvnUs4xxH0Ik3wn6bWfgtCSxcbGYmVlhZeXF5Ik6bs7tyVZlklLSyM2NhZvb2+tXyemx4VWIyYnhqf3PM3ikMVcTLuIuaE5g9wG8fmwz3G1cOVcyjkADsYe1HNPBaFlKywsxMHBQQRsPZIkCQcHh3rPdoigLbQarx18jdNJp3ms62MA9HPtB4CJgUnFY64WrhyKP0SJpkRv/RSE1kAEbP1ryP8DMT0utAqpBamcTTnLk92f5PFujzPJZxL2ZvYVz0/zm4a3jTd5JXk8tfspNodvZprfND32WBAEQffESFtoFQ7GHkRGZpjHMAC8bLywNraueF4lqejl0ovBboPp6tiVxSGLKdWU6qm3giDUR2RkJIGBgY1q48svv+T333/X6tpevXpRXFys1bWyLAPwzjvvVHxd3WMnTpyge/fudO/enW7durFhw4aKNkaNGkVGRoaW30ntRNAWWjxZlll/bT2uFq742/nXeq0kSdwbcC9J+UlcSb/STD1suOzibK5nXdd3NwRBb2RZRqPRNKqN0tJSfvnlF2bPnl3ntZGRkbi5uWFsbKxV26+//jobN24kLS2NZ599lrNnz1b7WGBgIMHBwYSEhLB9+3bmzZtHaakycJgzZw6LFy9u1PdYTgRtoUWTZZk/r/xJSEoIj3V9TKs1oKA2QQAEJ7XM9LcJuQn8cPYH1lxdw5O7nmTm5pmkFqTqu1uC0GwiIyMJCAjgySefpGfPnsTExKBWq3n00Ufp3LkzY8aMoaCgAICQkBD69etH165dmTp1arUj1j179tCzZ08MDZUV35MnT9K1a1f69+/PggULKo3it23bxrhx4wCwtLTklVdeoVevXowaNYoTJ04wbNgwfHx82LRpEwAffvgh27dv548//uCpp56ie/fu1T5mbm5e8f6FhYWVPqsmT57MqlWrdPKzE2vaQou28vJKFp1YRC+XXkxtP1Wr1zibO9POqh3BScE80PmBJu5h/VxJv8KjOx4lo6jyB88vob/wcu+X9dQr4Xb28YmPuZx+WadtdrTvyCt9Xqn1mitXrrBs2TIWL15MZGQk165dY9WqVfz000/cfffdrFu3jvvuu4/777+fb775hqFDh/LWW2/x7rvv8uWXX1Zq6/Dhw/Tq1avi64ceeoglS5YwYMAAFi5cWOna7du388UXXwCQl5fHsGHD+Pjjj5k6dSpvvPEGO3fu5OLFizzwwANMnjyZN954g7Fjx2JoaMh3333Hww8/zJo1a6o81q1bN44fP87cuXOJiopi+fLlFUHczs6OoqIi0tLScHBwaNTPVgRtoVnll+RzJvkMbS3b4m1T+9lEWZZZfXk13Zy68fOYnzFQGWj9Pr1cerE7ejeyLLeYXbLphek8vedpjA2M2XznZs6nnudi2kWyi7P568pfPNj5QZzNnfXdTUFoFp6envTr16/ia29vb7p37w4oa86RkZFkZWWRmZnJ0KFDAXjggQe46667qrSVkJBAQEAAAJmZmeTk5DBgwAAAZs+ezT///ANAcXExsbGx+Pj4AGBsbFwx6u7SpQsmJiYYGRnRpUsXIiMjAXj//feRJImQkBDeeecdZFmma9euVR4D6Nu3LxcuXODSpUs88MADjB8/HlNTUwCcnZ2Jj48XQVtoXT44/gGbwjfhZunGtmnbag2o51LPEZkdybsD3sVQVb9f1UDHQDaEbSAhL4G2lm0b2+1Gk2WZ946+R1pBGn9M+AMvGy+8bLyY5DuJmJwYtl7fyi+hv7Cwz8K6G6tBibqE9469RxuLNkRlR3Eo9hAzO87k2R7PtpgbF6HlqWtE3FQsLCwqfW1iYlLxdwMDg4rpcW2YmZlVnHcuD6DVOXjwIIMGDar42sjIqOLfhkqlquiDSqWqWI8uf75809mN/5aqewwgICAACwsLQkNDCQpSlusKCwsxMzPT+nuqiVjTFpqNRtZwKO4QAHG5cZxPPV/jtbIsszhkMZZGlozxHFPv9+pg1wGgxWxG2xOzh93Ru3m6x9N0cuhU6TkPKw+GuA+p+Nk0xPXM63wb8i1/h/3ND2d/4EDsATrYd+Dn8z9zNuVsY7svCHphY2ODnZ0dBw8qCZOWL19eMeq+UUBAAGFhYYAyFW1lZcWxY8cAWL16dcV127dvZ/z48U3S14iIiIpAHxUVxZUrV/Dy8gKUz7PExMSKrxtDBG2h2VzLuEZ6YTqv9H4FI5URW65vqfHaw/GHORJ/hKd7PN2gPOIVQTtD/0E7vySfz4I/w9fGl/s73V/tNf72/kRnR1NYWr/sSLIs88K+F5iycQq/hP7CUPeh7Jqxi4MzD/LhoA8BuJpxtdHfgyDoy2+//caCBQvo2rUrISEhvPXWW1WuGT9+PAcOHKj4eunSpTz22GP0798fWZaxsbEBYN++fdUGfV04dOgQ3bp1o3v37kydOpXFixfj6OgIwKlTp+jXr1/FGndjiOlxoVmoNWrWXVsHwCjPUVxMu8jqK6vxs/Njmt80VFLl+8edUTuxMrLibv+7G/R+5kbmeFh56D1gaWQNrx58lbjcOH4c/WON0/ztbdsjIxORFUGAQ4DW7W+N2MrOqJ082PlB+rv2p4tTF6yMrQBoY9EGM0MzIrIidPK9CIKueHl5ERoaWuPXL730UsXfu3fvXjFqromnpycODg5cu3YNPz8/OnfuzLlzSlrjRYsWERQURGxsLI6OjpWmqHNz/yvtWz7VXd1z2pgzZw5z5syp9rnly5fz5JNP1qu9moiRttAsvgv5jlWXVzHBewJtLNrwRr836Onck3ePvst7R9+rdK0syxyKPUT/tv0xUmlf/eZm/nb+eg/af175kz0xe3ix14sVaVer0962PQBhmWFat52Ul8SiE4sIdAjkuZ7PMcBtQEXABiXhjI+ND+GZ4Q3/BlBuPG5MVPPHxT84En+kUW0Kgq4tWrSIhIQEALZs2UL37t0JDAzk4MGDvPHGG7i7u7Nt2za99C0wMJCRI0fqpC0RtIUml16Yzh+X/mCc1zgWDV4EKCPhpWOXcl/Afay7to6TiScrrr+acZXkgmQGuQ2qqUmtdLDvQHR2NPkl+Y1qp6Fyi3P54tQXDGw7kDmdqr8DL+dh7YGhylDroK3WqHn90OsUqYv4cPCHNe6s97HxITyrcUH7u5DvGLN2DOGZ4WwO38zHJz9mybkljWpTEHTN39+fIUOGADBz5kxCQkIIDQ1ly5YtODk56bVvjz76qM7aEkFbaFKpBak8tespitXFPNn9yUq7LFWSivk952NhZMGOyB0Vjx+MUzadNDZo+9v5IyNzLfNao9ppqO2R2ykoLajyfVfHSGWEt4231qPiH879wPHE47za59Vaj8752PqQnJ9MbnH9pvputD1iOykFKTyy4xHeP/Y+BpIB51POU6zWLg2k0DLVtstaaB4N+X8ggrbQZK5nXue+rfcRnhXOF8O+qDa4mBqa4mrhSmJ+YsVjB2MPEmAfgJN54+6O/e2VlKf13UG+5uoaXtz3IiXqhlcKU2vUrL26Fh8bH7o4dtHqNe1t2ms10l57dS0/nP2BKb5TuLP9nbVe62vjC9DgVKmxObFE50Qz038mao0aM0MzXuv7GsWaYkJTQ+tuQGiRTE1NSUtLE4Fbj8rraZef49aW2IgmNIno7Gju23Yfxipjlo1dRmfHzjVe28aiDUl5SYCSi/tsylnmBs5tdB/aWrTF0siy3uvai44volhTTGZRJnMD5zLQbWC93/u7kO+4kHaB9we+r/UZaV9bX7ZFbiO/JB9zI/Mqz0dnR/PrhV/55/o/9HftzzsD3qmzbR9bJYlEeGY4XZ26at1/WZY5k3yGTeFKKsfZAbOZ13UealmNqYEp7x97n5OJJ+np0lPrNoWWw93dndjYWFJSUvTdlduaqakp7u7u9XqNCNpCk/g0+FPUGjXL71iOh5VHrde2sWjDxbSLAByNP4paVjPEfUij+yBJEh3sOtQraKcVpFGsKcbKyIqwzDCe3/c8G6dsxNXSVes2UvJTWHZhGZN9J9c5Er5ReztlM1p4ZjhdnKqOzldcWsGaq2uwMrbSOuGMm6UbxipjrXeQF5YWcjzhOLG5sSw6oew/GOM5Bm9r70o3CF0du7I9crvW+eCFlsXIyAhv79ozEgotk5geF3QuNDWUvTF7ebTro3UGbIA25m1IL0ynSF3EwdiDWBtbaz2lXJfyoK2R664iFJcbxxO7ngBgyZglrJqoJPh/5eAr5JXkaf2eqy6vQq1R83jXx+vV19p2kMuyzP7Y/QxxH8Keu/ZofRNhqDLEy8ZLq81omYWZ3P3P3Ty952k+OfkJgQ6B7Jqxi8+GfVYlMN/pdydhmWG1JsgRBEH3RNAWdG7FpRVYGFlwT8d7tLrexcIFgPjceA7HH2Zg24H1yjNeG397f/JK8ojLjavz2h/P/sil9Es4mzkTYB9AW8u2vD/wfc6lnOO1g69ptf53POE4y0KXMdpzNB7Wdd+w3Mjd0h0TA5Nqg3ZYZhhxuXEM8xiGqWH91sC0Pfa18vJKIrIi6O7UHbWsZlbHWRX/b2423ms8RiqjShsIBUFoeiJoCzqVUZjB9sjtTPGdgoWRRd0vQJkeB5j892RSC1IZ0W6EzvpTnhmtrinyUk0pe2P2MrLdSDZN3VRx0zDWayzP9HiGPTF76Pp7VzZc21BrO1+d/oq2lm15Z8A79e6rgcoADysPYnNiqzy3P3Y/AEPd65/NycfWh/jceApKa87lnF+Sz8rLKxnuMZyvR3zN/J7zGe9dc7pHS2NLAhwCGj3SLlGX8NHxjxi1ZlTFvgZBEGomgragU/9G/kupppRpftO0fk0b8zYVf/9k6CeM9Rqrs/60t22PhMTV9NqD9p7oPWQWZTLRZ2KVm437O9/PaM/RwH/BszpZRVlcSLvARJ+JlZKc1IezuTPJ+clVHt8Xs49ODp0aVAXM18YXGZnIrMgar9kQtoGsoizmBs7FztSOR7o8grGBca3tdnXsysW0i5RotNtlv/bqWk4knKj02M+hP7Py8kqS8pPYfH2zVu0Iwu1MBO1mpJE1t/wRi60RW2lv275ihKuN8pH2UPehjPMap9ONTeZG5nhae9aag/xEwgle3P8i7azaMbBt1Z3iRiojPh/2OZN8JnE25WyN/w+DE4PRyJpaM5/VxcnMieSCykE7rSCNcynnGOY+rEFt+toqx76qW9eWZZkHtz/IohOL6Onck+7O3bVut4tjFwrVhYRl1H5MrVhdTERWBO8dfY9n9jxDVHYUoCyHLD2/lLFeY+nu1J3N4ZtRa9Taf2OCcBsSQbuZ/Hz+ZwauGsgHxz/Qd1eazPaI7ZxJPsMU3yn1CrymhqbsmrGLr4Z/1ST96uLYhdNJp2vcjLY1YisWRhb8Nemvao9alevu3J3UglRic6tOX4OSFMbc0Lzand/acjZ3Jq0grVLw+uf6P8jIDV42aGfVDkPJkOuZVc9qR2RFcCrpFADP93q+Xu2Wf5+nk0/XeE1SXhLTN01n8t+TkZExUBlw/7b7CU0N5bPgz5CQeLHXi8zoMIPrWdd5Zs8zInALQi1aTdDOL8nn+7Pf879j/yMlv3WdLbycfpmvT39Nbkku666uI7UgVd9d0rkidRHvH3ufrk5dubfTvfV+vYuFi842n92sf9v+ZBRlcCntUpXnZFnmYNxBBrQdUOcafDenbgCcST5T5bnMwky2RmxltOfoRuVLdzZ3Ri2rSS9MB6BEU8Lyi8vp06ZPRbKY+jIyMKKddbtqN6OVB9zNd26u1ygblI1zPjY+tW5Ge/fou6QUpOBt4810v+n8MeEPTA1MmbdzHjuidjC3y1xcLV2Z7DuZBUELOBh3kPVh6+vVD0G4nbSaoP35qc9ZHLKY9dfWM3vr7EalZWxOoamhPL/3eWxMbFg1cRVqWc2qy6v03S2dOxx3mOzibJ7s9mSjglZTGNB2AKCU+7zZ1YyrJOcnM9htcJ3t+Nn54WDqwMHYg1WeW3dtHQWlBTzY+cFG9bV8zbp8ijw0NZSk/CRmdZzVqHZ9bX2rzYp2JvkM9qb2eFp71rtNSZKY6DOR08mnq92dn5KfwuH4w8zuOJtNd27i7f5v42Pjw6Ihi8gryWO052geCXykoq05nebQ07kn35z+hqyirPp/k4JwG2jxQTuvJI+fz//MX1f+4t6Ae/l5zM8k5iW2isAnyzJvH3mbYk0xXw3/ikDHQEZ5jmLFpRVkFmbqu3s6tT1yO7YmtvRx7aPvrlThYOZAoEMgW65vqTJFviNqBypJxWD3uoO2SlIp56Sj93Ak/kilte1zKefwtvGuSJDSUC7myhGr5DwlaJfvJC8/w91QPjY+ROdEV8oXLssywYnBdHfq3uB9BOWbBg/HVb0h2haxDY2s4Q7fOwAq3qOHcw923bWLT4d+ipHBfzd4kiSxsM9CMosy+eHsDw3qjyDc6lp80I7MjuSr018x0G0gT3d/mp4uPRnqPpSfzv/E1utbORJ/hENxh/TdzWqFpoZyNeMq87rOq0j3+FT3p8gvyWfttbV67p3ulKhLOBB7gBHtRrS4UXa5+zrdx/Ws6+yJ3lPxmCzLbIvYRp82fXA0c9SqnaEeQynWFDNv57xK5SkjsyPxsfFpdD/L862nFChLQAl5SqlBVwvtM7JVx9fWF42sITI7suKxk4knic+LZ6Rnw0sGelh51Fiz+3D8Ydrbtq/25+Jo5lilhjpAgEMA473Hsyl80y2/aVMQGqLFB20jlREb79zI4pGLsTS2BODNfm8SYB/AKwdf4aldT/Hc3ueIzo7Wc0+r+vXCr5gZmjHBe0LFY762vnjbeHM2+awee6Zbp5JPkVeS16AzxM1lrNdYPKw8WHJuSUUwOJ18mpicmEr/f+oyxG0IszvOBpS9CqCsO0fnRONl7dXofjqYOqCSVCTlK2eW43PjsTe1r3dClZuVB84bN6OtvboWa2NrxniOaXC7KkmFl7VXlan3Uk0pIckh9HLpVe82e7n0Irs4m8S8xLovFoTbTJ1BW5KkXyRJSpYkKfSGx96XJOmcJEkhkiTtkCSp7Q3PvSpJUpgkSVckSRp7w+O9JEk6X/bc15KW83GOZo742PhUmr5zsXBhyZgl9HftTzvrdhipjPgs+DOtv+mmdDn9Mk/uepJ3j77LjqgdPBT4UMXNRrlODp0qcm3fCg7EHsBIZdSoo05NzVBlyMOBD3Mp/RIHYg8gyzLfh3yPg6kD47zHad2OkYERr/Z9FWdz54qNXXE5cZRqSmstkaktA5UBntaeFb8f8bnxuFm6NbpdT2tPVJKq0rGv4KTgBmVYu5mPrU+VoH0t4xr5pfn0dK5/QZHyDXflN0UtzfXM62wO30x6YToLDy7kpf0vEZ8br+9uCbcJbUbavwI3f6p9IstyV1mWuwP/AG8BSJLUCZgFdC57zWJJksq3BH8PPAb4lf3R6pPSzsSu2sdNDEz4cfSPrJu8jns63sO+2H0t4h/Ol6e+5GDcQTaFbaKfa79qq1V1cuhEckHyLbGLXJZl9kbvpXeb3rUel2oJJvtOxtPakwUHFjBn2xyOJx7nkS6PYGZoVu+22tv+V0azfGrYy8ZLJ/3s26Yvp5JOUaIuISEvodFT46Acq3O3dK+40SgsLSSlIIV2Vu0a3baPjQ+JeYnkl+RXPFa+K70hVcD8bP2QkFps0H5x/4u8dug1Zm+ZzY7IHRyIPcD7x97Xd7eE20SdQVuW5QNA+k2PZd/wpQVQvvg0BVgty3KRLMsRQBjQR5IkV8BaluWjsjI3+TtwpzYdrG1ALkkShipD7upwFwAPbX+Ir05/Va/iDroUkhzC4fjDzO85n1NzTvHTmJ8wMTCpcl0nh04At8Ro+1zqOWJzY2tNedlSGBkY8cvYX+jdpjeFpYUsCFrA7IDZDWrL19aXS+mXWHd1HRfSLgDoZHocoJ9rPwpKCzibcpb43HjaWrat+0Va8LH9Lwd5+Q2um1XjR/HlU+8R2f+ta++K2oWntWdF4pz6KE+I0xKDtkbWEJMTAygFZj4f9jl3tr+z4iZLEJpag0tzSpL0AXA/kAUML3vYDTh2w2WxZY+VlP395sd1wtXSlRd6vcDhuMP8fP5n1l9bj5e1F50cOjHIbRD9XPs12Rngcgm5CSw8uBBXC1dm+dd+PKejfUdAOW6kixKU+rQ5fDMmBiaMajdK313RirO5M9+N/K7R7ZTv5n7n6DsA9HXti42JTaPbBQhqE4RKUrEhbAPFmmKdBe3ODp3ZH7Of5PzkigQx7pb1q+VbHT87PwAup12ms0Nn4nLjCE4K5unuTze4zY72HVtkBbFrGdcoUhcx3W86gY6BDPMYRqmmlFWXVxGaFkoP5x767qJwi2vwRjRZll+XZdkDWAGU/+usblgs1/J4tSRJekySpGBJkoK1LdL+QOcHWDJmCSsnrKSbUzc0soY1V9fw+K7HmfT3JL4+/XWtBRMa40DsAe7ceCfphel8MvSTKmvYN7MwssDe1L7awhCtyfXM66y7to4J3hPq/J5vNSPbjeS+gPuY7jcdSyNL3uj7hs7atjGxoZ9rPzaFbwLQWSAY4zkGGZmdUTsrfvfcrRoftNtZtcPa2LoiyO6K2gXAJN9JDW7T396fuNw4souz6764GR1LUMYkT3R7ghkdZgAQ5BKEhFQlr3pLci7lHDHZMfruhqADDR5p32AlsAV4G2UEfWM9Qncgvuxx92oer5Ysy0uAJQBBQUH1OvfRxakLX4/4GlDW7fbF7mPd1XX8fP5ntkVsI9AxEGdzZ6Z3mI6PjQ/Zxdl8H/I9g90HVyThqI/TSad5ds+z+Nv788WwL7QeFdVUzak1WXRiEeaG5szvOV/fXWl2NiY2vNLnFQBe7ftqtcsgjXGHzx0ciT9CN6duFTMzjeVj60MHuw5si9hGN6dumBqY4mDq0Oh2JUmiq1NXzqYoJyKisqOwMbFp1AxB+fd8Jf0Kvdv0bnQfdaGwtJDjCcfxsvaqVLLU1tSW9nbtq82Up28JuQl8GvwpO6J2YGtiy7Kxy2hv156U/BQsjCxa/D4UoaoGBW1JkvxkWb5W9uVkoHzxaROwUpKkz4G2KBvOTsiyrJYkKUeSpH7AcZRp9W8a1/W6mRqaMs5rHOO8xnE47jDLQpdxMe0iu6N3s+LSCpzNnUnKT0Ija1h/bT0L+yxEkiR6ufTCw6r2WshF6iKOJxzn7SNv427lzs9jfq5XZSd3K3fOJP33j1wja0grSKs4p9vSnUg4wdGEoywIWoCDWeM/+FszXQdsUEbynRw68VjXx3Ta7qh2o/j+7PcYSAa4WbrprDhLN6duHI47TE5xDgl5CbS1aNyUfksL2nui9zB/r3JzOtN/ZpXnuzl149+If9HImmrPn+vD32F/88GxD5CReTjwYTaGb+SB7Q/Qu01vdkfvRiWpGOQ2iI8Gf4S1sbW+uytoqc6gLUnSKmAY4ChJUizKiHqCJEn+gAaIAh4HkGX5giRJfwEXgVLgKVmWy7P/P4GyE90M2Fb2p9kMdBvIQDelglN6YTpLzy8lOT8ZDysPujh24aMTH/HWkbcqrg9yCWJ6h+lM9J5Y5YMtPDOceTvnkZSfhIeVB18O+7LepRjdLd3ZFrGNEnUJRgZGrL26lvePvc/y8cvrnQO6ucmyzJenv8TF3IWZHat+gAmNZ25kzp93/Knzdge6DWTx2cWcTj6t082D3Z27IyNzOuk0CbkJDUqLeiNHM0ccTB202oy2PWI735/9HjdLNz4d+mmTjB7XX/svH3p1Rxu7OXVj7dW1RGRFVFRV05eMwgxWXl7JknNL6O3Sm/cGvkdby7ZM7zCdhQcWcj71PPcF3IehypBfL/zKP+H/NHhDptD86gzasizfU83DS2u5/gOgSikrWZaDgcB69a6J2Jvas6D3gkqPDXYfTFR2lHKEKWYvG8M38urBV0nMS+SRLkp+ZFmWWX9tPf938v8wNzLns6GfMdh9cIOODHlYeaCRNSTkJdDOul3FOuA7R97hx9E/Vpp+a2n+jfyX86nneX/g+00yyhSaTmeHztia2JJZlMn9ne7XWbs9nXtibmjO/tj9xOfF079t/0a32d6ufbVFTm50Ouk0rx58FS8bLw7FHeLVg6/y8ZCPySjMwNbUtkH/Nm+mkTWcSzkHKMmeqhv5lxeTOZtyVq9BO68kj3k753Ep/RL9XPvx1fCvKm5iPKw8WDFxRaXr98bs5UDcARG0W5GWMY/TAhiqDPG19aW9XXse7foom+/czATvCXx1+itOJp5ElmU+PP4h7xx9h0DHQFZMWMEYrzEN/lAo3wAUkxODRtZwKf0SzubOxOfFM27dOBYeXNgi0zgWq4v58vSXdLDrwCSfhm80EvTDQGXAXR3uYrLvZAIddXcPbWxgzEC3gWwK30RBaYFOzpa7W7pXW4gElEAanhnORyc+wtncmd/H/84rfV5hT8we+qzow5h1Yxj659BKI+SGCk0NJaMog0WDF3Hi3hPVnhLwsvbC3tSek4knG/1+DSHLMtsjtzNj0wyuZFzhu5Hf8dOYn+qcdRjiPoSTCScrnbEXWjZdbES7JUmSxNv93+Z86nke/vdh2li0ITEvkZn+M3mt72uNXrfytfHFSGXEzqidOJk7kVmUyf8G/o/uzt356dxPbAzfyHiv8Qz1aFmpQb8N+Za43Dh+HP1jkx+jE5rGsz2fbZJ2h3sMZ2fUTgCdHFNzt3InoyiDvJK8SmVT80ryePfou2yLUFbYPh78MVbGVtwbcC9ulm6cTTmLq4Ur2yK28b9j/6OzQ+cGlzUF2Bm1E0PJkEFugzBUVf+RKUkS/dv250j8kWZf1y7VlPLawdfYFrkNbxtvfh7zs9b7AAa5DWL5xeWcSjqlVdEcQf/ESLsW5VPgswNmo5bVWJtY80yPZ3TyD9LW1Ja7/e/m77C/K0YDfdr0wdPak7cHvI2HlQcfn/yYpLykRr+Xrqy9upZlocuY0WFGg3baC7e28opfoOROaKzy2agbT1nE58Yzcf1EtkVs46HAh3hvwHuV0tAO8xjG/J7zudv/bj4f9jm2Jra8cuAV9kbvrVThTBvZxdl8FvwZv174lf5t+9d5Dn9g24GkF6ZXW7e9Ke2N2cu2yG082f1JNkzeUK+Ne92dumMoGVZksBNaPhG06xDgEMDCPgtZP3k9a+5Yo7MEGgBzA+eikTWsvLQSd0v3ig86I5URHw76kPTCdB7c/qDe07OWT70tOrGIAW0H6PRMsnDrMDYw5rW+r2FqYKqT7HDliV/KE8EALA5ZTE5xDsvHL+eFXi8w1W9qjTfRdqZ2fDDoA8Kzwnl277OsuLSi2uuqU6op5fGdj/PrhV8BtNq0V77RtbmnyP+N/Bd7U3se7fJovWe/zI3M6eTQidNJ1QftEnUJu6N281nwZ0zbNI1ndj/D5L8n882Zb+p9EyTohgjaWrIxsdHJ6OFGzubO9HDugYxc5e64u3N3loxeQlZxFs/tfY5STalO31tbGlnDohOLWLB/AV7WXnww6AMxLS7U6J6O93Di3hOVprMbqjxox+Uo69rphelsvr6ZmR1nan3Con/b/vx1x184mTmxMWyj1vtEziSf4XzqeV7r+xo/jPqBiT4T63yNvak91sbWNa7DN4X8knwOxB5gtOfoGqfu69LTpSfnU89TWFpY6fHL6ZeZsnEKz+17jj8u/oGVkRWhaaFYGFqw5NwS5mybw/ch3/PHxT+qLc0qNA2xpq1nI9qN4HTy6WqntLo6deXt/m/z0v6X+PPKnzibO+Nk5kQ3p246O19bG42s4a3Db7ExfCNzOs3hxV4vioAt1ElXv5s2JjZYGllWjLSvZ15HI2sY1HZQvdoJcAjg8W6P8/6x97mQdkGrDXgH4w5iqDJkks+kemX7c7FwITG/+UqKHog7QEFpQaWlifrq79qfXy/8yuH4w4xsN5JSTSlX0q/w+K7HMTEw4dsR3zLAbQBGKqOK1+yM2slnwZ+x+OxiAIxPGbNm0hp8bBtfU16onRhp69md7e/kvoD7GNFuRLXPj/Ecw8C2A/ks+DNe2PcCc7bN4Y3Db1CiafriBEvOLWFj+EYe7/Y4C4IWiIAtNCtJkvC09qyophadEw1AO+v6VyYb7z0eSyNLloUu0+r6Q3GH6OXcq97peduYt2nWfSg7InfgYOrQoBKo5fq49sHe1J4t17cA8PaRt5m1ZRZqWc2yscsY6jG0UsAGGO05mu3Tt3N6zmm2Tt2KmZEZL+5/seKkjdB0RNDWs/J0mDVNJ0qSxOt9X0clqejl0ot5XeexKXwTz+x+hqyirCbrV1hGGN+f/Z47fO7gyW5PNsvIXhBu1tWpK6GpoZRoSojKjsJQZdigymFWxlbc0/EedkbtrDUH95G4I6y7uo5rGdcY5jGs3u9TfsqkOeQU51RMjTfmhtpQZcgE7wnsi9lHWEYYW69vZazXWP6c+Cce1rVnhjRSGeFh7cHHg5Wz8XP/ncuTu59EI2sa3B+hdiJotwIe1h5sunMTP47+kad7PM27A97lWMIxJv89ma3XtyLLMiHJIfx07qcq61INtfjsYswMzXil9ysiYAt608O5BwWlBVzNuEpMTgzulu4NXrud4D0BGZmzqWerfT6rKIt5u+bxztF3sDWxZZrftHq/h4u5CxlFGRyJP1KpRPDW61u5f9v9vLz/ZYrURQ3q/83WXF1DkbqIqX5TG93WRJ+JlGhKeG7fc6hlNfN7zq8zYN9ooNtAtk7byjM9nuFQ3CF+v/B7o/skVE+sabcSN557neY3jc4OnXnnyDu8cvAV1l9bz5WMK2QWZfLHpT+Y4D2BF3q9gJGBUS0tVqWRNaQXprM9Yjs7o3byZLcnsTW11fF3IgjaK69wFpIcQlR2VKPSo3pae2IoGXI983q1z28O3wwoG8qe6/lcg9Khls8CzNs5D0OVId+N/I5dUbtYc3UNPjY+nEk+g5mRGe8OeLfS62RZZlf0LqKyo/Cw8uBk4kmS8pVp9mntpzG83fBK12tkDX9c/IN+rv3o5NCp3v28WWeHznhZexGZHclk38l11l6ojrmROY92eZRLaZf46sxX9GvbT2fFboT/iKDdSvnb+/PHhD9YfWU1S88vRa1R896A9zgUd4g/Lv3BtcxrfD7scy6lXeLtI29TrC6mSF1Ee9v2BLUJoqtjV8yNzDFSGSEjk16Yzrdnvq1YP+zv2p9Huz6q5+9SuN21sWiDm6Ube6P3EpMTQ1/Xvg1uy8jAiHbW7Sp+x28kyzLrrq0j0CGQVXesalR/yzmaOTJv5zxAOd75TI9n+PzU56y4tIJ5XedV3IjLssxP53/imzP/1VCyMLLAzdKN3OJc5u+dz/rJ62lv177i+cjsSFIKUnimxzMN7uuNJEnirg53sezCMl7o9UKj2nm7/9uc3XSWhQcWsvqO1Zgamuqkj4JCBO1WzEBlwL0B93JPx3soLC3E3MicqX5T2Ri2kXeOvMPYtWPJLcnFy9qL3m16Y6gy5FLaJX4+/3O1a072pvYsCFpAe9v2FdcLgr5NaT+FxSHKLuXGbLgC8LX15WrG1SqPn0s9R1hmGG/3f7tR7buYKzUDfG18WTxqMcsvLmec97iK3ORzAuaw4tIKfgn9hWd6PEOJpoSXD7zMycSTjPcez2t9XuNKxhWldKqhKZmFmYxfP56vTn/F1yO+rliqupB6AUCnqWjv73w/9wbc2+gNp7amtvxv4P+Yt2sei0MW80JQw28Cbkd1bTIWn8q3AJWkqjSVN6X9FHxtfZWkLVbuPNj5wUrP5xbnEpYZRrG6uOIXxNLYEh8bn3pXKxOEpja1/VR+PPsjPZx7MLLdyEa15Wvry+7o3RSpiyoVu9lwbQNmhmaNrnzmae3JS0EvMcF7Ak7mThU118u5WroywXsCf175kz+vKFXcTAxMeK3va8zoMAMjlVGl2QRbU1se6/oYn5/6nG9DvuWejvfgaObIxbSLmBqY4m3j3aj+3kxXJ0QGuA1gavupLL+0nOkdpje66tvtIqsoixf3v1jrNVJL354fFBQkBwcH67sbgiDoUXBiMF42XjiaOTaqnR2RO3hx/4tVSuBO2jAJbxtvvh7xdSN7Wje1Rs3BuIPE5sSSVZzFYLfBdHXqWuP1GlnD/L3z2RezD1sTW34c/SMfn/gYjaxh+YTlTd7fhkrJT2HS35PwsfFh2bhlFTdJsixzOf0ykdmR9HDu0aDTALeqhQcX8m/kv4TcH3JKluWg6q4RI21BEFq8oDbVfn7VW/+2/TFSGfFv5L8VQbtIXUR0TjRjvMbo5D3qYqAyqNdxMpWk4qvhX3Ep7RLP7nmWj098zKX0Sw3a3d6cnMyd+GDgBzy37zle2v8Sd/reSXBSMBfSLnAm+QwA5obmrJy4sko501JNKZvDN6OW1YzzGlfv8/KtUXJ+Mv9G/Ms9AfcQQkiN14kjX4Ig3DasjK0Y6DaQHVE7KvZ1RGZFopE1+Nn66bl3NVNJKjo7dmaM1xhOJ5+moLSA7k7d9d2tOo30HMnrfV9nX8w+ntv3HOuurSOjMIOFfRayfPxyTA1NWXBgARpZQ2FpIUfjj/LV6a+Ys3UObx15i3ePvsvsrbPJKMzQ97fS5P688idqWc09He+p9Tox0hYE4bYyzmsc+2L2EZIcQk+XnhW7ydvbtq/9hS1AN+du/HHpDwCt86/r26yOsxjQdgBphWl0duiMsYFxxXMLei/g1YOvMnrtaDILMynWFGMoGeJl48V7A97DwcyBp3Y/xb+R/zKr4yw9fhdNq0hdxNqraxnqMbTO43YiaAuCcFsZ5jEMEwMTtkdurwjahpJhq9gsVT66bmvRtlWtBbezbldt+tmxXmN549AbJOcnM91vOiPajaCXS6+KDJGyLONm6caR+CO3dNBeeWkl6YXp3BdwX53XiqAtCMJtxcLIgsFug9kRuYOXe7/MxbSLeNl41TsZkT60sWiDl7UXvVx66bsrOmGkMuK38b+Rmp/KSM+qJwMkSaJ/2/5si9hGiaakSg50bcmyzNpra4nIimCy72QkJPzt/RvbfZ0ITgzmi1NfMMxjGH3a9KnzehG0BUG47UxpP4Vd0bvYGLaR4MRgZnacqe8uae338b/fUglLys+w12SQ2yDWXl3LyksreaDzAw16j98u/MZnpz4DYPnF5VgZW/H18K85En8ELxsv7vC5o8a67E1t5eWV2Jna8X9D/k+rlNEiaAuCcNsZ4j4EHxsf3jn6DgCD3Qbrt0P1YGdqp+8uNKvhHsMZ1W4Un5/6nCHuQ+p9Nj2rKIsl55Yw2G0w3Zy6cTn9MgdiD/DQvw9VXLP84nK+HP4lbpZuuu5+rTIKM9gbs5d7Ot6DmaGZVq8Ru8cFQbjtqCQVLwW9VPH1rTLdfCtSSSpe7/c6KlSsv7a+3q//88qf5JTkML/nfOZ1m8cXw7/gqxFf8Vb/t9hz1x4+Hvwx4ZnhrLi0ogl6X7t119ZRqillanvti76IkbYgCLelwe6D+WfqP+QU51Ta0Sy0PI5mjgzzGMam8E082+NZrfcfaGQN66+tp2+bvpXWsAe5Dar4+wSfCawPW8/R+KM673dtitXFrLi0gv6u/fGz0/64oRhpC4Jw2/K09tRp/m6h6Uzzm0Z6YTp7Y/Zq/Zr9MfuJy41jeofptV7X37U/YZlhpOSnNLabWtsXs4/UgtR6r9OLoC0IgiC0eAPaDsDVwpV119ZpdX1UdhTvHn0XHxufOnPW92/bH4Aj8Uca3U9t7Yrahb2pPf1c+9XrdSJoC4IgCC2egcqAyb6TORp/lMzCzFqvPRx3mBmbZlCsKebToZ/WufzR0b4jzubO7IvZp7P+1qZIXcT+2P0M9xhe7yItImgLgiAIrcIgt0HIyJxIPAEowe+l/S8xcs1I3jv6Hvkl+ZxMPMn8vfPxtvFmw+QNWq0XqyQVwz2Gczj+MIWlhU39bfDz+Z/JL81nos/Eer9WbEQTBEEQWoVAx0AsjCw4En+EYwnH2B65nZziHIa5D2Pt1bWcTTlLTE4M7pbu/Dj6x3odjxvZbiR/XvmT7ZHbubP9nU32PYRnhvPTuZ+Y5DOJ3m161/v1ImgLgiAIrYKhypDeLr0r1rVHeIxgos9ExniNYXfUbl7a/xKBjoF8Puzzep9n7+valy6OXfjy1JcMcx+GramtTvqcX5KPRtZgaWyJLMt8FvwZ5obmLOi9oEHtiXragiAIQqtxLuUcf175k04OnZjdcXalLGJpBWnYmtjWe5243IW0C8zZOof2tu15s9+bdHHq0uB+Hks4xvmU82wK30R8bjx3+99NTnEOG8M38lLQS7XuGpckqcZ62iJoC4IgCML/t3fm8VZVZR///rgXRRFwAlFAccJMcBYVM8iBUpwqK9QcKjVMySYHTF8cciacEMpwyFk0tVLRNAcQBVNfEVFxQF6VNDWHcECE+7x/POvI9naBM+zD5Rye7+dzPvfstff57eeuvfZ+1nrW2mslJrw+gRMnnsiceXPot04/Tut3WsmLsyxoWkD/cf354NMPaFADu623G/fMugchDu9zOEO3GrrYKUvDaQdBEARBkXz02UfcPONmxkwdw9wFc9l8zc3pvWZvVm+3OgdtehBzF8ylQ9sOi5zkZfwr4zl+wvF8e+NvM6DHAAb0GMCL771Iu8Z2S1x6E8JpB0EQBEHJvPqfV7n9pdu5c+advPPJO8xrmkfnlTrz/qfv07V9V8776nn/NTnP3bPuZtiEYfTs1JOb976ZxjalDx0Lpx0EQRAEZdJkTSxoWsC0d6ZxwRMXsFb7tZj29jQ+nv8xV+9x9eeLmMx8fyaD7xzMJqttwqhdR9FpxU5lnW9xTnuJ72lLukLSW5KeyaSdL+l5SU9Luk3Sqpl9wyS9JGmGpK9n0reRNC3tu1jFrEEWBEEQBK1MG7WhbUNbtl5ra67Z8xpG9B/B2IFjaaM2HHXfUbw7910Aznv8PNq2acvIASPLdthLtKWIY64CvtEs7V6gt5ltDrwADAOQ9GVgMLBZ+s1oSYVhfGOAI4GN06e5ZhAEQRDUBD069uDSXS9l9oezuXnGzTz02kNMmj2JI/ocQeeVO1ftvEsMtpvZBEk9m6X9LbM5Gdg/fd8XuNHMPgVekfQS0FfSLKCjmT0KIOlqYD9gfKX/QBAEQRC0Br3X7M3WXbZm9NTRtG9sT6/VenHApgdU9Zx5TGP6QxY6327Aa5l9r6e0bul78/QgCIIgqFkG9hxIkzXxyYJPuHiXi1mxYcWqnq+iGdEk/RqYDxRWD2+pn9oWk74o3SPxUDrrrrtuJSYGQRAEQdXYe8O9eeWDVzhw0wPptkr126JlO21JhwJ7AbvawiHorwPZl9C6A/9M6d1bSG8RM7sMuAx89Hi5NgZBEARBNem4QkdO3uHkpXa+ssLjkr4BnADsY2YfZ3b9BRgsaUVJ6+MDzh4zszeAOZJ2SKPGDwH+XKHtQRAEQbBcscSWtqQbgAHAmpJeB4bjo8VXBO5Nb25NNrMhZjZd0jjgWTxsfrSZLUhSR+Ej0VfC+8BjEFoQBEEQlMAyP7mKpDnAjJxlOwEf5KxZbe1a062mdq3pVlO71nSrqR02V1+3mtq1pltN7U3MrEOLe8xsmf4Aj1dB87Iq2lsV7VrTrUWbIy8iL+rF5siLms+LRfq9PF75qkX+WoPataZbTe1a062mdq3pVlM7bK6+bjW1a0232totUgvh8cdtEXOwBkEQBEG9sTi/Vwst7cta24AgCIIgWIos0u8t8y3tIFgUkmRRgIMgWI6ohZZ2UGUkVaUcSGp5hfh8tFcMh+0Vl9a2oVRq0eagdqm38hZOO0ckHSJpoKR10nYu+SvpJ5IOT99zLYCShgInSuqYs+7PgOsk9clTN2kfDrwo6ZCcdYdI+qGkrdJ2XtfvIEk7FfI450rSSpnz1MrDaYXClzxtlrRKNXSTXvcq6W6TtTtH3X0kbZy3btI+QtJX0/c8r1/Xwr2Rcz63y5wjT3sPkdRfUqe0vVT8aTjtHEgP5InAAcBA4CJJHc2sKQftNYGjgV9KWjWv1qWk7SVNBnYB/mJm/8lBU5LaSjobGASca2bTKtXN6O8i6e/At4BHgM9y0t1A0gRgb2Bt4HJJq1d6/SStL2kScBCwJ3CxpDXNrKnSh4ekXSU9DFwq6fsAOZaNvSSNkrRGHnoZ3YGSxgOXSDoY8rFZ0m6S7sPvu2Pz0k3aK0i6Frg/Z91d0zPjcBazDkMZultJeho4mEzlKCftXVI+/4a0tHJO16+QF5cCo3PU3V3SvcB5kgbnoZuecWtLegA4FDgQGFPqfS2pV9lGVOv9teXhAzQAbfFC/O2UtjE+iKBTBbqNzbYvBCYCv03bqtDmNsBFwJ8y6StXmBeN6e9K+GsQq6ftTpljyrI72dseuB7YL6WdCVxa2F+hzYOAMzPplwKr5ZAXzXUvB67L4RquDjyKL4n7NeB24JQK80Lpsy8+o+Fs4Lvl6jXTbQSOBx5PeXJgupb75qT7KPBNvAL6V6BfpTY3O89NwBvAIRWWY6X77ydJb/CizluB7ecCh1eqk9Frgzv/UekZtBfwc+DXlZS3jH4vYEoqy12Au4BdcrB7o6S7L7AVcC1wUiU2Aw0Zm69N3xuBi0nP0iVdQ2BLYBbwArB+OXZUtMrXso6k7+KLlTxnZu9JamP5tH4bgXPwqVxvAs4wX0McfE727YAdJD1jZrOLPW9Gt62kv5rZffK1zNsAg4GHJZ1lZv+u0OZrgTuA7VMNdBNgXUmPAveb2cxybQamAi/i094en84xExhraT31MmxuB9xgZgdmdt8NnC9pFTP7sEzdFSRdD3wJ6CVpO+AH+IPpOUkPmdm0MvJiBUnX4eWgZ+aQGcBpknYws8mllMdC6C0dvw4wDbjNzBbIpxeeLGmsmb0hlTZAL6st6VXgq8BOwI+Ax/CHTMlkdOdLeg04wMxeTOHgrSizJdhMdyIwMn1fD/gYeC5zbFl5AZikFfDpmB8FbgbOkvRnMyt5BqyMzQskfQTcADyQ9u2ZzjEHmF+Kzc2uXQPQOdmKpCHAk8AzZvZxBeVinqTbzeyYlD4Qr9ieWc7ztFlZ3hJfn+IWeffRR8ALktqa2Wfl5gWwPfCEmf057bsfGJnukbdK1G0ETgcaJN0FdAQWpHPNT9Gdf0rqb2YPtXRfS2own9K7N3A28BVgX0mjzWxeMXYUqMvwuDxcPQVf63sIMEJSp5wctvCaVVdgMj4X++HysPCBeKEbjl+UMfB5ISpF9zG8n/ko4H2gnZnNBq4GJki6TVLRi7a2oD0c2AxvFQ/DncCd+IP04jJt/gfwSzwsty0eEm7AW0AzgJHF2tuC9qO4szta0srpkLnAdKCkEG4LNg/DW0CP4xGTHniYfE28NVhuXgwDPgH2knS4pKOBdfEozEnF6ibtH+CVzzNS0ofAjslGzOxFfHncUcXoLUL7NynpWTN7Jz3sPgb2T86rXN0zU9LtwMvpYfwhXuZanqaxNHunpAfnTvgiRBsCwyWdUIH26eDOKu3aG28BTgSOl7RzmbqFvLgLd9BjJT2LL0P8O+DUMnVPS0kd8JZfD0m34mXkOBaW41Ic9hfy2czuS+mNeIXxKUnbl2JvS7rA08A2kv6QdLvgFd8rKtSdBhyYGj3gEdGXgBHp/ynWYfcHngBWS78/A++W+5qkvhmt00nXL3tfS2qUdBZwdtK618x+j1d69gG+XMr/STpB3XxYGK6+FK/Vg4erRwF75HSOjnh/aoe0/XXgElJ4PHPcasAEYPMydb+BO7pz8JDXpmn/B8CJVkQoZjHae+IPkFOBXs1svh/oXabuINwhjcdb3D/KHPsMsFeF+XwRcHDa7gK8jM/RW2lejMT7p44F1s4cOxXoX6buXnjo9krg+8AteO2/VyovqxSpuwru8I7FW02F//ePePQhe/4pwMYl5HFz7Y1Setv0d/tUHrZt9rslhQBb1M3sXwG4tXk5q0QXjxZtlPk+nSLvvSXkRSfg1PT9ALyy+CywcjFlrgXdXil9YCoHW6TtPqm89SnT3oLuaXil8bi03YhXmnct9j5ZTF4Uun164JX8L5V47y2qLHfGKxdHpe12wNvAjmXqFuy6EI9oTMKji32S3V1LKBc7k545aXs0vvjVYXhLHrzx2xUYB6yXObZ/uqZj8LELU4CvZvaPTJ9Vi7XHzOrDaaeCOSLdBNvjrcjCO+ht04XaPsfzXQ8MzRSYw/CKQtfMMTsA15AegGXqHoq33uYAM/FW6+B0EzZWYHOHZPMovuik+iWbGyrQPQQ4H3g43UTd0k04Dtgwp3zuntIuJ/WtVah7KPBbvCY9OKX3xB1tKTd487w4NNm7RuaY7wIjSrR33fT3HGBc+t4eeIv0YMMrrJcBPSrQvj6TXrh/zgP+B3eEQyrVTWldgLvT927A/nnoZo5pwFtqW1aQFzek7yvhFc6/4w/g24BbKtC9MX1vA3TMHNOIr4JYSkWjJd12eATwZNI4lXQ/HpZzuRgPnJxNqyCP2wBjgZ0zx40CBpWpW7hHGvDxH19J2z3wSvSKJeiujHcpFvqzDwLOTt+fYuH9vi2ZSnRKa+7wLyr8Nm13Bx4EdkrbnYrJz5oPjzcLS07BwxQDMoc04eGMPPvvbwO2lLS2eajvaeBToJt8xPCvgd/jk76XMsK5ue7z+IP5+2a2gZndZmY34qOy51dg85xk8zxgLUmdk81jgH+Y97sVO7q5ue4MPBowGm9RXYBflxfM7OUKbC7k8zygS7Lv38BnZYRvW8rnN/Huh1MkXYmHWqea2Ztl6s7BQ3TzgJ6S1pB0Bv5QmQzFv35iZq+mrxcmrUFm9hHeqjo5hQZPBrbAu2eKppn2Rqm/EryyC16ZOQ4PDXct1u7F6AKsD3RKfYF3AGtVam/qzy1wIrAe8Col0Ex7Q0l7mNkneFRgipltYWbfBDaTVHRYs5nuBpK+bh5CzV6rE/CH+GsV6O5pZnPxe2494Mfpvi70mRfNYq5f4V67EX/erWDJ05ShW8jjJjxqdpmkTSSdhHcvPlumbs+UxwuAD8zs4bRvCN5lVfSz08w+NrNPbeES07vjUQDw8S+bSroDb9E/CV+4P54AxmXK5mS8IoGkRjN7Ha+snJA0LkznXHx+llL7WhY/LDqMWhjpuQHwVOb4VYqpzSzhnGvjLZBhmbSH8T7hI/HaXEktniXoFmqK7apg8zZ46/gPOdo8Ceibvm9NCa3VEvNjAGmUeg66j+ARmvXw2nSe1287oC9wFtCzwvL+Y2BiZnuPdM7ryrG5Be2HMts98IfReFJ0Iyfdn+EV6d9VYnMLut9L1/E6oFueedFsX9lvWrRg8yDgITxKU7bNLZSLLYBf4JGedfPOC3wE/BBKiMoVYfOIdO1uyLlc9MUr4XdV8CwqvHUznoXdBRsBq+IVjCVeOzySMrRZ2tl4xf7MYm2pi2lM5SOAHzWzS+QjU/fHH5Sn4H3a38EHBo0BZpvZ8BzO2Q9vNV2C9yFdiYeDp1kFmdqC7lj8VYXHasjmQth6chVsHouH5SrSbkH3CnysQEX5vAjdX5nZk5XoJu025qOEb8EjA014flR0/VrQ/mfSvh142cyKbv0VYfO7+ICh581sQk66b+BdSM/gEZ3Hy9Vtpv0n/NU34a/4TMlJt2Dzh3iI9cVKykcLugJ+bznMkdBCuWjEn6PP2sLWZ6W6b+GDHsfhZfmTnHTfwCOg9+F5XGqkL6srPMowFo+o/RCP9A21JcxxkVrahnfTHmNmL0vaFO962QN/DXRW0cZUUgNbVj64U76c1D+Lt+4uxIfXH4bXZP6XNKAkx/PugT+Un08XY5nWDZtrWzdpr4wPcHwb+GmVtN/JU7uZ7rHLur3VzOelkMfVLBe1lhd56+6AV2YfJjPItojfCe8XvwafGOpO3PmXNRdEvbS018Zf+H/PzM5OaZPwEM4BeIj8p5bpn5TyWWxCPr+2Wel9zK2iW03tsHmp6P4K7/s8wRbODbBMa9eabjW1a023mto1qNsdf6V1ZKm6knbAu24eAa40s8vLtqMenDa0GJa8Cp/+83nLhHFSmEP2xXfpcpl0JQiqTTXLarW0a023mtq1pltN7VrTrYRKHP5/adWL0waQtAceKu8HjDKzUc32f34xU59CP7w/Ye5SNzYIgiAISqSunDYsOSwpqR0+9/EQfPDDVNxxP5ZXyDwIgiAIqkHNv6fdHDP7rOCw1WyptDSK7xLgZ2bWFx8w9AGwh6QO4bCDIAiCZZm6c9pZMqHwjeXLWi7AXyvoKamb+asFk/B37XZvPUuDIAiCYMnUndOWNFLSKel7L0nj8Okdr5HU18zuxV/e/5/0k4n4u5gDJa3TKkYHQRAEQRHUY5/2zvikEOvhM0U9aWZjJT2IV1J2w+c7vhl/h3ayfEnGVczsgUVoRl93EARB0OrUldPOzIZzK/CWmQ2RtA3ejz0Fn27uJjMbIWk4vth6/yJ021ppc4gHQRAEQe7Um9OWmZmkNYBXgM3xJRI7m9lw+aLwI/A5pt/G57edsRi9HYCh+MIDVwAzrYKp+4IgCIKgEuqqTzs57DZm9m985a9b8BVd2klaH58lZwrQ3nz1lhmZFVm+gKTeeAv9DuBf+EIgh6R9xa6AFQRBEAS5UVdOGxaOGDezk/E1jbcD3scHnL1tZrua2bOZ4xcVatgJn03tBnwFrI+BgyT1TJWDcNxBEATBUqXunDZ84f3sYfjC6mcDfczsorS/oYXfHCDpNEn7pKQpQHdJG5mvXdyEv9N9BBSx5mkQBEEQ5ExdOu00GK2Nmd0KvCrpO2b2nqSG1O/9hbnIU1/38cAsYISkQ/Fl3R4GrpR0O7AtPuK8Mc2qFgRBEARLlcbWNqBaJMfdAfgIeDml/dcgshTq3hE4x8xukvQavpznm2Z2iqTNgF5mdpukbYFDY67yIAiCoDWoW6ed2BafW3xqNlHSIcD/4Quuvws8B3ST1Ghm96XXxL4mabqZTQemp5/uAkyO97aDIAiC1qDenfaDhQlT0sCxrsD1eP/0y0B7SUcBrwF9gI2A54GbgAuANYHXJfUFzk2/OzIcdhAEQdAa1GWfdoGCc5XUkL53AGab2a7AT/CBZZfg85F3AbaT1MnMZqV930pSM4FT08jzl5fyvxEEQRAEQJ23tCU1AqcDDZLuAjoCCwDMbL6kY/ABZ1/GW+D74e9yn423qqekY98BHlra9gdBEARBlrptaUvqDzwBrAa8BJwBfIb3VfeFz9/pPh0418zuwxcW+YqkKel3D7aC6UEQBEHQInU1jWmWtHBITzO7Jm2PBqYBnwBDzWyb9D53FzxEfpyZzZK0Kj5j2uxWMj0IgiAIWqRuW9p4K3tcZiKVScC6ZnYVHi4fmlra3YH5qR8bM3s/HHYQBEGwLFK3TjvNLf5p5t3s3fFFQgB+AGwq6Q58be0nW8PGIAiCICiFuh6IBp9PWWrAWsBfUvIc4CSgN/BKtKyDIAiCWqBuW9oZmoC2wDvA5ql1fQrQZGYPh8MOgiAIaoW6HYiWJa2L/Uj6XGlml7eySUEQBEFQMsuL0+4OHAyMNLNPW9ueIAiCICiH5cJpB0EQBEE9sDz0aQdBEARBXRBOOwiCIAhqhHDaQRAEQVAjhNMOgiAIghohnHYQBEEQ1AjhtIOgBpG0QNJTkqZLmirpF2kBnMX9pqekA0s4xxrpHE9JelPS7Mx2X0kXV/6fBEFQCvHKVxDUIJI+NLNV0vcu+Hrwk8xs+GJ+MwD4lZntVcb5TgU+NLMRZRkcBEEuREs7CGocM3sLOBI4Rk5PSRMlPZk+/dKh5wA7p5byzyU1SDpf0j8kPS3px8WeU9KANCUwkk6V9EdJf5M0S9K3JJ0naZqkuyW1TcdtI+khSU9IukfS2nnnRRDUO+G0g6AOMLOZ+P3cBXgL2N3Mtga+BxTC2CcCE81sSzO7APgR8IGZbQdsBxwhaf0yTdgQGATsC1wLPGBmffD16wclx30JsL+ZbQNcAZxZ5rmCYLml7lf5CoLlCKW/bYFRkrYEFgC9FnH8QHwRnf3TdidgY+CVMs493sw+kzQNaADuTunTgJ7AJviqevdKIh3zRhnnCYLlmnDaQVAHSNoAd9BvAcOBfwFb4K3vuYv6GTDUzO7JwYRPAcysSdJntnCwTBP+nBEw3cx2zOFcQbDcEuHxIKhxJHUGfgeMSs6yE/CGmTXhC+U0pEPnAB0yP70HOCrT59xLUvsqmTkD6Cxpx3SutpI2q9K5gqBuiZZ2ENQmK0l6Cg+FzweuAUamfaOBP0n6DvAA8FFKfxqYL2kqcBVwER66flIes34b2K8axprZvBSGv1hSJ/zZcyEwvRrnC4J6JV75CoIgCIIaIcLjQRAEQVAjhNMOgiAIghohnHYQBEEQ1AjhtIMgCIKgRginHQRBEAQ1QjjtIAiCIKgRwmkHQRAEQY0QTjsIgiAIaoT/B7qkLSPOEBU+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n",
    "plot_features = df[plot_cols]\n",
    "plot_features.index = date_time\n",
    "_ = plot_features.plot(subplots=True)\n",
    "\n",
    "plot_features = df[plot_cols][:480]\n",
    "plot_features.index = date_time[:480]\n",
    "_ = plot_features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p (mbar)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>989.212842</td>\n",
       "      <td>8.358886</td>\n",
       "      <td>913.60</td>\n",
       "      <td>984.20</td>\n",
       "      <td>989.57</td>\n",
       "      <td>994.720</td>\n",
       "      <td>1015.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T (degC)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>9.450482</td>\n",
       "      <td>8.423384</td>\n",
       "      <td>-22.76</td>\n",
       "      <td>3.35</td>\n",
       "      <td>9.41</td>\n",
       "      <td>15.480</td>\n",
       "      <td>37.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tpot (K)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>283.493086</td>\n",
       "      <td>8.504424</td>\n",
       "      <td>250.85</td>\n",
       "      <td>277.44</td>\n",
       "      <td>283.46</td>\n",
       "      <td>289.530</td>\n",
       "      <td>311.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>4.956471</td>\n",
       "      <td>6.730081</td>\n",
       "      <td>-24.80</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5.21</td>\n",
       "      <td>10.080</td>\n",
       "      <td>23.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rh (%)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>76.009788</td>\n",
       "      <td>16.474920</td>\n",
       "      <td>13.88</td>\n",
       "      <td>65.21</td>\n",
       "      <td>79.30</td>\n",
       "      <td>89.400</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>13.576576</td>\n",
       "      <td>7.739883</td>\n",
       "      <td>0.97</td>\n",
       "      <td>7.77</td>\n",
       "      <td>11.82</td>\n",
       "      <td>17.610</td>\n",
       "      <td>63.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>9.533968</td>\n",
       "      <td>4.183658</td>\n",
       "      <td>0.81</td>\n",
       "      <td>6.22</td>\n",
       "      <td>8.86</td>\n",
       "      <td>12.360</td>\n",
       "      <td>28.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>4.042536</td>\n",
       "      <td>4.898549</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.19</td>\n",
       "      <td>5.300</td>\n",
       "      <td>46.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>6.022560</td>\n",
       "      <td>2.655812</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.59</td>\n",
       "      <td>7.800</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>9.640437</td>\n",
       "      <td>4.234862</td>\n",
       "      <td>0.81</td>\n",
       "      <td>6.29</td>\n",
       "      <td>8.96</td>\n",
       "      <td>12.490</td>\n",
       "      <td>28.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>1216.061232</td>\n",
       "      <td>39.974263</td>\n",
       "      <td>1059.45</td>\n",
       "      <td>1187.47</td>\n",
       "      <td>1213.80</td>\n",
       "      <td>1242.765</td>\n",
       "      <td>1393.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wv (m/s)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>1.702567</td>\n",
       "      <td>65.447512</td>\n",
       "      <td>-9999.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.860</td>\n",
       "      <td>14.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>2.963041</td>\n",
       "      <td>75.597657</td>\n",
       "      <td>-9999.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.98</td>\n",
       "      <td>4.740</td>\n",
       "      <td>23.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wd (deg)</th>\n",
       "      <td>70091.0</td>\n",
       "      <td>174.789095</td>\n",
       "      <td>86.619431</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125.30</td>\n",
       "      <td>198.10</td>\n",
       "      <td>234.000</td>\n",
       "      <td>360.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count         mean        std      min      25%      50%  \\\n",
       "p (mbar)         70091.0   989.212842   8.358886   913.60   984.20   989.57   \n",
       "T (degC)         70091.0     9.450482   8.423384   -22.76     3.35     9.41   \n",
       "Tpot (K)         70091.0   283.493086   8.504424   250.85   277.44   283.46   \n",
       "Tdew (degC)      70091.0     4.956471   6.730081   -24.80     0.24     5.21   \n",
       "rh (%)           70091.0    76.009788  16.474920    13.88    65.21    79.30   \n",
       "VPmax (mbar)     70091.0    13.576576   7.739883     0.97     7.77    11.82   \n",
       "VPact (mbar)     70091.0     9.533968   4.183658     0.81     6.22     8.86   \n",
       "VPdef (mbar)     70091.0     4.042536   4.898549     0.00     0.87     2.19   \n",
       "sh (g/kg)        70091.0     6.022560   2.655812     0.51     3.92     5.59   \n",
       "H2OC (mmol/mol)  70091.0     9.640437   4.234862     0.81     6.29     8.96   \n",
       "rho (g/m**3)     70091.0  1216.061232  39.974263  1059.45  1187.47  1213.80   \n",
       "wv (m/s)         70091.0     1.702567  65.447512 -9999.00     0.99     1.76   \n",
       "max. wv (m/s)    70091.0     2.963041  75.597657 -9999.00     1.76     2.98   \n",
       "wd (deg)         70091.0   174.789095  86.619431     0.00   125.30   198.10   \n",
       "\n",
       "                      75%      max  \n",
       "p (mbar)          994.720  1015.29  \n",
       "T (degC)           15.480    37.28  \n",
       "Tpot (K)          289.530   311.21  \n",
       "Tdew (degC)        10.080    23.06  \n",
       "rh (%)             89.400   100.00  \n",
       "VPmax (mbar)       17.610    63.77  \n",
       "VPact (mbar)       12.360    28.25  \n",
       "VPdef (mbar)        5.300    46.01  \n",
       "sh (g/kg)           7.800    18.07  \n",
       "H2OC (mmol/mol)    12.490    28.74  \n",
       "rho (g/m**3)     1242.765  1393.54  \n",
       "wv (m/s)            2.860    14.01  \n",
       "max. wv (m/s)       4.740    23.50  \n",
       "wd (deg)          234.000   360.00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv = df['wv (m/s)']\n",
    "bad_wv = wv == -9999.0\n",
    "wv[bad_wv] = 0.0\n",
    "\n",
    "max_wv = df['max. wv (m/s)']\n",
    "bad_max_wv = max_wv == -9999.0\n",
    "max_wv[bad_max_wv] = 0.0\n",
    "\n",
    "# The above inplace edits are reflected in the DataFrame\n",
    "df['wv (m/s)'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Wind Velocity [m/s]')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(df['wd (deg)'], df['wv (m/s)'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind Direction [deg]')\n",
    "plt.ylabel('Wind Velocity [m/s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = df.pop('wv (m/s)')\n",
    "max_wv = df.pop('max. wv (m/s)')\n",
    "\n",
    "# Convert to radians.\n",
    "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
    "\n",
    "# Calculate the wind x and y components.\n",
    "df['Wx'] = wv*np.cos(wd_rad)\n",
    "df['Wy'] = wv*np.sin(wd_rad)\n",
    "\n",
    "# Calculate the max wind x and y components.\n",
    "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
    "df['max Wy'] = max_wv*np.sin(wd_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-11.305513973134667, 8.24469928549079, -8.27438540335515, 7.7338312955467785)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]')\n",
    "ax = plt.gca()\n",
    "ax.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_s = date_time.map(datetime.datetime.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 24*60*60\n",
    "year = (365.2425)*day\n",
    "\n",
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Time of day signal')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(df['Day sin'])[:25])\n",
    "plt.plot(np.array(df['Day cos'])[:25])\n",
    "plt.xlabel('Time [h]')\n",
    "plt.title('Time of day signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'est ce qui est montré sur ce schéma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fft = tf.signal.rfft(df['T (degC)']) ### utilisation de tensorflow\n",
    "f_per_dataset = np.arange(0, len(fft))\n",
    "\n",
    "n_samples_h = len(df['T (degC)'])\n",
    "hours_per_year = 24*365.2524\n",
    "years_per_dataset = n_samples_h/(hours_per_year)\n",
    "\n",
    "f_per_year = f_per_dataset/years_per_dataset\n",
    "plt.step(f_per_year, np.abs(fft))\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 400000)\n",
    "plt.xlim([0.1, max(plt.xlim())])\n",
    "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
    "_ = plt.xlabel('Frequency (log scale)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "num_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_std = (df - train_mean) / train_std\n",
    "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data windowing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self,\n",
    "                 input_width,\n",
    "                 label_width,\n",
    "                 shift,\n",
    "                 train_df = train_df,\n",
    "                 val_df = val_df, \n",
    "                 test_df = test_df,\n",
    "                 label_columns = None,\n",
    "                 dataframe = None):\n",
    "        if dataframe is not None: \n",
    "            self.y = dataframe[label_columns]\n",
    "            self.x = dataframe\n",
    "        \n",
    "        # Store the raw data\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        # Work out the label column indices\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = { name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = { name: i for i, name in enumerate(train_df.columns)}\n",
    "        \n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        \n",
    "        self.total_window_size = input_width + shift\n",
    "        \n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        \n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.label_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.label_slice]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y) // self.total_window_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.x.iloc[self.input_indices + self.total_window_size*idx].values, \n",
    "            self.y.iloc[self.label_indices + self.total_window_size*idx].values,\n",
    "        )\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(input_width = 24, label_width = 1, shift = 24, label_columns=['T (degC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total window size: 48\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Label indices: [47]\n",
      "Label column name(s): ['T (degC)']\n"
     ]
    }
   ],
   "source": [
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = WindowGenerator(input_width = 6, label_width = 1, shift = 1, label_columns=['T (degC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total window size: 7\n",
      "Input indices: [0 1 2 3 4 5]\n",
      "Label indices: [6]\n",
      "Label column name(s): ['T (degC)']\n"
     ]
    }
   ],
   "source": [
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "    #print(self.input_slice)\n",
    "    #print(self.label_slice)\n",
    "    #print(features[:, self.input_slice, :])\n",
    "    inputs = features[:, self.input_slice, :]\n",
    "    labels = features[:, self.label_slice, :]\n",
    "    if self.label_columns is not None:\n",
    "        #labels = tf.stack(\n",
    "        #[labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        #axis=-1) ## utilisation de tensorflow\n",
    "        labels = torch.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1\n",
    "        )\n",
    "\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the tf.data.Datasets are easier to inspect.\n",
    "\n",
    "    #inputs.set_shape([None, self.input_width, None])\n",
    "    #labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are: (batch, time, feature)\n",
      "Window shape: torch.Size([3, 7, 19])\n",
      "Inputs shape: torch.Size([3, 6, 19])\n",
      "labels shape: torch.Size([3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Stack three slices, the length of the total window:\n",
    "#example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "#                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "#                           np.array(train_df[200:200+w2.total_window_size])]) # utilisation de tensorflow\n",
    "example_window = torch.stack([torch.tensor(train_df[:w2.total_window_size].values),\n",
    "                                torch.tensor(train_df[100:100+w2.total_window_size].values),\n",
    "                                torch.tensor(train_df[200:200+w2.total_window_size].values)])\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, feature)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2.example = example_inputs, example_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
    "    inputs, labels = self.example\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plot_col_index = self.column_indices[plot_col]\n",
    "    max_n = min(max_subplots, len(inputs))\n",
    "    for n in range(max_n):\n",
    "        plt.subplot(3, 1, n+1)\n",
    "        plt.ylabel(f'{plot_col} [normed]')\n",
    "        plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                 label='Inputs', marker='.', zorder=-10)\n",
    "        \n",
    "        if self.label_columns:\n",
    "            label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "        else:\n",
    "            label_col_index = plot_col_index\n",
    "            \n",
    "        if label_col_index is None:\n",
    "            continue\n",
    "            \n",
    "        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "        if model is not None:\n",
    "            predictions = model(inputs)\n",
    "            plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                        marker = 'X', edgecolors = 'k', label = 'Predictions', \n",
    "                        c = '#ff7f0e', s=64)\n",
    "            \n",
    "        if n == 0:\n",
    "            plt.legend()\n",
    "    plt.xlabel('Time [h]')\n",
    "    \n",
    "WindowGenerator.plot = plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    input_width = 1,\n",
    "    label_width = 1,\n",
    "    shift = 1,\n",
    "    label_columns = ['T (degC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 2\n",
       "Input indices: [0]\n",
       "Label indices: [1]\n",
       "Label column name(s): ['T (degC)']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_ds = WindowGenerator(\n",
    "    dataframe=train_df, label_columns=['T (degC)'],\n",
    "    input_width=1, label_width=1, shift=1\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "val_ds = WindowGenerator(\n",
    "    dataframe=val_df, label_columns=['T (degC)'],\n",
    "    input_width=1, label_width=1, shift=1\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24531\n",
      "49063\n",
      "2\n",
      "24531\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds.y) // train_ds.total_window_size)\n",
    "print(len(train_ds.y))\n",
    "print(train_ds.total_window_size)\n",
    "print(len(train_ds))\n",
    "#print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 19]) torch.Size([4, 1, 1])\n",
      "tensor([[[ 9.4531e-01, -1.9825e+00, -2.0419e+00, -1.9190e+00,  1.1171e+00,\n",
      "          -1.3029e+00, -1.4773e+00, -7.9042e-01, -1.4800e+00, -1.4827e+00,\n",
      "           2.2185e+00,  1.9341e-01,  2.2116e-01,  1.1114e-01,  2.1793e-01,\n",
      "           4.7198e-05,  1.4142e+00, -6.2412e-02,  1.4285e+00]],\n",
      "\n",
      "        [[ 9.8628e-01, -2.0703e+00, -2.1324e+00, -2.0452e+00,  1.0627e+00,\n",
      "          -1.3288e+00, -1.5272e+00, -7.8835e-01, -1.5287e+00, -1.5320e+00,\n",
      "           2.3240e+00,  2.0798e-01,  2.7627e-01,  1.1122e-01,  3.2408e-01,\n",
      "           7.0718e-01,  1.2248e+00, -6.0366e-02,  1.4284e+00]],\n",
      "\n",
      "        [[ 1.0610e+00, -2.1650e+00, -2.2322e+00, -2.1872e+00,  9.8421e-01,\n",
      "          -1.3535e+00, -1.5795e+00, -7.8212e-01, -1.5811e+00, -1.5860e+00,\n",
      "           2.4463e+00,  1.1226e-01,  3.5082e-01,  4.8640e-02,  4.0205e-01,\n",
      "           1.2248e+00,  7.0718e-01, -5.8320e-02,  1.4284e+00]],\n",
      "\n",
      "        [[ 1.1659e+00, -2.1119e+00, -2.1863e+00, -2.1083e+00,  1.0265e+00,\n",
      "          -1.3405e+00, -1.5510e+00, -7.8420e-01, -1.5549e+00, -1.5578e+00,\n",
      "           2.4168e+00,  1.3088e+00, -8.0017e-03,  1.2110e+00,  5.7261e-02,\n",
      "           1.4143e+00,  1.2304e-04, -5.6274e-02,  1.4284e+00]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[[-2.0784]],\n",
      "\n",
      "        [[-2.0980]],\n",
      "\n",
      "        [[-2.1696]],\n",
      "\n",
      "        [[-1.9883]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for (inputs, label) in train_loader:\n",
    "    print(inputs.shape, label.shape)\n",
    "    print(inputs)\n",
    "    print(label)\n",
    "    break\n",
    "#print(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x[:, -1, 1].reshape((x.shape[0], -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (inputs, label) in train_loader:\n",
    "    out = baseline(inputs)\n",
    "    print(out)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0\n",
    "pbar = tqdm(val_loader)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, label) in enumerate (pbar):\n",
    "        out = baseline(inputs)\n",
    "        running_loss += loss(out, label) \n",
    "        if not (i % 100):\n",
    "            #print(f\"Loss total: {running_loss}\")\n",
    "            pbar.set_description(f\"Loss: {running_loss / (i+1):.5f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "outputs = []\n",
    "\n",
    "for i in range(24):\n",
    "    targets.append(float(val_ds[i][1]))\n",
    "    outputs.append(baseline(val_ds[i][0][None, :]).squeeze())\n",
    "    \n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(targets, \"xr-\", label=\"Targets\")\n",
    "plt.plot(outputs, \"ok\", label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_ds[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_ds[i][0][None, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.dense = nn.Linear(19, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = Linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4381]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.6778]],\n",
      "\n",
      "        [[-0.4847]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for (inputs, label) in train_loader:\n",
    "    out = linear(inputs.float())\n",
    "    print(out)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.03185): 100%|██████████| 6133/6133 [00:09<00:00, 635.21it/s]\n",
      "Epoch #2 - Loss = 0.00899): 100%|██████████| 6133/6133 [00:09<00:00, 618.57it/s]\n",
      "Epoch #3 - Loss = 0.00893): 100%|██████████| 6133/6133 [00:10<00:00, 613.17it/s]\n",
      "Epoch #4 - Loss = 0.00890): 100%|██████████| 6133/6133 [00:10<00:00, 593.48it/s]\n",
      "Epoch #5 - Loss = 0.00889): 100%|██████████| 6133/6133 [00:09<00:00, 636.81it/s]\n",
      "Epoch #6 - Loss = 0.00888): 100%|██████████| 6133/6133 [00:09<00:00, 627.27it/s]\n",
      "Epoch #7 - Loss = 0.00887): 100%|██████████| 6133/6133 [00:09<00:00, 622.68it/s]\n",
      "Epoch #8 - Loss = 0.00886): 100%|██████████| 6133/6133 [00:10<00:00, 573.89it/s]\n",
      "Epoch #9 - Loss = 0.00885): 100%|██████████| 6133/6133 [00:10<00:00, 601.26it/s]\n",
      "Epoch #10 - Loss = 0.00885): 100%|██████████| 6133/6133 [00:10<00:00, 599.14it/s]\n",
      "Epoch #11 - Loss = 0.00885): 100%|██████████| 6133/6133 [00:09<00:00, 625.68it/s]\n",
      "Epoch #12 - Loss = 0.00884): 100%|██████████| 6133/6133 [00:09<00:00, 643.80it/s]\n",
      "Epoch #13 - Loss = 0.00884): 100%|██████████| 6133/6133 [00:09<00:00, 644.49it/s]\n",
      "Epoch #14 - Loss = 0.00884): 100%|██████████| 6133/6133 [00:09<00:00, 650.41it/s]\n",
      "Epoch #15 - Loss = 0.00884): 100%|██████████| 6133/6133 [00:10<00:00, 605.31it/s]\n",
      "Epoch #16 - Loss = 0.00884): 100%|██████████| 6133/6133 [00:09<00:00, 628.76it/s]\n",
      "Epoch #17 - Loss = 0.00884): 100%|██████████| 6133/6133 [00:09<00:00, 619.94it/s]\n",
      "Epoch #18 - Loss = 0.00884): 100%|██████████| 6133/6133 [00:09<00:00, 623.77it/s]\n",
      "Epoch #19 - Loss = 0.00884): 100%|██████████| 6133/6133 [00:10<00:00, 581.29it/s]\n",
      "Epoch #20 - Loss = 0.00883): 100%|██████████| 6133/6133 [00:09<00:00, 630.12it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_EPOCHS = 20\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(linear.parameters())\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    running_loss = 0\n",
    "    pbar = tqdm(train_loader)\n",
    "    for i, (inputs, label) in enumerate(pbar):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = linear(inputs.float())\n",
    "        loss = criterion(outputs, label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if not(i % 100):\n",
    "            pbar.set_description(\n",
    "            f\"Epoch #{epoch+1} - Loss = {running_loss / (i+1):.5f})\"\n",
    "            )\n",
    "            history.append(running_loss / (i+1))\n",
    "        \n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets = []\n",
    "outputs = []\n",
    "for i in range(24):\n",
    "    outputs.append(linear(torch.Tensor(val_ds[i][0])))\n",
    "    targets.append(val_ds[i][1].squeeze())\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(targets, \"xr-\", label=\"Targets\")\n",
    "plt.plot(outputs, \"ok\", label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x = range(len(train_df.columns)),\n",
    "       height = list(linear.parameters())[0].data.squeeze().numpy()\n",
    "       )\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(len(train_df.columns)))\n",
    "_ = axis.set_xticklabels(train_df.columns, rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dense, self).__init__()\n",
    "        self.dense_1 = nn.Linear(19,64)\n",
    "        self.dense_2 = nn.Linear(64,64)\n",
    "        self.dense_3 = nn.Linear(64,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dense_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2105],\n",
      "         [-0.2090],\n",
      "         [-0.2006]],\n",
      "\n",
      "        [[-0.1878],\n",
      "         [-0.1842],\n",
      "         [-0.2095]],\n",
      "\n",
      "        [[-0.1755],\n",
      "         [-0.1839],\n",
      "         [-0.1724]],\n",
      "\n",
      "        [[-0.1976],\n",
      "         [-0.2034],\n",
      "         [-0.2094]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for (inputs, label) in train_loader:\n",
    "    out = dense(inputs.float())\n",
    "    print(out)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.01938): 100%|██████████| 6133/6133 [00:10<00:00, 581.47it/s]\n",
      "Epoch #2 - Loss = 0.00868): 100%|██████████| 6133/6133 [00:10<00:00, 583.83it/s]\n",
      "Epoch #3 - Loss = 0.00818): 100%|██████████| 6133/6133 [00:10<00:00, 592.38it/s]\n",
      "Epoch #4 - Loss = 0.00790): 100%|██████████| 6133/6133 [00:10<00:00, 585.43it/s]\n",
      "Epoch #5 - Loss = 0.00771): 100%|██████████| 6133/6133 [00:11<00:00, 531.11it/s]\n",
      "Epoch #6 - Loss = 0.00757): 100%|██████████| 6133/6133 [00:11<00:00, 540.45it/s]\n",
      "Epoch #7 - Loss = 0.00746): 100%|██████████| 6133/6133 [00:11<00:00, 539.80it/s]\n",
      "Epoch #8 - Loss = 0.00736): 100%|██████████| 6133/6133 [00:10<00:00, 586.23it/s]\n",
      "Epoch #9 - Loss = 0.00728): 100%|██████████| 6133/6133 [00:10<00:00, 580.48it/s]\n",
      "Epoch #10 - Loss = 0.00720): 100%|██████████| 6133/6133 [00:10<00:00, 583.18it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_EPOCHS = 10\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(linear.parameters()) ## Pourquoi ne marche pas avec cet optimiseur?\n",
    "optimizer = optim.SGD(dense.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    running_loss = 0\n",
    "    pbar = tqdm(train_loader)\n",
    "    for i, (inputs, label) in enumerate(pbar):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = dense(inputs.float())\n",
    "        loss = criterion(outputs, label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if not(i % 100):\n",
    "            pbar.set_description(\n",
    "            f\"Epoch #{epoch+1} - Loss = {running_loss / (i+1):.5f})\"\n",
    "            )\n",
    "            history.append(running_loss / (i+1))\n",
    "        \n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets = []\n",
    "outputs = []\n",
    "for i in range(24):\n",
    "    outputs.append(dense(torch.Tensor(val_ds[i][0])))\n",
    "    targets.append(val_ds[i][1].squeeze())\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(targets, \"xr-\", label=\"Targets\")\n",
    "plt.plot(outputs, \"ok\", label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-step dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "CONV_WIDTH = 3\n",
    "\n",
    "train_ds = WindowGenerator(\n",
    "    dataframe = train_df,\n",
    "    input_width = CONV_WIDTH,\n",
    "    label_width = 1,\n",
    "    shift = 1,\n",
    "    label_columns = ['T (degC)']\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "val_ds = WindowGenerator(\n",
    "    dataframe = val_df, \n",
    "    input_width = CONV_WIDTH,\n",
    "    label_width = 1,\n",
    "    shift = 1,\n",
    "    label_columns = ['T (degC)']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size = BATCH_SIZE, shuffle = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 19]) torch.Size([4, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for (inputs, label) in train_loader:\n",
    "    print(inputs.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.4531e-01, -1.9825e+00, -2.0419e+00, -1.9190e+00,  1.1171e+00,\n",
      "          -1.3029e+00, -1.4773e+00, -7.9042e-01, -1.4800e+00, -1.4827e+00,\n",
      "           2.2185e+00,  1.9341e-01,  2.2116e-01,  1.1114e-01,  2.1793e-01,\n",
      "           4.7198e-05,  1.4142e+00, -6.2412e-02,  1.4285e+00],\n",
      "         [ 9.5977e-01, -2.0784e+00, -2.1382e+00, -2.0610e+00,  1.0446e+00,\n",
      "          -1.3301e+00, -1.5344e+00, -7.8627e-01, -1.5362e+00, -1.5390e+00,\n",
      "           2.3257e+00,  1.7299e-01,  2.2210e-01,  1.0946e-01,  2.2780e-01,\n",
      "           3.6609e-01,  1.3661e+00, -6.1389e-02,  1.4284e+00],\n",
      "         [ 9.8628e-01, -2.0703e+00, -2.1324e+00, -2.0452e+00,  1.0627e+00,\n",
      "          -1.3288e+00, -1.5272e+00, -7.8835e-01, -1.5287e+00, -1.5320e+00,\n",
      "           2.3240e+00,  2.0798e-01,  2.7627e-01,  1.1122e-01,  3.2408e-01,\n",
      "           7.0718e-01,  1.2248e+00, -6.0366e-02,  1.4284e+00]],\n",
      "\n",
      "        [[ 1.0610e+00, -2.1650e+00, -2.2322e+00, -2.1872e+00,  9.8421e-01,\n",
      "          -1.3535e+00, -1.5795e+00, -7.8212e-01, -1.5811e+00, -1.5860e+00,\n",
      "           2.4463e+00,  1.1226e-01,  3.5082e-01,  4.8640e-02,  4.0205e-01,\n",
      "           1.2248e+00,  7.0718e-01, -5.8320e-02,  1.4284e+00],\n",
      "         [ 1.0911e+00, -2.1696e+00, -2.2390e+00, -2.1829e+00,  1.0144e+00,\n",
      "          -1.3548e+00, -1.5795e+00, -7.8627e-01, -1.5811e+00, -1.5836e+00,\n",
      "           2.4590e+00,  2.7459e-01,  2.6863e-01,  1.7511e-01,  3.7753e-01,\n",
      "           1.3661e+00,  3.6613e-01, -5.7297e-02,  1.4284e+00],\n",
      "         [ 1.1659e+00, -2.1119e+00, -2.1863e+00, -2.1083e+00,  1.0265e+00,\n",
      "          -1.3405e+00, -1.5510e+00, -7.8420e-01, -1.5549e+00, -1.5578e+00,\n",
      "           2.4168e+00,  1.3088e+00, -8.0017e-03,  1.2110e+00,  5.7261e-02,\n",
      "           1.4143e+00,  1.2304e-04, -5.6274e-02,  1.4284e+00]],\n",
      "\n",
      "        [[ 1.3298e+00, -1.9374e+00, -2.0258e+00, -1.9276e+00,  9.2381e-01,\n",
      "          -1.2899e+00, -1.4797e+00, -7.6759e-01, -1.4838e+00, -1.4874e+00,\n",
      "           2.2742e+00,  1.3880e-01,  1.6846e-01,  1.2115e-01,  1.7993e-01,\n",
      "           1.2248e+00, -7.0694e-01, -5.4229e-02,  1.4284e+00],\n",
      "         [ 1.3997e+00, -1.8658e+00, -1.9594e+00, -1.8315e+00,  9.4797e-01,\n",
      "          -1.2678e+00, -1.4393e+00, -7.6759e-01, -1.4463e+00, -1.4498e+00,\n",
      "           2.2161e+00,  5.7201e-01, -6.0656e-01,  6.7631e-01, -7.8645e-01,\n",
      "           1.0001e+00, -9.9981e-01, -5.3206e-02,  1.4283e+00],\n",
      "         [ 1.4720e+00, -1.9085e+00, -2.0075e+00, -1.9018e+00,  8.9361e-01,\n",
      "          -1.2808e+00, -1.4702e+00, -7.6136e-01, -1.4763e+00, -1.4780e+00,\n",
      "           2.2813e+00,  2.8856e-01, -9.7242e-01,  3.0012e-01, -1.0194e+00,\n",
      "           7.0718e-01, -1.2245e+00, -5.2183e-02,  1.4283e+00]],\n",
      "\n",
      "        [[ 1.3707e+00, -1.7329e+00, -1.8253e+00, -1.7297e+00,  7.6676e-01,\n",
      "          -1.2249e+00, -1.3965e+00, -7.3646e-01, -1.4014e+00, -1.4052e+00,\n",
      "           2.0689e+00,  1.4308e-02,  2.0434e-01, -8.8801e-02,  2.1017e-01,\n",
      "           4.7198e-05, -1.4140e+00, -5.0137e-02,  1.4283e+00],\n",
      "         [ 1.3442e+00, -1.7387e+00, -1.8287e+00, -1.7253e+00,  7.9696e-01,\n",
      "          -1.2262e+00, -1.3942e+00, -7.4061e-01, -1.4014e+00, -1.4029e+00,\n",
      "           2.0674e+00, -2.0721e-01,  7.2125e-01, -2.0972e-01,  7.1955e-01,\n",
      "          -3.6599e-01, -1.3658e+00, -4.9114e-02,  1.4283e+00],\n",
      "         [ 1.3527e+00, -1.7098e+00, -1.8012e+00, -1.6637e+00,  8.7549e-01,\n",
      "          -1.2171e+00, -1.3656e+00, -7.5099e-01, -1.3715e+00, -1.3747e+00,\n",
      "           2.0391e+00, -1.1510e-01,  7.8147e-01, -1.1667e-01,  7.7914e-01,\n",
      "          -7.0709e-01, -1.2245e+00, -4.8091e-02,  1.4283e+00]]])\n",
      "tensor([[ 9.4531e-01, -1.9825e+00, -2.0419e+00, -1.9190e+00,  1.1171e+00,\n",
      "         -1.3029e+00, -1.4773e+00, -7.9042e-01, -1.4800e+00, -1.4827e+00,\n",
      "          2.2185e+00,  1.9341e-01,  2.2116e-01,  1.1114e-01,  2.1793e-01,\n",
      "          4.7198e-05,  1.4142e+00, -6.2412e-02,  1.4285e+00,  9.5977e-01,\n",
      "         -2.0784e+00, -2.1382e+00, -2.0610e+00,  1.0446e+00, -1.3301e+00,\n",
      "         -1.5344e+00, -7.8627e-01, -1.5362e+00, -1.5390e+00,  2.3257e+00,\n",
      "          1.7299e-01,  2.2210e-01,  1.0946e-01,  2.2780e-01,  3.6609e-01,\n",
      "          1.3661e+00, -6.1389e-02,  1.4284e+00,  9.8628e-01, -2.0703e+00,\n",
      "         -2.1324e+00, -2.0452e+00,  1.0627e+00, -1.3288e+00, -1.5272e+00,\n",
      "         -7.8835e-01, -1.5287e+00, -1.5320e+00,  2.3240e+00,  2.0798e-01,\n",
      "          2.7627e-01,  1.1122e-01,  3.2408e-01,  7.0718e-01,  1.2248e+00,\n",
      "         -6.0366e-02,  1.4284e+00],\n",
      "        [ 1.0610e+00, -2.1650e+00, -2.2322e+00, -2.1872e+00,  9.8421e-01,\n",
      "         -1.3535e+00, -1.5795e+00, -7.8212e-01, -1.5811e+00, -1.5860e+00,\n",
      "          2.4463e+00,  1.1226e-01,  3.5082e-01,  4.8640e-02,  4.0205e-01,\n",
      "          1.2248e+00,  7.0718e-01, -5.8320e-02,  1.4284e+00,  1.0911e+00,\n",
      "         -2.1696e+00, -2.2390e+00, -2.1829e+00,  1.0144e+00, -1.3548e+00,\n",
      "         -1.5795e+00, -7.8627e-01, -1.5811e+00, -1.5836e+00,  2.4590e+00,\n",
      "          2.7459e-01,  2.6863e-01,  1.7511e-01,  3.7753e-01,  1.3661e+00,\n",
      "          3.6613e-01, -5.7297e-02,  1.4284e+00,  1.1659e+00, -2.1119e+00,\n",
      "         -2.1863e+00, -2.1083e+00,  1.0265e+00, -1.3405e+00, -1.5510e+00,\n",
      "         -7.8420e-01, -1.5549e+00, -1.5578e+00,  2.4168e+00,  1.3088e+00,\n",
      "         -8.0017e-03,  1.2110e+00,  5.7261e-02,  1.4143e+00,  1.2304e-04,\n",
      "         -5.6274e-02,  1.4284e+00],\n",
      "        [ 1.3298e+00, -1.9374e+00, -2.0258e+00, -1.9276e+00,  9.2381e-01,\n",
      "         -1.2899e+00, -1.4797e+00, -7.6759e-01, -1.4838e+00, -1.4874e+00,\n",
      "          2.2742e+00,  1.3880e-01,  1.6846e-01,  1.2115e-01,  1.7993e-01,\n",
      "          1.2248e+00, -7.0694e-01, -5.4229e-02,  1.4284e+00,  1.3997e+00,\n",
      "         -1.8658e+00, -1.9594e+00, -1.8315e+00,  9.4797e-01, -1.2678e+00,\n",
      "         -1.4393e+00, -7.6759e-01, -1.4463e+00, -1.4498e+00,  2.2161e+00,\n",
      "          5.7201e-01, -6.0656e-01,  6.7631e-01, -7.8645e-01,  1.0001e+00,\n",
      "         -9.9981e-01, -5.3206e-02,  1.4283e+00,  1.4720e+00, -1.9085e+00,\n",
      "         -2.0075e+00, -1.9018e+00,  8.9361e-01, -1.2808e+00, -1.4702e+00,\n",
      "         -7.6136e-01, -1.4763e+00, -1.4780e+00,  2.2813e+00,  2.8856e-01,\n",
      "         -9.7242e-01,  3.0012e-01, -1.0194e+00,  7.0718e-01, -1.2245e+00,\n",
      "         -5.2183e-02,  1.4283e+00],\n",
      "        [ 1.3707e+00, -1.7329e+00, -1.8253e+00, -1.7297e+00,  7.6676e-01,\n",
      "         -1.2249e+00, -1.3965e+00, -7.3646e-01, -1.4014e+00, -1.4052e+00,\n",
      "          2.0689e+00,  1.4308e-02,  2.0434e-01, -8.8801e-02,  2.1017e-01,\n",
      "          4.7198e-05, -1.4140e+00, -5.0137e-02,  1.4283e+00,  1.3442e+00,\n",
      "         -1.7387e+00, -1.8287e+00, -1.7253e+00,  7.9696e-01, -1.2262e+00,\n",
      "         -1.3942e+00, -7.4061e-01, -1.4014e+00, -1.4029e+00,  2.0674e+00,\n",
      "         -2.0721e-01,  7.2125e-01, -2.0972e-01,  7.1955e-01, -3.6599e-01,\n",
      "         -1.3658e+00, -4.9114e-02,  1.4283e+00,  1.3527e+00, -1.7098e+00,\n",
      "         -1.8012e+00, -1.6637e+00,  8.7549e-01, -1.2171e+00, -1.3656e+00,\n",
      "         -7.5099e-01, -1.3715e+00, -1.3747e+00,  2.0391e+00, -1.1510e-01,\n",
      "          7.8147e-01, -1.1667e-01,  7.7914e-01, -7.0709e-01, -1.2245e+00,\n",
      "         -4.8091e-02,  1.4283e+00]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.float())\n",
    "print(torch.flatten(inputs, start_dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiStepDense,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_1 = nn.Linear(19*CONV_WIDTH,32)\n",
    "        self.dense_2 = nn.Linear(32,32)\n",
    "        self.dense_3 = nn.Linear(32,1)\n",
    "        #self.reshape = torch.reshape([1, -1])\n",
    "        #self.reshape = nn.Unflatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense_3(x)\n",
    "        x = torch.reshape(x, [1,-1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "multistep = MultiStepDense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0142, -0.0289, -0.0156,  0.0518]], grad_fn=<ViewBackward>)\n",
      "tensor([[[-2.0980]],\n",
      "\n",
      "        [[-1.9883]],\n",
      "\n",
      "        [[-1.8461]],\n",
      "\n",
      "        [[-1.6763]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for (inputs, label) in train_loader:\n",
    "    out = multistep(inputs.float())\n",
    "    print(out)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3067 [00:00<?, ?it/s]/usr/local/anaconda3/envs/batteryprobeai/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([4, 1, 1])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch #1 - Loss = 4.70757:   1%|          | 32/3067 [00:00<00:09, 310.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2150],\n",
      "        [0.2783],\n",
      "        [0.2710],\n",
      "        [0.2820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0980]],\n",
      "\n",
      "        [[-1.9883]],\n",
      "\n",
      "        [[-1.8461]],\n",
      "\n",
      "        [[-1.6763]]], dtype=torch.float64)\n",
      "tensor([[0.1924],\n",
      "        [0.1802],\n",
      "        [0.1693],\n",
      "        [0.1928]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6185]],\n",
      "\n",
      "        [[-1.5769]],\n",
      "\n",
      "        [[-1.5815]],\n",
      "\n",
      "        [[-1.5527]]], dtype=torch.float64)\n",
      "tensor([[0.1987],\n",
      "        [0.2033],\n",
      "        [0.1149],\n",
      "        [0.1691]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4129]],\n",
      "\n",
      "        [[-1.3713]],\n",
      "\n",
      "        [[-1.4337]],\n",
      "\n",
      "        [[-1.5966]]], dtype=torch.float64)\n",
      "tensor([[0.1130],\n",
      "        [0.1333],\n",
      "        [0.1901],\n",
      "        [0.2340]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7699]],\n",
      "\n",
      "        [[-2.1246]],\n",
      "\n",
      "        [[-1.7410]],\n",
      "\n",
      "        [[-1.3759]]], dtype=torch.float64)\n",
      "tensor([[0.1424],\n",
      "        [0.1349],\n",
      "        [0.0680],\n",
      "        [0.0615]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4960]],\n",
      "\n",
      "        [[-1.2719]],\n",
      "\n",
      "        [[-1.2696]],\n",
      "\n",
      "        [[-1.1552]]], dtype=torch.float64)\n",
      "tensor([[ 0.0166],\n",
      "        [ 0.0124],\n",
      "        [-0.0116],\n",
      "        [-0.0050]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1922]],\n",
      "\n",
      "        [[-1.1737]],\n",
      "\n",
      "        [[-1.2326]],\n",
      "\n",
      "        [[-1.2222]]], dtype=torch.float64)\n",
      "tensor([[-0.0958],\n",
      "        [-0.0641],\n",
      "        [-0.0646],\n",
      "        [-0.0205]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2557]],\n",
      "\n",
      "        [[-1.3666]],\n",
      "\n",
      "        [[-1.4741]],\n",
      "\n",
      "        [[-1.7156]]], dtype=torch.float64)\n",
      "tensor([[-0.1403],\n",
      "        [-0.0798],\n",
      "        [-0.1152],\n",
      "        [-0.1133]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1073]],\n",
      "\n",
      "        [[-2.5117]],\n",
      "\n",
      "        [[-2.7034]],\n",
      "\n",
      "        [[-3.0073]]], dtype=torch.float64)\n",
      "tensor([[-0.2138],\n",
      "        [-0.1748],\n",
      "        [-0.1757],\n",
      "        [-0.1959]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.7300]],\n",
      "\n",
      "        [[-2.6145]],\n",
      "\n",
      "        [[-3.1725]],\n",
      "\n",
      "        [[-3.4891]]], dtype=torch.float64)\n",
      "tensor([[-0.3367],\n",
      "        [-0.3481],\n",
      "        [-0.3598],\n",
      "        [-0.2771]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-3.6393]],\n",
      "\n",
      "        [[-3.6520]],\n",
      "\n",
      "        [[-2.9588]],\n",
      "\n",
      "        [[-2.1593]]], dtype=torch.float64)\n",
      "tensor([[-0.3586],\n",
      "        [-0.3584],\n",
      "        [-0.4292],\n",
      "        [-0.4621]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9594]],\n",
      "\n",
      "        [[-2.2979]],\n",
      "\n",
      "        [[-2.4747]],\n",
      "\n",
      "        [[-2.2089]]], dtype=torch.float64)\n",
      "tensor([[-0.5902],\n",
      "        [-0.4396],\n",
      "        [-0.5050],\n",
      "        [-0.5411]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8427]],\n",
      "\n",
      "        [[-1.6266]],\n",
      "\n",
      "        [[-2.2852]],\n",
      "\n",
      "        [[-2.6595]]], dtype=torch.float64)\n",
      "tensor([[-0.8097],\n",
      "        [-0.8622],\n",
      "        [-0.8676],\n",
      "        [-0.6703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.9345]],\n",
      "\n",
      "        [[-3.0189]],\n",
      "\n",
      "        [[-2.2621]],\n",
      "\n",
      "        [[-1.6012]]], dtype=torch.float64)\n",
      "tensor([[-0.8745],\n",
      "        [-0.9590],\n",
      "        [-1.0357],\n",
      "        [-1.1286]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4308]],\n",
      "\n",
      "        [[-2.5821]],\n",
      "\n",
      "        [[-2.7381]],\n",
      "\n",
      "        [[-2.8386]]], dtype=torch.float64)\n",
      "tensor([[-1.3965],\n",
      "        [-1.0673],\n",
      "        [-1.1211],\n",
      "        [-1.1940]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9166]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-2.1431]],\n",
      "\n",
      "        [[-2.2944]]], dtype=torch.float64)\n",
      "tensor([[-1.6407],\n",
      "        [-1.7058],\n",
      "        [-1.6299],\n",
      "        [-1.2669]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.5752]],\n",
      "\n",
      "        [[-2.6006]],\n",
      "\n",
      "        [[-1.8750]],\n",
      "\n",
      "        [[-1.0905]]], dtype=torch.float64)\n",
      "tensor([[-1.6337],\n",
      "        [-1.6897],\n",
      "        [-1.8381],\n",
      "        [-1.9909]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0079]],\n",
      "\n",
      "        [[-2.0876]],\n",
      "\n",
      "        [[-2.1616]],\n",
      "\n",
      "        [[-2.1315]]], dtype=torch.float64)\n",
      "tensor([[-2.1231],\n",
      "        [-1.5566],\n",
      "        [-1.6511],\n",
      "        [-1.7918]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4729]],\n",
      "\n",
      "        [[-0.8779]],\n",
      "\n",
      "        [[-1.4602]],\n",
      "\n",
      "        [[-1.6520]]], dtype=torch.float64)\n",
      "tensor([[-2.1710],\n",
      "        [-2.1801],\n",
      "        [-1.9455],\n",
      "        [-1.3155]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6185]],\n",
      "\n",
      "        [[-1.4868]],\n",
      "\n",
      "        [[-0.7543]],\n",
      "\n",
      "        [[-0.6769]]], dtype=torch.float64)\n",
      "tensor([[-1.9037],\n",
      "        [-2.1391],\n",
      "        [-2.5219],\n",
      "        [-2.8225]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2338]],\n",
      "\n",
      "        [[-1.5619]],\n",
      "\n",
      "        [[-2.0218]],\n",
      "\n",
      "        [[-2.2320]]], dtype=torch.float64)\n",
      "tensor([[-2.8367],\n",
      "        [-2.0733],\n",
      "        [-1.9767],\n",
      "        [-1.8703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5931]],\n",
      "\n",
      "        [[-1.1829]],\n",
      "\n",
      "        [[-1.2476]],\n",
      "\n",
      "        [[-1.0015]]], dtype=torch.float64)\n",
      "tensor([[-1.9239],\n",
      "        [-2.1174],\n",
      "        [-2.0253],\n",
      "        [-1.7380]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0928]],\n",
      "\n",
      "        [[-1.0535]],\n",
      "\n",
      "        [[-0.8224]],\n",
      "\n",
      "        [[-0.7543]]], dtype=torch.float64)\n",
      "tensor([[-2.0450],\n",
      "        [-2.3369],\n",
      "        [-2.5360],\n",
      "        [-2.6994]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3863]],\n",
      "\n",
      "        [[-1.5180]],\n",
      "\n",
      "        [[-1.6428]],\n",
      "\n",
      "        [[-1.5457]]], dtype=torch.float64)\n",
      "tensor([[-2.5637],\n",
      "        [-2.0849],\n",
      "        [-2.0257],\n",
      "        [-2.1288]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3817]],\n",
      "\n",
      "        [[-1.0085]],\n",
      "\n",
      "        [[-1.2580]],\n",
      "\n",
      "        [[-1.3181]]], dtype=torch.float64)\n",
      "tensor([[-2.2255],\n",
      "        [-2.2249],\n",
      "        [-2.0291],\n",
      "        [-1.7217]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2881]],\n",
      "\n",
      "        [[-1.1956]],\n",
      "\n",
      "        [[-0.9715]],\n",
      "\n",
      "        [[-0.8132]]], dtype=torch.float64)\n",
      "tensor([[-1.5312],\n",
      "        [-1.6148],\n",
      "        [-1.5720],\n",
      "        [-1.7920]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9264]],\n",
      "\n",
      "        [[-0.8282]],\n",
      "\n",
      "        [[-0.9391]],\n",
      "\n",
      "        [[-0.8721]]], dtype=torch.float64)\n",
      "tensor([[-1.4183],\n",
      "        [-1.1255],\n",
      "        [-1.2526],\n",
      "        [-1.2532]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4689]],\n",
      "\n",
      "        [[-0.7115]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.7185]]], dtype=torch.float64)\n",
      "tensor([[-1.4090],\n",
      "        [-1.5017],\n",
      "        [-1.3692],\n",
      "        [-1.2127]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9056]],\n",
      "\n",
      "        [[-0.9553]],\n",
      "\n",
      "        [[-0.6919]],\n",
      "\n",
      "        [[-0.6584]]], dtype=torch.float64)\n",
      "tensor([[-1.0721],\n",
      "        [-1.0859],\n",
      "        [-1.0285],\n",
      "        [-1.1704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6249]],\n",
      "\n",
      "        [[-0.5810]],\n",
      "\n",
      "        [[-0.3314]],\n",
      "\n",
      "        [[-0.5163]]], dtype=torch.float64)\n",
      "tensor([[-0.9689],\n",
      "        [-0.9558],\n",
      "        [-1.1222],\n",
      "        [-1.3527]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5613]],\n",
      "\n",
      "        [[-0.6399]],\n",
      "\n",
      "        [[-1.1044]],\n",
      "\n",
      "        [[-1.3944]]], dtype=torch.float64)\n",
      "tensor([[-1.3408],\n",
      "        [-1.4291],\n",
      "        [-1.3540],\n",
      "        [-1.1630]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3331]],\n",
      "\n",
      "        [[-1.3874]],\n",
      "\n",
      "        [[-1.0813]],\n",
      "\n",
      "        [[-0.9611]]], dtype=torch.float64)\n",
      "tensor([[-1.0856],\n",
      "        [-1.2244],\n",
      "        [-1.3386],\n",
      "        [-1.3532]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2650]],\n",
      "\n",
      "        [[-1.4706]],\n",
      "\n",
      "        [[-1.4417]],\n",
      "\n",
      "        [[-1.4221]]], dtype=torch.float64)\n",
      "tensor([[-1.2078],\n",
      "        [-0.8216],\n",
      "        [-1.0221],\n",
      "        [-1.1254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8213]],\n",
      "\n",
      "        [[-0.7728]],\n",
      "\n",
      "        [[-1.1644]],\n",
      "\n",
      "        [[-1.1390]]], dtype=torch.float64)\n",
      "tensor([[-1.0948],\n",
      "        [-1.0413],\n",
      "        [-0.7485],\n",
      "        [-0.6809]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2095]],\n",
      "\n",
      "        [[-1.2268]],\n",
      "\n",
      "        [[-0.7034]],\n",
      "\n",
      "        [[-0.8213]]], dtype=torch.float64)\n",
      "tensor([[-0.5302],\n",
      "        [-0.6301],\n",
      "        [-0.7739],\n",
      "        [-0.8237]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4631]],\n",
      "\n",
      "        [[-0.5983]],\n",
      "\n",
      "        [[-0.7705]],\n",
      "\n",
      "        [[-0.8132]]], dtype=torch.float64)\n",
      "tensor([[-0.5600],\n",
      "        [-0.5726],\n",
      "        [-0.7418],\n",
      "        [-0.8662]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6110]],\n",
      "\n",
      "        [[-0.6133]],\n",
      "\n",
      "        [[-0.7808]],\n",
      "\n",
      "        [[-1.0189]]], dtype=torch.float64)\n",
      "tensor([[-0.8590],\n",
      "        [-0.8933],\n",
      "        [-0.8609],\n",
      "        [-0.5985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9923]],\n",
      "\n",
      "        [[-1.1413]],\n",
      "\n",
      "        [[-0.6838]],\n",
      "\n",
      "        [[-0.4030]]], dtype=torch.float64)\n",
      "tensor([[-0.7592],\n",
      "        [-0.9031],\n",
      "        [-0.9673],\n",
      "        [-1.0258]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1517]],\n",
      "\n",
      "        [[-1.4313]],\n",
      "\n",
      "        [[-1.5388]],\n",
      "\n",
      "        [[-1.7190]]], dtype=torch.float64)\n",
      "tensor([[-1.0389],\n",
      "        [-0.9270],\n",
      "        [-0.8973],\n",
      "        [-0.8842]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4082]],\n",
      "\n",
      "        [[-1.3528]],\n",
      "\n",
      "        [[-1.2361]],\n",
      "\n",
      "        [[-1.1841]]], dtype=torch.float64)\n",
      "tensor([[-0.9048],\n",
      "        [-0.8795],\n",
      "        [-0.9617],\n",
      "        [-0.9384]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1876]],\n",
      "\n",
      "        [[-1.1795]],\n",
      "\n",
      "        [[-1.2014]],\n",
      "\n",
      "        [[-1.2176]]], dtype=torch.float64)\n",
      "tensor([[-0.9891],\n",
      "        [-0.9489],\n",
      "        [-0.9108],\n",
      "        [-0.9525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2488]],\n",
      "\n",
      "        [[-1.2465]],\n",
      "\n",
      "        [[-1.2754]],\n",
      "\n",
      "        [[-1.3724]]], dtype=torch.float64)\n",
      "tensor([[-0.9707],\n",
      "        [-0.9580],\n",
      "        [-0.9487],\n",
      "        [-0.9390]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3574]],\n",
      "\n",
      "        [[-1.3354]],\n",
      "\n",
      "        [[-1.3539]],\n",
      "\n",
      "        [[-1.3690]]], dtype=torch.float64)\n",
      "tensor([[-0.9577],\n",
      "        [-0.9852],\n",
      "        [-1.0668],\n",
      "        [-1.0535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3678]],\n",
      "\n",
      "        [[-1.4256]],\n",
      "\n",
      "        [[-1.2719]],\n",
      "\n",
      "        [[-1.2534]]], dtype=torch.float64)\n",
      "tensor([[-1.0304],\n",
      "        [-1.0312],\n",
      "        [-1.0340],\n",
      "        [-1.0121]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2765]],\n",
      "\n",
      "        [[-1.2788]],\n",
      "\n",
      "        [[-1.3054]],\n",
      "\n",
      "        [[-1.3666]]], dtype=torch.float64)\n",
      "tensor([[-1.0801],\n",
      "        [-1.1775],\n",
      "        [-1.0910],\n",
      "        [-1.1033]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3747]],\n",
      "\n",
      "        [[-1.3250]],\n",
      "\n",
      "        [[-1.3031]],\n",
      "\n",
      "        [[-1.3389]]], dtype=torch.float64)\n",
      "tensor([[-1.0510],\n",
      "        [-1.0566],\n",
      "        [-1.0552],\n",
      "        [-1.1091]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3227]],\n",
      "\n",
      "        [[-1.2892]],\n",
      "\n",
      "        [[-1.2222]],\n",
      "\n",
      "        [[-1.2361]]], dtype=torch.float64)\n",
      "tensor([[-1.1552],\n",
      "        [-1.0971],\n",
      "        [-1.1371],\n",
      "        [-1.1171]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3239]],\n",
      "\n",
      "        [[-1.3955]],\n",
      "\n",
      "        [[-1.4776]],\n",
      "\n",
      "        [[-1.5319]]], dtype=torch.float64)\n",
      "tensor([[-1.1818],\n",
      "        [-1.2067],\n",
      "        [-1.2466],\n",
      "        [-1.1256]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4094]],\n",
      "\n",
      "        [[-1.3678]],\n",
      "\n",
      "        [[-1.4325]],\n",
      "\n",
      "        [[-1.3458]]], dtype=torch.float64)\n",
      "tensor([[-1.0798],\n",
      "        [-1.0697],\n",
      "        [-0.9987],\n",
      "        [-0.7952]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3817]],\n",
      "\n",
      "        [[-1.6312]],\n",
      "\n",
      "        [[-1.0027]],\n",
      "\n",
      "        [[-0.7208]]], dtype=torch.float64)\n",
      "tensor([[-0.8690],\n",
      "        [-0.8503],\n",
      "        [-0.9797],\n",
      "        [-0.9632]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0085]],\n",
      "\n",
      "        [[-1.1564]],\n",
      "\n",
      "        [[-1.3678]],\n",
      "\n",
      "        [[-1.4313]]], dtype=torch.float64)\n",
      "tensor([[-0.9187],\n",
      "        [-0.6544],\n",
      "        [-0.7684],\n",
      "        [-0.9334]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9149]],\n",
      "\n",
      "        [[-0.4088]],\n",
      "\n",
      "        [[-1.0477]],\n",
      "\n",
      "        [[-1.3574]]], dtype=torch.float64)\n",
      "tensor([[-1.0161],\n",
      "        [-1.0817],\n",
      "        [-1.0166],\n",
      "        [-0.7796]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5342]],\n",
      "\n",
      "        [[-1.6104]],\n",
      "\n",
      "        [[-1.0119]],\n",
      "\n",
      "        [[-0.6283]]], dtype=torch.float64)\n",
      "tensor([[-0.8804],\n",
      "        [-0.8708],\n",
      "        [-0.8790],\n",
      "        [-0.9638]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0443]],\n",
      "\n",
      "        [[-0.9622]],\n",
      "\n",
      "        [[-1.0940]],\n",
      "\n",
      "        [[-1.1945]]], dtype=torch.float64)\n",
      "tensor([[-0.8033],\n",
      "        [-0.5359],\n",
      "        [-0.7163],\n",
      "        [-0.8618]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5891]],\n",
      "\n",
      "        [[-0.4342]],\n",
      "\n",
      "        [[-0.7150]],\n",
      "\n",
      "        [[-0.9622]]], dtype=torch.float64)\n",
      "tensor([[-0.8813],\n",
      "        [-0.9448],\n",
      "        [-0.9487],\n",
      "        [-0.5082]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1436]],\n",
      "\n",
      "        [[-1.0477]],\n",
      "\n",
      "        [[-0.7300]],\n",
      "\n",
      "        [[-0.1719]]], dtype=torch.float64)\n",
      "tensor([[-0.6540],\n",
      "        [-0.7906],\n",
      "        [-0.9485],\n",
      "        [-0.9982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6133]],\n",
      "\n",
      "        [[-0.9576]],\n",
      "\n",
      "        [[-1.2095]],\n",
      "\n",
      "        [[-1.2684]]], dtype=torch.float64)\n",
      "tensor([[-0.8816],\n",
      "        [-0.5160],\n",
      "        [-0.7325],\n",
      "        [-0.7955]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7485]],\n",
      "\n",
      "        [[-0.6029]],\n",
      "\n",
      "        [[-0.6907]],\n",
      "\n",
      "        [[-0.7970]]], dtype=torch.float64)\n",
      "tensor([[-0.9276],\n",
      "        [-0.9140],\n",
      "        [-0.9280],\n",
      "        [-0.9704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8952]],\n",
      "\n",
      "        [[-1.0408]],\n",
      "\n",
      "        [[-0.8016]],\n",
      "\n",
      "        [[-0.7023]]], dtype=torch.float64)\n",
      "tensor([[-0.9753],\n",
      "        [-1.0805],\n",
      "        [-1.1728],\n",
      "        [-1.1324]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0281]],\n",
      "\n",
      "        [[-1.3227]],\n",
      "\n",
      "        [[-1.3643]],\n",
      "\n",
      "        [[-1.1471]]], dtype=torch.float64)\n",
      "tensor([[-0.9017],\n",
      "        [-0.7765],\n",
      "        [-0.9046],\n",
      "        [-1.0411]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7993]],\n",
      "\n",
      "        [[-0.8248]],\n",
      "\n",
      "        [[-1.0917]],\n",
      "\n",
      "        [[-1.0674]]], dtype=torch.float64)\n",
      "tensor([[-0.9451],\n",
      "        [-0.8214],\n",
      "        [-0.6084],\n",
      "        [-0.6508]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1506]],\n",
      "\n",
      "        [[-0.7635]],\n",
      "\n",
      "        [[-0.2967]],\n",
      "\n",
      "        [[-0.5833]]], dtype=torch.float64)\n",
      "tensor([[-0.7780],\n",
      "        [-0.9529],\n",
      "        [-1.0641],\n",
      "        [-1.1051]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8363]],\n",
      "\n",
      "        [[-0.9750]],\n",
      "\n",
      "        [[-1.1009]],\n",
      "\n",
      "        [[-1.0720]]], dtype=torch.float64)\n",
      "tensor([[-1.0479],\n",
      "        [-1.0444],\n",
      "        [-0.9457],\n",
      "        [-1.0047]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.69537:   3%|▎         | 94/3067 [00:00<00:09, 308.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8929]],\n",
      "\n",
      "        [[-0.8132]],\n",
      "\n",
      "        [[-1.0327]],\n",
      "\n",
      "        [[-1.0836]]], dtype=torch.float64)\n",
      "tensor([[-1.2128],\n",
      "        [-1.3030],\n",
      "        [-1.2273],\n",
      "        [-1.0983]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2187]],\n",
      "\n",
      "        [[-1.4036]],\n",
      "\n",
      "        [[-1.0639]],\n",
      "\n",
      "        [[-1.0685]]], dtype=torch.float64)\n",
      "tensor([[-1.1857],\n",
      "        [-1.1564],\n",
      "        [-1.2013],\n",
      "        [-1.3359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2973]],\n",
      "\n",
      "        [[-1.2985]],\n",
      "\n",
      "        [[-1.4429]],\n",
      "\n",
      "        [[-1.5977]]], dtype=torch.float64)\n",
      "tensor([[-1.2882],\n",
      "        [-1.1242],\n",
      "        [-1.0913],\n",
      "        [-1.0764]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9726]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.1148]],\n",
      "\n",
      "        [[-1.1321]]], dtype=torch.float64)\n",
      "tensor([[-1.1499],\n",
      "        [-1.4040],\n",
      "        [-1.5761],\n",
      "        [-1.4500]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1991]],\n",
      "\n",
      "        [[-1.7110]],\n",
      "\n",
      "        [[-1.6035]],\n",
      "\n",
      "        [[-1.3493]]], dtype=torch.float64)\n",
      "tensor([[-1.3872],\n",
      "        [-1.3546],\n",
      "        [-1.4913],\n",
      "        [-1.5931]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5607]],\n",
      "\n",
      "        [[-1.6613]],\n",
      "\n",
      "        [[-1.9432]],\n",
      "\n",
      "        [[-1.8958]]], dtype=torch.float64)\n",
      "tensor([[-1.4785],\n",
      "        [-1.2304],\n",
      "        [-1.1776],\n",
      "        [-1.2721]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2765]],\n",
      "\n",
      "        [[-1.1910]],\n",
      "\n",
      "        [[-1.4267]],\n",
      "\n",
      "        [[-1.3921]]], dtype=torch.float64)\n",
      "tensor([[-1.1792],\n",
      "        [-1.2409],\n",
      "        [-1.0857],\n",
      "        [-0.9867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2938]],\n",
      "\n",
      "        [[-1.0859]],\n",
      "\n",
      "        [[-0.8479]],\n",
      "\n",
      "        [[-0.8409]]], dtype=torch.float64)\n",
      "tensor([[-1.0093],\n",
      "        [-1.0385],\n",
      "        [-1.1616],\n",
      "        [-1.2435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8952]],\n",
      "\n",
      "        [[-1.0789]],\n",
      "\n",
      "        [[-1.0339]],\n",
      "\n",
      "        [[-1.2534]]], dtype=torch.float64)\n",
      "tensor([[-1.6154],\n",
      "        [-1.7841],\n",
      "        [-1.6751],\n",
      "        [-1.5789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4117]],\n",
      "\n",
      "        [[-1.3354]],\n",
      "\n",
      "        [[-1.5792]],\n",
      "\n",
      "        [[-1.6266]]], dtype=torch.float64)\n",
      "tensor([[-1.4878],\n",
      "        [-1.4657],\n",
      "        [-1.5293],\n",
      "        [-1.5328]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6278]],\n",
      "\n",
      "        [[-1.6578]],\n",
      "\n",
      "        [[-1.3932]],\n",
      "\n",
      "        [[-1.1922]]], dtype=torch.float64)\n",
      "tensor([[-1.5015],\n",
      "        [-1.5544],\n",
      "        [-1.6916],\n",
      "        [-1.7704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5769]],\n",
      "\n",
      "        [[-1.9651]],\n",
      "\n",
      "        [[-2.3372]],\n",
      "\n",
      "        [[-2.1812]]], dtype=torch.float64)\n",
      "tensor([[-1.5772],\n",
      "        [-1.2379],\n",
      "        [-1.2544],\n",
      "        [-1.3962]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0928]],\n",
      "\n",
      "        [[-1.0177]],\n",
      "\n",
      "        [[-1.2338]],\n",
      "\n",
      "        [[-1.3343]]], dtype=torch.float64)\n",
      "tensor([[-1.3496],\n",
      "        [-1.3157],\n",
      "        [-1.1910],\n",
      "        [-1.0775]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3435]],\n",
      "\n",
      "        [[-1.0304]],\n",
      "\n",
      "        [[-0.7947]],\n",
      "\n",
      "        [[-0.8952]]], dtype=torch.float64)\n",
      "tensor([[-1.0750],\n",
      "        [-1.0687],\n",
      "        [-1.1241],\n",
      "        [-1.1987]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8791]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.9253]],\n",
      "\n",
      "        [[-1.0293]]], dtype=torch.float64)\n",
      "tensor([[-1.2436],\n",
      "        [-1.1996],\n",
      "        [-1.1924],\n",
      "        [-1.1444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9230]],\n",
      "\n",
      "        [[-0.8271]],\n",
      "\n",
      "        [[-0.9380]],\n",
      "\n",
      "        [[-1.0720]]], dtype=torch.float64)\n",
      "tensor([[-1.2891],\n",
      "        [-1.2155],\n",
      "        [-1.0162],\n",
      "        [-0.9230]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1425]],\n",
      "\n",
      "        [[-1.0223]],\n",
      "\n",
      "        [[-0.6826]],\n",
      "\n",
      "        [[-0.5833]]], dtype=torch.float64)\n",
      "tensor([[-0.8600],\n",
      "        [-0.9677],\n",
      "        [-1.0554],\n",
      "        [-1.0204]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6330]],\n",
      "\n",
      "        [[-0.7277]],\n",
      "\n",
      "        [[-0.8178]],\n",
      "\n",
      "        [[-0.8201]]], dtype=torch.float64)\n",
      "tensor([[-0.9465],\n",
      "        [-0.8819],\n",
      "        [-0.9339],\n",
      "        [-1.0700]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7289]],\n",
      "\n",
      "        [[-0.6029]],\n",
      "\n",
      "        [[-0.8224]],\n",
      "\n",
      "        [[-1.0870]]], dtype=torch.float64)\n",
      "tensor([[-1.2206],\n",
      "        [-1.3659],\n",
      "        [-1.2648],\n",
      "        [-1.3466]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1032]],\n",
      "\n",
      "        [[-1.1679]],\n",
      "\n",
      "        [[-1.1101]],\n",
      "\n",
      "        [[-1.0177]]], dtype=torch.float64)\n",
      "tensor([[-1.1901],\n",
      "        [-1.1810],\n",
      "        [-1.2826],\n",
      "        [-1.3630]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0466]],\n",
      "\n",
      "        [[-1.1725]],\n",
      "\n",
      "        [[-1.3100]],\n",
      "\n",
      "        [[-1.3239]]], dtype=torch.float64)\n",
      "tensor([[-1.0497],\n",
      "        [-0.8318],\n",
      "        [-0.9097],\n",
      "        [-0.9679]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6514]],\n",
      "\n",
      "        [[-0.4839]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.6491]]], dtype=torch.float64)\n",
      "tensor([[-0.9410],\n",
      "        [-0.8556],\n",
      "        [-0.9330],\n",
      "        [-0.8402]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7173]],\n",
      "\n",
      "        [[-0.8386]],\n",
      "\n",
      "        [[-0.5255]],\n",
      "\n",
      "        [[-0.4053]]], dtype=torch.float64)\n",
      "tensor([[-0.7584],\n",
      "        [-0.8278],\n",
      "        [-0.8397],\n",
      "        [-0.8355]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4862]],\n",
      "\n",
      "        [[-0.5636]],\n",
      "\n",
      "        [[-0.6480]],\n",
      "\n",
      "        [[-0.6341]]], dtype=torch.float64)\n",
      "tensor([[-0.7495],\n",
      "        [-0.6820],\n",
      "        [-0.7579],\n",
      "        [-0.7144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4527]],\n",
      "\n",
      "        [[-0.3799]],\n",
      "\n",
      "        [[-0.4284]],\n",
      "\n",
      "        [[-0.3603]]], dtype=torch.float64)\n",
      "tensor([[-0.7029],\n",
      "        [-0.6705],\n",
      "        [-0.5705],\n",
      "        [-0.5442]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3533]],\n",
      "\n",
      "        [[-0.3869]],\n",
      "\n",
      "        [[-0.1731]],\n",
      "\n",
      "        [[-0.1639]]], dtype=torch.float64)\n",
      "tensor([[-0.5807],\n",
      "        [-0.7214],\n",
      "        [-0.7216],\n",
      "        [-0.7517]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2852]],\n",
      "\n",
      "        [[-0.4204]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[-0.5891]]], dtype=torch.float64)\n",
      "tensor([[-0.6887],\n",
      "        [-0.5154],\n",
      "        [-0.6943],\n",
      "        [-0.8135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3741]],\n",
      "\n",
      "        [[ 0.2382]],\n",
      "\n",
      "        [[-0.6353]],\n",
      "\n",
      "        [[-0.6457]]], dtype=torch.float64)\n",
      "tensor([[-0.7625],\n",
      "        [-0.6258],\n",
      "        [-0.5809],\n",
      "        [-0.5284]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5128]],\n",
      "\n",
      "        [[-0.5267]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.2147]]], dtype=torch.float64)\n",
      "tensor([[-0.5771],\n",
      "        [-0.6529],\n",
      "        [-0.7449],\n",
      "        [-0.8208]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4354]],\n",
      "\n",
      "        [[-0.5787]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.8791]]], dtype=torch.float64)\n",
      "tensor([[-0.7274],\n",
      "        [-0.5176],\n",
      "        [-0.6267],\n",
      "        [-0.9219]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2563]],\n",
      "\n",
      "        [[-0.2205]],\n",
      "\n",
      "        [[-0.7462]],\n",
      "\n",
      "        [[-1.0917]]], dtype=torch.float64)\n",
      "tensor([[-0.8684],\n",
      "        [-0.7897],\n",
      "        [-0.5052],\n",
      "        [-0.4770]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9599]],\n",
      "\n",
      "        [[-0.7312]],\n",
      "\n",
      "        [[-0.0610]],\n",
      "\n",
      "        [[-0.0021]]], dtype=torch.float64)\n",
      "tensor([[-0.5396],\n",
      "        [-0.7635],\n",
      "        [-0.8617],\n",
      "        [-0.9103]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[-1.1668]],\n",
      "\n",
      "        [[-1.2303]]], dtype=torch.float64)\n",
      "tensor([[-0.8237],\n",
      "        [-0.6654],\n",
      "        [-0.6252],\n",
      "        [-0.5744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8005]],\n",
      "\n",
      "        [[-0.4631]],\n",
      "\n",
      "        [[-0.3857]],\n",
      "\n",
      "        [[-0.4585]]], dtype=torch.float64)\n",
      "tensor([[-0.5429],\n",
      "        [-0.6004],\n",
      "        [-0.6503],\n",
      "        [-0.6143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4435]],\n",
      "\n",
      "        [[-0.5994]],\n",
      "\n",
      "        [[-0.6722]],\n",
      "\n",
      "        [[-0.6018]]], dtype=torch.float64)\n",
      "tensor([[-0.6413],\n",
      "        [-0.6645],\n",
      "        [-0.6764],\n",
      "        [-0.6875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6780]],\n",
      "\n",
      "        [[-0.7277]],\n",
      "\n",
      "        [[-0.8536]],\n",
      "\n",
      "        [[-0.9022]]], dtype=torch.float64)\n",
      "tensor([[-0.6641],\n",
      "        [-0.6115],\n",
      "        [-0.7160],\n",
      "        [-0.7680]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7485]],\n",
      "\n",
      "        [[-0.8409]],\n",
      "\n",
      "        [[-0.8640]],\n",
      "\n",
      "        [[-1.2627]]], dtype=torch.float64)\n",
      "tensor([[-0.8221],\n",
      "        [-0.8244],\n",
      "        [-0.4905],\n",
      "        [-0.4617]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2950]],\n",
      "\n",
      "        [[-0.8190]],\n",
      "\n",
      "        [[-0.3834]],\n",
      "\n",
      "        [[-0.3707]]], dtype=torch.float64)\n",
      "tensor([[-0.4316],\n",
      "        [-0.6009],\n",
      "        [-0.6016],\n",
      "        [-0.6755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4250]],\n",
      "\n",
      "        [[-0.5671]],\n",
      "\n",
      "        [[-0.7335]],\n",
      "\n",
      "        [[-0.7866]]], dtype=torch.float64)\n",
      "tensor([[-0.5720],\n",
      "        [-0.5352],\n",
      "        [-0.5619],\n",
      "        [-0.6309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5498]],\n",
      "\n",
      "        [[-0.4331]],\n",
      "\n",
      "        [[-0.6179]],\n",
      "\n",
      "        [[-0.6861]]], dtype=torch.float64)\n",
      "tensor([[-0.6695],\n",
      "        [-0.6073],\n",
      "        [-0.4729],\n",
      "        [-0.4624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7866]],\n",
      "\n",
      "        [[-0.7416]],\n",
      "\n",
      "        [[-0.4643]],\n",
      "\n",
      "        [[-0.4469]]], dtype=torch.float64)\n",
      "tensor([[-0.6134],\n",
      "        [-0.6759],\n",
      "        [-0.6556],\n",
      "        [-0.6859]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6815]],\n",
      "\n",
      "        [[-0.8074]],\n",
      "\n",
      "        [[-0.9357]],\n",
      "\n",
      "        [[-0.9657]]], dtype=torch.float64)\n",
      "tensor([[-0.7070],\n",
      "        [-0.6677],\n",
      "        [-0.6141],\n",
      "        [-0.6489]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.5971]],\n",
      "\n",
      "        [[-0.6572]],\n",
      "\n",
      "        [[-0.6919]]], dtype=torch.float64)\n",
      "tensor([[-0.7078],\n",
      "        [-0.6919],\n",
      "        [-0.5969],\n",
      "        [-0.5038]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7716]],\n",
      "\n",
      "        [[-0.8663]],\n",
      "\n",
      "        [[-0.5151]],\n",
      "\n",
      "        [[-0.7543]]], dtype=torch.float64)\n",
      "tensor([[-0.6035],\n",
      "        [-0.5673],\n",
      "        [-0.5150],\n",
      "        [-0.5551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6757]],\n",
      "\n",
      "        [[-0.3753]],\n",
      "\n",
      "        [[-0.5267]],\n",
      "\n",
      "        [[-0.4550]]], dtype=torch.float64)\n",
      "tensor([[-0.6366],\n",
      "        [-0.6792],\n",
      "        [-0.5787],\n",
      "        [-0.6848]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0090]],\n",
      "\n",
      "        [[ 0.0661]],\n",
      "\n",
      "        [[-0.2644]],\n",
      "\n",
      "        [[-0.7300]]], dtype=torch.float64)\n",
      "tensor([[-0.7824],\n",
      "        [-0.7531],\n",
      "        [-0.6090],\n",
      "        [-0.4266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0489]],\n",
      "\n",
      "        [[-1.0073]],\n",
      "\n",
      "        [[ 0.0464]],\n",
      "\n",
      "        [[ 0.0892]]], dtype=torch.float64)\n",
      "tensor([[-0.4674],\n",
      "        [-0.5492],\n",
      "        [-0.6013],\n",
      "        [-0.5030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2008]],\n",
      "\n",
      "        [[-0.2655]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.3845]]], dtype=torch.float64)\n",
      "tensor([[-0.4906],\n",
      "        [-0.5078],\n",
      "        [-0.5496],\n",
      "        [-0.5979]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3372]],\n",
      "\n",
      "        [[-0.2944]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.3961]]], dtype=torch.float64)\n",
      "tensor([[-0.6255],\n",
      "        [-0.5923],\n",
      "        [-0.6552],\n",
      "        [-0.6444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4839]],\n",
      "\n",
      "        [[-0.4585]],\n",
      "\n",
      "        [[-0.1384]],\n",
      "\n",
      "        [[-0.2367]]], dtype=torch.float64)\n",
      "tensor([[-0.6184],\n",
      "        [-0.6781],\n",
      "        [-0.6543],\n",
      "        [-0.6571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3175]],\n",
      "\n",
      "        [[-0.4157]],\n",
      "\n",
      "        [[-0.5451]],\n",
      "\n",
      "        [[-0.4215]]], dtype=torch.float64)\n",
      "tensor([[-0.5690],\n",
      "        [-0.6475],\n",
      "        [-0.6577],\n",
      "        [-0.7877]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1789]],\n",
      "\n",
      "        [[ 0.0915]],\n",
      "\n",
      "        [[-0.3326]],\n",
      "\n",
      "        [[-0.7462]]], dtype=torch.float64)\n",
      "tensor([[-0.7160],\n",
      "        [-0.7969],\n",
      "        [-0.7053],\n",
      "        [-0.7134]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0466]],\n",
      "\n",
      "        [[-0.8363]],\n",
      "\n",
      "        [[-0.3938]],\n",
      "\n",
      "        [[-0.0922]]], dtype=torch.float64)\n",
      "tensor([[-0.6112],\n",
      "        [-0.6184],\n",
      "        [-0.6395],\n",
      "        [-0.6061]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5093]],\n",
      "\n",
      "        [[-0.6341]],\n",
      "\n",
      "        [[-0.7254]],\n",
      "\n",
      "        [[-0.6202]]], dtype=torch.float64)\n",
      "tensor([[-0.8568],\n",
      "        [-1.1515],\n",
      "        [-0.9709],\n",
      "        [-1.1715]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6676]],\n",
      "\n",
      "        [[-0.7323]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-1.0940]]], dtype=torch.float64)\n",
      "tensor([[-0.9081],\n",
      "        [-0.9951],\n",
      "        [-1.1750],\n",
      "        [-1.0556]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1321]],\n",
      "\n",
      "        [[-1.1610]],\n",
      "\n",
      "        [[-0.9495]],\n",
      "\n",
      "        [[-0.8005]]], dtype=torch.float64)\n",
      "tensor([[-0.9134],\n",
      "        [-0.8200],\n",
      "        [-0.8757],\n",
      "        [-0.8878]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9588]],\n",
      "\n",
      "        [[-1.2904]],\n",
      "\n",
      "        [[-1.4637]],\n",
      "\n",
      "        [[-1.0893]]], dtype=torch.float64)\n",
      "tensor([[-0.6413],\n",
      "        [-0.5392],\n",
      "        [-0.6841],\n",
      "        [-0.7181]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5775]],\n",
      "\n",
      "        [[-0.2505]],\n",
      "\n",
      "        [[-0.5937]],\n",
      "\n",
      "        [[-1.0316]]], dtype=torch.float64)\n",
      "tensor([[-0.7727],\n",
      "        [-0.6747],\n",
      "        [-0.5080],\n",
      "        [-0.5271]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2303]],\n",
      "\n",
      "        [[-0.6653]],\n",
      "\n",
      "        [[-0.5555]],\n",
      "\n",
      "        [[-0.1546]]], dtype=torch.float64)\n",
      "tensor([[-0.5074],\n",
      "        [-0.4803],\n",
      "        [-0.4048],\n",
      "        [-0.3696]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[-0.3395]],\n",
      "\n",
      "        [[-0.3776]],\n",
      "\n",
      "        [[-0.2979]]], dtype=torch.float64)\n",
      "tensor([[-0.3698],\n",
      "        [-0.4571],\n",
      "        [-0.4135],\n",
      "        [-0.6022]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2471]],\n",
      "\n",
      "        [[-0.1696]],\n",
      "\n",
      "        [[-0.5891]],\n",
      "\n",
      "        [[-0.9276]]], dtype=torch.float64)\n",
      "tensor([[-0.5207],\n",
      "        [-0.4991],\n",
      "        [-0.4064],\n",
      "        [-0.5704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8802]],\n",
      "\n",
      "        [[-0.8848]],\n",
      "\n",
      "        [[-0.5729]],\n",
      "\n",
      "        [[-1.0674]]], dtype=torch.float64)\n",
      "tensor([[-0.6925],\n",
      "        [-0.6964],\n",
      "        [-0.6869],\n",
      "        [-0.6895]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1171]],\n",
      "\n",
      "        [[-1.2546]],\n",
      "\n",
      "        [[-1.4325]],\n",
      "\n",
      "        [[-1.2499]]], dtype=torch.float64)\n",
      "tensor([[-0.4338],\n",
      "        [-0.5511],\n",
      "        [-0.6342],\n",
      "        [-0.6722]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8941]],\n",
      "\n",
      "        [[-0.7751]],\n",
      "\n",
      "        [[-0.9403]],\n",
      "\n",
      "        [[-1.0327]]], dtype=torch.float64)\n",
      "tensor([[-0.5780],\n",
      "        [-0.4814],\n",
      "        [-0.3445],\n",
      "        [-0.3817]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.69537:   5%|▌         | 161/3067 [00:00<00:09, 317.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8328]],\n",
      "\n",
      "        [[-0.7138]],\n",
      "\n",
      "        [[-0.2517]],\n",
      "\n",
      "        [[-0.1870]]], dtype=torch.float64)\n",
      "tensor([[-0.4507],\n",
      "        [-0.4891],\n",
      "        [-0.3965],\n",
      "        [-0.3718]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4735]],\n",
      "\n",
      "        [[-0.4654]],\n",
      "\n",
      "        [[-0.3360]],\n",
      "\n",
      "        [[-0.1269]]], dtype=torch.float64)\n",
      "tensor([[-0.2971],\n",
      "        [-0.3669],\n",
      "        [-0.4353],\n",
      "        [-0.5483]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5232]],\n",
      "\n",
      "        [[-0.1350]],\n",
      "\n",
      "        [[-0.6538]],\n",
      "\n",
      "        [[-0.5994]]], dtype=torch.float64)\n",
      "tensor([[-0.5159],\n",
      "        [-0.6653],\n",
      "        [-0.3566],\n",
      "        [-0.3651]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6665]],\n",
      "\n",
      "        [[-0.7104]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[-0.0668]]], dtype=torch.float64)\n",
      "tensor([[-0.5121],\n",
      "        [-0.4974],\n",
      "        [-0.4798],\n",
      "        [-0.5777]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5128]],\n",
      "\n",
      "        [[-0.5544]],\n",
      "\n",
      "        [[-0.6122]],\n",
      "\n",
      "        [[-0.5763]]], dtype=torch.float64)\n",
      "tensor([[-0.3149],\n",
      "        [-0.4756],\n",
      "        [-0.6884],\n",
      "        [-0.6338]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1639]],\n",
      "\n",
      "        [[-0.1280]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[-0.5174]]], dtype=torch.float64)\n",
      "tensor([[-0.6029],\n",
      "        [-0.5775],\n",
      "        [-0.6257],\n",
      "        [-0.6836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7277]],\n",
      "\n",
      "        [[-0.6549]],\n",
      "\n",
      "        [[-0.2424]],\n",
      "\n",
      "        [[-0.1304]]], dtype=torch.float64)\n",
      "tensor([[-0.6787],\n",
      "        [-0.6744],\n",
      "        [-0.7531],\n",
      "        [-0.8403]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4550]],\n",
      "\n",
      "        [[-1.0108]],\n",
      "\n",
      "        [[-1.2811]],\n",
      "\n",
      "        [[-1.2869]]], dtype=torch.float64)\n",
      "tensor([[-0.5873],\n",
      "        [-0.6770],\n",
      "        [-0.7258],\n",
      "        [-0.6079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0788]],\n",
      "\n",
      "        [[ 0.2833]],\n",
      "\n",
      "        [[-0.1361]],\n",
      "\n",
      "        [[-0.6503]]], dtype=torch.float64)\n",
      "tensor([[-0.7227],\n",
      "        [-0.7642],\n",
      "        [-0.6990],\n",
      "        [-0.8598]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1621]],\n",
      "\n",
      "        [[-0.4308]],\n",
      "\n",
      "        [[ 0.1747]],\n",
      "\n",
      "        [[ 0.4520]]], dtype=torch.float64)\n",
      "tensor([[-0.7200],\n",
      "        [-0.8316],\n",
      "        [-0.7840],\n",
      "        [-0.7937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2625]],\n",
      "\n",
      "        [[-0.1084]],\n",
      "\n",
      "        [[-0.4319]],\n",
      "\n",
      "        [[-0.2609]]], dtype=torch.float64)\n",
      "tensor([[-0.6424],\n",
      "        [-0.5999],\n",
      "        [-0.5746],\n",
      "        [-0.5016]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5340]],\n",
      "\n",
      "        [[0.8148]],\n",
      "\n",
      "        [[0.3838]],\n",
      "\n",
      "        [[0.0464]]], dtype=torch.float64)\n",
      "tensor([[-0.4929],\n",
      "        [-0.5770],\n",
      "        [-0.3207],\n",
      "        [-0.4140]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5567]],\n",
      "\n",
      "        [[-0.2124]],\n",
      "\n",
      "        [[ 1.0066]],\n",
      "\n",
      "        [[ 1.5323]]], dtype=torch.float64)\n",
      "tensor([[-0.4545],\n",
      "        [-0.4501],\n",
      "        [-0.4159],\n",
      "        [-0.4161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9188]],\n",
      "\n",
      "        [[ 0.0950]],\n",
      "\n",
      "        [[-0.2898]],\n",
      "\n",
      "        [[ 0.0268]]], dtype=torch.float64)\n",
      "tensor([[-0.3105],\n",
      "        [-0.5509],\n",
      "        [-0.5082],\n",
      "        [-0.4626]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0805]],\n",
      "\n",
      "        [[1.1695]],\n",
      "\n",
      "        [[0.7270]],\n",
      "\n",
      "        [[0.2683]]], dtype=torch.float64)\n",
      "tensor([[-0.4046],\n",
      "        [-0.4534],\n",
      "        [-0.3294],\n",
      "        [-0.3836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1597]],\n",
      "\n",
      "        [[0.0337]],\n",
      "\n",
      "        [[0.3746]],\n",
      "\n",
      "        [[0.5594]]], dtype=torch.float64)\n",
      "tensor([[-0.4790],\n",
      "        [-0.4087],\n",
      "        [-0.3810],\n",
      "        [-0.3737]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1666]],\n",
      "\n",
      "        [[-0.1858]],\n",
      "\n",
      "        [[-0.3025]],\n",
      "\n",
      "        [[-0.2667]]], dtype=torch.float64)\n",
      "tensor([[-0.2152],\n",
      "        [-0.2711],\n",
      "        [-0.3066],\n",
      "        [-0.3574]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7905]],\n",
      "\n",
      "        [[1.1002]],\n",
      "\n",
      "        [[0.7293]],\n",
      "\n",
      "        [[0.0510]]], dtype=torch.float64)\n",
      "tensor([[-0.2837],\n",
      "        [-0.3038],\n",
      "        [-0.1293],\n",
      "        [-0.3168]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2898]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[ 1.2873]],\n",
      "\n",
      "        [[ 1.4953]]], dtype=torch.float64)\n",
      "tensor([[-0.2794],\n",
      "        [-0.3014],\n",
      "        [-0.2621],\n",
      "        [-0.2052]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6160]],\n",
      "\n",
      "        [[ 0.1389]],\n",
      "\n",
      "        [[-0.0021]],\n",
      "\n",
      "        [[ 0.1123]]], dtype=torch.float64)\n",
      "tensor([[-0.0677],\n",
      "        [-0.1796],\n",
      "        [-0.2066],\n",
      "        [-0.2622]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8598]],\n",
      "\n",
      "        [[0.9442]],\n",
      "\n",
      "        [[0.4681]],\n",
      "\n",
      "        [[0.2232]]], dtype=torch.float64)\n",
      "tensor([[-0.2745],\n",
      "        [-0.2249],\n",
      "        [-0.1099],\n",
      "        [-0.1851]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[ 0.0603]],\n",
      "\n",
      "        [[ 0.8621]],\n",
      "\n",
      "        [[ 0.8541]]], dtype=torch.float64)\n",
      "tensor([[-0.2034],\n",
      "        [-0.2194],\n",
      "        [-0.2348],\n",
      "        [-0.2868]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5513]],\n",
      "\n",
      "        [[ 0.0095]],\n",
      "\n",
      "        [[-0.3880]],\n",
      "\n",
      "        [[-0.3187]]], dtype=torch.float64)\n",
      "tensor([[-0.0055],\n",
      "        [ 0.1044],\n",
      "        [ 0.0254],\n",
      "        [-0.2053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1845]],\n",
      "\n",
      "        [[1.5461]],\n",
      "\n",
      "        [[1.0193]],\n",
      "\n",
      "        [[0.5918]]], dtype=torch.float64)\n",
      "tensor([[-0.1390],\n",
      "        [-0.1326],\n",
      "        [ 0.0256],\n",
      "        [ 0.0710]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0703]],\n",
      "\n",
      "        [[ 0.3757]],\n",
      "\n",
      "        [[ 1.1129]],\n",
      "\n",
      "        [[ 1.3913]]], dtype=torch.float64)\n",
      "tensor([[ 0.0241],\n",
      "        [-0.1573],\n",
      "        [-0.1191],\n",
      "        [-0.1266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9754]],\n",
      "\n",
      "        [[ 0.4150]],\n",
      "\n",
      "        [[-0.1315]],\n",
      "\n",
      "        [[ 0.4878]]], dtype=torch.float64)\n",
      "tensor([[ 0.1074],\n",
      "        [ 0.0975],\n",
      "        [ 0.0521],\n",
      "        [-0.0966]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0112]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[0.8078]],\n",
      "\n",
      "        [[0.1874]]], dtype=torch.float64)\n",
      "tensor([[-0.1103],\n",
      "        [-0.1893],\n",
      "        [ 0.1500],\n",
      "        [ 0.1853]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4215]],\n",
      "\n",
      "        [[ 0.0037]],\n",
      "\n",
      "        [[ 0.9858]],\n",
      "\n",
      "        [[ 1.1695]]], dtype=torch.float64)\n",
      "tensor([[ 0.1237],\n",
      "        [-0.0474],\n",
      "        [-0.1440],\n",
      "        [-0.1060]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7512]],\n",
      "\n",
      "        [[ 0.0788]],\n",
      "\n",
      "        [[-0.3545]],\n",
      "\n",
      "        [[ 0.2244]]], dtype=torch.float64)\n",
      "tensor([[ 0.2874],\n",
      "        [ 0.3114],\n",
      "        [ 0.2566],\n",
      "        [-0.0089]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0886]],\n",
      "\n",
      "        [[1.2781]],\n",
      "\n",
      "        [[0.8471]],\n",
      "\n",
      "        [[0.1227]]], dtype=torch.float64)\n",
      "tensor([[-0.0538],\n",
      "        [-0.0509],\n",
      "        [ 0.3566],\n",
      "        [ 0.4945]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2667]],\n",
      "\n",
      "        [[ 0.1573]],\n",
      "\n",
      "        [[ 1.3821]],\n",
      "\n",
      "        [[ 1.4086]]], dtype=torch.float64)\n",
      "tensor([[ 0.4279],\n",
      "        [ 0.1727],\n",
      "        [-0.0159],\n",
      "        [-0.0408]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.0204]],\n",
      "\n",
      "        [[ 0.4947]],\n",
      "\n",
      "        [[-0.3118]],\n",
      "\n",
      "        [[ 0.5144]]], dtype=torch.float64)\n",
      "tensor([[0.4135],\n",
      "        [0.6794],\n",
      "        [0.5333],\n",
      "        [0.1139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1625]],\n",
      "\n",
      "        [[1.4606]],\n",
      "\n",
      "        [[0.8252]],\n",
      "\n",
      "        [[0.3826]]], dtype=torch.float64)\n",
      "tensor([[0.1696],\n",
      "        [0.1558],\n",
      "        [0.1166],\n",
      "        [0.1150]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0869]],\n",
      "\n",
      "        [[-0.2239]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.2586]]], dtype=torch.float64)\n",
      "tensor([[ 0.0749],\n",
      "        [-0.0111],\n",
      "        [ 0.0206],\n",
      "        [-0.0496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2078]],\n",
      "\n",
      "        [[-0.1026]],\n",
      "\n",
      "        [[-0.3314]],\n",
      "\n",
      "        [[-0.4481]]], dtype=torch.float64)\n",
      "tensor([[0.0032],\n",
      "        [0.2064],\n",
      "        [0.0330],\n",
      "        [0.0122]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1951]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[-0.1153]],\n",
      "\n",
      "        [[-0.1465]]], dtype=torch.float64)\n",
      "tensor([[0.0432],\n",
      "        [0.1017],\n",
      "        [0.2072],\n",
      "        [0.3475]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1165]],\n",
      "\n",
      "        [[-0.0807]],\n",
      "\n",
      "        [[ 0.3006]],\n",
      "\n",
      "        [[ 0.5952]]], dtype=torch.float64)\n",
      "tensor([[ 0.2591],\n",
      "        [ 0.0415],\n",
      "        [-0.0688],\n",
      "        [-0.0360]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2960]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[-0.6098]],\n",
      "\n",
      "        [[-0.1615]]], dtype=torch.float64)\n",
      "tensor([[0.3051],\n",
      "        [0.4361],\n",
      "        [0.4346],\n",
      "        [0.1320]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6334]],\n",
      "\n",
      "        [[ 0.8263]],\n",
      "\n",
      "        [[ 0.4878]],\n",
      "\n",
      "        [[-0.1130]]], dtype=torch.float64)\n",
      "tensor([[-0.0438],\n",
      "        [-0.0481],\n",
      "        [ 0.3947],\n",
      "        [ 0.5815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6029]],\n",
      "\n",
      "        [[ 0.0129]],\n",
      "\n",
      "        [[ 0.6611]],\n",
      "\n",
      "        [[ 0.9107]]], dtype=torch.float64)\n",
      "tensor([[ 0.5349],\n",
      "        [ 0.0966],\n",
      "        [-0.1159],\n",
      "        [-0.0609]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5201]],\n",
      "\n",
      "        [[-0.3210]],\n",
      "\n",
      "        [[-0.7023]],\n",
      "\n",
      "        [[-0.0922]]], dtype=torch.float64)\n",
      "tensor([[ 0.4633],\n",
      "        [ 0.2885],\n",
      "        [ 0.1898],\n",
      "        [-0.0021]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6888]],\n",
      "\n",
      "        [[ 0.0534]],\n",
      "\n",
      "        [[-0.3302]],\n",
      "\n",
      "        [[-0.4215]]], dtype=torch.float64)\n",
      "tensor([[-0.0633],\n",
      "        [ 0.0208],\n",
      "        [ 0.0967],\n",
      "        [ 0.0198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5475]],\n",
      "\n",
      "        [[-0.4111]],\n",
      "\n",
      "        [[-0.1200]],\n",
      "\n",
      "        [[-0.1072]]], dtype=torch.float64)\n",
      "tensor([[-0.0152],\n",
      "        [-0.0447],\n",
      "        [-0.0786],\n",
      "        [-0.0731]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2078]],\n",
      "\n",
      "        [[-0.5775]],\n",
      "\n",
      "        [[-0.6953]],\n",
      "\n",
      "        [[-0.5267]]], dtype=torch.float64)\n",
      "tensor([[0.1175],\n",
      "        [0.6386],\n",
      "        [0.5928],\n",
      "        [0.4363]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4450]],\n",
      "\n",
      "        [[0.9892]],\n",
      "\n",
      "        [[0.6230]],\n",
      "\n",
      "        [[0.1735]]], dtype=torch.float64)\n",
      "tensor([[0.1149],\n",
      "        [0.1346],\n",
      "        [0.7163],\n",
      "        [0.9613]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2008]],\n",
      "\n",
      "        [[ 0.2440]],\n",
      "\n",
      "        [[ 1.1117]],\n",
      "\n",
      "        [[ 1.4398]]], dtype=torch.float64)\n",
      "tensor([[0.8497],\n",
      "        [0.2351],\n",
      "        [0.0667],\n",
      "        [0.0948]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8645]],\n",
      "\n",
      "        [[ 0.0256]],\n",
      "\n",
      "        [[-0.4204]],\n",
      "\n",
      "        [[ 0.1389]]], dtype=torch.float64)\n",
      "tensor([[0.7623],\n",
      "        [0.9075],\n",
      "        [0.8774],\n",
      "        [0.3746]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1452]],\n",
      "\n",
      "        [[1.3128]],\n",
      "\n",
      "        [[0.9523]],\n",
      "\n",
      "        [[0.4185]]], dtype=torch.float64)\n",
      "tensor([[0.3134],\n",
      "        [0.4215],\n",
      "        [0.7684],\n",
      "        [0.9937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3769]],\n",
      "\n",
      "        [[0.8090]],\n",
      "\n",
      "        [[1.0955]],\n",
      "\n",
      "        [[1.3543]]], dtype=torch.float64)\n",
      "tensor([[0.6150],\n",
      "        [0.3210],\n",
      "        [0.3020],\n",
      "        [0.4254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7073]],\n",
      "\n",
      "        [[0.3711]],\n",
      "\n",
      "        [[0.1539]],\n",
      "\n",
      "        [[0.5629]]], dtype=torch.float64)\n",
      "tensor([[0.9900],\n",
      "        [0.7762],\n",
      "        [0.2233],\n",
      "        [0.1886]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.3035]],\n",
      "\n",
      "        [[ 0.3896]],\n",
      "\n",
      "        [[ 0.0464]],\n",
      "\n",
      "        [[-0.0553]]], dtype=torch.float64)\n",
      "tensor([[0.2129],\n",
      "        [0.2844],\n",
      "        [0.2661],\n",
      "        [0.3048]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1142]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[ 0.0638]],\n",
      "\n",
      "        [[ 0.1908]]], dtype=torch.float64)\n",
      "tensor([[0.2580],\n",
      "        [0.1646],\n",
      "        [0.2371],\n",
      "        [0.2471]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0603]],\n",
      "\n",
      "        [[-0.0160]],\n",
      "\n",
      "        [[-0.0021]],\n",
      "\n",
      "        [[ 0.1747]]], dtype=torch.float64)\n",
      "tensor([[0.4059],\n",
      "        [0.4805],\n",
      "        [0.3712],\n",
      "        [0.1640]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6472]],\n",
      "\n",
      "        [[0.9176]],\n",
      "\n",
      "        [[0.4785]],\n",
      "\n",
      "        [[0.0672]]], dtype=torch.float64)\n",
      "tensor([[0.0904],\n",
      "        [0.2539],\n",
      "        [0.4592],\n",
      "        [0.6291]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0587]],\n",
      "\n",
      "        [[ 0.0926]],\n",
      "\n",
      "        [[ 0.7894]],\n",
      "\n",
      "        [[ 0.9130]]], dtype=torch.float64)\n",
      "tensor([[0.3852],\n",
      "        [0.1812],\n",
      "        [0.1400],\n",
      "        [0.1206]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6103]],\n",
      "\n",
      "        [[ 0.1423]],\n",
      "\n",
      "        [[-0.2505]],\n",
      "\n",
      "        [[-0.1442]]], dtype=torch.float64)\n",
      "tensor([[0.5247],\n",
      "        [0.6530],\n",
      "        [0.4866],\n",
      "        [0.1372]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9569]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[0.7039]],\n",
      "\n",
      "        [[0.1134]]], dtype=torch.float64)\n",
      "tensor([[0.1104],\n",
      "        [0.0720],\n",
      "        [0.5993],\n",
      "        [0.8896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2644]],\n",
      "\n",
      "        [[-0.0148]],\n",
      "\n",
      "        [[ 1.1822]],\n",
      "\n",
      "        [[ 1.2885]]], dtype=torch.float64)\n",
      "tensor([[0.4578],\n",
      "        [0.1207],\n",
      "        [0.1337],\n",
      "        [0.1678]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4751]],\n",
      "\n",
      "        [[ 0.0753]],\n",
      "\n",
      "        [[-0.2274]],\n",
      "\n",
      "        [[-0.2078]]], dtype=torch.float64)\n",
      "tensor([[0.1885],\n",
      "        [0.1685],\n",
      "        [0.2665],\n",
      "        [0.0298]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2609]],\n",
      "\n",
      "        [[ 0.3087]],\n",
      "\n",
      "        [[-0.0137]],\n",
      "\n",
      "        [[-0.6746]]], dtype=torch.float64)\n",
      "tensor([[-0.1568],\n",
      "        [-0.1489],\n",
      "        [ 0.4052],\n",
      "        [ 0.2986]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9726]],\n",
      "\n",
      "        [[-0.5798]],\n",
      "\n",
      "        [[ 0.2174]],\n",
      "\n",
      "        [[ 0.0880]]], dtype=torch.float64)\n",
      "tensor([[0.2094],\n",
      "        [0.1410],\n",
      "        [0.1545],\n",
      "        [0.2964]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0349]],\n",
      "\n",
      "        [[-0.0749]],\n",
      "\n",
      "        [[-0.0321]],\n",
      "\n",
      "        [[ 0.2024]]], dtype=torch.float64)\n",
      "tensor([[0.3476],\n",
      "        [0.2440],\n",
      "        [0.1947],\n",
      "        [0.1587]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3861]],\n",
      "\n",
      "        [[0.2625]],\n",
      "\n",
      "        [[0.2278]],\n",
      "\n",
      "        [[0.0961]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.49745:   7%|▋         | 219/3067 [00:00<00:09, 299.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1823],\n",
      "        [0.3117],\n",
      "        [0.5012],\n",
      "        [0.6076]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0857]],\n",
      "\n",
      "        [[0.5271]],\n",
      "\n",
      "        [[0.9372]],\n",
      "\n",
      "        [[1.1152]]], dtype=torch.float64)\n",
      "tensor([[0.5132],\n",
      "        [0.1864],\n",
      "        [0.1658],\n",
      "        [0.2427]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8136]],\n",
      "\n",
      "        [[ 0.1631]],\n",
      "\n",
      "        [[-0.2759]],\n",
      "\n",
      "        [[ 0.1389]]], dtype=torch.float64)\n",
      "tensor([[0.4552],\n",
      "        [0.6649],\n",
      "        [0.4415],\n",
      "        [0.2024]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8922]],\n",
      "\n",
      "        [[1.2284]],\n",
      "\n",
      "        [[0.5814]],\n",
      "\n",
      "        [[0.3075]]], dtype=torch.float64)\n",
      "tensor([[0.0503],\n",
      "        [0.0637],\n",
      "        [0.4871],\n",
      "        [0.7402]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4088]],\n",
      "\n",
      "        [[ 0.0672]],\n",
      "\n",
      "        [[ 0.8425]],\n",
      "\n",
      "        [[ 1.0770]]], dtype=torch.float64)\n",
      "tensor([[0.5508],\n",
      "        [0.2899],\n",
      "        [0.3469],\n",
      "        [0.2694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8598]],\n",
      "\n",
      "        [[0.5352]],\n",
      "\n",
      "        [[0.3884]],\n",
      "\n",
      "        [[0.3249]]], dtype=torch.float64)\n",
      "tensor([[0.3456],\n",
      "        [0.5426],\n",
      "        [0.4865],\n",
      "        [0.1461]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6680]],\n",
      "\n",
      "        [[0.9384]],\n",
      "\n",
      "        [[0.5883]],\n",
      "\n",
      "        [[0.1862]]], dtype=torch.float64)\n",
      "tensor([[0.1910],\n",
      "        [0.2894],\n",
      "        [0.3875],\n",
      "        [0.2944]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1273]],\n",
      "\n",
      "        [[0.0984]],\n",
      "\n",
      "        [[0.3422]],\n",
      "\n",
      "        [[0.2636]]], dtype=torch.float64)\n",
      "tensor([[0.1286],\n",
      "        [0.0980],\n",
      "        [0.1046],\n",
      "        [0.0555]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0141]],\n",
      "\n",
      "        [[-0.0160]],\n",
      "\n",
      "        [[-0.0587]],\n",
      "\n",
      "        [[-0.0460]]], dtype=torch.float64)\n",
      "tensor([[0.4167],\n",
      "        [0.5040],\n",
      "        [0.4070],\n",
      "        [0.1549]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3156]],\n",
      "\n",
      "        [[ 0.6172]],\n",
      "\n",
      "        [[ 0.3584]],\n",
      "\n",
      "        [[-0.0183]]], dtype=torch.float64)\n",
      "tensor([[0.0447],\n",
      "        [0.0309],\n",
      "        [0.3471],\n",
      "        [0.5720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2124]],\n",
      "\n",
      "        [[-0.0356]],\n",
      "\n",
      "        [[ 0.6426]],\n",
      "\n",
      "        [[ 0.7628]]], dtype=torch.float64)\n",
      "tensor([[0.4753],\n",
      "        [0.3521],\n",
      "        [0.1204],\n",
      "        [0.1535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5906]],\n",
      "\n",
      "        [[ 0.1458]],\n",
      "\n",
      "        [[-0.1200]],\n",
      "\n",
      "        [[-0.0171]]], dtype=torch.float64)\n",
      "tensor([[0.3941],\n",
      "        [0.7352],\n",
      "        [0.6024],\n",
      "        [0.2538]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6345]],\n",
      "\n",
      "        [[0.9650]],\n",
      "\n",
      "        [[0.5213]],\n",
      "\n",
      "        [[0.2047]]], dtype=torch.float64)\n",
      "tensor([[0.2187],\n",
      "        [0.3223],\n",
      "        [0.6559],\n",
      "        [0.6543]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0730]],\n",
      "\n",
      "        [[0.3549]],\n",
      "\n",
      "        [[0.9580]],\n",
      "\n",
      "        [[1.1961]]], dtype=torch.float64)\n",
      "tensor([[0.6976],\n",
      "        [0.4133],\n",
      "        [0.2176],\n",
      "        [0.2825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9130]],\n",
      "\n",
      "        [[0.3226]],\n",
      "\n",
      "        [[0.1146]],\n",
      "\n",
      "        [[0.3780]]], dtype=torch.float64)\n",
      "tensor([[0.3861],\n",
      "        [0.4439],\n",
      "        [0.3743],\n",
      "        [0.1772]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7466]],\n",
      "\n",
      "        [[0.7836]],\n",
      "\n",
      "        [[0.5271]],\n",
      "\n",
      "        [[0.0926]]], dtype=torch.float64)\n",
      "tensor([[0.0881],\n",
      "        [0.1709],\n",
      "        [0.7339],\n",
      "        [1.0397]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3164]],\n",
      "\n",
      "        [[ 0.4404]],\n",
      "\n",
      "        [[ 1.3266]],\n",
      "\n",
      "        [[ 1.8673]]], dtype=torch.float64)\n",
      "tensor([[0.8487],\n",
      "        [0.2662],\n",
      "        [0.3040],\n",
      "        [0.3988]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8182]],\n",
      "\n",
      "        [[0.4970]],\n",
      "\n",
      "        [[0.4427]],\n",
      "\n",
      "        [[0.6195]]], dtype=torch.float64)\n",
      "tensor([[0.4782],\n",
      "        [0.6343],\n",
      "        [0.5111],\n",
      "        [0.1553]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0643]],\n",
      "\n",
      "        [[1.1441]],\n",
      "\n",
      "        [[0.6981]],\n",
      "\n",
      "        [[0.3006]]], dtype=torch.float64)\n",
      "tensor([[0.2070],\n",
      "        [0.2820],\n",
      "        [0.6686],\n",
      "        [0.7174]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0287]],\n",
      "\n",
      "        [[ 0.6137]],\n",
      "\n",
      "        [[ 1.2215]],\n",
      "\n",
      "        [[ 1.3047]]], dtype=torch.float64)\n",
      "tensor([[0.6004],\n",
      "        [0.2495],\n",
      "        [0.2250],\n",
      "        [0.3470]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0331]],\n",
      "\n",
      "        [[0.2763]],\n",
      "\n",
      "        [[0.3526]],\n",
      "\n",
      "        [[0.8194]]], dtype=torch.float64)\n",
      "tensor([[0.7225],\n",
      "        [0.8467],\n",
      "        [0.7298],\n",
      "        [0.3983]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3393]],\n",
      "\n",
      "        [[1.4849]],\n",
      "\n",
      "        [[1.2538]],\n",
      "\n",
      "        [[0.5744]]], dtype=torch.float64)\n",
      "tensor([[0.3729],\n",
      "        [0.4231],\n",
      "        [0.8000],\n",
      "        [0.9229]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4450]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[1.3393]],\n",
      "\n",
      "        [[1.3867]]], dtype=torch.float64)\n",
      "tensor([[0.5410],\n",
      "        [0.3733],\n",
      "        [0.4165],\n",
      "        [0.5004]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9315]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[0.4936]],\n",
      "\n",
      "        [[0.2036]]], dtype=torch.float64)\n",
      "tensor([[0.4006],\n",
      "        [0.6236],\n",
      "        [0.3273],\n",
      "        [0.2161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5432]],\n",
      "\n",
      "        [[0.9777]],\n",
      "\n",
      "        [[0.4370]],\n",
      "\n",
      "        [[0.1793]]], dtype=torch.float64)\n",
      "tensor([[0.1647],\n",
      "        [0.3063],\n",
      "        [0.4187],\n",
      "        [0.5048]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2598]],\n",
      "\n",
      "        [[ 0.4289]],\n",
      "\n",
      "        [[ 0.8078]],\n",
      "\n",
      "        [[ 1.0470]]], dtype=torch.float64)\n",
      "tensor([[0.5614],\n",
      "        [0.2441],\n",
      "        [0.2867],\n",
      "        [0.4573]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7501]],\n",
      "\n",
      "        [[0.4127]],\n",
      "\n",
      "        [[0.2660]],\n",
      "\n",
      "        [[0.8621]]], dtype=torch.float64)\n",
      "tensor([[1.0709],\n",
      "        [0.9908],\n",
      "        [0.9234],\n",
      "        [0.5272]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6120]],\n",
      "\n",
      "        [[1.8315]],\n",
      "\n",
      "        [[1.3717]],\n",
      "\n",
      "        [[0.7570]]], dtype=torch.float64)\n",
      "tensor([[0.4373],\n",
      "        [0.5180],\n",
      "        [0.9256],\n",
      "        [1.1518]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3387]],\n",
      "\n",
      "        [[0.8344]],\n",
      "\n",
      "        [[1.5277]],\n",
      "\n",
      "        [[1.7114]]], dtype=torch.float64)\n",
      "tensor([[1.0493],\n",
      "        [0.5778],\n",
      "        [0.5308],\n",
      "        [0.8341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3959]],\n",
      "\n",
      "        [[0.7062]],\n",
      "\n",
      "        [[0.7558]],\n",
      "\n",
      "        [[1.3359]]], dtype=torch.float64)\n",
      "tensor([[1.3574],\n",
      "        [1.2940],\n",
      "        [0.9111],\n",
      "        [0.5025]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6952]],\n",
      "\n",
      "        [[1.6929]],\n",
      "\n",
      "        [[1.2873]],\n",
      "\n",
      "        [[0.4474]]], dtype=torch.float64)\n",
      "tensor([[0.4109],\n",
      "        [0.3796],\n",
      "        [0.5259],\n",
      "        [0.4970]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0395]],\n",
      "\n",
      "        [[0.3445]],\n",
      "\n",
      "        [[0.6207]],\n",
      "\n",
      "        [[0.8194]]], dtype=torch.float64)\n",
      "tensor([[0.5719],\n",
      "        [0.3523],\n",
      "        [0.3111],\n",
      "        [0.3724]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5144]],\n",
      "\n",
      "        [[0.2740]],\n",
      "\n",
      "        [[0.0545]],\n",
      "\n",
      "        [[0.3122]]], dtype=torch.float64)\n",
      "tensor([[0.5897],\n",
      "        [0.5410],\n",
      "        [0.3860],\n",
      "        [0.2917]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7177]],\n",
      "\n",
      "        [[ 0.2613]],\n",
      "\n",
      "        [[ 0.3688]],\n",
      "\n",
      "        [[-0.1488]]], dtype=torch.float64)\n",
      "tensor([[0.1867],\n",
      "        [0.4019],\n",
      "        [0.4616],\n",
      "        [0.6321]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[ 0.1527]],\n",
      "\n",
      "        [[ 0.3434]],\n",
      "\n",
      "        [[ 0.7350]]], dtype=torch.float64)\n",
      "tensor([[0.4833],\n",
      "        [0.2146],\n",
      "        [0.2354],\n",
      "        [0.2160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5271]],\n",
      "\n",
      "        [[ 0.1053]],\n",
      "\n",
      "        [[-0.2147]],\n",
      "\n",
      "        [[-0.0414]]], dtype=torch.float64)\n",
      "tensor([[0.5445],\n",
      "        [0.4976],\n",
      "        [0.2996],\n",
      "        [0.3354]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5109]],\n",
      "\n",
      "        [[0.2729]],\n",
      "\n",
      "        [[0.3295]],\n",
      "\n",
      "        [[0.3064]]], dtype=torch.float64)\n",
      "tensor([[0.4164],\n",
      "        [0.4312],\n",
      "        [0.6863],\n",
      "        [0.7068]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1701]],\n",
      "\n",
      "        [[0.2324]],\n",
      "\n",
      "        [[0.6368]],\n",
      "\n",
      "        [[0.9153]]], dtype=torch.float64)\n",
      "tensor([[0.7687],\n",
      "        [0.4571],\n",
      "        [0.4926],\n",
      "        [0.6135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8055]],\n",
      "\n",
      "        [[0.3780]],\n",
      "\n",
      "        [[0.2867]],\n",
      "\n",
      "        [[0.4277]]], dtype=torch.float64)\n",
      "tensor([[0.9210],\n",
      "        [0.9327],\n",
      "        [0.8892],\n",
      "        [0.5363]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9407]],\n",
      "\n",
      "        [[1.2330]],\n",
      "\n",
      "        [[0.9037]],\n",
      "\n",
      "        [[0.4266]]], dtype=torch.float64)\n",
      "tensor([[0.5484],\n",
      "        [0.7480],\n",
      "        [1.0963],\n",
      "        [1.1094]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2706]],\n",
      "\n",
      "        [[0.9708]],\n",
      "\n",
      "        [[1.3948]],\n",
      "\n",
      "        [[1.6201]]], dtype=torch.float64)\n",
      "tensor([[1.0299],\n",
      "        [0.5476],\n",
      "        [0.4319],\n",
      "        [0.4326]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.0574]],\n",
      "\n",
      "        [[ 0.4543]],\n",
      "\n",
      "        [[-0.0079]],\n",
      "\n",
      "        [[ 0.2348]]], dtype=torch.float64)\n",
      "tensor([[0.4102],\n",
      "        [0.4600],\n",
      "        [0.4284],\n",
      "        [0.3427]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3295]],\n",
      "\n",
      "        [[ 0.4381]],\n",
      "\n",
      "        [[ 0.1238]],\n",
      "\n",
      "        [[-0.0206]]], dtype=torch.float64)\n",
      "tensor([[0.3332],\n",
      "        [0.3444],\n",
      "        [0.4858],\n",
      "        [0.4654]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2205]],\n",
      "\n",
      "        [[-0.0968]],\n",
      "\n",
      "        [[ 0.0580]],\n",
      "\n",
      "        [[ 0.3561]]], dtype=torch.float64)\n",
      "tensor([[0.4048],\n",
      "        [0.3212],\n",
      "        [0.3166],\n",
      "        [0.3878]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1227]],\n",
      "\n",
      "        [[-0.0102]],\n",
      "\n",
      "        [[-0.2736]],\n",
      "\n",
      "        [[ 0.1019]]], dtype=torch.float64)\n",
      "tensor([[0.4254],\n",
      "        [0.3898],\n",
      "        [0.4571],\n",
      "        [0.1852]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1053]],\n",
      "\n",
      "        [[ 0.2995]],\n",
      "\n",
      "        [[ 0.1643]],\n",
      "\n",
      "        [[-0.4250]]], dtype=torch.float64)\n",
      "tensor([[0.0454],\n",
      "        [0.2359],\n",
      "        [0.6544],\n",
      "        [0.4363]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5405]],\n",
      "\n",
      "        [[-0.0529]],\n",
      "\n",
      "        [[ 0.1446]],\n",
      "\n",
      "        [[-0.0310]]], dtype=torch.float64)\n",
      "tensor([[0.3784],\n",
      "        [0.4008],\n",
      "        [0.3680],\n",
      "        [0.4538]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0580]],\n",
      "\n",
      "        [[-0.0321]],\n",
      "\n",
      "        [[-0.2274]],\n",
      "\n",
      "        [[ 0.2463]]], dtype=torch.float64)\n",
      "tensor([[0.7321],\n",
      "        [0.7696],\n",
      "        [0.5662],\n",
      "        [0.4885]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6773]],\n",
      "\n",
      "        [[0.9164]],\n",
      "\n",
      "        [[0.4219]],\n",
      "\n",
      "        [[0.1735]]], dtype=torch.float64)\n",
      "tensor([[0.4071],\n",
      "        [0.5775],\n",
      "        [0.7639],\n",
      "        [0.8750]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0067]],\n",
      "\n",
      "        [[ 0.4751]],\n",
      "\n",
      "        [[ 0.8922]],\n",
      "\n",
      "        [[ 1.1394]]], dtype=torch.float64)\n",
      "tensor([[0.7221],\n",
      "        [0.4762],\n",
      "        [0.5305],\n",
      "        [0.6517]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8506]],\n",
      "\n",
      "        [[0.4300]],\n",
      "\n",
      "        [[0.2833]],\n",
      "\n",
      "        [[0.5225]]], dtype=torch.float64)\n",
      "tensor([[0.8221],\n",
      "        [0.9041],\n",
      "        [0.8282],\n",
      "        [0.4680]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5664]],\n",
      "\n",
      "        [[1.1290]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.4393]]], dtype=torch.float64)\n",
      "tensor([[0.4822],\n",
      "        [0.6758],\n",
      "        [0.8264],\n",
      "        [0.8103]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1712]],\n",
      "\n",
      "        [[0.6877]],\n",
      "\n",
      "        [[0.9384]],\n",
      "\n",
      "        [[0.5444]]], dtype=torch.float64)\n",
      "tensor([[0.5348],\n",
      "        [0.4161],\n",
      "        [0.4676],\n",
      "        [0.8308]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7050]],\n",
      "\n",
      "        [[0.4254]],\n",
      "\n",
      "        [[0.3457]],\n",
      "\n",
      "        [[0.7015]]], dtype=torch.float64)\n",
      "tensor([[0.9639],\n",
      "        [0.4783],\n",
      "        [0.2932],\n",
      "        [0.2372]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8910]],\n",
      "\n",
      "        [[0.4185]],\n",
      "\n",
      "        [[0.1805]],\n",
      "\n",
      "        [[0.0788]]], dtype=torch.float64)\n",
      "tensor([[0.2754],\n",
      "        [0.3078],\n",
      "        [0.3445],\n",
      "        [0.3708]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0876]],\n",
      "\n",
      "        [[ 0.2717]],\n",
      "\n",
      "        [[ 0.5594]],\n",
      "\n",
      "        [[ 0.5606]]], dtype=torch.float64)\n",
      "tensor([[0.2652],\n",
      "        [0.2143],\n",
      "        [0.1493],\n",
      "        [0.3655]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0603]],\n",
      "\n",
      "        [[-0.1673]],\n",
      "\n",
      "        [[-0.1257]],\n",
      "\n",
      "        [[ 0.2925]]], dtype=torch.float64)\n",
      "tensor([[0.3583],\n",
      "        [0.5189],\n",
      "        [0.5964],\n",
      "        [0.3540]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8575]],\n",
      "\n",
      "        [[1.1729]],\n",
      "\n",
      "        [[0.8402]],\n",
      "\n",
      "        [[0.1204]]], dtype=torch.float64)\n",
      "tensor([[0.1275],\n",
      "        [0.2424],\n",
      "        [0.7809],\n",
      "        [0.9568]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3383]],\n",
      "\n",
      "        [[ 0.4601]],\n",
      "\n",
      "        [[ 1.4502]],\n",
      "\n",
      "        [[ 1.6709]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.39015:   9%|▉         | 279/3067 [00:00<00:09, 290.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8084],\n",
      "        [0.6272],\n",
      "        [0.5666],\n",
      "        [0.6677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2665]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.4924]],\n",
      "\n",
      "        [[1.0066]]], dtype=torch.float64)\n",
      "tensor([[1.0658],\n",
      "        [0.9842],\n",
      "        [0.6447],\n",
      "        [0.3382]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4468]],\n",
      "\n",
      "        [[0.9003]],\n",
      "\n",
      "        [[0.6184]],\n",
      "\n",
      "        [[0.1805]]], dtype=torch.float64)\n",
      "tensor([[0.3999],\n",
      "        [0.4515],\n",
      "        [0.5696],\n",
      "        [0.3909]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2012]],\n",
      "\n",
      "        [[0.3561]],\n",
      "\n",
      "        [[0.5490]],\n",
      "\n",
      "        [[0.8645]]], dtype=torch.float64)\n",
      "tensor([[0.2995],\n",
      "        [0.2525],\n",
      "        [0.2243],\n",
      "        [0.3378]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3133]],\n",
      "\n",
      "        [[ 0.0349]],\n",
      "\n",
      "        [[-0.1327]],\n",
      "\n",
      "        [[ 0.3156]]], dtype=torch.float64)\n",
      "tensor([[0.5845],\n",
      "        [0.7466],\n",
      "        [0.7567],\n",
      "        [0.3893]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9037]],\n",
      "\n",
      "        [[1.2457]],\n",
      "\n",
      "        [[1.0008]],\n",
      "\n",
      "        [[0.4370]]], dtype=torch.float64)\n",
      "tensor([[0.3903],\n",
      "        [0.4978],\n",
      "        [0.8791],\n",
      "        [0.8488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1908]],\n",
      "\n",
      "        [[1.1418]],\n",
      "\n",
      "        [[1.3890]],\n",
      "\n",
      "        [[1.2423]]], dtype=torch.float64)\n",
      "tensor([[0.8337],\n",
      "        [0.5864],\n",
      "        [0.6171],\n",
      "        [0.7255]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2538]],\n",
      "\n",
      "        [[0.9141]],\n",
      "\n",
      "        [[0.5906]],\n",
      "\n",
      "        [[0.9326]]], dtype=torch.float64)\n",
      "tensor([[0.8277],\n",
      "        [0.5945],\n",
      "        [0.5142],\n",
      "        [0.2616]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8356]],\n",
      "\n",
      "        [[1.0666]],\n",
      "\n",
      "        [[0.5467]],\n",
      "\n",
      "        [[0.4000]]], dtype=torch.float64)\n",
      "tensor([[0.3092],\n",
      "        [0.3624],\n",
      "        [0.5379],\n",
      "        [0.4219]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0788]],\n",
      "\n",
      "        [[0.5536]],\n",
      "\n",
      "        [[0.8309]],\n",
      "\n",
      "        [[0.9465]]], dtype=torch.float64)\n",
      "tensor([[0.3822],\n",
      "        [0.2253],\n",
      "        [0.2346],\n",
      "        [0.2737]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5132]],\n",
      "\n",
      "        [[ 0.2220]],\n",
      "\n",
      "        [[-0.1049]],\n",
      "\n",
      "        [[ 0.1077]]], dtype=torch.float64)\n",
      "tensor([[0.4545],\n",
      "        [0.3801],\n",
      "        [0.3038],\n",
      "        [0.2136]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3018]],\n",
      "\n",
      "        [[0.7662]],\n",
      "\n",
      "        [[0.4092]],\n",
      "\n",
      "        [[0.1377]]], dtype=torch.float64)\n",
      "tensor([[0.2730],\n",
      "        [0.3993],\n",
      "        [0.2863],\n",
      "        [0.3274]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0152]],\n",
      "\n",
      "        [[0.1712]],\n",
      "\n",
      "        [[0.3954]],\n",
      "\n",
      "        [[0.6773]]], dtype=torch.float64)\n",
      "tensor([[0.3120],\n",
      "        [0.3586],\n",
      "        [0.3464],\n",
      "        [0.3014]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3734]],\n",
      "\n",
      "        [[0.2636]],\n",
      "\n",
      "        [[0.1238]],\n",
      "\n",
      "        [[0.3260]]], dtype=torch.float64)\n",
      "tensor([[0.3660],\n",
      "        [0.4964],\n",
      "        [0.5109],\n",
      "        [0.3549]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6519]],\n",
      "\n",
      "        [[0.9176]],\n",
      "\n",
      "        [[0.8448]],\n",
      "\n",
      "        [[0.4624]]], dtype=torch.float64)\n",
      "tensor([[0.3339],\n",
      "        [0.3465],\n",
      "        [0.7036],\n",
      "        [0.7519]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2694]],\n",
      "\n",
      "        [[0.4346]],\n",
      "\n",
      "        [[0.9153]],\n",
      "\n",
      "        [[1.2989]]], dtype=torch.float64)\n",
      "tensor([[0.8908],\n",
      "        [0.7434],\n",
      "        [0.6862],\n",
      "        [0.5841]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2677]],\n",
      "\n",
      "        [[0.8841]],\n",
      "\n",
      "        [[0.5952]],\n",
      "\n",
      "        [[0.5144]]], dtype=torch.float64)\n",
      "tensor([[0.7203],\n",
      "        [0.6521],\n",
      "        [0.5759],\n",
      "        [0.5300]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5756]],\n",
      "\n",
      "        [[0.6819]],\n",
      "\n",
      "        [[0.6184]],\n",
      "\n",
      "        [[0.6126]]], dtype=torch.float64)\n",
      "tensor([[0.7222],\n",
      "        [0.8383],\n",
      "        [1.0867],\n",
      "        [1.1187]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6484]],\n",
      "\n",
      "        [[0.7628]],\n",
      "\n",
      "        [[0.8864]],\n",
      "\n",
      "        [[1.4006]]], dtype=torch.float64)\n",
      "tensor([[1.0717],\n",
      "        [0.8815],\n",
      "        [0.9133],\n",
      "        [0.9530]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1995]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[0.8194]],\n",
      "\n",
      "        [[0.7986]]], dtype=torch.float64)\n",
      "tensor([[1.0134],\n",
      "        [0.9735],\n",
      "        [0.7847],\n",
      "        [0.6696]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9511]],\n",
      "\n",
      "        [[0.8679]],\n",
      "\n",
      "        [[0.7385]],\n",
      "\n",
      "        [[0.7212]]], dtype=torch.float64)\n",
      "tensor([[0.7544],\n",
      "        [0.9175],\n",
      "        [1.0363],\n",
      "        [0.9258]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6992]],\n",
      "\n",
      "        [[0.8379]],\n",
      "\n",
      "        [[1.1764]],\n",
      "\n",
      "        [[1.2400]]], dtype=torch.float64)\n",
      "tensor([[0.9076],\n",
      "        [0.6641],\n",
      "        [0.5796],\n",
      "        [0.5312]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1233]],\n",
      "\n",
      "        [[0.5525]],\n",
      "\n",
      "        [[0.2232]],\n",
      "\n",
      "        [[0.5710]]], dtype=torch.float64)\n",
      "tensor([[1.2463],\n",
      "        [1.2866],\n",
      "        [1.1082],\n",
      "        [0.7660]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5011]],\n",
      "\n",
      "        [[1.6467]],\n",
      "\n",
      "        [[1.4710]],\n",
      "\n",
      "        [[0.7408]]], dtype=torch.float64)\n",
      "tensor([[0.6330],\n",
      "        [0.6931],\n",
      "        [1.3667],\n",
      "        [1.3606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4127]],\n",
      "\n",
      "        [[1.2065]],\n",
      "\n",
      "        [[1.7160]],\n",
      "\n",
      "        [[1.8616]]], dtype=torch.float64)\n",
      "tensor([[1.3262],\n",
      "        [0.9784],\n",
      "        [0.8586],\n",
      "        [0.8979]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6201]],\n",
      "\n",
      "        [[1.0285]],\n",
      "\n",
      "        [[0.6865]],\n",
      "\n",
      "        [[1.2943]]], dtype=torch.float64)\n",
      "tensor([[1.5877],\n",
      "        [1.4438],\n",
      "        [1.2759],\n",
      "        [1.1290]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8142]],\n",
      "\n",
      "        [[1.2376]],\n",
      "\n",
      "        [[1.3486]],\n",
      "\n",
      "        [[1.1233]]], dtype=torch.float64)\n",
      "tensor([[1.1191],\n",
      "        [1.1224],\n",
      "        [1.5355],\n",
      "        [1.6274]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9222]],\n",
      "\n",
      "        [[1.0678]],\n",
      "\n",
      "        [[1.7969]],\n",
      "\n",
      "        [[1.9806]]], dtype=torch.float64)\n",
      "tensor([[1.3359],\n",
      "        [1.0523],\n",
      "        [1.1190],\n",
      "        [1.1498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4572]],\n",
      "\n",
      "        [[1.1498]],\n",
      "\n",
      "        [[0.8656]],\n",
      "\n",
      "        [[1.1579]]], dtype=torch.float64)\n",
      "tensor([[1.5553],\n",
      "        [1.6701],\n",
      "        [1.6317],\n",
      "        [1.3239]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8362]],\n",
      "\n",
      "        [[2.1111]],\n",
      "\n",
      "        [[1.7818]],\n",
      "\n",
      "        [[1.3162]]], dtype=torch.float64)\n",
      "tensor([[1.2610],\n",
      "        [1.3983],\n",
      "        [1.4586],\n",
      "        [1.4858]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9765]],\n",
      "\n",
      "        [[1.3775]],\n",
      "\n",
      "        [[1.3717]],\n",
      "\n",
      "        [[1.8142]]], dtype=torch.float64)\n",
      "tensor([[1.5155],\n",
      "        [1.0813],\n",
      "        [0.9466],\n",
      "        [1.0265]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5288]],\n",
      "\n",
      "        [[0.9476]],\n",
      "\n",
      "        [[0.7281]],\n",
      "\n",
      "        [[1.2480]]], dtype=torch.float64)\n",
      "tensor([[1.3498],\n",
      "        [1.3054],\n",
      "        [1.2361],\n",
      "        [0.9009]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6940]],\n",
      "\n",
      "        [[1.9124]],\n",
      "\n",
      "        [[1.4941]],\n",
      "\n",
      "        [[0.8275]]], dtype=torch.float64)\n",
      "tensor([[0.7381],\n",
      "        [0.8838],\n",
      "        [1.2014],\n",
      "        [1.1259]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4346]],\n",
      "\n",
      "        [[0.7293]],\n",
      "\n",
      "        [[1.1903]],\n",
      "\n",
      "        [[1.3590]]], dtype=torch.float64)\n",
      "tensor([[1.2097],\n",
      "        [0.6945],\n",
      "        [0.7884],\n",
      "        [0.8104]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2665]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[0.3803]],\n",
      "\n",
      "        [[0.8136]]], dtype=torch.float64)\n",
      "tensor([[1.1310],\n",
      "        [1.0963],\n",
      "        [0.9075],\n",
      "        [0.7229]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4271]],\n",
      "\n",
      "        [[0.5687]],\n",
      "\n",
      "        [[0.7963]],\n",
      "\n",
      "        [[0.5456]]], dtype=torch.float64)\n",
      "tensor([[0.5847],\n",
      "        [0.7355],\n",
      "        [0.8162],\n",
      "        [0.7605]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5121]],\n",
      "\n",
      "        [[0.6253]],\n",
      "\n",
      "        [[0.9500]],\n",
      "\n",
      "        [[1.0181]]], dtype=torch.float64)\n",
      "tensor([[0.5652],\n",
      "        [0.5872],\n",
      "        [0.5518],\n",
      "        [0.6838]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6819]],\n",
      "\n",
      "        [[0.4739]],\n",
      "\n",
      "        [[0.2937]],\n",
      "\n",
      "        [[0.6022]]], dtype=torch.float64)\n",
      "tensor([[0.6526],\n",
      "        [0.6465],\n",
      "        [0.5965],\n",
      "        [0.4657]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9303]],\n",
      "\n",
      "        [[0.8656]],\n",
      "\n",
      "        [[0.7593]],\n",
      "\n",
      "        [[0.4023]]], dtype=torch.float64)\n",
      "tensor([[0.5171],\n",
      "        [0.6371],\n",
      "        [0.6354],\n",
      "        [0.5289]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1712]],\n",
      "\n",
      "        [[0.5028]],\n",
      "\n",
      "        [[0.8067]],\n",
      "\n",
      "        [[0.5513]]], dtype=torch.float64)\n",
      "tensor([[0.3828],\n",
      "        [0.3776],\n",
      "        [0.5287],\n",
      "        [0.5487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2486]],\n",
      "\n",
      "        [[0.2775]],\n",
      "\n",
      "        [[0.2059]],\n",
      "\n",
      "        [[0.3838]]], dtype=torch.float64)\n",
      "tensor([[0.5774],\n",
      "        [0.5418],\n",
      "        [0.4482],\n",
      "        [0.3601]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5617]],\n",
      "\n",
      "        [[0.5664]],\n",
      "\n",
      "        [[0.1862]],\n",
      "\n",
      "        [[0.2036]]], dtype=torch.float64)\n",
      "tensor([[0.6017],\n",
      "        [0.7030],\n",
      "        [1.1422],\n",
      "        [0.9584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2140]],\n",
      "\n",
      "        [[0.4115]],\n",
      "\n",
      "        [[1.1071]],\n",
      "\n",
      "        [[1.2792]]], dtype=torch.float64)\n",
      "tensor([[1.0559],\n",
      "        [0.8767],\n",
      "        [1.0259],\n",
      "        [1.0242]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1498]],\n",
      "\n",
      "        [[0.8333]],\n",
      "\n",
      "        [[0.7801]],\n",
      "\n",
      "        [[1.1660]]], dtype=torch.float64)\n",
      "tensor([[1.3532],\n",
      "        [1.3250],\n",
      "        [1.3385],\n",
      "        [1.2057]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5508]],\n",
      "\n",
      "        [[1.7160]],\n",
      "\n",
      "        [[1.5219]],\n",
      "\n",
      "        [[1.0759]]], dtype=torch.float64)\n",
      "tensor([[1.1299],\n",
      "        [1.3527],\n",
      "        [1.4866],\n",
      "        [1.5087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8402]],\n",
      "\n",
      "        [[1.1637]],\n",
      "\n",
      "        [[1.5496]],\n",
      "\n",
      "        [[1.6074]]], dtype=torch.float64)\n",
      "tensor([[1.4152],\n",
      "        [1.2028],\n",
      "        [1.1242],\n",
      "        [1.3282]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3289]],\n",
      "\n",
      "        [[1.0239]],\n",
      "\n",
      "        [[1.0331]],\n",
      "\n",
      "        [[1.2457]]], dtype=torch.float64)\n",
      "tensor([[1.3420],\n",
      "        [1.3336],\n",
      "        [1.2645],\n",
      "        [0.9886]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4595]],\n",
      "\n",
      "        [[1.5912]],\n",
      "\n",
      "        [[1.4468]],\n",
      "\n",
      "        [[0.9557]]], dtype=torch.float64)\n",
      "tensor([[0.9884],\n",
      "        [0.9571],\n",
      "        [1.2232],\n",
      "        [1.3652]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6495]],\n",
      "\n",
      "        [[1.2977]],\n",
      "\n",
      "        [[1.8200]],\n",
      "\n",
      "        [[1.9806]]], dtype=torch.float64)\n",
      "tensor([[1.3590],\n",
      "        [0.9560],\n",
      "        [0.7537],\n",
      "        [0.9307]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6548]],\n",
      "\n",
      "        [[0.8344]],\n",
      "\n",
      "        [[0.4635]],\n",
      "\n",
      "        [[1.3382]]], dtype=torch.float64)\n",
      "tensor([[1.9192],\n",
      "        [1.4011],\n",
      "        [1.3090],\n",
      "        [1.0768]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8084]],\n",
      "\n",
      "        [[1.6721]],\n",
      "\n",
      "        [[1.4398]],\n",
      "\n",
      "        [[0.7027]]], dtype=torch.float64)\n",
      "tensor([[0.7671],\n",
      "        [0.9079],\n",
      "        [0.7351],\n",
      "        [0.6871]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5017]],\n",
      "\n",
      "        [[0.6426]],\n",
      "\n",
      "        [[0.7974]],\n",
      "\n",
      "        [[1.0135]]], dtype=torch.float64)\n",
      "tensor([[0.6202],\n",
      "        [0.4790],\n",
      "        [0.6191],\n",
      "        [0.7651]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7339]],\n",
      "\n",
      "        [[0.4797]],\n",
      "\n",
      "        [[0.4046]],\n",
      "\n",
      "        [[0.6750]]], dtype=torch.float64)\n",
      "tensor([[0.7628],\n",
      "        [0.6988],\n",
      "        [0.8004],\n",
      "        [0.5085]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8205]],\n",
      "\n",
      "        [[0.8749]],\n",
      "\n",
      "        [[0.6045]],\n",
      "\n",
      "        [[0.4855]]], dtype=torch.float64)\n",
      "tensor([[0.6019],\n",
      "        [0.7000],\n",
      "        [0.7683],\n",
      "        [0.7806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2070]],\n",
      "\n",
      "        [[0.5906]],\n",
      "\n",
      "        [[1.0077]],\n",
      "\n",
      "        [[1.1002]]], dtype=torch.float64)\n",
      "tensor([[0.7766],\n",
      "        [0.4637],\n",
      "        [0.5798],\n",
      "        [0.6055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7674]],\n",
      "\n",
      "        [[0.4011]],\n",
      "\n",
      "        [[0.2660]],\n",
      "\n",
      "        [[0.4959]]], dtype=torch.float64)\n",
      "tensor([[1.0538],\n",
      "        [1.2339],\n",
      "        [1.5201],\n",
      "        [1.2041]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2631]],\n",
      "\n",
      "        [[1.8465]],\n",
      "\n",
      "        [[1.6663]],\n",
      "\n",
      "        [[1.2169]]], dtype=torch.float64)\n",
      "tensor([[1.1161],\n",
      "        [1.0251],\n",
      "        [1.8194],\n",
      "        [1.4983]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1695]],\n",
      "\n",
      "        [[0.9234]],\n",
      "\n",
      "        [[1.6028]],\n",
      "\n",
      "        [[1.9540]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.39015:  11%|█         | 342/3067 [00:01<00:09, 302.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5834],\n",
      "        [1.2226],\n",
      "        [1.3163],\n",
      "        [1.5016]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7391]],\n",
      "\n",
      "        [[1.1348]],\n",
      "\n",
      "        [[1.1614]],\n",
      "\n",
      "        [[1.6709]]], dtype=torch.float64)\n",
      "tensor([[1.5185],\n",
      "        [1.6079],\n",
      "        [1.3423],\n",
      "        [1.0404]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3151]],\n",
      "\n",
      "        [[1.1314]],\n",
      "\n",
      "        [[1.2977]],\n",
      "\n",
      "        [[0.6935]]], dtype=torch.float64)\n",
      "tensor([[0.8901],\n",
      "        [0.9875],\n",
      "        [1.0656],\n",
      "        [1.0247]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6010]],\n",
      "\n",
      "        [[0.9315]],\n",
      "\n",
      "        [[1.0840]],\n",
      "\n",
      "        [[1.3139]]], dtype=torch.float64)\n",
      "tensor([[0.5776],\n",
      "        [0.5368],\n",
      "        [0.6264],\n",
      "        [0.7365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8021]],\n",
      "\n",
      "        [[0.6022]],\n",
      "\n",
      "        [[0.4358]],\n",
      "\n",
      "        [[0.6403]]], dtype=torch.float64)\n",
      "tensor([[0.6081],\n",
      "        [0.6147],\n",
      "        [0.4909],\n",
      "        [0.5275]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9430]],\n",
      "\n",
      "        [[0.8852]],\n",
      "\n",
      "        [[0.6969]],\n",
      "\n",
      "        [[0.5051]]], dtype=torch.float64)\n",
      "tensor([[0.5213],\n",
      "        [0.5832],\n",
      "        [0.7058],\n",
      "        [0.7830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3376]],\n",
      "\n",
      "        [[0.7408]],\n",
      "\n",
      "        [[1.2076]],\n",
      "\n",
      "        [[1.3532]]], dtype=torch.float64)\n",
      "tensor([[0.8477],\n",
      "        [0.5312],\n",
      "        [0.5220],\n",
      "        [0.6108]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0551]],\n",
      "\n",
      "        [[0.5536]],\n",
      "\n",
      "        [[0.2683]],\n",
      "\n",
      "        [[0.8656]]], dtype=torch.float64)\n",
      "tensor([[1.1204],\n",
      "        [1.4536],\n",
      "        [1.3938],\n",
      "        [1.0755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7830]],\n",
      "\n",
      "        [[2.1158]],\n",
      "\n",
      "        [[1.7888]],\n",
      "\n",
      "        [[1.0551]]], dtype=torch.float64)\n",
      "tensor([[1.0740],\n",
      "        [0.7741],\n",
      "        [0.7605],\n",
      "        [1.0377]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8587]],\n",
      "\n",
      "        [[0.7870]],\n",
      "\n",
      "        [[1.2943]],\n",
      "\n",
      "        [[1.5750]]], dtype=torch.float64)\n",
      "tensor([[0.9530],\n",
      "        [0.6922],\n",
      "        [0.6238],\n",
      "        [0.5590]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2769]],\n",
      "\n",
      "        [[0.6287]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.7790]]], dtype=torch.float64)\n",
      "tensor([[1.1232],\n",
      "        [1.3493],\n",
      "        [1.3326],\n",
      "        [0.9132]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6894]],\n",
      "\n",
      "        [[1.9725]],\n",
      "\n",
      "        [[1.5300]],\n",
      "\n",
      "        [[0.7443]]], dtype=torch.float64)\n",
      "tensor([[0.8017],\n",
      "        [0.9054],\n",
      "        [1.0185],\n",
      "        [0.9539]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5617]],\n",
      "\n",
      "        [[1.3659]],\n",
      "\n",
      "        [[1.5565]],\n",
      "\n",
      "        [[1.4237]]], dtype=torch.float64)\n",
      "tensor([[0.8292],\n",
      "        [0.5734],\n",
      "        [0.4794],\n",
      "        [0.4666]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1452]],\n",
      "\n",
      "        [[0.5744]],\n",
      "\n",
      "        [[0.2163]],\n",
      "\n",
      "        [[0.4462]]], dtype=torch.float64)\n",
      "tensor([[0.7984],\n",
      "        [0.8501],\n",
      "        [0.8407],\n",
      "        [0.6044]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0609]],\n",
      "\n",
      "        [[1.2561]],\n",
      "\n",
      "        [[1.0147]],\n",
      "\n",
      "        [[0.4358]]], dtype=torch.float64)\n",
      "tensor([[0.4457],\n",
      "        [0.4760],\n",
      "        [1.3338],\n",
      "        [1.5920]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0684]],\n",
      "\n",
      "        [[0.7362]],\n",
      "\n",
      "        [[1.7195]],\n",
      "\n",
      "        [[1.9505]]], dtype=torch.float64)\n",
      "tensor([[1.5668],\n",
      "        [1.1202],\n",
      "        [0.9057],\n",
      "        [0.9135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6802]],\n",
      "\n",
      "        [[0.8182]],\n",
      "\n",
      "        [[0.3896]],\n",
      "\n",
      "        [[0.7882]]], dtype=torch.float64)\n",
      "tensor([[1.8935],\n",
      "        [1.6195],\n",
      "        [1.3983],\n",
      "        [1.2251]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1481]],\n",
      "\n",
      "        [[1.8200]],\n",
      "\n",
      "        [[1.3786]],\n",
      "\n",
      "        [[1.1602]]], dtype=torch.float64)\n",
      "tensor([[1.2187],\n",
      "        [1.0174],\n",
      "        [0.9718],\n",
      "        [0.9569]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8090]],\n",
      "\n",
      "        [[0.5837]],\n",
      "\n",
      "        [[1.0366]],\n",
      "\n",
      "        [[1.2111]]], dtype=torch.float64)\n",
      "tensor([[0.8719],\n",
      "        [0.8437],\n",
      "        [0.6733],\n",
      "        [0.6270]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9765]],\n",
      "\n",
      "        [[0.6646]],\n",
      "\n",
      "        [[0.3561]],\n",
      "\n",
      "        [[0.8309]]], dtype=torch.float64)\n",
      "tensor([[1.0907],\n",
      "        [1.1707],\n",
      "        [1.0314],\n",
      "        [0.7756]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2688]],\n",
      "\n",
      "        [[1.4757]],\n",
      "\n",
      "        [[1.2088]],\n",
      "\n",
      "        [[0.5063]]], dtype=torch.float64)\n",
      "tensor([[0.5365],\n",
      "        [0.5421],\n",
      "        [1.2093],\n",
      "        [1.3787]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1365]],\n",
      "\n",
      "        [[0.7027]],\n",
      "\n",
      "        [[1.4907]],\n",
      "\n",
      "        [[1.7241]]], dtype=torch.float64)\n",
      "tensor([[1.4141],\n",
      "        [1.0610],\n",
      "        [0.8477],\n",
      "        [0.7790]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4341]],\n",
      "\n",
      "        [[0.7512]],\n",
      "\n",
      "        [[0.3850]],\n",
      "\n",
      "        [[0.9107]]], dtype=torch.float64)\n",
      "tensor([[1.5223],\n",
      "        [1.6821],\n",
      "        [1.6443],\n",
      "        [1.1161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7379]],\n",
      "\n",
      "        [[1.9309]],\n",
      "\n",
      "        [[1.6062]],\n",
      "\n",
      "        [[0.9211]]], dtype=torch.float64)\n",
      "tensor([[1.0162],\n",
      "        [0.9598],\n",
      "        [1.6909],\n",
      "        [1.8425]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5594]],\n",
      "\n",
      "        [[1.1510]],\n",
      "\n",
      "        [[1.9251]],\n",
      "\n",
      "        [[2.1238]]], dtype=torch.float64)\n",
      "tensor([[1.7365],\n",
      "        [1.2905],\n",
      "        [1.0517],\n",
      "        [1.0245]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6883]],\n",
      "\n",
      "        [[1.1637]],\n",
      "\n",
      "        [[0.5860]],\n",
      "\n",
      "        [[1.1314]]], dtype=torch.float64)\n",
      "tensor([[1.7078],\n",
      "        [1.8542],\n",
      "        [1.6192],\n",
      "        [1.1805]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9286]],\n",
      "\n",
      "        [[2.0360]],\n",
      "\n",
      "        [[1.3717]],\n",
      "\n",
      "        [[1.0643]]], dtype=torch.float64)\n",
      "tensor([[1.2707],\n",
      "        [1.3130],\n",
      "        [1.4163],\n",
      "        [1.4412]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9257]],\n",
      "\n",
      "        [[0.8841]],\n",
      "\n",
      "        [[1.4063]],\n",
      "\n",
      "        [[1.6755]]], dtype=torch.float64)\n",
      "tensor([[1.4041],\n",
      "        [1.1573],\n",
      "        [1.0777],\n",
      "        [1.1180]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5126]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[0.7420]],\n",
      "\n",
      "        [[1.0239]]], dtype=torch.float64)\n",
      "tensor([[1.7506],\n",
      "        [1.2906],\n",
      "        [1.2412],\n",
      "        [1.1654]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8558]],\n",
      "\n",
      "        [[1.1002]],\n",
      "\n",
      "        [[0.9973]],\n",
      "\n",
      "        [[0.7790]]], dtype=torch.float64)\n",
      "tensor([[1.2339],\n",
      "        [1.1873],\n",
      "        [1.2705],\n",
      "        [1.0896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8725]],\n",
      "\n",
      "        [[0.8633]],\n",
      "\n",
      "        [[1.1868]],\n",
      "\n",
      "        [[1.3463]]], dtype=torch.float64)\n",
      "tensor([[1.0563],\n",
      "        [1.0201],\n",
      "        [1.0786],\n",
      "        [1.0368]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1290]],\n",
      "\n",
      "        [[0.9696]],\n",
      "\n",
      "        [[0.8009]],\n",
      "\n",
      "        [[0.9361]]], dtype=torch.float64)\n",
      "tensor([[0.9543],\n",
      "        [1.1341],\n",
      "        [0.9493],\n",
      "        [0.9539]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2619]],\n",
      "\n",
      "        [[1.3740]],\n",
      "\n",
      "        [[0.8148]],\n",
      "\n",
      "        [[0.7316]]], dtype=torch.float64)\n",
      "tensor([[0.9393],\n",
      "        [0.9951],\n",
      "        [0.7941],\n",
      "        [0.8154]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5479]],\n",
      "\n",
      "        [[0.7882]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[1.3128]]], dtype=torch.float64)\n",
      "tensor([[0.7869],\n",
      "        [0.6449],\n",
      "        [0.6906],\n",
      "        [0.6144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0251]],\n",
      "\n",
      "        [[0.4670]],\n",
      "\n",
      "        [[0.2752]],\n",
      "\n",
      "        [[0.5895]]], dtype=torch.float64)\n",
      "tensor([[0.8454],\n",
      "        [0.8960],\n",
      "        [0.8174],\n",
      "        [0.6032]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0262]],\n",
      "\n",
      "        [[1.4884]],\n",
      "\n",
      "        [[1.0112]],\n",
      "\n",
      "        [[0.4751]]], dtype=torch.float64)\n",
      "tensor([[0.5409],\n",
      "        [0.4620],\n",
      "        [1.0528],\n",
      "        [1.3939]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0880]],\n",
      "\n",
      "        [[0.5872]],\n",
      "\n",
      "        [[1.7148]],\n",
      "\n",
      "        [[2.1481]]], dtype=torch.float64)\n",
      "tensor([[1.2975],\n",
      "        [0.8799],\n",
      "        [0.8010],\n",
      "        [0.7514]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6028]],\n",
      "\n",
      "        [[0.8702]],\n",
      "\n",
      "        [[0.3930]],\n",
      "\n",
      "        [[0.9349]]], dtype=torch.float64)\n",
      "tensor([[1.4438],\n",
      "        [1.6239],\n",
      "        [1.5460],\n",
      "        [1.1669]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1689]],\n",
      "\n",
      "        [[2.4185]],\n",
      "\n",
      "        [[1.9251]],\n",
      "\n",
      "        [[1.2480]]], dtype=torch.float64)\n",
      "tensor([[1.2183],\n",
      "        [1.1475],\n",
      "        [1.5488],\n",
      "        [1.5046]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0043]],\n",
      "\n",
      "        [[1.1903]],\n",
      "\n",
      "        [[1.8951]],\n",
      "\n",
      "        [[2.1897]]], dtype=torch.float64)\n",
      "tensor([[1.2974],\n",
      "        [1.0545],\n",
      "        [0.9071],\n",
      "        [0.8397]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2319]],\n",
      "\n",
      "        [[1.0990]],\n",
      "\n",
      "        [[0.7096]],\n",
      "\n",
      "        [[0.9315]]], dtype=torch.float64)\n",
      "tensor([[0.7618],\n",
      "        [0.9097],\n",
      "        [0.8278],\n",
      "        [0.6145]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3266]],\n",
      "\n",
      "        [[1.6455]],\n",
      "\n",
      "        [[1.2388]],\n",
      "\n",
      "        [[0.4970]]], dtype=torch.float64)\n",
      "tensor([[0.5189],\n",
      "        [0.5238],\n",
      "        [1.0907],\n",
      "        [1.4681]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1504]],\n",
      "\n",
      "        [[0.6611]],\n",
      "\n",
      "        [[1.8720]],\n",
      "\n",
      "        [[2.2567]]], dtype=torch.float64)\n",
      "tensor([[1.5930],\n",
      "        [1.0913],\n",
      "        [1.1335],\n",
      "        [1.0499]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7934]],\n",
      "\n",
      "        [[1.3255]],\n",
      "\n",
      "        [[1.0251]],\n",
      "\n",
      "        [[1.3024]]], dtype=torch.float64)\n",
      "tensor([[1.7407],\n",
      "        [2.1112],\n",
      "        [1.9786],\n",
      "        [1.5198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3907]],\n",
      "\n",
      "        [[2.7385]],\n",
      "\n",
      "        [[2.2729]],\n",
      "\n",
      "        [[1.6536]]], dtype=torch.float64)\n",
      "tensor([[1.6237],\n",
      "        [1.5689],\n",
      "        [1.4682],\n",
      "        [1.5497]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4341]],\n",
      "\n",
      "        [[1.1764]],\n",
      "\n",
      "        [[1.3024]],\n",
      "\n",
      "        [[1.5022]]], dtype=torch.float64)\n",
      "tensor([[1.2012],\n",
      "        [0.7766],\n",
      "        [0.7927],\n",
      "        [0.7970]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8275]],\n",
      "\n",
      "        [[0.6103]],\n",
      "\n",
      "        [[0.3630]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[0.9535],\n",
      "        [0.7572],\n",
      "        [0.7267],\n",
      "        [0.5170]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1683]],\n",
      "\n",
      "        [[1.2400]],\n",
      "\n",
      "        [[0.8645]],\n",
      "\n",
      "        [[0.2810]]], dtype=torch.float64)\n",
      "tensor([[0.6017],\n",
      "        [0.4052],\n",
      "        [0.8131],\n",
      "        [1.0643]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0164]],\n",
      "\n",
      "        [[0.1816]],\n",
      "\n",
      "        [[1.3590]],\n",
      "\n",
      "        [[1.5369]]], dtype=torch.float64)\n",
      "tensor([[1.0289],\n",
      "        [0.7928],\n",
      "        [0.7365],\n",
      "        [0.6109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1649]],\n",
      "\n",
      "        [[0.7177]],\n",
      "\n",
      "        [[0.2556]],\n",
      "\n",
      "        [[0.8263]]], dtype=torch.float64)\n",
      "tensor([[1.1414],\n",
      "        [1.3936],\n",
      "        [1.5473],\n",
      "        [1.0687]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5727]],\n",
      "\n",
      "        [[1.9933]],\n",
      "\n",
      "        [[1.5519]],\n",
      "\n",
      "        [[1.0251]]], dtype=torch.float64)\n",
      "tensor([[0.9704],\n",
      "        [1.0737],\n",
      "        [1.7508],\n",
      "        [1.9051]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6784]],\n",
      "\n",
      "        [[1.0019]],\n",
      "\n",
      "        [[1.9736]],\n",
      "\n",
      "        [[1.6132]]], dtype=torch.float64)\n",
      "tensor([[1.5539],\n",
      "        [1.3498],\n",
      "        [1.5544],\n",
      "        [1.5443]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5138]],\n",
      "\n",
      "        [[1.0655]],\n",
      "\n",
      "        [[1.0089]],\n",
      "\n",
      "        [[1.1337]]], dtype=torch.float64)\n",
      "tensor([[1.5700],\n",
      "        [1.4851],\n",
      "        [1.3866],\n",
      "        [1.3900]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2249]],\n",
      "\n",
      "        [[1.4664]],\n",
      "\n",
      "        [[1.2480]],\n",
      "\n",
      "        [[0.8587]]], dtype=torch.float64)\n",
      "tensor([[1.2878],\n",
      "        [0.9920],\n",
      "        [1.5906],\n",
      "        [1.7680]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5802]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[1.8870]],\n",
      "\n",
      "        [[2.0407]]], dtype=torch.float64)\n",
      "tensor([[1.5912],\n",
      "        [1.2753],\n",
      "        [1.2038],\n",
      "        [1.0971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7033]],\n",
      "\n",
      "        [[0.9835]],\n",
      "\n",
      "        [[0.6391]],\n",
      "\n",
      "        [[0.9234]]], dtype=torch.float64)\n",
      "tensor([[1.4818],\n",
      "        [1.5847],\n",
      "        [1.2313],\n",
      "        [0.8266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9113]],\n",
      "\n",
      "        [[1.9136]],\n",
      "\n",
      "        [[1.2203]],\n",
      "\n",
      "        [[0.8425]]], dtype=torch.float64)\n",
      "tensor([[0.7016],\n",
      "        [0.5916],\n",
      "        [0.6650],\n",
      "        [0.5308]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5698]],\n",
      "\n",
      "        [[0.7270]],\n",
      "\n",
      "        [[0.8413]],\n",
      "\n",
      "        [[0.9372]]], dtype=torch.float64)\n",
      "tensor([[0.5968],\n",
      "        [0.4055],\n",
      "        [0.2472],\n",
      "        [0.1544]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5432]],\n",
      "\n",
      "        [[ 0.0626]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[ 0.1458]]], dtype=torch.float64)\n",
      "tensor([[0.7532],\n",
      "        [0.6845],\n",
      "        [0.6259],\n",
      "        [0.4851]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1163]],\n",
      "\n",
      "        [[1.3000]],\n",
      "\n",
      "        [[0.7870]],\n",
      "\n",
      "        [[0.2971]]], dtype=torch.float64)\n",
      "tensor([[0.3752],\n",
      "        [0.2224],\n",
      "        [0.9452],\n",
      "        [1.1123]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1350]],\n",
      "\n",
      "        [[ 0.2359]],\n",
      "\n",
      "        [[ 1.5762]],\n",
      "\n",
      "        [[ 1.8154]]], dtype=torch.float64)\n",
      "tensor([[1.1602],\n",
      "        [0.6599],\n",
      "        [0.5006],\n",
      "        [0.6342]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3509]],\n",
      "\n",
      "        [[0.4670]],\n",
      "\n",
      "        [[0.2740]],\n",
      "\n",
      "        [[0.9430]]], dtype=torch.float64)\n",
      "tensor([[1.4526],\n",
      "        [1.7445],\n",
      "        [1.7704],\n",
      "        [1.1351]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2278]],\n",
      "\n",
      "        [[2.4196]],\n",
      "\n",
      "        [[1.9968]],\n",
      "\n",
      "        [[0.8956]]], dtype=torch.float64)\n",
      "tensor([[1.2245],\n",
      "        [1.1864],\n",
      "        [1.1913],\n",
      "        [1.0085]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7824]],\n",
      "\n",
      "        [[1.0054]],\n",
      "\n",
      "        [[1.4167]],\n",
      "\n",
      "        [[1.5773]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.34806:  13%|█▎        | 402/3067 [00:01<00:09, 293.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9421],\n",
      "        [0.8207],\n",
      "        [0.9394],\n",
      "        [0.8744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1591]],\n",
      "\n",
      "        [[0.7824]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[0.8252]]], dtype=torch.float64)\n",
      "tensor([[1.2025],\n",
      "        [1.0592],\n",
      "        [0.7062],\n",
      "        [0.6007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7974]],\n",
      "\n",
      "        [[1.1244]],\n",
      "\n",
      "        [[0.7986]],\n",
      "\n",
      "        [[0.5825]]], dtype=torch.float64)\n",
      "tensor([[0.6228],\n",
      "        [0.6632],\n",
      "        [0.8145],\n",
      "        [0.7447]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4936]],\n",
      "\n",
      "        [[0.6368]],\n",
      "\n",
      "        [[0.9627]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[0.3787],\n",
      "        [0.3609],\n",
      "        [0.4931],\n",
      "        [0.6204]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2613]],\n",
      "\n",
      "        [[0.1654]],\n",
      "\n",
      "        [[0.1562]],\n",
      "\n",
      "        [[0.3226]]], dtype=torch.float64)\n",
      "tensor([[0.5121],\n",
      "        [0.5416],\n",
      "        [0.4639],\n",
      "        [0.4409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5987]],\n",
      "\n",
      "        [[0.7258]],\n",
      "\n",
      "        [[0.2798]],\n",
      "\n",
      "        [[0.1828]]], dtype=torch.float64)\n",
      "tensor([[0.4931],\n",
      "        [0.3524],\n",
      "        [0.5238],\n",
      "        [0.4816]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0760]],\n",
      "\n",
      "        [[ 0.1966]],\n",
      "\n",
      "        [[ 0.6056]],\n",
      "\n",
      "        [[ 0.8171]]], dtype=torch.float64)\n",
      "tensor([[0.4319],\n",
      "        [0.4334],\n",
      "        [0.4338],\n",
      "        [0.3156]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5132]],\n",
      "\n",
      "        [[ 0.1504]],\n",
      "\n",
      "        [[-0.0772]],\n",
      "\n",
      "        [[ 0.0164]]], dtype=torch.float64)\n",
      "tensor([[0.6844],\n",
      "        [0.8901],\n",
      "        [0.8444],\n",
      "        [0.5618]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1660]],\n",
      "\n",
      "        [[1.5161]],\n",
      "\n",
      "        [[0.9534]],\n",
      "\n",
      "        [[0.3179]]], dtype=torch.float64)\n",
      "tensor([[0.4698],\n",
      "        [0.3797],\n",
      "        [0.7920],\n",
      "        [1.2479]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[ 0.2775]],\n",
      "\n",
      "        [[ 1.5727]],\n",
      "\n",
      "        [[ 1.9193]]], dtype=torch.float64)\n",
      "tensor([[1.0594],\n",
      "        [0.7349],\n",
      "        [0.6117],\n",
      "        [0.4442]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2065]],\n",
      "\n",
      "        [[0.3907]],\n",
      "\n",
      "        [[0.1666]],\n",
      "\n",
      "        [[0.3757]]], dtype=torch.float64)\n",
      "tensor([[0.9646],\n",
      "        [1.1932],\n",
      "        [1.0042],\n",
      "        [0.6482]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6652]],\n",
      "\n",
      "        [[1.8304]],\n",
      "\n",
      "        [[1.2076]],\n",
      "\n",
      "        [[0.5791]]], dtype=torch.float64)\n",
      "tensor([[0.5893],\n",
      "        [0.6401],\n",
      "        [0.8264],\n",
      "        [0.6979]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2151]],\n",
      "\n",
      "        [[0.6796]],\n",
      "\n",
      "        [[0.8517]],\n",
      "\n",
      "        [[1.0216]]], dtype=torch.float64)\n",
      "tensor([[0.6033],\n",
      "        [0.5470],\n",
      "        [0.6370],\n",
      "        [0.5888]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7905]],\n",
      "\n",
      "        [[0.6703]],\n",
      "\n",
      "        [[0.4901]],\n",
      "\n",
      "        [[0.4543]]], dtype=torch.float64)\n",
      "tensor([[0.5856],\n",
      "        [0.6216],\n",
      "        [0.5792],\n",
      "        [0.4995]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9211]],\n",
      "\n",
      "        [[1.0331]],\n",
      "\n",
      "        [[0.7501]],\n",
      "\n",
      "        [[0.4393]]], dtype=torch.float64)\n",
      "tensor([[0.4865],\n",
      "        [0.3787],\n",
      "        [0.5819],\n",
      "        [0.6094]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2059]],\n",
      "\n",
      "        [[0.4000]],\n",
      "\n",
      "        [[0.7639]],\n",
      "\n",
      "        [[1.0123]]], dtype=torch.float64)\n",
      "tensor([[0.5090],\n",
      "        [0.3575],\n",
      "        [0.3923],\n",
      "        [0.3488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7085]],\n",
      "\n",
      "        [[0.1643]],\n",
      "\n",
      "        [[0.1134]],\n",
      "\n",
      "        [[0.2960]]], dtype=torch.float64)\n",
      "tensor([[0.3075],\n",
      "        [0.3011],\n",
      "        [0.2591],\n",
      "        [0.3685]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3699]],\n",
      "\n",
      "        [[0.4092]],\n",
      "\n",
      "        [[0.1134]],\n",
      "\n",
      "        [[0.0152]]], dtype=torch.float64)\n",
      "tensor([[0.3999],\n",
      "        [0.5296],\n",
      "        [0.4085],\n",
      "        [0.3572]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0337]],\n",
      "\n",
      "        [[0.1481]],\n",
      "\n",
      "        [[0.2463]],\n",
      "\n",
      "        [[0.3226]]], dtype=torch.float64)\n",
      "tensor([[0.3781],\n",
      "        [0.6386],\n",
      "        [0.7507],\n",
      "        [0.8054]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3526]],\n",
      "\n",
      "        [[0.4450]],\n",
      "\n",
      "        [[0.4370]],\n",
      "\n",
      "        [[0.3572]]], dtype=torch.float64)\n",
      "tensor([[0.5958],\n",
      "        [0.6068],\n",
      "        [0.7665],\n",
      "        [0.8275]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4589]],\n",
      "\n",
      "        [[0.7628]],\n",
      "\n",
      "        [[0.7535]],\n",
      "\n",
      "        [[0.6946]]], dtype=torch.float64)\n",
      "tensor([[0.9639],\n",
      "        [0.9233],\n",
      "        [0.7064],\n",
      "        [0.6735]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5952]],\n",
      "\n",
      "        [[0.4439]],\n",
      "\n",
      "        [[0.4728]],\n",
      "\n",
      "        [[0.7986]]], dtype=torch.float64)\n",
      "tensor([[0.8323],\n",
      "        [0.8124],\n",
      "        [0.7706],\n",
      "        [0.5775]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9153]],\n",
      "\n",
      "        [[0.6565]],\n",
      "\n",
      "        [[0.4069]],\n",
      "\n",
      "        [[0.2891]]], dtype=torch.float64)\n",
      "tensor([[0.5316],\n",
      "        [0.6212],\n",
      "        [0.5656],\n",
      "        [0.4325]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4289]],\n",
      "\n",
      "        [[0.9315]],\n",
      "\n",
      "        [[0.6750]],\n",
      "\n",
      "        [[0.4381]]], dtype=torch.float64)\n",
      "tensor([[0.3925],\n",
      "        [0.2988],\n",
      "        [0.5312],\n",
      "        [0.8645]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1007]],\n",
      "\n",
      "        [[0.1296]],\n",
      "\n",
      "        [[0.9604]],\n",
      "\n",
      "        [[1.2134]]], dtype=torch.float64)\n",
      "tensor([[0.6975],\n",
      "        [0.5209],\n",
      "        [0.3988],\n",
      "        [0.3117]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8217]],\n",
      "\n",
      "        [[ 0.3445]],\n",
      "\n",
      "        [[ 0.0141]],\n",
      "\n",
      "        [[-0.0402]]], dtype=torch.float64)\n",
      "tensor([[0.6924],\n",
      "        [1.1161],\n",
      "        [0.8841],\n",
      "        [0.5964]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2041]],\n",
      "\n",
      "        [[1.5415]],\n",
      "\n",
      "        [[1.0874]],\n",
      "\n",
      "        [[0.4208]]], dtype=torch.float64)\n",
      "tensor([[0.5654],\n",
      "        [0.5140],\n",
      "        [0.9116],\n",
      "        [1.1523]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1377]],\n",
      "\n",
      "        [[0.3896]],\n",
      "\n",
      "        [[1.4410]],\n",
      "\n",
      "        [[1.6351]]], dtype=torch.float64)\n",
      "tensor([[0.9004],\n",
      "        [0.7427],\n",
      "        [0.8295],\n",
      "        [0.8123]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0147]],\n",
      "\n",
      "        [[0.6519]],\n",
      "\n",
      "        [[0.5721]],\n",
      "\n",
      "        [[0.6276]]], dtype=torch.float64)\n",
      "tensor([[0.7608],\n",
      "        [0.6597],\n",
      "        [0.5720],\n",
      "        [0.5993]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7004]],\n",
      "\n",
      "        [[0.8587]],\n",
      "\n",
      "        [[0.7535]],\n",
      "\n",
      "        [[0.4219]]], dtype=torch.float64)\n",
      "tensor([[0.6349],\n",
      "        [0.6814],\n",
      "        [0.8891],\n",
      "        [1.0291]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2844]],\n",
      "\n",
      "        [[0.4716]],\n",
      "\n",
      "        [[1.2307]],\n",
      "\n",
      "        [[1.4641]]], dtype=torch.float64)\n",
      "tensor([[0.8472],\n",
      "        [0.7084],\n",
      "        [0.6498],\n",
      "        [0.4826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9211]],\n",
      "\n",
      "        [[0.4242]],\n",
      "\n",
      "        [[0.1423]],\n",
      "\n",
      "        [[0.3503]]], dtype=torch.float64)\n",
      "tensor([[0.6904],\n",
      "        [0.6655],\n",
      "        [0.6203],\n",
      "        [0.6512]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3012]],\n",
      "\n",
      "        [[1.2203]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.7859]]], dtype=torch.float64)\n",
      "tensor([[0.7084],\n",
      "        [0.6847],\n",
      "        [0.5513],\n",
      "        [0.4050]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6299]],\n",
      "\n",
      "        [[0.5987]],\n",
      "\n",
      "        [[0.2937]],\n",
      "\n",
      "        [[0.5086]]], dtype=torch.float64)\n",
      "tensor([[0.3980],\n",
      "        [0.3619],\n",
      "        [0.3814],\n",
      "        [0.2699]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3468]],\n",
      "\n",
      "        [[ 0.1285]],\n",
      "\n",
      "        [[-0.0564]],\n",
      "\n",
      "        [[-0.1223]]], dtype=torch.float64)\n",
      "tensor([[0.2957],\n",
      "        [0.4734],\n",
      "        [0.2517],\n",
      "        [0.2049]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5883]],\n",
      "\n",
      "        [[ 0.6727]],\n",
      "\n",
      "        [[ 0.3052]],\n",
      "\n",
      "        [[-0.2089]]], dtype=torch.float64)\n",
      "tensor([[0.1133],\n",
      "        [0.0783],\n",
      "        [0.3079],\n",
      "        [0.5668]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4354]],\n",
      "\n",
      "        [[-0.4065]],\n",
      "\n",
      "        [[ 0.7847]],\n",
      "\n",
      "        [[ 0.9823]]], dtype=torch.float64)\n",
      "tensor([[0.3929],\n",
      "        [0.2494],\n",
      "        [0.1649],\n",
      "        [0.0891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3873]],\n",
      "\n",
      "        [[-0.0853]],\n",
      "\n",
      "        [[-0.4261]],\n",
      "\n",
      "        [[-0.4793]]], dtype=torch.float64)\n",
      "tensor([[0.2292],\n",
      "        [0.6258],\n",
      "        [0.4651],\n",
      "        [0.3410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8922]],\n",
      "\n",
      "        [[1.2030]],\n",
      "\n",
      "        [[0.5225]],\n",
      "\n",
      "        [[0.0175]]], dtype=torch.float64)\n",
      "tensor([[0.2276],\n",
      "        [0.1377],\n",
      "        [0.4278],\n",
      "        [0.4625]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1685]],\n",
      "\n",
      "        [[-0.3187]],\n",
      "\n",
      "        [[ 0.8691]],\n",
      "\n",
      "        [[ 0.8829]]], dtype=torch.float64)\n",
      "tensor([[0.3741],\n",
      "        [0.3790],\n",
      "        [0.4778],\n",
      "        [0.5014]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5698]],\n",
      "\n",
      "        [[0.4762]],\n",
      "\n",
      "        [[0.4843]],\n",
      "\n",
      "        [[0.4820]]], dtype=torch.float64)\n",
      "tensor([[0.5320],\n",
      "        [0.4099],\n",
      "        [0.3709],\n",
      "        [0.4896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8229]],\n",
      "\n",
      "        [[0.5721]],\n",
      "\n",
      "        [[0.4924]],\n",
      "\n",
      "        [[0.5074]]], dtype=torch.float64)\n",
      "tensor([[0.4729],\n",
      "        [0.1533],\n",
      "        [0.2339],\n",
      "        [0.3378]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0922]],\n",
      "\n",
      "        [[-0.2008]],\n",
      "\n",
      "        [[ 0.2082]],\n",
      "\n",
      "        [[ 0.4323]]], dtype=torch.float64)\n",
      "tensor([[0.2816],\n",
      "        [0.3879],\n",
      "        [0.6113],\n",
      "        [0.6378]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3480]],\n",
      "\n",
      "        [[0.4647]],\n",
      "\n",
      "        [[0.4716]],\n",
      "\n",
      "        [[0.4601]]], dtype=torch.float64)\n",
      "tensor([[0.5208],\n",
      "        [0.2130],\n",
      "        [0.2163],\n",
      "        [0.2384]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7997]],\n",
      "\n",
      "        [[ 0.2070]],\n",
      "\n",
      "        [[ 0.0406]],\n",
      "\n",
      "        [[-0.0841]]], dtype=torch.float64)\n",
      "tensor([[0.2143],\n",
      "        [0.1307],\n",
      "        [0.2260],\n",
      "        [0.1471]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2517]],\n",
      "\n",
      "        [[-0.1800]],\n",
      "\n",
      "        [[ 0.1435]],\n",
      "\n",
      "        [[ 0.1365]]], dtype=torch.float64)\n",
      "tensor([[0.1592],\n",
      "        [0.2263],\n",
      "        [0.1253],\n",
      "        [0.1262]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0310]],\n",
      "\n",
      "        [[-0.1662]],\n",
      "\n",
      "        [[-0.4770]],\n",
      "\n",
      "        [[-0.1639]]], dtype=torch.float64)\n",
      "tensor([[0.4148],\n",
      "        [0.5175],\n",
      "        [0.4836],\n",
      "        [0.3816]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4104]],\n",
      "\n",
      "        [[0.6472]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.4843]]], dtype=torch.float64)\n",
      "tensor([[0.4900],\n",
      "        [0.4667],\n",
      "        [0.4148],\n",
      "        [0.2442]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4427]],\n",
      "\n",
      "        [[0.3688]],\n",
      "\n",
      "        [[0.4924]],\n",
      "\n",
      "        [[0.3307]]], dtype=torch.float64)\n",
      "tensor([[0.2339],\n",
      "        [0.1817],\n",
      "        [0.2086],\n",
      "        [0.1588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1389]],\n",
      "\n",
      "        [[-0.0310]],\n",
      "\n",
      "        [[-0.0576]],\n",
      "\n",
      "        [[-0.2043]]], dtype=torch.float64)\n",
      "tensor([[0.3032],\n",
      "        [0.3690],\n",
      "        [0.2292],\n",
      "        [0.2846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4300]],\n",
      "\n",
      "        [[0.4866]],\n",
      "\n",
      "        [[0.0614]],\n",
      "\n",
      "        [[0.1446]]], dtype=torch.float64)\n",
      "tensor([[0.4590],\n",
      "        [0.5956],\n",
      "        [0.7292],\n",
      "        [0.6661]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2140]],\n",
      "\n",
      "        [[0.4820]],\n",
      "\n",
      "        [[0.9939]],\n",
      "\n",
      "        [[1.0539]]], dtype=torch.float64)\n",
      "tensor([[0.5421],\n",
      "        [0.6883],\n",
      "        [0.9738],\n",
      "        [0.9047]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5895]],\n",
      "\n",
      "        [[0.8390]],\n",
      "\n",
      "        [[0.8286]],\n",
      "\n",
      "        [[1.0389]]], dtype=torch.float64)\n",
      "tensor([[1.0523],\n",
      "        [1.0320],\n",
      "        [0.8844],\n",
      "        [0.8374]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2781]],\n",
      "\n",
      "        [[1.4930]],\n",
      "\n",
      "        [[1.1002]],\n",
      "\n",
      "        [[1.3971]]], dtype=torch.float64)\n",
      "tensor([[1.2504],\n",
      "        [1.0098],\n",
      "        [0.8515],\n",
      "        [0.3069]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1059]],\n",
      "\n",
      "        [[1.0944]],\n",
      "\n",
      "        [[0.5467]],\n",
      "\n",
      "        [[0.3930]]], dtype=torch.float64)\n",
      "tensor([[ 0.1718],\n",
      "        [ 0.1460],\n",
      "        [ 0.1036],\n",
      "        [-0.0199]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1608]],\n",
      "\n",
      "        [[-0.0067]],\n",
      "\n",
      "        [[-0.3048]],\n",
      "\n",
      "        [[-0.4781]]], dtype=torch.float64)\n",
      "tensor([[0.0553],\n",
      "        [0.2904],\n",
      "        [0.1018],\n",
      "        [0.0709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1516]],\n",
      "\n",
      "        [[ 0.2186]],\n",
      "\n",
      "        [[-0.1650]],\n",
      "\n",
      "        [[-0.3233]]], dtype=torch.float64)\n",
      "tensor([[0.1087],\n",
      "        [0.1526],\n",
      "        [0.4449],\n",
      "        [0.3933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2748]],\n",
      "\n",
      "        [[-0.0194]],\n",
      "\n",
      "        [[ 0.3387]],\n",
      "\n",
      "        [[ 0.3642]]], dtype=torch.float64)\n",
      "tensor([[0.2876],\n",
      "        [0.3008],\n",
      "        [0.3778],\n",
      "        [0.2637]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2833]],\n",
      "\n",
      "        [[0.1989]],\n",
      "\n",
      "        [[0.1412]],\n",
      "\n",
      "        [[0.1227]]], dtype=torch.float64)\n",
      "tensor([[0.1310],\n",
      "        [0.2552],\n",
      "        [0.2909],\n",
      "        [0.2360]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2683]],\n",
      "\n",
      "        [[ 0.2290]],\n",
      "\n",
      "        [[ 0.1007]],\n",
      "\n",
      "        [[-0.0287]]], dtype=torch.float64)\n",
      "tensor([[0.2756],\n",
      "        [0.2071],\n",
      "        [0.0663],\n",
      "        [0.0184]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2170]],\n",
      "\n",
      "        [[-0.2332]],\n",
      "\n",
      "        [[-0.2598]],\n",
      "\n",
      "        [[-0.1893]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.34806:  15%|█▌        | 468/3067 [00:01<00:08, 309.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0062],\n",
      "        [ 0.0456],\n",
      "        [ 0.0517],\n",
      "        [ 0.0074]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4712]],\n",
      "\n",
      "        [[-0.4446]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.4689]]], dtype=torch.float64)\n",
      "tensor([[-0.0901],\n",
      "        [-0.1285],\n",
      "        [-0.0733],\n",
      "        [-0.1594]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2297]],\n",
      "\n",
      "        [[-0.5994]],\n",
      "\n",
      "        [[-0.8016]],\n",
      "\n",
      "        [[-0.8698]]], dtype=torch.float64)\n",
      "tensor([[-0.1626],\n",
      "        [-0.0985],\n",
      "        [-0.1906],\n",
      "        [-0.0588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9160]],\n",
      "\n",
      "        [[-0.8987]],\n",
      "\n",
      "        [[-0.5948]],\n",
      "\n",
      "        [[-0.5590]]], dtype=torch.float64)\n",
      "tensor([[-0.1425],\n",
      "        [-0.1316],\n",
      "        [-0.0989],\n",
      "        [-0.1234]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7705]],\n",
      "\n",
      "        [[-0.9796]],\n",
      "\n",
      "        [[-0.9461]],\n",
      "\n",
      "        [[-0.9634]]], dtype=torch.float64)\n",
      "tensor([[-0.1954],\n",
      "        [-0.2317],\n",
      "        [-0.1905],\n",
      "        [-0.1043]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8144]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-0.8236]],\n",
      "\n",
      "        [[-0.7947]]], dtype=torch.float64)\n",
      "tensor([[-0.1347],\n",
      "        [-0.1318],\n",
      "        [-0.1746],\n",
      "        [ 0.0251]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7970]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.2852]]], dtype=torch.float64)\n",
      "tensor([[-0.0406],\n",
      "        [-0.1225],\n",
      "        [-0.0924],\n",
      "        [-0.1110]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4908]],\n",
      "\n",
      "        [[-0.6884]],\n",
      "\n",
      "        [[-0.6826]],\n",
      "\n",
      "        [[-0.6249]]], dtype=torch.float64)\n",
      "tensor([[-0.1312],\n",
      "        [-0.1419],\n",
      "        [-0.1675],\n",
      "        [-0.1390]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.5509]],\n",
      "\n",
      "        [[-0.6156]],\n",
      "\n",
      "        [[-0.5902]]], dtype=torch.float64)\n",
      "tensor([[-0.1449],\n",
      "        [-0.1344],\n",
      "        [-0.2289],\n",
      "        [-0.2096]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6480]],\n",
      "\n",
      "        [[-0.6642]],\n",
      "\n",
      "        [[-0.7196]],\n",
      "\n",
      "        [[-0.4423]]], dtype=torch.float64)\n",
      "tensor([[-0.2545],\n",
      "        [-0.2438],\n",
      "        [-0.2598],\n",
      "        [-0.2971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6410]],\n",
      "\n",
      "        [[-0.7520]],\n",
      "\n",
      "        [[-0.9703]],\n",
      "\n",
      "        [[-1.1587]]], dtype=torch.float64)\n",
      "tensor([[-0.3206],\n",
      "        [ 0.1050],\n",
      "        [-0.2557],\n",
      "        [-0.3352]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2898]],\n",
      "\n",
      "        [[-0.1246]],\n",
      "\n",
      "        [[-0.8421]],\n",
      "\n",
      "        [[-1.2199]]], dtype=torch.float64)\n",
      "tensor([[-0.4350],\n",
      "        [-0.4855],\n",
      "        [-0.3305],\n",
      "        [ 0.0416]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4498]],\n",
      "\n",
      "        [[-1.3886]],\n",
      "\n",
      "        [[-0.3383]],\n",
      "\n",
      "        [[-0.1893]]], dtype=torch.float64)\n",
      "tensor([[-0.2468],\n",
      "        [-0.3412],\n",
      "        [-0.4497],\n",
      "        [-0.5021]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8606]],\n",
      "\n",
      "        [[-1.1067]],\n",
      "\n",
      "        [[-1.3586]],\n",
      "\n",
      "        [[-1.0200]]], dtype=torch.float64)\n",
      "tensor([[-0.2674],\n",
      "        [ 0.0178],\n",
      "        [-0.2334],\n",
      "        [-0.3209]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2332]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-1.0154]]], dtype=torch.float64)\n",
      "tensor([[-0.4256],\n",
      "        [-0.4907],\n",
      "        [-0.4241],\n",
      "        [-0.2448]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1494]],\n",
      "\n",
      "        [[-1.1425]],\n",
      "\n",
      "        [[-0.4215]],\n",
      "\n",
      "        [[-0.4435]]], dtype=torch.float64)\n",
      "tensor([[-0.2762],\n",
      "        [-0.2743],\n",
      "        [-0.2498],\n",
      "        [-0.2606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5324]],\n",
      "\n",
      "        [[-0.4862]],\n",
      "\n",
      "        [[-0.5093]],\n",
      "\n",
      "        [[-0.5555]]], dtype=torch.float64)\n",
      "tensor([[-0.2813],\n",
      "        [-0.1245],\n",
      "        [-0.2006],\n",
      "        [-0.2018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1488]],\n",
      "\n",
      "        [[-0.0298]],\n",
      "\n",
      "        [[-0.2031]],\n",
      "\n",
      "        [[-0.2782]]], dtype=torch.float64)\n",
      "tensor([[-0.2288],\n",
      "        [-0.3230],\n",
      "        [-0.2092],\n",
      "        [ 0.0543]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4804]],\n",
      "\n",
      "        [[-0.4724]],\n",
      "\n",
      "        [[ 0.2660]],\n",
      "\n",
      "        [[ 0.0383]]], dtype=torch.float64)\n",
      "tensor([[-0.1671],\n",
      "        [-0.2091],\n",
      "        [-0.1051],\n",
      "        [-0.0649]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2228]],\n",
      "\n",
      "        [[-0.3302]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[-0.0911]]], dtype=torch.float64)\n",
      "tensor([[ 0.1060],\n",
      "        [-0.0671],\n",
      "        [-0.0352],\n",
      "        [-0.2321]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4554]],\n",
      "\n",
      "        [[ 0.3884]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.4377]]], dtype=torch.float64)\n",
      "tensor([[-0.4142],\n",
      "        [-0.4322],\n",
      "        [-0.0047],\n",
      "        [ 0.0060]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7335]],\n",
      "\n",
      "        [[-0.5151]],\n",
      "\n",
      "        [[ 0.3052]],\n",
      "\n",
      "        [[ 0.1666]]], dtype=torch.float64)\n",
      "tensor([[-0.0801],\n",
      "        [-0.0288],\n",
      "        [-0.0465],\n",
      "        [-0.2073]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1527]],\n",
      "\n",
      "        [[0.1597]],\n",
      "\n",
      "        [[0.1585]],\n",
      "\n",
      "        [[0.0915]]], dtype=torch.float64)\n",
      "tensor([[-0.2798],\n",
      "        [-0.2527],\n",
      "        [-0.1816],\n",
      "        [-0.1525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4069]],\n",
      "\n",
      "        [[ 0.2521]],\n",
      "\n",
      "        [[ 0.0337]],\n",
      "\n",
      "        [[-0.0217]]], dtype=torch.float64)\n",
      "tensor([[-0.1987],\n",
      "        [-0.2224],\n",
      "        [-0.0529],\n",
      "        [-0.0472]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0714]],\n",
      "\n",
      "        [[-0.0841]],\n",
      "\n",
      "        [[ 0.3538]],\n",
      "\n",
      "        [[ 0.3145]]], dtype=torch.float64)\n",
      "tensor([[-0.1870],\n",
      "        [-0.2504],\n",
      "        [-0.4010],\n",
      "        [-0.4106]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0968]],\n",
      "\n",
      "        [[-0.2528]],\n",
      "\n",
      "        [[-0.2713]],\n",
      "\n",
      "        [[-0.3302]]], dtype=torch.float64)\n",
      "tensor([[-0.2027],\n",
      "        [-0.1574],\n",
      "        [-0.2759],\n",
      "        [-0.3407]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2382]],\n",
      "\n",
      "        [[ 0.2232]],\n",
      "\n",
      "        [[ 0.0834]],\n",
      "\n",
      "        [[-0.1119]]], dtype=torch.float64)\n",
      "tensor([[-0.5191],\n",
      "        [-0.6370],\n",
      "        [-0.6308],\n",
      "        [-0.4737]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2944]],\n",
      "\n",
      "        [[-0.4238]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[-0.2852]]], dtype=torch.float64)\n",
      "tensor([[-0.6380],\n",
      "        [-0.7301],\n",
      "        [-0.7700],\n",
      "        [-0.8147]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4492]],\n",
      "\n",
      "        [[-0.8144]],\n",
      "\n",
      "        [[-1.0928]],\n",
      "\n",
      "        [[-1.2280]]], dtype=torch.float64)\n",
      "tensor([[-0.7642],\n",
      "        [-0.5829],\n",
      "        [-0.6915],\n",
      "        [-0.6819]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4700]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.9530]],\n",
      "\n",
      "        [[-1.0570]]], dtype=torch.float64)\n",
      "tensor([[-0.7072],\n",
      "        [-0.7727],\n",
      "        [-0.4990],\n",
      "        [-0.1437]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2407]],\n",
      "\n",
      "        [[-1.0859]],\n",
      "\n",
      "        [[-0.1176]],\n",
      "\n",
      "        [[-0.3684]]], dtype=torch.float64)\n",
      "tensor([[-0.4663],\n",
      "        [-0.3587],\n",
      "        [-0.2915],\n",
      "        [-0.3581]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5798]],\n",
      "\n",
      "        [[-0.4157]],\n",
      "\n",
      "        [[-0.5555]],\n",
      "\n",
      "        [[-0.3568]]], dtype=torch.float64)\n",
      "tensor([[-0.1506],\n",
      "        [-0.1171],\n",
      "        [-0.2216],\n",
      "        [-0.1946]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1719]],\n",
      "\n",
      "        [[-0.1627]],\n",
      "\n",
      "        [[-0.2598]],\n",
      "\n",
      "        [[-0.2008]]], dtype=torch.float64)\n",
      "tensor([[-0.2121],\n",
      "        [-0.3069],\n",
      "        [-0.3194],\n",
      "        [-0.2479]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3245]],\n",
      "\n",
      "        [[-0.3429]],\n",
      "\n",
      "        [[-0.2655]],\n",
      "\n",
      "        [[-0.2320]]], dtype=torch.float64)\n",
      "tensor([[-0.4464],\n",
      "        [-0.5052],\n",
      "        [-0.4268],\n",
      "        [-0.1621]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6838]],\n",
      "\n",
      "        [[-0.8583]],\n",
      "\n",
      "        [[-0.5555]],\n",
      "\n",
      "        [[-0.4700]]], dtype=torch.float64)\n",
      "tensor([[-0.0421],\n",
      "        [-0.1461],\n",
      "        [-0.2518],\n",
      "        [-0.3893]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1789]],\n",
      "\n",
      "        [[-0.3141]],\n",
      "\n",
      "        [[-0.5324]],\n",
      "\n",
      "        [[-0.6630]]], dtype=torch.float64)\n",
      "tensor([[-0.3972],\n",
      "        [-0.3537],\n",
      "        [-0.1058],\n",
      "        [-0.2139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5012]],\n",
      "\n",
      "        [[-0.3637]],\n",
      "\n",
      "        [[-0.0529]],\n",
      "\n",
      "        [[-0.1442]]], dtype=torch.float64)\n",
      "tensor([[-0.3507],\n",
      "        [-0.3564],\n",
      "        [-0.4296],\n",
      "        [-0.5045]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4146]],\n",
      "\n",
      "        [[-0.5082]],\n",
      "\n",
      "        [[-0.5717]],\n",
      "\n",
      "        [[-0.5255]]], dtype=torch.float64)\n",
      "tensor([[-0.1567],\n",
      "        [-0.1506],\n",
      "        [-0.2887],\n",
      "        [-0.4559]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1192]],\n",
      "\n",
      "        [[-0.0402]],\n",
      "\n",
      "        [[-0.1939]],\n",
      "\n",
      "        [[-0.7346]]], dtype=torch.float64)\n",
      "tensor([[-0.5406],\n",
      "        [-0.6063],\n",
      "        [-0.3187],\n",
      "        [-0.2339]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7658]],\n",
      "\n",
      "        [[-0.7115]],\n",
      "\n",
      "        [[-0.1465]],\n",
      "\n",
      "        [[-0.2563]]], dtype=torch.float64)\n",
      "tensor([[-0.3646],\n",
      "        [-0.4980],\n",
      "        [-0.5444],\n",
      "        [-0.6924]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4400]],\n",
      "\n",
      "        [[-0.7404]],\n",
      "\n",
      "        [[-0.7993]],\n",
      "\n",
      "        [[-0.9438]]], dtype=torch.float64)\n",
      "tensor([[-0.6152],\n",
      "        [-0.4726],\n",
      "        [-0.5091],\n",
      "        [-0.6820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2551]],\n",
      "\n",
      "        [[-0.2736]],\n",
      "\n",
      "        [[-0.4377]],\n",
      "\n",
      "        [[-0.6168]]], dtype=torch.float64)\n",
      "tensor([[-0.6216],\n",
      "        [-0.6547],\n",
      "        [-0.6702],\n",
      "        [-0.7043]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5636]],\n",
      "\n",
      "        [[-0.6376]],\n",
      "\n",
      "        [[-0.7023]],\n",
      "\n",
      "        [[-0.6480]]], dtype=torch.float64)\n",
      "tensor([[-0.5939],\n",
      "        [-0.5396],\n",
      "        [-0.5539],\n",
      "        [-0.5711]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6514]],\n",
      "\n",
      "        [[-0.6630]],\n",
      "\n",
      "        [[-0.6849]],\n",
      "\n",
      "        [[-0.6803]]], dtype=torch.float64)\n",
      "tensor([[-0.4948],\n",
      "        [-0.5457],\n",
      "        [-0.5034],\n",
      "        [-0.5107]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4308]],\n",
      "\n",
      "        [[-0.4365]],\n",
      "\n",
      "        [[-0.5740]],\n",
      "\n",
      "        [[-0.6422]]], dtype=torch.float64)\n",
      "tensor([[-0.5285],\n",
      "        [-0.5284],\n",
      "        [-0.4694],\n",
      "        [-0.5250]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6318]],\n",
      "\n",
      "        [[-0.4897]],\n",
      "\n",
      "        [[-0.2621]],\n",
      "\n",
      "        [[-0.3071]]], dtype=torch.float64)\n",
      "tensor([[-0.4562],\n",
      "        [-0.4704],\n",
      "        [-0.6467],\n",
      "        [-0.6874]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4007]],\n",
      "\n",
      "        [[-0.6249]],\n",
      "\n",
      "        [[-0.8663]],\n",
      "\n",
      "        [[-0.7739]]], dtype=torch.float64)\n",
      "tensor([[-0.3554],\n",
      "        [-0.4106],\n",
      "        [-0.4351],\n",
      "        [-0.4190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[-0.3545]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[-0.5128]]], dtype=torch.float64)\n",
      "tensor([[-0.4888],\n",
      "        [-0.4596],\n",
      "        [-0.1869],\n",
      "        [-0.0031]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4065]],\n",
      "\n",
      "        [[-0.5059]],\n",
      "\n",
      "        [[ 0.1631]],\n",
      "\n",
      "        [[ 0.1897]]], dtype=torch.float64)\n",
      "tensor([[-0.0094],\n",
      "        [ 0.0371],\n",
      "        [-0.0520],\n",
      "        [-0.1192]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2694]],\n",
      "\n",
      "        [[ 0.0499]],\n",
      "\n",
      "        [[-0.0841]],\n",
      "\n",
      "        [[-0.1627]]], dtype=torch.float64)\n",
      "tensor([[-0.1501],\n",
      "        [-0.0536],\n",
      "        [-0.0633],\n",
      "        [-0.0514]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2394]],\n",
      "\n",
      "        [[0.3364]],\n",
      "\n",
      "        [[0.2255]],\n",
      "\n",
      "        [[0.1019]]], dtype=torch.float64)\n",
      "tensor([[-0.1284],\n",
      "        [-0.2676],\n",
      "        [-0.0592],\n",
      "        [-0.1371]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0071]],\n",
      "\n",
      "        [[-0.0818]],\n",
      "\n",
      "        [[ 0.3734]],\n",
      "\n",
      "        [[ 0.1157]]], dtype=torch.float64)\n",
      "tensor([[-0.1871],\n",
      "        [-0.2056],\n",
      "        [-0.3253],\n",
      "        [-0.5003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0449]],\n",
      "\n",
      "        [[-0.1431]],\n",
      "\n",
      "        [[-0.4284]],\n",
      "\n",
      "        [[-0.5475]]], dtype=torch.float64)\n",
      "tensor([[-0.4796],\n",
      "        [-0.2973],\n",
      "        [-0.0830],\n",
      "        [ 0.1923]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2297]],\n",
      "\n",
      "        [[-0.0610]],\n",
      "\n",
      "        [[ 0.0892]],\n",
      "\n",
      "        [[ 0.1481]]], dtype=torch.float64)\n",
      "tensor([[ 0.1387],\n",
      "        [ 0.0719],\n",
      "        [ 0.0479],\n",
      "        [-0.1820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0984]],\n",
      "\n",
      "        [[ 0.0695]],\n",
      "\n",
      "        [[ 0.1631]],\n",
      "\n",
      "        [[-0.1015]]], dtype=torch.float64)\n",
      "tensor([[-0.2345],\n",
      "        [-0.2014],\n",
      "        [-0.4411],\n",
      "        [-0.3330]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1165]],\n",
      "\n",
      "        [[-0.1673]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.2112]]], dtype=torch.float64)\n",
      "tensor([[-0.1497],\n",
      "        [-0.1237],\n",
      "        [-0.1283],\n",
      "        [-0.1035]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0464]],\n",
      "\n",
      "        [[-0.0090]],\n",
      "\n",
      "        [[ 0.0187]],\n",
      "\n",
      "        [[ 0.0695]]], dtype=torch.float64)\n",
      "tensor([[-0.0942],\n",
      "        [-0.1638],\n",
      "        [-0.1096],\n",
      "        [-0.1580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0275]],\n",
      "\n",
      "        [[-0.0587]],\n",
      "\n",
      "        [[ 0.3006]],\n",
      "\n",
      "        [[ 0.1573]]], dtype=torch.float64)\n",
      "tensor([[-0.3001],\n",
      "        [-0.4683],\n",
      "        [-0.5141],\n",
      "        [-0.6029]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1777]],\n",
      "\n",
      "        [[-0.3880]],\n",
      "\n",
      "        [[-0.5833]],\n",
      "\n",
      "        [[-0.6202]]], dtype=torch.float64)\n",
      "tensor([[-0.2967],\n",
      "        [ 0.1565],\n",
      "        [-0.1980],\n",
      "        [-0.3995]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1562]],\n",
      "\n",
      "        [[ 0.5502]],\n",
      "\n",
      "        [[ 0.0152]],\n",
      "\n",
      "        [[-0.0518]]], dtype=torch.float64)\n",
      "tensor([[-0.3655],\n",
      "        [-0.4320],\n",
      "        [-0.3156],\n",
      "        [-0.0998]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1974]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[ 0.1758]],\n",
      "\n",
      "        [[ 0.3411]]], dtype=torch.float64)\n",
      "tensor([[-0.1405],\n",
      "        [-0.1111],\n",
      "        [-0.0689],\n",
      "        [-0.2117]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0603]],\n",
      "\n",
      "        [[0.0626]],\n",
      "\n",
      "        [[0.1943]],\n",
      "\n",
      "        [[0.0291]]], dtype=torch.float64)\n",
      "tensor([[-0.0389],\n",
      "        [-0.0233],\n",
      "        [-0.0531],\n",
      "        [-0.0167]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4612]],\n",
      "\n",
      "        [[0.2914]],\n",
      "\n",
      "        [[0.1204]],\n",
      "\n",
      "        [[0.1458]]], dtype=torch.float64)\n",
      "tensor([[-0.0594],\n",
      "        [-0.1453],\n",
      "        [-0.0887],\n",
      "        [-0.0175]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[-0.2817]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[ 0.0707]]], dtype=torch.float64)\n",
      "tensor([[ 0.0536],\n",
      "        [ 0.1306],\n",
      "        [-0.1033],\n",
      "        [-0.2721]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1493]],\n",
      "\n",
      "        [[ 0.0083]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[-0.1119]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.30495:  17%|█▋        | 530/3067 [00:01<00:08, 289.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1067],\n",
      "        [-0.1952],\n",
      "        [-0.0278],\n",
      "        [ 0.0790]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1377]],\n",
      "\n",
      "        [[-0.1454]],\n",
      "\n",
      "        [[ 0.3087]],\n",
      "\n",
      "        [[ 0.2787]]], dtype=torch.float64)\n",
      "tensor([[0.1338],\n",
      "        [0.0340],\n",
      "        [0.0249],\n",
      "        [0.0233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1989]],\n",
      "\n",
      "        [[0.1550]],\n",
      "\n",
      "        [[0.4635]],\n",
      "\n",
      "        [[0.2371]]], dtype=torch.float64)\n",
      "tensor([[-0.1212],\n",
      "        [-0.1342],\n",
      "        [-0.0424],\n",
      "        [-0.2561]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0210]],\n",
      "\n",
      "        [[ 0.0141]],\n",
      "\n",
      "        [[-0.0992]],\n",
      "\n",
      "        [[-0.2702]]], dtype=torch.float64)\n",
      "tensor([[-0.1064],\n",
      "        [-0.0139],\n",
      "        [-0.1297],\n",
      "        [-0.1978]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0287]],\n",
      "\n",
      "        [[-0.1049]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[-0.2471]]], dtype=torch.float64)\n",
      "tensor([[-0.1996],\n",
      "        [-0.3033],\n",
      "        [ 0.0836],\n",
      "        [-0.0971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2205]],\n",
      "\n",
      "        [[-0.3487]],\n",
      "\n",
      "        [[ 0.0406]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[-0.2693],\n",
      "        [-0.2764],\n",
      "        [-0.3013],\n",
      "        [-0.3251]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3522]],\n",
      "\n",
      "        [[-0.4492]],\n",
      "\n",
      "        [[-0.5139]],\n",
      "\n",
      "        [[-0.4019]]], dtype=torch.float64)\n",
      "tensor([[-0.0620],\n",
      "        [-0.0385],\n",
      "        [-0.1834],\n",
      "        [ 0.0863]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1188]],\n",
      "\n",
      "        [[-0.1731]],\n",
      "\n",
      "        [[-0.0830]],\n",
      "\n",
      "        [[-0.0113]]], dtype=torch.float64)\n",
      "tensor([[ 0.0787],\n",
      "        [-0.0376],\n",
      "        [-0.0697],\n",
      "        [-0.0098]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1327]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[ 0.1527]],\n",
      "\n",
      "        [[ 0.1435]]], dtype=torch.float64)\n",
      "tensor([[-0.1777],\n",
      "        [-0.1924],\n",
      "        [-0.2635],\n",
      "        [-0.4928]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1304]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.4908]],\n",
      "\n",
      "        [[-0.7000]]], dtype=torch.float64)\n",
      "tensor([[-0.5529],\n",
      "        [-0.2398],\n",
      "        [-0.2809],\n",
      "        [-0.2161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.3672]],\n",
      "\n",
      "        [[-0.4077]],\n",
      "\n",
      "        [[-0.4631]]], dtype=torch.float64)\n",
      "tensor([[-0.3809],\n",
      "        [-0.5299],\n",
      "        [-0.5509],\n",
      "        [-0.4711]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5787]],\n",
      "\n",
      "        [[-0.6688]],\n",
      "\n",
      "        [[-0.5891]],\n",
      "\n",
      "        [[-0.5313]]], dtype=torch.float64)\n",
      "tensor([[-0.4715],\n",
      "        [-0.5666],\n",
      "        [-0.6553],\n",
      "        [-0.7513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7358]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-1.2488]],\n",
      "\n",
      "        [[-1.2083]]], dtype=torch.float64)\n",
      "tensor([[-0.6382],\n",
      "        [-0.4137],\n",
      "        [-0.5194],\n",
      "        [-0.5406]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5267]],\n",
      "\n",
      "        [[-0.6769]],\n",
      "\n",
      "        [[-0.9461]],\n",
      "\n",
      "        [[-0.8224]]], dtype=torch.float64)\n",
      "tensor([[-0.4951],\n",
      "        [-0.5191],\n",
      "        [-0.3769],\n",
      "        [-0.2303]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8941]],\n",
      "\n",
      "        [[-0.7439]],\n",
      "\n",
      "        [[-0.3372]],\n",
      "\n",
      "        [[-0.2956]]], dtype=torch.float64)\n",
      "tensor([[-0.4006],\n",
      "        [-0.4776],\n",
      "        [-0.4217],\n",
      "        [-0.5231]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5613]],\n",
      "\n",
      "        [[-0.6156]],\n",
      "\n",
      "        [[-0.6018]],\n",
      "\n",
      "        [[-0.6792]]], dtype=torch.float64)\n",
      "tensor([[-0.4356],\n",
      "        [-0.5561],\n",
      "        [-0.5533],\n",
      "        [-0.6916]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.6815]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-1.2869]]], dtype=torch.float64)\n",
      "tensor([[-0.7087],\n",
      "        [-0.7981],\n",
      "        [-0.7022],\n",
      "        [-0.4244]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2187]],\n",
      "\n",
      "        [[-1.2673]],\n",
      "\n",
      "        [[-0.8444]],\n",
      "\n",
      "        [[-0.7034]]], dtype=torch.float64)\n",
      "tensor([[-0.5443],\n",
      "        [-0.5676],\n",
      "        [-0.4334],\n",
      "        [-0.3013]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6561]],\n",
      "\n",
      "        [[-0.6780]],\n",
      "\n",
      "        [[-0.6341]],\n",
      "\n",
      "        [[-0.4828]]], dtype=torch.float64)\n",
      "tensor([[-0.2318],\n",
      "        [-0.0839],\n",
      "        [-0.2488],\n",
      "        [-0.0095]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1234]],\n",
      "\n",
      "        [[-0.1535]],\n",
      "\n",
      "        [[-0.1777]],\n",
      "\n",
      "        [[-0.0968]]], dtype=torch.float64)\n",
      "tensor([[-0.1053],\n",
      "        [-0.4009],\n",
      "        [-0.5231],\n",
      "        [-0.2428]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2933]],\n",
      "\n",
      "        [[-0.7057]],\n",
      "\n",
      "        [[-0.3580]],\n",
      "\n",
      "        [[-0.3187]]], dtype=torch.float64)\n",
      "tensor([[-0.5594],\n",
      "        [-0.5602],\n",
      "        [-0.4408],\n",
      "        [-0.2871]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7589]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.3152]]], dtype=torch.float64)\n",
      "tensor([[-0.3500],\n",
      "        [-0.4089],\n",
      "        [-0.4877],\n",
      "        [-0.4728]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2251]],\n",
      "\n",
      "        [[-0.3845]],\n",
      "\n",
      "        [[-0.4550]],\n",
      "\n",
      "        [[-0.4539]]], dtype=torch.float64)\n",
      "tensor([[-0.4641],\n",
      "        [-0.5031],\n",
      "        [-0.5722],\n",
      "        [-0.4738]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4238]],\n",
      "\n",
      "        [[-0.4550]],\n",
      "\n",
      "        [[-0.3834]],\n",
      "\n",
      "        [[-0.4100]]], dtype=torch.float64)\n",
      "tensor([[-0.6072],\n",
      "        [-0.7525],\n",
      "        [-0.7465],\n",
      "        [-0.6472]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-1.0189]],\n",
      "\n",
      "        [[-0.9368]],\n",
      "\n",
      "        [[-0.8063]]], dtype=torch.float64)\n",
      "tensor([[-0.5477],\n",
      "        [-0.4821],\n",
      "        [-0.3630],\n",
      "        [-0.4148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5313]],\n",
      "\n",
      "        [[-0.2736]],\n",
      "\n",
      "        [[-0.3094]],\n",
      "\n",
      "        [[-0.5255]]], dtype=torch.float64)\n",
      "tensor([[-0.6320],\n",
      "        [-0.6413],\n",
      "        [-0.9766],\n",
      "        [-1.0025]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8883]],\n",
      "\n",
      "        [[-0.8028]],\n",
      "\n",
      "        [[-0.9530]],\n",
      "\n",
      "        [[-0.9322]]], dtype=torch.float64)\n",
      "tensor([[-0.9160],\n",
      "        [-0.8761],\n",
      "        [-0.8659],\n",
      "        [-0.9198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9565]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.0258]],\n",
      "\n",
      "        [[-1.0431]]], dtype=torch.float64)\n",
      "tensor([[-1.0371],\n",
      "        [-1.0346],\n",
      "        [-0.9928],\n",
      "        [-0.9689]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0166]],\n",
      "\n",
      "        [[-1.0397]],\n",
      "\n",
      "        [[-1.1725]],\n",
      "\n",
      "        [[-1.2176]]], dtype=torch.float64)\n",
      "tensor([[-1.0388],\n",
      "        [-1.1559],\n",
      "        [-1.2682],\n",
      "        [-1.2570]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2788]],\n",
      "\n",
      "        [[-1.4487]],\n",
      "\n",
      "        [[-1.3978]],\n",
      "\n",
      "        [[-1.4256]]], dtype=torch.float64)\n",
      "tensor([[-1.2343],\n",
      "        [-1.1974],\n",
      "        [-1.1759],\n",
      "        [-1.1371]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4660]],\n",
      "\n",
      "        [[-1.4914]],\n",
      "\n",
      "        [[-1.5388]],\n",
      "\n",
      "        [[-1.5272]]], dtype=torch.float64)\n",
      "tensor([[-1.3145],\n",
      "        [-1.2818],\n",
      "        [-1.2395],\n",
      "        [-1.1568]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4683]],\n",
      "\n",
      "        [[-1.4487]],\n",
      "\n",
      "        [[-1.4221]],\n",
      "\n",
      "        [[-1.3609]]], dtype=torch.float64)\n",
      "tensor([[-1.1596],\n",
      "        [-1.1746],\n",
      "        [-1.2447],\n",
      "        [-1.2747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3447]],\n",
      "\n",
      "        [[-1.4001]],\n",
      "\n",
      "        [[-1.2915]],\n",
      "\n",
      "        [[-1.3216]]], dtype=torch.float64)\n",
      "tensor([[-1.2658],\n",
      "        [-1.2145],\n",
      "        [-1.2047],\n",
      "        [-1.2058]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2973]],\n",
      "\n",
      "        [[-1.3574]],\n",
      "\n",
      "        [[-1.4279]],\n",
      "\n",
      "        [[-1.4256]]], dtype=torch.float64)\n",
      "tensor([[-1.2503],\n",
      "        [-1.2677],\n",
      "        [-1.3141],\n",
      "        [-1.2780]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3978]],\n",
      "\n",
      "        [[-1.4718]],\n",
      "\n",
      "        [[-1.7086]],\n",
      "\n",
      "        [[-1.8912]]], dtype=torch.float64)\n",
      "tensor([[-1.4366],\n",
      "        [-1.4476],\n",
      "        [-1.4672],\n",
      "        [-1.5059]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9432]],\n",
      "\n",
      "        [[-1.9859]],\n",
      "\n",
      "        [[-1.7248]],\n",
      "\n",
      "        [[-1.7884]]], dtype=torch.float64)\n",
      "tensor([[-1.5146],\n",
      "        [-1.4577],\n",
      "        [-1.4997],\n",
      "        [-1.5080]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7722]],\n",
      "\n",
      "        [[-1.8912]],\n",
      "\n",
      "        [[-1.7826]],\n",
      "\n",
      "        [[-2.0807]]], dtype=torch.float64)\n",
      "tensor([[-2.0527],\n",
      "        [-2.1715],\n",
      "        [-2.1618],\n",
      "        [-2.1542]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3742]],\n",
      "\n",
      "        [[-2.6214]],\n",
      "\n",
      "        [[-2.6884]],\n",
      "\n",
      "        [[-2.8213]]], dtype=torch.float64)\n",
      "tensor([[-2.3435],\n",
      "        [-2.3538],\n",
      "        [-2.4361],\n",
      "        [-2.3941]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.8929]],\n",
      "\n",
      "        [[-3.0131]],\n",
      "\n",
      "        [[-2.8825]],\n",
      "\n",
      "        [[-2.9253]]], dtype=torch.float64)\n",
      "tensor([[-2.4948],\n",
      "        [-2.3503],\n",
      "        [-2.3499],\n",
      "        [-2.4439]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.8872]],\n",
      "\n",
      "        [[-2.8409]],\n",
      "\n",
      "        [[-2.9519]],\n",
      "\n",
      "        [[-3.0593]]], dtype=torch.float64)\n",
      "tensor([[-2.5018],\n",
      "        [-2.1501],\n",
      "        [-1.9521],\n",
      "        [-1.6119]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3349]],\n",
      "\n",
      "        [[-2.1593]],\n",
      "\n",
      "        [[-1.9732]],\n",
      "\n",
      "        [[-1.5908]]], dtype=torch.float64)\n",
      "tensor([[-1.7861],\n",
      "        [-1.7960],\n",
      "        [-1.6970],\n",
      "        [-1.7534]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5758]],\n",
      "\n",
      "        [[-1.6266]],\n",
      "\n",
      "        [[-1.3817]],\n",
      "\n",
      "        [[-1.4441]]], dtype=torch.float64)\n",
      "tensor([[-1.7917],\n",
      "        [-1.6263],\n",
      "        [-1.4412],\n",
      "        [-1.4525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2858]],\n",
      "\n",
      "        [[-1.1344]],\n",
      "\n",
      "        [[-1.1101]],\n",
      "\n",
      "        [[-1.0119]]], dtype=torch.float64)\n",
      "tensor([[-0.7250],\n",
      "        [-0.3761],\n",
      "        [-0.8992],\n",
      "        [-1.0777]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3949]],\n",
      "\n",
      "        [[-0.2286]],\n",
      "\n",
      "        [[-0.4885]],\n",
      "\n",
      "        [[-0.7520]]], dtype=torch.float64)\n",
      "tensor([[-1.5221],\n",
      "        [-1.6411],\n",
      "        [-1.6040],\n",
      "        [-1.3992]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1067]],\n",
      "\n",
      "        [[-1.1125]],\n",
      "\n",
      "        [[-0.9969]],\n",
      "\n",
      "        [[-1.0639]]], dtype=torch.float64)\n",
      "tensor([[-1.8112],\n",
      "        [-1.7019],\n",
      "        [-1.8019],\n",
      "        [-1.8356]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3008]],\n",
      "\n",
      "        [[-1.2303]],\n",
      "\n",
      "        [[-1.1598]],\n",
      "\n",
      "        [[-1.1806]]], dtype=torch.float64)\n",
      "tensor([[-1.6352],\n",
      "        [-1.5710],\n",
      "        [-1.5895],\n",
      "        [-1.5149]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9218]],\n",
      "\n",
      "        [[-0.9865]],\n",
      "\n",
      "        [[-1.0420]],\n",
      "\n",
      "        [[-1.0166]]], dtype=torch.float64)\n",
      "tensor([[-1.3209],\n",
      "        [-0.9523],\n",
      "        [-0.4686],\n",
      "        [-0.7529]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9218]],\n",
      "\n",
      "        [[-0.5047]],\n",
      "\n",
      "        [[-0.3302]],\n",
      "\n",
      "        [[-0.5590]]], dtype=torch.float64)\n",
      "tensor([[-0.8357],\n",
      "        [-0.9754],\n",
      "        [-1.1420],\n",
      "        [-1.4553]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5625]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.7624]],\n",
      "\n",
      "        [[-0.9230]]], dtype=torch.float64)\n",
      "tensor([[-1.0280],\n",
      "        [-1.0104],\n",
      "        [-1.4257],\n",
      "        [-1.4984]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5625]],\n",
      "\n",
      "        [[-0.8005]],\n",
      "\n",
      "        [[-1.0119]],\n",
      "\n",
      "        [[-1.1252]]], dtype=torch.float64)\n",
      "tensor([[-1.5868],\n",
      "        [-1.7166],\n",
      "        [-1.7394],\n",
      "        [-1.3357]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2811]],\n",
      "\n",
      "        [[-1.4325]],\n",
      "\n",
      "        [[-0.9969]],\n",
      "\n",
      "        [[-1.0177]]], dtype=torch.float64)\n",
      "tensor([[-1.2945],\n",
      "        [-0.8734],\n",
      "        [-1.1672],\n",
      "        [-0.8876]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8640]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.7832]],\n",
      "\n",
      "        [[-0.7554]]], dtype=torch.float64)\n",
      "tensor([[-0.9831],\n",
      "        [-1.2093],\n",
      "        [-1.2227],\n",
      "        [-1.4110]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7196]],\n",
      "\n",
      "        [[-0.7277]],\n",
      "\n",
      "        [[-0.8860]],\n",
      "\n",
      "        [[-1.2962]]], dtype=torch.float64)\n",
      "tensor([[-1.6395],\n",
      "        [-1.7234],\n",
      "        [-1.7584],\n",
      "        [-1.3901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5076]],\n",
      "\n",
      "        [[-1.6208]],\n",
      "\n",
      "        [[-1.2569]],\n",
      "\n",
      "        [[-0.9611]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.27186:  19%|█▉        | 590/3067 [00:02<00:08, 288.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2283],\n",
      "        [-1.2273],\n",
      "        [-1.0910],\n",
      "        [-1.1785]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1876]],\n",
      "\n",
      "        [[-1.1413]],\n",
      "\n",
      "        [[-1.0801]],\n",
      "\n",
      "        [[-1.0628]]], dtype=torch.float64)\n",
      "tensor([[-0.7555],\n",
      "        [-0.6679],\n",
      "        [-1.0677],\n",
      "        [-1.2584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5093]],\n",
      "\n",
      "        [[-0.8698]],\n",
      "\n",
      "        [[-1.0154]],\n",
      "\n",
      "        [[-1.1286]]], dtype=torch.float64)\n",
      "tensor([[-1.1417],\n",
      "        [-1.2888],\n",
      "        [-1.4298],\n",
      "        [-1.4638]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1552]],\n",
      "\n",
      "        [[-1.1806]],\n",
      "\n",
      "        [[-1.2014]],\n",
      "\n",
      "        [[-1.2060]]], dtype=torch.float64)\n",
      "tensor([[-1.2848],\n",
      "        [-1.3891],\n",
      "        [-1.3737],\n",
      "        [-1.5049]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2072]],\n",
      "\n",
      "        [[-1.3817]],\n",
      "\n",
      "        [[-1.4776]],\n",
      "\n",
      "        [[-1.5111]]], dtype=torch.float64)\n",
      "tensor([[-1.6085],\n",
      "        [-1.5324],\n",
      "        [-1.5077],\n",
      "        [-1.3003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5111]],\n",
      "\n",
      "        [[-1.5111]],\n",
      "\n",
      "        [[-1.5180]],\n",
      "\n",
      "        [[-1.5111]]], dtype=torch.float64)\n",
      "tensor([[-1.3406],\n",
      "        [-1.3039],\n",
      "        [-1.3755],\n",
      "        [-1.4720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5492]],\n",
      "\n",
      "        [[-1.5030]],\n",
      "\n",
      "        [[-1.4845]],\n",
      "\n",
      "        [[-1.6694]]], dtype=torch.float64)\n",
      "tensor([[-1.7378],\n",
      "        [-1.7424],\n",
      "        [-1.6394],\n",
      "        [-1.5276]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8796]],\n",
      "\n",
      "        [[-2.0229]],\n",
      "\n",
      "        [[-1.7549]],\n",
      "\n",
      "        [[-1.6185]]], dtype=torch.float64)\n",
      "tensor([[-1.3710],\n",
      "        [-1.3032],\n",
      "        [-1.6960],\n",
      "        [-1.7115]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2858]],\n",
      "\n",
      "        [[-1.3135]],\n",
      "\n",
      "        [[-1.6902]],\n",
      "\n",
      "        [[-1.7572]]], dtype=torch.float64)\n",
      "tensor([[-1.7313],\n",
      "        [-1.8071],\n",
      "        [-1.7134],\n",
      "        [-1.4372]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8196]],\n",
      "\n",
      "        [[-1.8300]],\n",
      "\n",
      "        [[-1.5758]],\n",
      "\n",
      "        [[-1.6520]]], dtype=torch.float64)\n",
      "tensor([[-1.4990],\n",
      "        [-1.5309],\n",
      "        [-1.8280],\n",
      "        [-2.0143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8172]],\n",
      "\n",
      "        [[-2.1708]],\n",
      "\n",
      "        [[-2.5359]],\n",
      "\n",
      "        [[-2.7242]]], dtype=torch.float64)\n",
      "tensor([[-1.8915],\n",
      "        [-1.4997],\n",
      "        [-1.7374],\n",
      "        [-1.7638]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9490]],\n",
      "\n",
      "        [[-1.9201]],\n",
      "\n",
      "        [[-2.2910]],\n",
      "\n",
      "        [[-2.2101]]], dtype=torch.float64)\n",
      "tensor([[-1.7625],\n",
      "        [-1.7607],\n",
      "        [-1.7473],\n",
      "        [-1.5842]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1997]],\n",
      "\n",
      "        [[-2.2205]],\n",
      "\n",
      "        [[-1.8889]],\n",
      "\n",
      "        [[-1.8750]]], dtype=torch.float64)\n",
      "tensor([[-1.7005],\n",
      "        [-1.7099],\n",
      "        [-1.7460],\n",
      "        [-1.7554]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2008]],\n",
      "\n",
      "        [[-2.3095]],\n",
      "\n",
      "        [[-2.1419]],\n",
      "\n",
      "        [[-2.0275]]], dtype=torch.float64)\n",
      "tensor([[-1.8047],\n",
      "        [-1.5666],\n",
      "        [-1.8543],\n",
      "        [-2.0744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7121]],\n",
      "\n",
      "        [[-1.7352]],\n",
      "\n",
      "        [[-2.2216]],\n",
      "\n",
      "        [[-2.3926]]], dtype=torch.float64)\n",
      "tensor([[-2.3042],\n",
      "        [-2.3189],\n",
      "        [-2.5112],\n",
      "        [-2.5252]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4504]],\n",
      "\n",
      "        [[-2.2702]],\n",
      "\n",
      "        [[-2.1847]],\n",
      "\n",
      "        [[-2.0564]]], dtype=torch.float64)\n",
      "tensor([[-2.6180],\n",
      "        [-2.4767],\n",
      "        [-2.3445],\n",
      "        [-2.1536]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8692]],\n",
      "\n",
      "        [[-1.7837]],\n",
      "\n",
      "        [[-1.7514]],\n",
      "\n",
      "        [[-1.6405]]], dtype=torch.float64)\n",
      "tensor([[-2.1085],\n",
      "        [-2.1278],\n",
      "        [-2.1406],\n",
      "        [-2.0544]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5792]],\n",
      "\n",
      "        [[-1.6220]],\n",
      "\n",
      "        [[-1.6566]],\n",
      "\n",
      "        [[-1.6844]]], dtype=torch.float64)\n",
      "tensor([[-1.9430],\n",
      "        [-1.9370],\n",
      "        [-2.0226],\n",
      "        [-1.9085]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6613]],\n",
      "\n",
      "        [[-1.6647]],\n",
      "\n",
      "        [[-1.6000]],\n",
      "\n",
      "        [[-1.6335]]], dtype=torch.float64)\n",
      "tensor([[-1.7680],\n",
      "        [-1.7429],\n",
      "        [-1.7638],\n",
      "        [-1.8867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6936]],\n",
      "\n",
      "        [[-1.6647]],\n",
      "\n",
      "        [[-1.8045]],\n",
      "\n",
      "        [[-1.8334]]], dtype=torch.float64)\n",
      "tensor([[-2.0676],\n",
      "        [-2.0439],\n",
      "        [-1.9628],\n",
      "        [-1.8493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8588]],\n",
      "\n",
      "        [[-1.8612]],\n",
      "\n",
      "        [[-1.8692]],\n",
      "\n",
      "        [[-1.8843]]], dtype=torch.float64)\n",
      "tensor([[-1.7548],\n",
      "        [-1.8091],\n",
      "        [-1.7610],\n",
      "        [-1.7198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8773]],\n",
      "\n",
      "        [[-1.9039]],\n",
      "\n",
      "        [[-1.6844]],\n",
      "\n",
      "        [[-1.6405]]], dtype=torch.float64)\n",
      "tensor([[-1.7908],\n",
      "        [-1.9040],\n",
      "        [-2.1236],\n",
      "        [-2.2419]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9975]],\n",
      "\n",
      "        [[-2.3510]],\n",
      "\n",
      "        [[-2.6977]],\n",
      "\n",
      "        [[-2.7682]]], dtype=torch.float64)\n",
      "tensor([[-2.0708],\n",
      "        [-1.6790],\n",
      "        [-1.4507],\n",
      "        [-1.2750]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0206]],\n",
      "\n",
      "        [[-1.7502]],\n",
      "\n",
      "        [[-1.5261]],\n",
      "\n",
      "        [[-1.4868]]], dtype=torch.float64)\n",
      "tensor([[-1.2493],\n",
      "        [-1.2461],\n",
      "        [-1.2550],\n",
      "        [-1.1501]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5180]],\n",
      "\n",
      "        [[-1.4337]],\n",
      "\n",
      "        [[-1.1402]],\n",
      "\n",
      "        [[-1.1714]]], dtype=torch.float64)\n",
      "tensor([[-1.1962],\n",
      "        [-1.1909],\n",
      "        [-1.2656],\n",
      "        [-1.2498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2627]],\n",
      "\n",
      "        [[-1.3482]],\n",
      "\n",
      "        [[-1.3713]],\n",
      "\n",
      "        [[-1.3736]]], dtype=torch.float64)\n",
      "tensor([[-1.3376],\n",
      "        [-1.3901],\n",
      "        [-1.4429],\n",
      "        [-1.3913]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2072]],\n",
      "\n",
      "        [[-1.1829]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.2996]]], dtype=torch.float64)\n",
      "tensor([[-1.3139],\n",
      "        [-1.2398],\n",
      "        [-1.3677],\n",
      "        [-1.3231]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3227]],\n",
      "\n",
      "        [[-1.3643]],\n",
      "\n",
      "        [[-1.3632]],\n",
      "\n",
      "        [[-1.3100]]], dtype=torch.float64)\n",
      "tensor([[-1.3577],\n",
      "        [-1.3531],\n",
      "        [-1.0990],\n",
      "        [-1.0556]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5192]],\n",
      "\n",
      "        [[-1.4487]],\n",
      "\n",
      "        [[-1.3470]],\n",
      "\n",
      "        [[-1.2372]]], dtype=torch.float64)\n",
      "tensor([[-0.9814],\n",
      "        [-0.8798],\n",
      "        [-0.8637],\n",
      "        [-0.8382]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9669]],\n",
      "\n",
      "        [[-0.9160]],\n",
      "\n",
      "        [[-0.8456]],\n",
      "\n",
      "        [[-0.7554]]], dtype=torch.float64)\n",
      "tensor([[-0.7577],\n",
      "        [-0.9567],\n",
      "        [-0.9136],\n",
      "        [-0.9943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7947]],\n",
      "\n",
      "        [[-0.8571]],\n",
      "\n",
      "        [[-0.6861]],\n",
      "\n",
      "        [[-0.7000]]], dtype=torch.float64)\n",
      "tensor([[-0.9834],\n",
      "        [-1.0822],\n",
      "        [-1.0063],\n",
      "        [-1.0148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8975]],\n",
      "\n",
      "        [[-1.0200]],\n",
      "\n",
      "        [[-1.0420]],\n",
      "\n",
      "        [[-1.0408]]], dtype=torch.float64)\n",
      "tensor([[-1.0536],\n",
      "        [-0.9955],\n",
      "        [-0.9938],\n",
      "        [-1.0370]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9045]],\n",
      "\n",
      "        [[-0.7947]],\n",
      "\n",
      "        [[-0.9391]],\n",
      "\n",
      "        [[-1.0293]]], dtype=torch.float64)\n",
      "tensor([[-1.0567],\n",
      "        [-1.1511],\n",
      "        [-1.1529],\n",
      "        [-1.0377]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1332]],\n",
      "\n",
      "        [[-1.2026]],\n",
      "\n",
      "        [[-0.9022]],\n",
      "\n",
      "        [[-0.9218]]], dtype=torch.float64)\n",
      "tensor([[-1.1640],\n",
      "        [-1.3461],\n",
      "        [-1.5731],\n",
      "        [-1.7338]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1725]],\n",
      "\n",
      "        [[-1.4048]],\n",
      "\n",
      "        [[-1.6197]],\n",
      "\n",
      "        [[-1.7560]]], dtype=torch.float64)\n",
      "tensor([[-1.8126],\n",
      "        [-1.8773],\n",
      "        [-1.8945],\n",
      "        [-1.8859]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7930]],\n",
      "\n",
      "        [[-1.8069]],\n",
      "\n",
      "        [[-1.8947]],\n",
      "\n",
      "        [[-1.9235]]], dtype=torch.float64)\n",
      "tensor([[-1.8138],\n",
      "        [-1.8001],\n",
      "        [-1.7609],\n",
      "        [-1.8477]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9293]],\n",
      "\n",
      "        [[-1.8843]],\n",
      "\n",
      "        [[-1.7445]],\n",
      "\n",
      "        [[-1.7410]]], dtype=torch.float64)\n",
      "tensor([[-1.6803],\n",
      "        [-1.6141],\n",
      "        [-1.6246],\n",
      "        [-1.6803]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6774]],\n",
      "\n",
      "        [[-1.7953]],\n",
      "\n",
      "        [[-1.8484]],\n",
      "\n",
      "        [[-1.8958]]], dtype=torch.float64)\n",
      "tensor([[-1.7096],\n",
      "        [-1.6994],\n",
      "        [-1.6300],\n",
      "        [-1.6042]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6798]],\n",
      "\n",
      "        [[-1.5908]],\n",
      "\n",
      "        [[-1.6335]],\n",
      "\n",
      "        [[-1.6844]]], dtype=torch.float64)\n",
      "tensor([[-1.5998],\n",
      "        [-1.6624],\n",
      "        [-1.6400],\n",
      "        [-1.5582]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8172]],\n",
      "\n",
      "        [[-1.8288]],\n",
      "\n",
      "        [[-1.6659]],\n",
      "\n",
      "        [[-1.6093]]], dtype=torch.float64)\n",
      "tensor([[-1.6059],\n",
      "        [-1.5622],\n",
      "        [-1.5565],\n",
      "        [-1.5551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6058]],\n",
      "\n",
      "        [[-1.6509]],\n",
      "\n",
      "        [[-1.6566]],\n",
      "\n",
      "        [[-1.7537]]], dtype=torch.float64)\n",
      "tensor([[-1.7161],\n",
      "        [-1.6854],\n",
      "        [-1.8956],\n",
      "        [-2.0304]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5792]],\n",
      "\n",
      "        [[-1.6532]],\n",
      "\n",
      "        [[-1.8646]],\n",
      "\n",
      "        [[-2.0310]]], dtype=torch.float64)\n",
      "tensor([[-2.1099],\n",
      "        [-2.3582],\n",
      "        [-2.4659],\n",
      "        [-2.3815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2401]],\n",
      "\n",
      "        [[-2.5197]],\n",
      "\n",
      "        [[-2.3661]],\n",
      "\n",
      "        [[-2.3718]]], dtype=torch.float64)\n",
      "tensor([[-2.5135],\n",
      "        [-2.5823],\n",
      "        [-2.5919],\n",
      "        [-2.6349]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6699]],\n",
      "\n",
      "        [[-2.9195]],\n",
      "\n",
      "        [[-3.1021]],\n",
      "\n",
      "        [[-3.0755]]], dtype=torch.float64)\n",
      "tensor([[-2.4388],\n",
      "        [-1.9700],\n",
      "        [-1.4918],\n",
      "        [-1.1642]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2725]],\n",
      "\n",
      "        [[-1.7699]],\n",
      "\n",
      "        [[-1.6081]],\n",
      "\n",
      "        [[-1.6047]]], dtype=torch.float64)\n",
      "tensor([[-1.1905],\n",
      "        [-0.9537],\n",
      "        [-0.8644],\n",
      "        [-0.7938]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2499]],\n",
      "\n",
      "        [[-1.0720]],\n",
      "\n",
      "        [[-0.8155]],\n",
      "\n",
      "        [[-0.9334]]], dtype=torch.float64)\n",
      "tensor([[-0.8995],\n",
      "        [-0.8738],\n",
      "        [-0.9002],\n",
      "        [-0.7957]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0789]],\n",
      "\n",
      "        [[-1.1125]],\n",
      "\n",
      "        [[-1.1529]],\n",
      "\n",
      "        [[-1.1564]]], dtype=torch.float64)\n",
      "tensor([[-0.8151],\n",
      "        [-0.7451],\n",
      "        [-0.6585],\n",
      "        [-0.5401]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8675]],\n",
      "\n",
      "        [[-0.9276]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-1.1564]]], dtype=torch.float64)\n",
      "tensor([[-0.9269],\n",
      "        [-1.0268],\n",
      "        [-1.0209],\n",
      "        [-1.0695]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2315]],\n",
      "\n",
      "        [[-1.3482]],\n",
      "\n",
      "        [[-1.2164]],\n",
      "\n",
      "        [[-1.2546]]], dtype=torch.float64)\n",
      "tensor([[-1.3729],\n",
      "        [-1.3380],\n",
      "        [-1.4945],\n",
      "        [-1.7030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5249]],\n",
      "\n",
      "        [[-1.5469]],\n",
      "\n",
      "        [[-1.7988]],\n",
      "\n",
      "        [[-2.0356]]], dtype=torch.float64)\n",
      "tensor([[-1.5039],\n",
      "        [-1.3268],\n",
      "        [-1.4696],\n",
      "        [-1.6054]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3516]],\n",
      "\n",
      "        [[-1.0697]],\n",
      "\n",
      "        [[-1.6289]],\n",
      "\n",
      "        [[-1.6624]]], dtype=torch.float64)\n",
      "tensor([[-1.3382],\n",
      "        [-1.3438],\n",
      "        [-1.3061],\n",
      "        [-1.2287]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3990]],\n",
      "\n",
      "        [[-1.4325]],\n",
      "\n",
      "        [[-1.1228]],\n",
      "\n",
      "        [[-1.1887]]], dtype=torch.float64)\n",
      "tensor([[-1.4161],\n",
      "        [-1.4594],\n",
      "        [-1.5453],\n",
      "        [-1.8954]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3539]],\n",
      "\n",
      "        [[-1.3274]],\n",
      "\n",
      "        [[-1.6659]],\n",
      "\n",
      "        [[-1.8011]]], dtype=torch.float64)\n",
      "tensor([[-1.6213],\n",
      "        [-1.2765],\n",
      "        [-1.0411],\n",
      "        [-0.7304]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0836]],\n",
      "\n",
      "        [[-1.0096]],\n",
      "\n",
      "        [[-0.9126]],\n",
      "\n",
      "        [[-0.8132]]], dtype=torch.float64)\n",
      "tensor([[-0.7495],\n",
      "        [-1.1584],\n",
      "        [-1.0926],\n",
      "        [-1.1125]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9946]],\n",
      "\n",
      "        [[-1.1252]],\n",
      "\n",
      "        [[-0.7785]],\n",
      "\n",
      "        [[-0.8767]]], dtype=torch.float64)\n",
      "tensor([[-1.3588],\n",
      "        [-1.4852],\n",
      "        [-1.6278],\n",
      "        [-1.5481]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1587]],\n",
      "\n",
      "        [[-1.4337]],\n",
      "\n",
      "        [[-1.5550]],\n",
      "\n",
      "        [[-1.3262]]], dtype=torch.float64)\n",
      "tensor([[-1.0908],\n",
      "        [-0.8269],\n",
      "        [-0.9679],\n",
      "        [-1.1541]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5833]],\n",
      "\n",
      "        [[-0.5775]],\n",
      "\n",
      "        [[-0.8663]],\n",
      "\n",
      "        [[-1.1182]]], dtype=torch.float64)\n",
      "tensor([[-1.2562],\n",
      "        [-1.3435],\n",
      "        [-1.2392],\n",
      "        [-1.1018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1852]],\n",
      "\n",
      "        [[-1.3285]],\n",
      "\n",
      "        [[-0.9195]],\n",
      "\n",
      "        [[-0.9981]]], dtype=torch.float64)\n",
      "tensor([[-1.3244],\n",
      "        [-1.3565],\n",
      "        [-1.3396],\n",
      "        [-1.2878]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2280]],\n",
      "\n",
      "        [[-1.2187]],\n",
      "\n",
      "        [[-1.1922]],\n",
      "\n",
      "        [[-1.1795]]], dtype=torch.float64)\n",
      "tensor([[-1.2998],\n",
      "        [-1.1537],\n",
      "        [-1.2455],\n",
      "        [-1.3499]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9565]],\n",
      "\n",
      "        [[-0.8964]],\n",
      "\n",
      "        [[-1.0108]],\n",
      "\n",
      "        [[-1.1575]]], dtype=torch.float64)\n",
      "tensor([[-1.5464],\n",
      "        [-1.7509],\n",
      "        [-2.0604],\n",
      "        [-2.0906]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3794]],\n",
      "\n",
      "        [[-1.6127]],\n",
      "\n",
      "        [[-1.7029]],\n",
      "\n",
      "        [[-1.8230]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.27186:  21%|██▏       | 656/3067 [00:02<00:07, 305.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0621],\n",
      "        [-1.9839],\n",
      "        [-1.8444],\n",
      "        [-1.8708]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8346]],\n",
      "\n",
      "        [[-1.7445]],\n",
      "\n",
      "        [[-1.7884]],\n",
      "\n",
      "        [[-1.8380]]], dtype=torch.float64)\n",
      "tensor([[-1.9774],\n",
      "        [-2.0542],\n",
      "        [-2.0480],\n",
      "        [-2.0257]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8415]],\n",
      "\n",
      "        [[-1.8669]],\n",
      "\n",
      "        [[-2.1015]],\n",
      "\n",
      "        [[-1.9617]]], dtype=torch.float64)\n",
      "tensor([[-1.8000],\n",
      "        [-1.7954],\n",
      "        [-1.8159],\n",
      "        [-1.7361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8935]],\n",
      "\n",
      "        [[-2.0079]],\n",
      "\n",
      "        [[-1.7017]],\n",
      "\n",
      "        [[-1.7086]]], dtype=torch.float64)\n",
      "tensor([[-1.8312],\n",
      "        [-1.6927],\n",
      "        [-1.7146],\n",
      "        [-1.7265]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8219]],\n",
      "\n",
      "        [[-1.8392]],\n",
      "\n",
      "        [[-1.8762]],\n",
      "\n",
      "        [[-1.8843]]], dtype=torch.float64)\n",
      "tensor([[-1.6472],\n",
      "        [-1.7478],\n",
      "        [-1.7973],\n",
      "        [-1.8055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7537]],\n",
      "\n",
      "        [[-1.7375]],\n",
      "\n",
      "        [[-1.8739]],\n",
      "\n",
      "        [[-1.8993]]], dtype=torch.float64)\n",
      "tensor([[-1.8271],\n",
      "        [-1.8033],\n",
      "        [-1.7413],\n",
      "        [-1.7087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9455]],\n",
      "\n",
      "        [[-1.8346]],\n",
      "\n",
      "        [[-1.7110]],\n",
      "\n",
      "        [[-1.7040]]], dtype=torch.float64)\n",
      "tensor([[-1.7273],\n",
      "        [-1.5892],\n",
      "        [-1.4759],\n",
      "        [-1.4344]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7491]],\n",
      "\n",
      "        [[-1.6255]],\n",
      "\n",
      "        [[-1.5388]],\n",
      "\n",
      "        [[-1.5007]]], dtype=torch.float64)\n",
      "tensor([[-1.3917],\n",
      "        [-1.4180],\n",
      "        [-1.4764],\n",
      "        [-1.4605]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3505]],\n",
      "\n",
      "        [[-1.4105]],\n",
      "\n",
      "        [[-1.4880]],\n",
      "\n",
      "        [[-1.6035]]], dtype=torch.float64)\n",
      "tensor([[-1.5646],\n",
      "        [-1.6654],\n",
      "        [-1.5833],\n",
      "        [-1.5145]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7225]],\n",
      "\n",
      "        [[-1.6774]],\n",
      "\n",
      "        [[-1.4105]],\n",
      "\n",
      "        [[-1.4960]]], dtype=torch.float64)\n",
      "tensor([[-1.6291],\n",
      "        [-1.6046],\n",
      "        [-1.5952],\n",
      "        [-1.6836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6578]],\n",
      "\n",
      "        [[-1.7133]],\n",
      "\n",
      "        [[-1.8704]],\n",
      "\n",
      "        [[-1.8311]]], dtype=torch.float64)\n",
      "tensor([[-1.5197],\n",
      "        [-1.4326],\n",
      "        [-1.5607],\n",
      "        [-1.5983]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2927]],\n",
      "\n",
      "        [[-1.3886]],\n",
      "\n",
      "        [[-1.5781]],\n",
      "\n",
      "        [[-1.6878]]], dtype=torch.float64)\n",
      "tensor([[-1.5925],\n",
      "        [-1.5680],\n",
      "        [-1.4408],\n",
      "        [-1.4207]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7156]],\n",
      "\n",
      "        [[-1.7294]],\n",
      "\n",
      "        [[-1.3747]],\n",
      "\n",
      "        [[-1.4487]]], dtype=torch.float64)\n",
      "tensor([[-1.4374],\n",
      "        [-1.5931],\n",
      "        [-1.5856],\n",
      "        [-1.4923]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5457]],\n",
      "\n",
      "        [[-1.8334]],\n",
      "\n",
      "        [[-1.7687]],\n",
      "\n",
      "        [[-1.6948]]], dtype=torch.float64)\n",
      "tensor([[-1.4192],\n",
      "        [-1.3959],\n",
      "        [-1.5540],\n",
      "        [-1.8419]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4221]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.8924]],\n",
      "\n",
      "        [[-2.3487]]], dtype=torch.float64)\n",
      "tensor([[-2.0711],\n",
      "        [-2.1412],\n",
      "        [-1.5603],\n",
      "        [-0.7533]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6156]],\n",
      "\n",
      "        [[-2.4724]],\n",
      "\n",
      "        [[-1.0801]],\n",
      "\n",
      "        [[-0.7462]]], dtype=torch.float64)\n",
      "tensor([[-0.9939],\n",
      "        [-1.0863],\n",
      "        [-1.0162],\n",
      "        [-0.9543]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1402]],\n",
      "\n",
      "        [[-1.2407]],\n",
      "\n",
      "        [[-1.1309]],\n",
      "\n",
      "        [[-0.9518]]], dtype=torch.float64)\n",
      "tensor([[-0.5580],\n",
      "        [-0.3488],\n",
      "        [-0.8295],\n",
      "        [-0.9758]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.4319]],\n",
      "\n",
      "        [[-0.9438]],\n",
      "\n",
      "        [[-1.2141]]], dtype=torch.float64)\n",
      "tensor([[-1.0934],\n",
      "        [-0.9735],\n",
      "        [-0.6915],\n",
      "        [-0.3787]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2395]],\n",
      "\n",
      "        [[-0.9415]],\n",
      "\n",
      "        [[-0.6018]],\n",
      "\n",
      "        [[-0.4793]]], dtype=torch.float64)\n",
      "tensor([[-0.5130],\n",
      "        [-0.7402],\n",
      "        [-0.8880],\n",
      "        [-0.9589]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8016]],\n",
      "\n",
      "        [[-0.9565]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-1.1483]]], dtype=torch.float64)\n",
      "tensor([[-0.9921],\n",
      "        [-0.8509],\n",
      "        [-1.0357],\n",
      "        [-1.1715]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7208]],\n",
      "\n",
      "        [[-0.7289]],\n",
      "\n",
      "        [[-1.0397]],\n",
      "\n",
      "        [[-1.2696]]], dtype=torch.float64)\n",
      "tensor([[-1.2091],\n",
      "        [-1.1766],\n",
      "        [-1.0079],\n",
      "        [-1.0270]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2650]],\n",
      "\n",
      "        [[-1.2176]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-0.8409]]], dtype=torch.float64)\n",
      "tensor([[-1.0058],\n",
      "        [-1.1245],\n",
      "        [-1.0867],\n",
      "        [-1.1886]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0131]],\n",
      "\n",
      "        [[-1.2419]],\n",
      "\n",
      "        [[-1.2476]],\n",
      "\n",
      "        [[-1.1852]]], dtype=torch.float64)\n",
      "tensor([[-0.6224],\n",
      "        [-0.4249],\n",
      "        [-0.4258],\n",
      "        [-0.4318]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.4423]],\n",
      "\n",
      "        [[-0.4400]],\n",
      "\n",
      "        [[-0.3187]]], dtype=torch.float64)\n",
      "tensor([[-0.3536],\n",
      "        [-0.1887],\n",
      "        [-0.0963],\n",
      "        [-0.3750]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5590]],\n",
      "\n",
      "        [[-0.3094]],\n",
      "\n",
      "        [[-0.3741]],\n",
      "\n",
      "        [[-0.9264]]], dtype=torch.float64)\n",
      "tensor([[-0.9310],\n",
      "        [-0.9740],\n",
      "        [-0.9703],\n",
      "        [-0.9440]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0709]],\n",
      "\n",
      "        [[-1.1101]],\n",
      "\n",
      "        [[-1.1332]],\n",
      "\n",
      "        [[-1.1090]]], dtype=torch.float64)\n",
      "tensor([[-0.7350],\n",
      "        [ 0.0213],\n",
      "        [-0.4017],\n",
      "        [-0.6969]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4030]],\n",
      "\n",
      "        [[-0.1477]],\n",
      "\n",
      "        [[-0.5740]],\n",
      "\n",
      "        [[-1.0015]]], dtype=torch.float64)\n",
      "tensor([[-0.9106],\n",
      "        [-0.6072],\n",
      "        [-0.0040],\n",
      "        [-0.0885]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6676]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-0.0056]],\n",
      "\n",
      "        [[ 0.0984]]], dtype=torch.float64)\n",
      "tensor([[-0.2973],\n",
      "        [-0.4880],\n",
      "        [-0.2976],\n",
      "        [-0.0680]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3314]],\n",
      "\n",
      "        [[-0.3094]],\n",
      "\n",
      "        [[-0.4146]],\n",
      "\n",
      "        [[-0.2933]]], dtype=torch.float64)\n",
      "tensor([[ 0.0418],\n",
      "        [-0.1372],\n",
      "        [-0.3756],\n",
      "        [-0.6925]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0206]],\n",
      "\n",
      "        [[ 0.0626]],\n",
      "\n",
      "        [[-0.4250]],\n",
      "\n",
      "        [[-0.6052]]], dtype=torch.float64)\n",
      "tensor([[-0.8485],\n",
      "        [-0.8911],\n",
      "        [-0.5511],\n",
      "        [-0.2241]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7439]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.2563]],\n",
      "\n",
      "        [[-0.0772]]], dtype=torch.float64)\n",
      "tensor([[-0.5542],\n",
      "        [-0.7840],\n",
      "        [-0.7360],\n",
      "        [-0.6233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4550]],\n",
      "\n",
      "        [[-0.5971]],\n",
      "\n",
      "        [[-0.5093]],\n",
      "\n",
      "        [[-0.5336]]], dtype=torch.float64)\n",
      "tensor([[-0.1466],\n",
      "        [ 0.1502],\n",
      "        [-0.0543],\n",
      "        [-0.2945]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2556]],\n",
      "\n",
      "        [[ 0.5132]],\n",
      "\n",
      "        [[ 0.0580]],\n",
      "\n",
      "        [[-0.2367]]], dtype=torch.float64)\n",
      "tensor([[-0.4296],\n",
      "        [-0.7145],\n",
      "        [-0.8017],\n",
      "        [-0.7634]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5740]],\n",
      "\n",
      "        [[-0.4735]],\n",
      "\n",
      "        [[-0.4065]],\n",
      "\n",
      "        [[-0.3811]]], dtype=torch.float64)\n",
      "tensor([[-0.9125],\n",
      "        [-0.9274],\n",
      "        [-0.9611],\n",
      "        [-1.1285]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8479]],\n",
      "\n",
      "        [[-0.9253]],\n",
      "\n",
      "        [[-1.0651]],\n",
      "\n",
      "        [[-1.0836]]], dtype=torch.float64)\n",
      "tensor([[-0.9931],\n",
      "        [-1.0791],\n",
      "        [-1.1864],\n",
      "        [-1.1132]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5833]],\n",
      "\n",
      "        [[-0.5555]],\n",
      "\n",
      "        [[-0.8871]],\n",
      "\n",
      "        [[-1.0477]]], dtype=torch.float64)\n",
      "tensor([[-1.1882],\n",
      "        [-1.1587],\n",
      "        [-1.1586],\n",
      "        [-0.9987]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1332]],\n",
      "\n",
      "        [[-0.9830]],\n",
      "\n",
      "        [[-0.5948]],\n",
      "\n",
      "        [[-0.5787]]], dtype=torch.float64)\n",
      "tensor([[-1.1634],\n",
      "        [-1.3683],\n",
      "        [-1.4437],\n",
      "        [-1.5118]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0015]],\n",
      "\n",
      "        [[-1.4475]],\n",
      "\n",
      "        [[-1.6139]],\n",
      "\n",
      "        [[-1.1621]]], dtype=torch.float64)\n",
      "tensor([[-1.2820],\n",
      "        [-1.2698],\n",
      "        [-1.3601],\n",
      "        [-1.4418]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9854]],\n",
      "\n",
      "        [[-0.9010]],\n",
      "\n",
      "        [[-1.2673]],\n",
      "\n",
      "        [[-1.4949]]], dtype=torch.float64)\n",
      "tensor([[-1.4377],\n",
      "        [-1.5746],\n",
      "        [-1.6665],\n",
      "        [-1.6518]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5584]],\n",
      "\n",
      "        [[-1.5411]],\n",
      "\n",
      "        [[-1.3666]],\n",
      "\n",
      "        [[-1.1772]]], dtype=torch.float64)\n",
      "tensor([[-1.4389],\n",
      "        [-1.3590],\n",
      "        [-1.1417],\n",
      "        [-1.1447]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4025]],\n",
      "\n",
      "        [[-1.4868]],\n",
      "\n",
      "        [[-1.3539]],\n",
      "\n",
      "        [[-1.4591]]], dtype=torch.float64)\n",
      "tensor([[-1.5610],\n",
      "        [-1.6785],\n",
      "        [-1.6104],\n",
      "        [-1.6080]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5804]],\n",
      "\n",
      "        [[-1.4383]],\n",
      "\n",
      "        [[-1.5515]],\n",
      "\n",
      "        [[-1.7167]]], dtype=torch.float64)\n",
      "tensor([[-1.5779],\n",
      "        [-1.6521],\n",
      "        [-1.6741],\n",
      "        [-1.5595]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7560]],\n",
      "\n",
      "        [[-1.8727]],\n",
      "\n",
      "        [[-1.4036]],\n",
      "\n",
      "        [[-1.2800]]], dtype=torch.float64)\n",
      "tensor([[-1.5744],\n",
      "        [-1.5632],\n",
      "        [-1.4988],\n",
      "        [-1.5657]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5908]],\n",
      "\n",
      "        [[-1.5723]],\n",
      "\n",
      "        [[-1.6462]],\n",
      "\n",
      "        [[-1.4729]]], dtype=torch.float64)\n",
      "tensor([[-1.3587],\n",
      "        [-1.3754],\n",
      "        [-1.3670],\n",
      "        [-1.4788]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3447]],\n",
      "\n",
      "        [[-1.3458]],\n",
      "\n",
      "        [[-1.5203]],\n",
      "\n",
      "        [[-1.7999]]], dtype=torch.float64)\n",
      "tensor([[-1.5654],\n",
      "        [-1.8398],\n",
      "        [-1.6161],\n",
      "        [-1.5120]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1569]],\n",
      "\n",
      "        [[-2.2297]],\n",
      "\n",
      "        [[-1.4464]],\n",
      "\n",
      "        [[-1.2303]]], dtype=torch.float64)\n",
      "tensor([[-1.3925],\n",
      "        [-1.5209],\n",
      "        [-1.5762],\n",
      "        [-1.6100]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4152]],\n",
      "\n",
      "        [[-1.7352]],\n",
      "\n",
      "        [[-2.0634]],\n",
      "\n",
      "        [[-1.5099]]], dtype=torch.float64)\n",
      "tensor([[-1.4381],\n",
      "        [-1.0850],\n",
      "        [-1.1826],\n",
      "        [-1.2621]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0443]],\n",
      "\n",
      "        [[-0.9230]],\n",
      "\n",
      "        [[-1.1263]],\n",
      "\n",
      "        [[-1.3897]]], dtype=torch.float64)\n",
      "tensor([[-1.3356],\n",
      "        [-1.3388],\n",
      "        [-1.3944],\n",
      "        [-1.1790]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6023]],\n",
      "\n",
      "        [[-1.7202]],\n",
      "\n",
      "        [[-1.3100]],\n",
      "\n",
      "        [[-1.1263]]], dtype=torch.float64)\n",
      "tensor([[-1.2687],\n",
      "        [-1.3199],\n",
      "        [-1.1586],\n",
      "        [-1.0396]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6197]],\n",
      "\n",
      "        [[-1.5758]],\n",
      "\n",
      "        [[-1.4787]],\n",
      "\n",
      "        [[-1.1286]]], dtype=torch.float64)\n",
      "tensor([[-0.8491],\n",
      "        [-0.6477],\n",
      "        [-0.8533],\n",
      "        [-0.6875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7762]],\n",
      "\n",
      "        [[-0.5509]],\n",
      "\n",
      "        [[-0.7947]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-0.7292],\n",
      "        [-0.7395],\n",
      "        [-0.7197],\n",
      "        [-0.6782]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9114]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.6584]],\n",
      "\n",
      "        [[-0.6711]]], dtype=torch.float64)\n",
      "tensor([[-0.7363],\n",
      "        [-0.5871],\n",
      "        [-0.4849],\n",
      "        [-0.6055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6919]],\n",
      "\n",
      "        [[-0.6711]],\n",
      "\n",
      "        [[-0.7242]],\n",
      "\n",
      "        [[-0.7832]]], dtype=torch.float64)\n",
      "tensor([[-0.6438],\n",
      "        [-0.4680],\n",
      "        [-0.5359],\n",
      "        [-0.6388]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4250]],\n",
      "\n",
      "        [[-0.4828]],\n",
      "\n",
      "        [[-0.5960]],\n",
      "\n",
      "        [[-0.9981]]], dtype=torch.float64)\n",
      "tensor([[-1.0063],\n",
      "        [-0.9955],\n",
      "        [-0.9520],\n",
      "        [-0.7333]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1714]],\n",
      "\n",
      "        [[-1.0108]],\n",
      "\n",
      "        [[-0.7647]],\n",
      "\n",
      "        [[-0.7612]]], dtype=torch.float64)\n",
      "tensor([[-0.6375],\n",
      "        [-0.4325],\n",
      "        [-0.3992],\n",
      "        [-0.7832]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6006]],\n",
      "\n",
      "        [[-0.5867]],\n",
      "\n",
      "        [[-0.7785]],\n",
      "\n",
      "        [[-0.9634]]], dtype=torch.float64)\n",
      "tensor([[-0.9133],\n",
      "        [-0.9572],\n",
      "        [-0.7964],\n",
      "        [-0.7905]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8178]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.7323]],\n",
      "\n",
      "        [[-0.8548]]], dtype=torch.float64)\n",
      "tensor([[-0.6922],\n",
      "        [-0.4444],\n",
      "        [-0.1781],\n",
      "        [-0.1487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6873]],\n",
      "\n",
      "        [[-0.5463]],\n",
      "\n",
      "        [[-0.0784]],\n",
      "\n",
      "        [[ 0.1042]]], dtype=torch.float64)\n",
      "tensor([[-0.2886],\n",
      "        [-0.5557],\n",
      "        [-0.7804],\n",
      "        [-1.0074]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3568]],\n",
      "\n",
      "        [[-0.7185]],\n",
      "\n",
      "        [[-1.0789]],\n",
      "\n",
      "        [[-0.7774]]], dtype=torch.float64)\n",
      "tensor([[ 0.0547],\n",
      "        [ 0.0838],\n",
      "        [ 0.0583],\n",
      "        [-0.3325]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4785]],\n",
      "\n",
      "        [[ 0.6495]],\n",
      "\n",
      "        [[ 0.0591]],\n",
      "\n",
      "        [[-0.3811]]], dtype=torch.float64)\n",
      "tensor([[-0.4691],\n",
      "        [-0.4946],\n",
      "        [ 0.3495],\n",
      "        [ 0.3738]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5775]],\n",
      "\n",
      "        [[-0.3788]],\n",
      "\n",
      "        [[ 0.7177]],\n",
      "\n",
      "        [[ 0.8067]]], dtype=torch.float64)\n",
      "tensor([[0.3916],\n",
      "        [0.2280],\n",
      "        [0.2640],\n",
      "        [0.2498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2694]],\n",
      "\n",
      "        [[0.1319]],\n",
      "\n",
      "        [[0.0661]],\n",
      "\n",
      "        [[0.1204]]], dtype=torch.float64)\n",
      "tensor([[0.3090],\n",
      "        [0.4073],\n",
      "        [0.3985],\n",
      "        [0.5088]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5479]],\n",
      "\n",
      "        [[0.6322]],\n",
      "\n",
      "        [[0.4993]],\n",
      "\n",
      "        [[0.3988]]], dtype=torch.float64)\n",
      "tensor([[0.5921],\n",
      "        [0.5368],\n",
      "        [0.5518],\n",
      "        [0.3069]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2636]],\n",
      "\n",
      "        [[0.3307]],\n",
      "\n",
      "        [[0.4855]],\n",
      "\n",
      "        [[0.1377]]], dtype=torch.float64)\n",
      "tensor([[ 0.1728],\n",
      "        [ 0.1850],\n",
      "        [-0.3531],\n",
      "        [-0.4875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0888]],\n",
      "\n",
      "        [[-0.4758]],\n",
      "\n",
      "        [[-0.6988]],\n",
      "\n",
      "        [[-0.5278]]], dtype=torch.float64)\n",
      "tensor([[0.0606],\n",
      "        [0.1561],\n",
      "        [0.1302],\n",
      "        [0.2097]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1296]],\n",
      "\n",
      "        [[ 0.3203]],\n",
      "\n",
      "        [[ 0.1389]],\n",
      "\n",
      "        [[-0.1835]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.25180:  23%|██▎       | 718/3067 [00:02<00:07, 304.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1000],\n",
      "        [-0.3749],\n",
      "        [ 0.1208],\n",
      "        [ 0.0884]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6283]],\n",
      "\n",
      "        [[-0.5082]],\n",
      "\n",
      "        [[ 0.4173]],\n",
      "\n",
      "        [[ 0.3757]]], dtype=torch.float64)\n",
      "tensor([[ 0.0065],\n",
      "        [-0.3511],\n",
      "        [-0.6322],\n",
      "        [-0.7579]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1719]],\n",
      "\n",
      "        [[-0.6792]],\n",
      "\n",
      "        [[-1.0027]],\n",
      "\n",
      "        [[-0.5821]]], dtype=torch.float64)\n",
      "tensor([[0.1861],\n",
      "        [0.4318],\n",
      "        [0.3776],\n",
      "        [0.2588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7235]],\n",
      "\n",
      "        [[1.0297]],\n",
      "\n",
      "        [[0.4739]],\n",
      "\n",
      "        [[0.0545]]], dtype=torch.float64)\n",
      "tensor([[ 0.1506],\n",
      "        [-0.1667],\n",
      "        [ 0.3469],\n",
      "        [ 0.5718]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3048]],\n",
      "\n",
      "        [[-0.1350]],\n",
      "\n",
      "        [[ 1.0493]],\n",
      "\n",
      "        [[ 1.2966]]], dtype=torch.float64)\n",
      "tensor([[0.4585],\n",
      "        [0.3643],\n",
      "        [0.2876],\n",
      "        [0.1239]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6484]],\n",
      "\n",
      "        [[ 0.2983]],\n",
      "\n",
      "        [[ 0.0302]],\n",
      "\n",
      "        [[-0.0599]]], dtype=torch.float64)\n",
      "tensor([[ 0.4705],\n",
      "        [ 0.6537],\n",
      "        [ 0.2457],\n",
      "        [-0.1219]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.2434]],\n",
      "\n",
      "        [[ 1.4329]],\n",
      "\n",
      "        [[-0.2910]],\n",
      "\n",
      "        [[-0.3418]]], dtype=torch.float64)\n",
      "tensor([[ 0.0015],\n",
      "        [ 0.0286],\n",
      "        [-0.0680],\n",
      "        [ 0.0304]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-3.1637e-01]],\n",
      "\n",
      "        [[-2.4589e-01]],\n",
      "\n",
      "        [[ 2.0721e-04]],\n",
      "\n",
      "        [[ 5.3356e-02]]], dtype=torch.float64)\n",
      "tensor([[-0.0803],\n",
      "        [-0.2219],\n",
      "        [-0.2592],\n",
      "        [-0.0255]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2517]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-0.5232]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[ 0.1607],\n",
      "        [-0.0599],\n",
      "        [ 0.0341],\n",
      "        [-0.0215]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1042]],\n",
      "\n",
      "        [[ 0.1770]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[-0.1800]]], dtype=torch.float64)\n",
      "tensor([[0.1123],\n",
      "        [0.1578],\n",
      "        [0.3340],\n",
      "        [0.2809]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3152]],\n",
      "\n",
      "        [[-0.0899]],\n",
      "\n",
      "        [[ 0.3630]],\n",
      "\n",
      "        [[ 0.1319]]], dtype=torch.float64)\n",
      "tensor([[0.0714],\n",
      "        [0.0573],\n",
      "        [0.2039],\n",
      "        [0.1457]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1789]],\n",
      "\n",
      "        [[-0.1523]],\n",
      "\n",
      "        [[-0.3302]],\n",
      "\n",
      "        [[-0.2251]]], dtype=torch.float64)\n",
      "tensor([[0.4291],\n",
      "        [0.6083],\n",
      "        [0.4103],\n",
      "        [0.2197]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7940]],\n",
      "\n",
      "        [[ 1.0643]],\n",
      "\n",
      "        [[ 0.6149]],\n",
      "\n",
      "        [[-0.0899]]], dtype=torch.float64)\n",
      "tensor([[ 0.1606],\n",
      "        [-0.1997],\n",
      "        [ 0.0238],\n",
      "        [ 0.0181]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2782]],\n",
      "\n",
      "        [[-0.4458]],\n",
      "\n",
      "        [[-0.0714]],\n",
      "\n",
      "        [[ 0.1481]]], dtype=torch.float64)\n",
      "tensor([[-0.1373],\n",
      "        [-0.3663],\n",
      "        [-0.5088],\n",
      "        [-0.5606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3141]],\n",
      "\n",
      "        [[-0.6202]],\n",
      "\n",
      "        [[-0.7624]],\n",
      "\n",
      "        [[-0.4481]]], dtype=torch.float64)\n",
      "tensor([[-0.1663],\n",
      "        [-0.2218],\n",
      "        [-0.3601],\n",
      "        [-0.6742]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2078]],\n",
      "\n",
      "        [[-0.1165]],\n",
      "\n",
      "        [[-0.4227]],\n",
      "\n",
      "        [[-0.8964]]], dtype=torch.float64)\n",
      "tensor([[-0.7966],\n",
      "        [-0.8990],\n",
      "        [-0.0259],\n",
      "        [-0.0467]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2349]],\n",
      "\n",
      "        [[-0.7127]],\n",
      "\n",
      "        [[-0.0553]],\n",
      "\n",
      "        [[ 0.1689]]], dtype=torch.float64)\n",
      "tensor([[-0.4175],\n",
      "        [-0.7826],\n",
      "        [-0.8868],\n",
      "        [-0.6790]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3765]],\n",
      "\n",
      "        [[-0.9946]],\n",
      "\n",
      "        [[-0.9472]],\n",
      "\n",
      "        [[-0.5579]]], dtype=torch.float64)\n",
      "tensor([[ 0.0420],\n",
      "        [ 0.0228],\n",
      "        [ 0.0737],\n",
      "        [-0.1224]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2105]],\n",
      "\n",
      "        [[ 0.3376]],\n",
      "\n",
      "        [[ 0.0129]],\n",
      "\n",
      "        [[-0.2794]]], dtype=torch.float64)\n",
      "tensor([[-0.1138],\n",
      "        [-0.0412],\n",
      "        [ 0.1453],\n",
      "        [ 0.0291]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4400]],\n",
      "\n",
      "        [[-0.0472]],\n",
      "\n",
      "        [[ 0.2498]],\n",
      "\n",
      "        [[ 0.3665]]], dtype=torch.float64)\n",
      "tensor([[-0.0337],\n",
      "        [-0.3077],\n",
      "        [-0.0818],\n",
      "        [-0.1679]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1512]],\n",
      "\n",
      "        [[-0.4677]],\n",
      "\n",
      "        [[-0.3233]],\n",
      "\n",
      "        [[-0.3152]]], dtype=torch.float64)\n",
      "tensor([[-0.3450],\n",
      "        [-0.0726],\n",
      "        [-0.3271],\n",
      "        [-0.6182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0703]],\n",
      "\n",
      "        [[ 0.0175]],\n",
      "\n",
      "        [[-0.3222]],\n",
      "\n",
      "        [[-0.7566]]], dtype=torch.float64)\n",
      "tensor([[-0.6866],\n",
      "        [-0.6408],\n",
      "        [ 0.1561],\n",
      "        [ 0.2047]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8687]],\n",
      "\n",
      "        [[-0.4481]],\n",
      "\n",
      "        [[ 0.3861]],\n",
      "\n",
      "        [[ 0.5664]]], dtype=torch.float64)\n",
      "tensor([[ 0.1429],\n",
      "        [-0.2566],\n",
      "        [-0.4363],\n",
      "        [-0.4933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0857]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[-0.7589]],\n",
      "\n",
      "        [[-0.1292]]], dtype=torch.float64)\n",
      "tensor([[ 0.2155],\n",
      "        [ 0.3135],\n",
      "        [ 0.3153],\n",
      "        [-0.2076]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6299]],\n",
      "\n",
      "        [[ 1.0066]],\n",
      "\n",
      "        [[ 0.4242]],\n",
      "\n",
      "        [[-0.1338]]], dtype=torch.float64)\n",
      "tensor([[-0.3802],\n",
      "        [-0.4258],\n",
      "        [ 0.3081],\n",
      "        [ 0.2617]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7023]],\n",
      "\n",
      "        [[-0.2390]],\n",
      "\n",
      "        [[ 1.1094]],\n",
      "\n",
      "        [[ 0.8887]]], dtype=torch.float64)\n",
      "tensor([[ 0.1745],\n",
      "        [ 0.1827],\n",
      "        [ 0.3343],\n",
      "        [-0.2978]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2948]],\n",
      "\n",
      "        [[ 0.0418]],\n",
      "\n",
      "        [[-0.2609]],\n",
      "\n",
      "        [[-0.1072]]], dtype=torch.float64)\n",
      "tensor([[-0.1666],\n",
      "        [-0.1725],\n",
      "        [-0.0736],\n",
      "        [-0.0895]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1793]],\n",
      "\n",
      "        [[ 0.3133]],\n",
      "\n",
      "        [[ 0.0326]],\n",
      "\n",
      "        [[-0.1304]]], dtype=torch.float64)\n",
      "tensor([[-0.1520],\n",
      "        [-0.2959],\n",
      "        [-0.4265],\n",
      "        [-0.4586]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4250]],\n",
      "\n",
      "        [[-0.4781]],\n",
      "\n",
      "        [[-0.3938]],\n",
      "\n",
      "        [[-0.1142]]], dtype=torch.float64)\n",
      "tensor([[-0.3119],\n",
      "        [-0.4885],\n",
      "        [-0.4685],\n",
      "        [-0.6487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5521]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.8999]]], dtype=torch.float64)\n",
      "tensor([[-0.7150],\n",
      "        [-0.5295],\n",
      "        [-0.6118],\n",
      "        [-0.5861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5902]],\n",
      "\n",
      "        [[-0.4955]],\n",
      "\n",
      "        [[-0.5775]],\n",
      "\n",
      "        [[-0.6249]]], dtype=torch.float64)\n",
      "tensor([[-0.4662],\n",
      "        [-0.5377],\n",
      "        [-0.5432],\n",
      "        [-0.2862]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6965]],\n",
      "\n",
      "        [[-0.7693]],\n",
      "\n",
      "        [[-0.6422]],\n",
      "\n",
      "        [[-0.1015]]], dtype=torch.float64)\n",
      "tensor([[-0.1376],\n",
      "        [-0.1574],\n",
      "        [-0.2011],\n",
      "        [-0.3070]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2089]],\n",
      "\n",
      "        [[-0.2505]],\n",
      "\n",
      "        [[-0.4908]],\n",
      "\n",
      "        [[-0.4308]]], dtype=torch.float64)\n",
      "tensor([[ 0.0117],\n",
      "        [ 0.1233],\n",
      "        [ 0.0202],\n",
      "        [-0.0936]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1620]],\n",
      "\n",
      "        [[ 0.3214]],\n",
      "\n",
      "        [[ 0.0337]],\n",
      "\n",
      "        [[-0.1384]]], dtype=torch.float64)\n",
      "tensor([[-0.1209],\n",
      "        [-0.3675],\n",
      "        [-0.0976],\n",
      "        [-0.1902]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4770]],\n",
      "\n",
      "        [[-0.3926]],\n",
      "\n",
      "        [[-0.1662]],\n",
      "\n",
      "        [[-0.3996]]], dtype=torch.float64)\n",
      "tensor([[-0.3833],\n",
      "        [-0.2984],\n",
      "        [-0.1428],\n",
      "        [-0.3068]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4781]],\n",
      "\n",
      "        [[-0.4573]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.5636]]], dtype=torch.float64)\n",
      "tensor([[-0.4061],\n",
      "        [-0.4573],\n",
      "        [-0.4643],\n",
      "        [-0.3459]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4689]],\n",
      "\n",
      "        [[-0.5579]],\n",
      "\n",
      "        [[-0.5475]],\n",
      "\n",
      "        [[-0.6122]]], dtype=torch.float64)\n",
      "tensor([[-0.3210],\n",
      "        [-0.4099],\n",
      "        [-0.0485],\n",
      "        [-0.0087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6815]],\n",
      "\n",
      "        [[-0.4030]],\n",
      "\n",
      "        [[-0.1246]],\n",
      "\n",
      "        [[ 0.0626]]], dtype=torch.float64)\n",
      "tensor([[-0.1261],\n",
      "        [-0.4709],\n",
      "        [-0.6836],\n",
      "        [-0.6861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2921]],\n",
      "\n",
      "        [[-0.7185]],\n",
      "\n",
      "        [[-1.1332]],\n",
      "\n",
      "        [[-0.5093]]], dtype=torch.float64)\n",
      "tensor([[-0.0205],\n",
      "        [ 0.1523],\n",
      "        [ 0.1593],\n",
      "        [-0.2273]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2140]],\n",
      "\n",
      "        [[ 0.7986]],\n",
      "\n",
      "        [[ 0.1666]],\n",
      "\n",
      "        [[-0.6642]]], dtype=torch.float64)\n",
      "tensor([[-0.5410],\n",
      "        [-0.5467],\n",
      "        [ 0.3179],\n",
      "        [ 0.4014]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0235]],\n",
      "\n",
      "        [[-0.2355]],\n",
      "\n",
      "        [[ 0.8494]],\n",
      "\n",
      "        [[ 0.9962]]], dtype=torch.float64)\n",
      "tensor([[ 0.3224],\n",
      "        [ 0.1085],\n",
      "        [-0.1966],\n",
      "        [-0.2465]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5802]],\n",
      "\n",
      "        [[-0.2528]],\n",
      "\n",
      "        [[-0.6653]],\n",
      "\n",
      "        [[ 0.0291]]], dtype=torch.float64)\n",
      "tensor([[ 0.3150],\n",
      "        [ 0.2605],\n",
      "        [ 0.0452],\n",
      "        [-0.0505]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 4.5428e-01]],\n",
      "\n",
      "        [[ 4.7508e-01]],\n",
      "\n",
      "        [[ 2.0721e-04]],\n",
      "\n",
      "        [[-8.7604e-02]]], dtype=torch.float64)\n",
      "tensor([[-0.0177],\n",
      "        [-0.1490],\n",
      "        [ 0.2712],\n",
      "        [ 0.2051]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3314]],\n",
      "\n",
      "        [[ 0.0383]],\n",
      "\n",
      "        [[ 0.6010]],\n",
      "\n",
      "        [[ 0.8148]]], dtype=torch.float64)\n",
      "tensor([[ 0.0980],\n",
      "        [-0.1956],\n",
      "        [-0.3622],\n",
      "        [-0.4115]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2452]],\n",
      "\n",
      "        [[-0.2112]],\n",
      "\n",
      "        [[-0.5174]],\n",
      "\n",
      "        [[-0.4296]]], dtype=torch.float64)\n",
      "tensor([[-0.4900],\n",
      "        [-0.3412],\n",
      "        [-0.5429],\n",
      "        [-0.6936]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5787]],\n",
      "\n",
      "        [[-0.2286]],\n",
      "\n",
      "        [[-0.5914]],\n",
      "\n",
      "        [[-0.8733]]], dtype=torch.float64)\n",
      "tensor([[-0.6435],\n",
      "        [-0.4310],\n",
      "        [-0.4803],\n",
      "        [-0.2624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0200]],\n",
      "\n",
      "        [[-0.5810]],\n",
      "\n",
      "        [[-0.0853]],\n",
      "\n",
      "        [[ 0.2313]]], dtype=torch.float64)\n",
      "tensor([[-0.2376],\n",
      "        [-0.6183],\n",
      "        [-0.7863],\n",
      "        [-0.7503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2124]],\n",
      "\n",
      "        [[-0.9299]],\n",
      "\n",
      "        [[-1.2858]],\n",
      "\n",
      "        [[-0.5821]]], dtype=torch.float64)\n",
      "tensor([[ 0.1030],\n",
      "        [ 0.0989],\n",
      "        [ 0.0061],\n",
      "        [-0.2877]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4601]],\n",
      "\n",
      "        [[ 0.5629]],\n",
      "\n",
      "        [[ 0.1839]],\n",
      "\n",
      "        [[-0.5243]]], dtype=torch.float64)\n",
      "tensor([[-0.5325],\n",
      "        [-0.5064],\n",
      "        [ 0.2457],\n",
      "        [ 0.3607]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9449]],\n",
      "\n",
      "        [[-0.2193]],\n",
      "\n",
      "        [[ 0.9153]],\n",
      "\n",
      "        [[ 0.9604]]], dtype=torch.float64)\n",
      "tensor([[ 0.2346],\n",
      "        [ 0.1214],\n",
      "        [-0.0897],\n",
      "        [-0.1883]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4889]],\n",
      "\n",
      "        [[ 0.0557]],\n",
      "\n",
      "        [[-0.6214]],\n",
      "\n",
      "        [[ 0.0672]]], dtype=torch.float64)\n",
      "tensor([[0.4072],\n",
      "        [0.5591],\n",
      "        [0.5621],\n",
      "        [0.3530]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2758]],\n",
      "\n",
      "        [[1.4260]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.2498]]], dtype=torch.float64)\n",
      "tensor([[0.2866],\n",
      "        [0.3570],\n",
      "        [0.2854],\n",
      "        [0.2761]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1974]],\n",
      "\n",
      "        [[ 0.4266]],\n",
      "\n",
      "        [[ 0.4866]],\n",
      "\n",
      "        [[ 0.8090]]], dtype=torch.float64)\n",
      "tensor([[0.2557],\n",
      "        [0.2160],\n",
      "        [0.3440],\n",
      "        [0.3673]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3965]],\n",
      "\n",
      "        [[0.1493]],\n",
      "\n",
      "        [[0.0418]],\n",
      "\n",
      "        [[0.1932]]], dtype=torch.float64)\n",
      "tensor([[0.2479],\n",
      "        [0.1774],\n",
      "        [0.2162],\n",
      "        [0.0647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6842]],\n",
      "\n",
      "        [[ 0.8182]],\n",
      "\n",
      "        [[ 0.4034]],\n",
      "\n",
      "        [[-0.3314]]], dtype=torch.float64)\n",
      "tensor([[-0.1240],\n",
      "        [-0.0736],\n",
      "        [ 0.4237],\n",
      "        [ 0.4844]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6988]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[ 0.9199]],\n",
      "\n",
      "        [[ 1.3162]]], dtype=torch.float64)\n",
      "tensor([[0.5252],\n",
      "        [0.2751],\n",
      "        [0.1694],\n",
      "        [0.2079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7524]],\n",
      "\n",
      "        [[-0.0252]],\n",
      "\n",
      "        [[-0.3961]],\n",
      "\n",
      "        [[ 0.4462]]], dtype=torch.float64)\n",
      "tensor([[0.7532],\n",
      "        [0.7627],\n",
      "        [0.6580],\n",
      "        [0.5044]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6201]],\n",
      "\n",
      "        [[1.7241]],\n",
      "\n",
      "        [[1.3000]],\n",
      "\n",
      "        [[0.4219]]], dtype=torch.float64)\n",
      "tensor([[0.3916],\n",
      "        [0.6844],\n",
      "        [0.6994],\n",
      "        [0.6584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2763]],\n",
      "\n",
      "        [[1.1718]],\n",
      "\n",
      "        [[1.4086]],\n",
      "\n",
      "        [[1.3151]]], dtype=torch.float64)\n",
      "tensor([[0.4613],\n",
      "        [0.5013],\n",
      "        [0.5078],\n",
      "        [0.4116]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8298]],\n",
      "\n",
      "        [[0.3838]],\n",
      "\n",
      "        [[0.1516]],\n",
      "\n",
      "        [[0.3260]]], dtype=torch.float64)\n",
      "tensor([[0.3975],\n",
      "        [0.2680],\n",
      "        [0.3101],\n",
      "        [0.3261]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5005]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[0.4508]],\n",
      "\n",
      "        [[0.0846]]], dtype=torch.float64)\n",
      "tensor([[0.3846],\n",
      "        [0.2690],\n",
      "        [0.3073],\n",
      "        [0.2982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0957]],\n",
      "\n",
      "        [[ 0.0684]],\n",
      "\n",
      "        [[ 0.3434]],\n",
      "\n",
      "        [[ 0.1920]]], dtype=torch.float64)\n",
      "tensor([[0.1694],\n",
      "        [0.3128],\n",
      "        [0.4585],\n",
      "        [0.4523]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1308]],\n",
      "\n",
      "        [[0.0938]],\n",
      "\n",
      "        [[0.0222]],\n",
      "\n",
      "        [[0.2498]]], dtype=torch.float64)\n",
      "tensor([[0.3679],\n",
      "        [0.3139],\n",
      "        [0.0571],\n",
      "        [0.1908]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.25180:  26%|██▌       | 785/3067 [00:02<00:07, 309.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5629]],\n",
      "\n",
      "        [[ 0.3618]],\n",
      "\n",
      "        [[-0.0841]],\n",
      "\n",
      "        [[-0.1581]]], dtype=torch.float64)\n",
      "tensor([[ 0.2692],\n",
      "        [ 0.3260],\n",
      "        [ 0.1008],\n",
      "        [-0.1355]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1315]],\n",
      "\n",
      "        [[-0.1176]],\n",
      "\n",
      "        [[-0.1442]],\n",
      "\n",
      "        [[-0.1685]]], dtype=torch.float64)\n",
      "tensor([[-0.1566],\n",
      "        [-0.2583],\n",
      "        [-0.5245],\n",
      "        [-0.5412]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1904]],\n",
      "\n",
      "        [[-0.4781]],\n",
      "\n",
      "        [[-0.8259]],\n",
      "\n",
      "        [[-0.5694]]], dtype=torch.float64)\n",
      "tensor([[-0.2283],\n",
      "        [-0.0004],\n",
      "        [-0.1045],\n",
      "        [-0.1409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1454]],\n",
      "\n",
      "        [[ 0.1215]],\n",
      "\n",
      "        [[-0.0079]],\n",
      "\n",
      "        [[-0.3672]]], dtype=torch.float64)\n",
      "tensor([[-0.2112],\n",
      "        [-0.0242],\n",
      "        [-0.0281],\n",
      "        [-0.1497]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5243]],\n",
      "\n",
      "        [[-0.4100]],\n",
      "\n",
      "        [[-0.4007]],\n",
      "\n",
      "        [[-0.4238]]], dtype=torch.float64)\n",
      "tensor([[-0.2496],\n",
      "        [-0.1743],\n",
      "        [-0.0091],\n",
      "        [ 0.1152]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4400]],\n",
      "\n",
      "        [[-0.4562]],\n",
      "\n",
      "        [[-0.4273]],\n",
      "\n",
      "        [[-0.3141]]], dtype=torch.float64)\n",
      "tensor([[ 0.1736],\n",
      "        [ 0.1394],\n",
      "        [-0.0798],\n",
      "        [-0.1333]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1500]],\n",
      "\n",
      "        [[-0.1338]],\n",
      "\n",
      "        [[-0.2609]],\n",
      "\n",
      "        [[-0.4365]]], dtype=torch.float64)\n",
      "tensor([[-0.0617],\n",
      "        [ 0.0929],\n",
      "        [ 0.2278],\n",
      "        [ 0.1709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4596]],\n",
      "\n",
      "        [[ 0.1192]],\n",
      "\n",
      "        [[ 0.3711]],\n",
      "\n",
      "        [[ 0.5225]]], dtype=torch.float64)\n",
      "tensor([[0.2144],\n",
      "        [0.2325],\n",
      "        [0.0050],\n",
      "        [0.0026]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1908]],\n",
      "\n",
      "        [[-0.1916]],\n",
      "\n",
      "        [[-0.5833]],\n",
      "\n",
      "        [[ 0.1932]]], dtype=torch.float64)\n",
      "tensor([[0.5961],\n",
      "        [0.2891],\n",
      "        [0.2380],\n",
      "        [0.2631]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7593]],\n",
      "\n",
      "        [[ 0.1331]],\n",
      "\n",
      "        [[ 0.0903]],\n",
      "\n",
      "        [[-0.0264]]], dtype=torch.float64)\n",
      "tensor([[ 0.2920],\n",
      "        [ 0.2511],\n",
      "        [ 0.0999],\n",
      "        [-0.0413]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0899]],\n",
      "\n",
      "        [[-0.0714]],\n",
      "\n",
      "        [[-0.1812]],\n",
      "\n",
      "        [[ 0.0141]]], dtype=torch.float64)\n",
      "tensor([[-0.1005],\n",
      "        [ 0.0085],\n",
      "        [ 0.1357],\n",
      "        [ 0.1537]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1026]],\n",
      "\n",
      "        [[-0.1997]],\n",
      "\n",
      "        [[-0.2667]],\n",
      "\n",
      "        [[-0.1488]]], dtype=torch.float64)\n",
      "tensor([[ 0.1811],\n",
      "        [ 0.1660],\n",
      "        [-0.0162],\n",
      "        [ 0.1066]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1493]],\n",
      "\n",
      "        [[ 0.1516]],\n",
      "\n",
      "        [[-0.0391]],\n",
      "\n",
      "        [[-0.0541]]], dtype=torch.float64)\n",
      "tensor([[0.3303],\n",
      "        [0.3632],\n",
      "        [0.4842],\n",
      "        [0.3345]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1315]],\n",
      "\n",
      "        [[ 0.1966]],\n",
      "\n",
      "        [[ 0.4508]],\n",
      "\n",
      "        [[ 0.5340]]], dtype=torch.float64)\n",
      "tensor([[0.1669],\n",
      "        [0.0158],\n",
      "        [0.0254],\n",
      "        [0.0558]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1377]],\n",
      "\n",
      "        [[-0.1951]],\n",
      "\n",
      "        [[-0.2933]],\n",
      "\n",
      "        [[-0.2055]]], dtype=torch.float64)\n",
      "tensor([[ 0.0166],\n",
      "        [-0.0733],\n",
      "        [-0.2327],\n",
      "        [-0.1718]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1176]],\n",
      "\n",
      "        [[-0.1165]],\n",
      "\n",
      "        [[-0.1777]],\n",
      "\n",
      "        [[-0.2852]]], dtype=torch.float64)\n",
      "tensor([[-0.0359],\n",
      "        [-0.0658],\n",
      "        [-0.0699],\n",
      "        [-0.0845]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3499]],\n",
      "\n",
      "        [[-0.2840]],\n",
      "\n",
      "        [[-0.0957]],\n",
      "\n",
      "        [[-0.2193]]], dtype=torch.float64)\n",
      "tensor([[-0.2165],\n",
      "        [-0.1077],\n",
      "        [-0.0308],\n",
      "        [ 0.0018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3326]],\n",
      "\n",
      "        [[-0.4169]],\n",
      "\n",
      "        [[-0.4851]],\n",
      "\n",
      "        [[-0.4053]]], dtype=torch.float64)\n",
      "tensor([[-0.2037],\n",
      "        [-0.2853],\n",
      "        [-0.2877],\n",
      "        [-0.2066]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4342]],\n",
      "\n",
      "        [[-0.2782]],\n",
      "\n",
      "        [[-0.4088]],\n",
      "\n",
      "        [[-0.4088]]], dtype=torch.float64)\n",
      "tensor([[-0.0161],\n",
      "        [ 0.0966],\n",
      "        [ 0.0576],\n",
      "        [-0.0007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3464]],\n",
      "\n",
      "        [[-0.0541]],\n",
      "\n",
      "        [[ 0.3734]],\n",
      "\n",
      "        [[ 0.4543]]], dtype=torch.float64)\n",
      "tensor([[ 0.0817],\n",
      "        [ 0.0603],\n",
      "        [-0.2830],\n",
      "        [ 0.0802]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1677]],\n",
      "\n",
      "        [[-0.3406]],\n",
      "\n",
      "        [[-0.6838]],\n",
      "\n",
      "        [[ 0.3653]]], dtype=torch.float64)\n",
      "tensor([[0.2259],\n",
      "        [0.2646],\n",
      "        [0.1990],\n",
      "        [0.2517]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6507]],\n",
      "\n",
      "        [[ 0.5687]],\n",
      "\n",
      "        [[ 0.2602]],\n",
      "\n",
      "        [[-0.0102]]], dtype=torch.float64)\n",
      "tensor([[ 0.3108],\n",
      "        [ 0.1661],\n",
      "        [-0.0387],\n",
      "        [-0.0844]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1581]],\n",
      "\n",
      "        [[-0.1708]],\n",
      "\n",
      "        [[ 0.2001]],\n",
      "\n",
      "        [[ 0.2417]]], dtype=torch.float64)\n",
      "tensor([[-0.0202],\n",
      "        [ 0.0728],\n",
      "        [ 0.1017],\n",
      "        [ 0.0820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0268]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[-0.3938]],\n",
      "\n",
      "        [[-0.4157]]], dtype=torch.float64)\n",
      "tensor([[ 0.0455],\n",
      "        [-0.1059],\n",
      "        [-0.0353],\n",
      "        [ 0.1077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1800]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.0518]],\n",
      "\n",
      "        [[ 0.0326]]], dtype=torch.float64)\n",
      "tensor([[0.3116],\n",
      "        [0.2528],\n",
      "        [0.2007],\n",
      "        [0.1393]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0460]],\n",
      "\n",
      "        [[-0.0009]],\n",
      "\n",
      "        [[ 0.1781]],\n",
      "\n",
      "        [[ 0.1770]]], dtype=torch.float64)\n",
      "tensor([[0.1287],\n",
      "        [0.2069],\n",
      "        [0.2896],\n",
      "        [0.2888]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0302]],\n",
      "\n",
      "        [[ 0.0164]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[ 0.1331]]], dtype=torch.float64)\n",
      "tensor([[0.3174],\n",
      "        [0.3892],\n",
      "        [0.6196],\n",
      "        [0.2749]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8229]],\n",
      "\n",
      "        [[1.1198]],\n",
      "\n",
      "        [[0.7813]],\n",
      "\n",
      "        [[0.0614]]], dtype=torch.float64)\n",
      "tensor([[0.1966],\n",
      "        [0.2309],\n",
      "        [0.6523],\n",
      "        [0.4824]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2343]],\n",
      "\n",
      "        [[ 0.5560]],\n",
      "\n",
      "        [[ 1.1094]],\n",
      "\n",
      "        [[ 1.2307]]], dtype=torch.float64)\n",
      "tensor([[0.3741],\n",
      "        [0.2721],\n",
      "        [0.4727],\n",
      "        [0.5546]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4011]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.3607]],\n",
      "\n",
      "        [[0.7212]]], dtype=torch.float64)\n",
      "tensor([[0.6827],\n",
      "        [0.8457],\n",
      "        [0.7269],\n",
      "        [0.4746]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1810]],\n",
      "\n",
      "        [[1.5207]],\n",
      "\n",
      "        [[0.9511]],\n",
      "\n",
      "        [[0.6010]]], dtype=torch.float64)\n",
      "tensor([[0.4655],\n",
      "        [0.6206],\n",
      "        [0.8391],\n",
      "        [0.6936]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2775]],\n",
      "\n",
      "        [[1.0759]],\n",
      "\n",
      "        [[1.4329]],\n",
      "\n",
      "        [[1.3983]]], dtype=torch.float64)\n",
      "tensor([[0.6090],\n",
      "        [0.4591],\n",
      "        [0.3644],\n",
      "        [0.3932]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9280]],\n",
      "\n",
      "        [[0.3145]],\n",
      "\n",
      "        [[0.1932]],\n",
      "\n",
      "        [[0.4797]]], dtype=torch.float64)\n",
      "tensor([[0.4168],\n",
      "        [0.4346],\n",
      "        [0.4110],\n",
      "        [0.1677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8991]],\n",
      "\n",
      "        [[1.0863]],\n",
      "\n",
      "        [[0.4785]],\n",
      "\n",
      "        [[0.1493]]], dtype=torch.float64)\n",
      "tensor([[ 0.0962],\n",
      "        [-0.1627],\n",
      "        [ 0.2201],\n",
      "        [ 0.2628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0968]],\n",
      "\n",
      "        [[-0.0888]],\n",
      "\n",
      "        [[ 0.5432]],\n",
      "\n",
      "        [[ 0.3572]]], dtype=torch.float64)\n",
      "tensor([[0.1615],\n",
      "        [0.2297],\n",
      "        [0.3229],\n",
      "        [0.4178]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2971]],\n",
      "\n",
      "        [[0.1758]],\n",
      "\n",
      "        [[0.2140]],\n",
      "\n",
      "        [[0.0418]]], dtype=torch.float64)\n",
      "tensor([[0.1216],\n",
      "        [0.2819],\n",
      "        [0.3203],\n",
      "        [0.2533]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2186]],\n",
      "\n",
      "        [[0.6796]],\n",
      "\n",
      "        [[0.4312]],\n",
      "\n",
      "        [[0.1562]]], dtype=torch.float64)\n",
      "tensor([[0.3731],\n",
      "        [0.4419],\n",
      "        [0.4456],\n",
      "        [0.4384]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1469]],\n",
      "\n",
      "        [[0.4705]],\n",
      "\n",
      "        [[0.6519]],\n",
      "\n",
      "        [[0.7894]]], dtype=torch.float64)\n",
      "tensor([[0.4103],\n",
      "        [0.2631],\n",
      "        [0.1745],\n",
      "        [0.1493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5583]],\n",
      "\n",
      "        [[-0.0171]],\n",
      "\n",
      "        [[-0.3014]],\n",
      "\n",
      "        [[ 0.2567]]], dtype=torch.float64)\n",
      "tensor([[0.6617],\n",
      "        [0.7916],\n",
      "        [0.7153],\n",
      "        [0.4938]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0378]],\n",
      "\n",
      "        [[1.2203]],\n",
      "\n",
      "        [[0.8286]],\n",
      "\n",
      "        [[0.3815]]], dtype=torch.float64)\n",
      "tensor([[0.4995],\n",
      "        [0.5288],\n",
      "        [0.7227],\n",
      "        [0.6658]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2821]],\n",
      "\n",
      "        [[0.3642]],\n",
      "\n",
      "        [[0.8148]],\n",
      "\n",
      "        [[0.7859]]], dtype=torch.float64)\n",
      "tensor([[0.4466],\n",
      "        [0.2090],\n",
      "        [0.0819],\n",
      "        [0.0856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4208]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[-0.2956]],\n",
      "\n",
      "        [[-0.0518]]], dtype=torch.float64)\n",
      "tensor([[0.1249],\n",
      "        [0.0925],\n",
      "        [0.0489],\n",
      "        [0.1745]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3584]],\n",
      "\n",
      "        [[ 0.1527]],\n",
      "\n",
      "        [[ 0.1077]],\n",
      "\n",
      "        [[-0.0691]]], dtype=torch.float64)\n",
      "tensor([[0.2921],\n",
      "        [0.2790],\n",
      "        [0.1522],\n",
      "        [0.0908]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0229]],\n",
      "\n",
      "        [[ 0.0765]],\n",
      "\n",
      "        [[ 0.1019]],\n",
      "\n",
      "        [[ 0.0822]]], dtype=torch.float64)\n",
      "tensor([[0.1094],\n",
      "        [0.2007],\n",
      "        [0.3042],\n",
      "        [0.2277]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0984]],\n",
      "\n",
      "        [[-0.0564]],\n",
      "\n",
      "        [[-0.0703]],\n",
      "\n",
      "        [[ 0.0222]]], dtype=torch.float64)\n",
      "tensor([[0.2908],\n",
      "        [0.1493],\n",
      "        [0.3293],\n",
      "        [0.3605]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1273]],\n",
      "\n",
      "        [[0.4474]],\n",
      "\n",
      "        [[0.5028]],\n",
      "\n",
      "        [[0.4531]]], dtype=torch.float64)\n",
      "tensor([[0.5095],\n",
      "        [0.3644],\n",
      "        [0.4799],\n",
      "        [0.6050]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3642]],\n",
      "\n",
      "        [[0.4081]],\n",
      "\n",
      "        [[1.0193]],\n",
      "\n",
      "        [[1.3081]]], dtype=torch.float64)\n",
      "tensor([[0.7377],\n",
      "        [0.4477],\n",
      "        [0.2640],\n",
      "        [0.5131]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8772]],\n",
      "\n",
      "        [[ 0.3133]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[ 0.7235]]], dtype=torch.float64)\n",
      "tensor([[0.6858],\n",
      "        [0.9342],\n",
      "        [0.8690],\n",
      "        [0.5182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0597]],\n",
      "\n",
      "        [[1.4283]],\n",
      "\n",
      "        [[0.9303]],\n",
      "\n",
      "        [[0.2914]]], dtype=torch.float64)\n",
      "tensor([[0.4003],\n",
      "        [0.5529],\n",
      "        [1.2514],\n",
      "        [1.2535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1130]],\n",
      "\n",
      "        [[ 0.8887]],\n",
      "\n",
      "        [[ 1.6085]],\n",
      "\n",
      "        [[ 1.8489]]], dtype=torch.float64)\n",
      "tensor([[1.2889],\n",
      "        [0.8875],\n",
      "        [0.6751],\n",
      "        [0.8338]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3786]],\n",
      "\n",
      "        [[0.6854]],\n",
      "\n",
      "        [[0.3041]],\n",
      "\n",
      "        [[1.2966]]], dtype=torch.float64)\n",
      "tensor([[1.6493],\n",
      "        [1.7414],\n",
      "        [1.4382],\n",
      "        [1.0679]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0418]],\n",
      "\n",
      "        [[2.2024]],\n",
      "\n",
      "        [[1.6074]],\n",
      "\n",
      "        [[1.0216]]], dtype=torch.float64)\n",
      "tensor([[1.0544],\n",
      "        [1.1428],\n",
      "        [1.0531],\n",
      "        [0.7345]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8587]],\n",
      "\n",
      "        [[1.2457]],\n",
      "\n",
      "        [[1.1995]],\n",
      "\n",
      "        [[1.2873]]], dtype=torch.float64)\n",
      "tensor([[0.9036],\n",
      "        [0.5659],\n",
      "        [0.5072],\n",
      "        [0.6354]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0528]],\n",
      "\n",
      "        [[0.5317]],\n",
      "\n",
      "        [[0.1377]],\n",
      "\n",
      "        [[0.8760]]], dtype=torch.float64)\n",
      "tensor([[1.3296],\n",
      "        [1.5508],\n",
      "        [1.3394],\n",
      "        [1.0511]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7437]],\n",
      "\n",
      "        [[1.8962]],\n",
      "\n",
      "        [[1.4780]],\n",
      "\n",
      "        [[1.0147]]], dtype=torch.float64)\n",
      "tensor([[1.0815],\n",
      "        [1.1958],\n",
      "        [1.6990],\n",
      "        [1.9015]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8402]],\n",
      "\n",
      "        [[1.5357]],\n",
      "\n",
      "        [[2.0118]],\n",
      "\n",
      "        [[2.2972]]], dtype=torch.float64)\n",
      "tensor([[1.7633],\n",
      "        [1.4743],\n",
      "        [1.4598],\n",
      "        [1.4554]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8200]],\n",
      "\n",
      "        [[1.2688]],\n",
      "\n",
      "        [[1.1568]],\n",
      "\n",
      "        [[1.3370]]], dtype=torch.float64)\n",
      "tensor([[1.8019],\n",
      "        [1.8710],\n",
      "        [1.9243],\n",
      "        [1.6461]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0753]],\n",
      "\n",
      "        [[2.2452]],\n",
      "\n",
      "        [[1.8304]],\n",
      "\n",
      "        [[1.2492]]], dtype=torch.float64)\n",
      "tensor([[1.5595],\n",
      "        [1.6739],\n",
      "        [1.5924],\n",
      "        [1.3933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1475]],\n",
      "\n",
      "        [[1.5854]],\n",
      "\n",
      "        [[1.7391]],\n",
      "\n",
      "        [[1.7714]]], dtype=torch.float64)\n",
      "tensor([[1.5431],\n",
      "        [1.1649],\n",
      "        [1.2235],\n",
      "        [1.0709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3740]],\n",
      "\n",
      "        [[1.0978]],\n",
      "\n",
      "        [[0.9476]],\n",
      "\n",
      "        [[0.9014]]], dtype=torch.float64)\n",
      "tensor([[1.0242],\n",
      "        [1.0040],\n",
      "        [0.2474],\n",
      "        [0.3996]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0123]],\n",
      "\n",
      "        [[1.3393]],\n",
      "\n",
      "        [[0.4531]],\n",
      "\n",
      "        [[0.2983]]], dtype=torch.float64)\n",
      "tensor([[0.5177],\n",
      "        [0.5838],\n",
      "        [0.3300],\n",
      "        [0.4309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1504]],\n",
      "\n",
      "        [[0.5421]],\n",
      "\n",
      "        [[0.7974]],\n",
      "\n",
      "        [[0.9384]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.24195:  28%|██▊       | 847/3067 [00:02<00:07, 295.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5594],\n",
      "        [0.3795],\n",
      "        [0.4084],\n",
      "        [0.4901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5432]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.1770]],\n",
      "\n",
      "        [[0.4323]]], dtype=torch.float64)\n",
      "tensor([[0.5531],\n",
      "        [0.5417],\n",
      "        [0.6404],\n",
      "        [0.6898]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7015]],\n",
      "\n",
      "        [[0.7917]],\n",
      "\n",
      "        [[0.6819]],\n",
      "\n",
      "        [[0.4312]]], dtype=torch.float64)\n",
      "tensor([[0.6528],\n",
      "        [0.6435],\n",
      "        [0.6572],\n",
      "        [0.6718]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2532]],\n",
      "\n",
      "        [[0.5386]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[1.0713]]], dtype=torch.float64)\n",
      "tensor([[0.5085],\n",
      "        [0.3728],\n",
      "        [0.3603],\n",
      "        [0.2597]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6449]],\n",
      "\n",
      "        [[ 0.2729]],\n",
      "\n",
      "        [[-0.0252]],\n",
      "\n",
      "        [[ 0.3919]]], dtype=torch.float64)\n",
      "tensor([[0.3710],\n",
      "        [0.5824],\n",
      "        [0.6359],\n",
      "        [0.4767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7870]],\n",
      "\n",
      "        [[1.1048]],\n",
      "\n",
      "        [[0.9419]],\n",
      "\n",
      "        [[0.5629]]], dtype=torch.float64)\n",
      "tensor([[0.4688],\n",
      "        [0.3810],\n",
      "        [0.7447],\n",
      "        [0.8513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1781]],\n",
      "\n",
      "        [[0.6784]],\n",
      "\n",
      "        [[1.1348]],\n",
      "\n",
      "        [[1.3636]]], dtype=torch.float64)\n",
      "tensor([[0.9311],\n",
      "        [0.7041],\n",
      "        [0.6124],\n",
      "        [0.7929]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1071]],\n",
      "\n",
      "        [[0.7339]],\n",
      "\n",
      "        [[0.3006]],\n",
      "\n",
      "        [[0.8055]]], dtype=torch.float64)\n",
      "tensor([[0.9541],\n",
      "        [1.0157],\n",
      "        [0.6110],\n",
      "        [0.4246]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3139]],\n",
      "\n",
      "        [[1.1833]],\n",
      "\n",
      "        [[0.5860]],\n",
      "\n",
      "        [[0.2047]]], dtype=torch.float64)\n",
      "tensor([[0.3112],\n",
      "        [0.3108],\n",
      "        [0.3140],\n",
      "        [0.3847]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0356]],\n",
      "\n",
      "        [[ 0.1793]],\n",
      "\n",
      "        [[ 0.3642]],\n",
      "\n",
      "        [[ 0.6877]]], dtype=torch.float64)\n",
      "tensor([[0.3552],\n",
      "        [0.1840],\n",
      "        [0.2526],\n",
      "        [0.4082]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3595]],\n",
      "\n",
      "        [[ 0.0060]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[ 0.4069]]], dtype=torch.float64)\n",
      "tensor([[0.2466],\n",
      "        [0.3532],\n",
      "        [0.5664],\n",
      "        [0.3395]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5583]],\n",
      "\n",
      "        [[0.6103]],\n",
      "\n",
      "        [[0.4069]],\n",
      "\n",
      "        [[0.1493]]], dtype=torch.float64)\n",
      "tensor([[0.2826],\n",
      "        [0.3094],\n",
      "        [0.3178],\n",
      "        [0.3400]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0992]],\n",
      "\n",
      "        [[ 0.1285]],\n",
      "\n",
      "        [[ 0.5825]],\n",
      "\n",
      "        [[ 0.6784]]], dtype=torch.float64)\n",
      "tensor([[0.3398],\n",
      "        [0.3253],\n",
      "        [0.0871],\n",
      "        [0.3688]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4439]],\n",
      "\n",
      "        [[-0.0945]],\n",
      "\n",
      "        [[-0.4492]],\n",
      "\n",
      "        [[ 0.6461]]], dtype=torch.float64)\n",
      "tensor([[0.7189],\n",
      "        [0.7270],\n",
      "        [0.7693],\n",
      "        [0.6021]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9696]],\n",
      "\n",
      "        [[1.0239]],\n",
      "\n",
      "        [[0.7004]],\n",
      "\n",
      "        [[0.2093]]], dtype=torch.float64)\n",
      "tensor([[0.3766],\n",
      "        [0.5800],\n",
      "        [1.0131],\n",
      "        [1.0499]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2228]],\n",
      "\n",
      "        [[ 0.8356]],\n",
      "\n",
      "        [[ 1.2561]],\n",
      "\n",
      "        [[ 1.2873]]], dtype=torch.float64)\n",
      "tensor([[0.8466],\n",
      "        [0.8245],\n",
      "        [0.7353],\n",
      "        [0.9863]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9962]],\n",
      "\n",
      "        [[0.6519]],\n",
      "\n",
      "        [[0.3203]],\n",
      "\n",
      "        [[1.2376]]], dtype=torch.float64)\n",
      "tensor([[1.1691],\n",
      "        [1.0888],\n",
      "        [1.4410],\n",
      "        [1.0099]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4653]],\n",
      "\n",
      "        [[1.7495]],\n",
      "\n",
      "        [[1.3613]],\n",
      "\n",
      "        [[0.6449]]], dtype=torch.float64)\n",
      "tensor([[0.7216],\n",
      "        [0.8184],\n",
      "        [1.5755],\n",
      "        [1.1362]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3549]],\n",
      "\n",
      "        [[1.1660]],\n",
      "\n",
      "        [[1.8142]],\n",
      "\n",
      "        [[1.6039]]], dtype=torch.float64)\n",
      "tensor([[1.3183],\n",
      "        [1.0834],\n",
      "        [0.9518],\n",
      "        [0.9263]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2515]],\n",
      "\n",
      "        [[0.8933]],\n",
      "\n",
      "        [[0.6750]],\n",
      "\n",
      "        [[0.9811]]], dtype=torch.float64)\n",
      "tensor([[1.0580],\n",
      "        [1.1013],\n",
      "        [1.0585],\n",
      "        [0.8183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4029]],\n",
      "\n",
      "        [[1.5461]],\n",
      "\n",
      "        [[1.1175]],\n",
      "\n",
      "        [[0.5040]]], dtype=torch.float64)\n",
      "tensor([[0.6133],\n",
      "        [0.8402],\n",
      "        [1.2664],\n",
      "        [1.3909]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0915]],\n",
      "\n",
      "        [[1.1568]],\n",
      "\n",
      "        [[1.5797]],\n",
      "\n",
      "        [[1.7738]]], dtype=torch.float64)\n",
      "tensor([[1.3312],\n",
      "        [1.0004],\n",
      "        [0.7069],\n",
      "        [0.9937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4029]],\n",
      "\n",
      "        [[0.6068]],\n",
      "\n",
      "        [[0.1920]],\n",
      "\n",
      "        [[1.5727]]], dtype=torch.float64)\n",
      "tensor([[1.5356],\n",
      "        [1.6245],\n",
      "        [1.5862],\n",
      "        [1.1927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8962]],\n",
      "\n",
      "        [[2.0025]],\n",
      "\n",
      "        [[1.6709]],\n",
      "\n",
      "        [[0.8298]]], dtype=torch.float64)\n",
      "tensor([[0.8960],\n",
      "        [1.1195],\n",
      "        [1.7830],\n",
      "        [1.7838]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4601]],\n",
      "\n",
      "        [[1.5092]],\n",
      "\n",
      "        [[2.1389]],\n",
      "\n",
      "        [[2.2625]]], dtype=torch.float64)\n",
      "tensor([[1.8693],\n",
      "        [1.3480],\n",
      "        [1.3731],\n",
      "        [1.5306]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8315]],\n",
      "\n",
      "        [[1.1776]],\n",
      "\n",
      "        [[0.9407]],\n",
      "\n",
      "        [[1.3555]]], dtype=torch.float64)\n",
      "tensor([[1.6406],\n",
      "        [1.6690],\n",
      "        [1.6450],\n",
      "        [1.3671]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8130]],\n",
      "\n",
      "        [[2.1019]],\n",
      "\n",
      "        [[1.5900]],\n",
      "\n",
      "        [[1.0066]]], dtype=torch.float64)\n",
      "tensor([[1.2516],\n",
      "        [1.3211],\n",
      "        [1.9229],\n",
      "        [1.8958]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6657]],\n",
      "\n",
      "        [[1.4294]],\n",
      "\n",
      "        [[2.1481]],\n",
      "\n",
      "        [[2.1666]]], dtype=torch.float64)\n",
      "tensor([[1.7067],\n",
      "        [1.4895],\n",
      "        [1.2533],\n",
      "        [1.3190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6940]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[1.4294]]], dtype=torch.float64)\n",
      "tensor([[1.8791],\n",
      "        [1.8434],\n",
      "        [1.6754],\n",
      "        [1.4696]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1481]],\n",
      "\n",
      "        [[2.1666]],\n",
      "\n",
      "        [[1.6940]],\n",
      "\n",
      "        [[1.2065]]], dtype=torch.float64)\n",
      "tensor([[1.3367],\n",
      "        [1.3968],\n",
      "        [2.1470],\n",
      "        [2.0618]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7836]],\n",
      "\n",
      "        [[1.5935]],\n",
      "\n",
      "        [[2.3468]],\n",
      "\n",
      "        [[2.4393]]], dtype=torch.float64)\n",
      "tensor([[1.9896],\n",
      "        [1.6050],\n",
      "        [1.5104],\n",
      "        [1.5785]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0164]],\n",
      "\n",
      "        [[1.4514]],\n",
      "\n",
      "        [[1.0227]],\n",
      "\n",
      "        [[1.9251]]], dtype=torch.float64)\n",
      "tensor([[2.2001],\n",
      "        [2.0483],\n",
      "        [2.0213],\n",
      "        [1.6077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.4404]],\n",
      "\n",
      "        [[2.5306]],\n",
      "\n",
      "        [[2.1158]],\n",
      "\n",
      "        [[1.3243]]], dtype=torch.float64)\n",
      "tensor([[1.3549],\n",
      "        [1.4812],\n",
      "        [1.6123],\n",
      "        [1.7323]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0008]],\n",
      "\n",
      "        [[1.7599]],\n",
      "\n",
      "        [[1.7495]],\n",
      "\n",
      "        [[2.0072]]], dtype=torch.float64)\n",
      "tensor([[1.6206],\n",
      "        [1.3828],\n",
      "        [1.4475],\n",
      "        [1.5517]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2596]],\n",
      "\n",
      "        [[0.9996]],\n",
      "\n",
      "        [[0.8922]],\n",
      "\n",
      "        [[1.5265]]], dtype=torch.float64)\n",
      "tensor([[1.8254],\n",
      "        [1.2554],\n",
      "        [1.4115],\n",
      "        [1.1695]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8327]],\n",
      "\n",
      "        [[1.6929]],\n",
      "\n",
      "        [[1.1753]],\n",
      "\n",
      "        [[0.9084]]], dtype=torch.float64)\n",
      "tensor([[1.2343],\n",
      "        [0.9715],\n",
      "        [0.7548],\n",
      "        [0.7595]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7385]],\n",
      "\n",
      "        [[0.5294]],\n",
      "\n",
      "        [[0.8956]],\n",
      "\n",
      "        [[1.1036]]], dtype=torch.float64)\n",
      "tensor([[0.6733],\n",
      "        [0.5724],\n",
      "        [0.5832],\n",
      "        [0.6944]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7686]],\n",
      "\n",
      "        [[0.2613]],\n",
      "\n",
      "        [[0.0025]],\n",
      "\n",
      "        [[0.9361]]], dtype=torch.float64)\n",
      "tensor([[0.8484],\n",
      "        [0.9206],\n",
      "        [0.9554],\n",
      "        [0.8438]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4133]],\n",
      "\n",
      "        [[1.5669]],\n",
      "\n",
      "        [[1.2099]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[0.8134],\n",
      "        [0.8211],\n",
      "        [1.4450],\n",
      "        [1.4517]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3907]],\n",
      "\n",
      "        [[1.1903]],\n",
      "\n",
      "        [[2.0233]],\n",
      "\n",
      "        [[2.2047]]], dtype=torch.float64)\n",
      "tensor([[1.4748],\n",
      "        [1.2920],\n",
      "        [1.0441],\n",
      "        [1.2157]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7911]],\n",
      "\n",
      "        [[1.1198]],\n",
      "\n",
      "        [[0.6126]],\n",
      "\n",
      "        [[1.6189]]], dtype=torch.float64)\n",
      "tensor([[1.8995],\n",
      "        [2.0306],\n",
      "        [2.0652],\n",
      "        [1.4601]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.4855]],\n",
      "\n",
      "        [[2.7455]],\n",
      "\n",
      "        [[2.1724]],\n",
      "\n",
      "        [[1.2307]]], dtype=torch.float64)\n",
      "tensor([[1.3716],\n",
      "        [1.5616],\n",
      "        [2.1617],\n",
      "        [2.1747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1302]],\n",
      "\n",
      "        [[1.9794]],\n",
      "\n",
      "        [[2.7385]],\n",
      "\n",
      "        [[2.7951]]], dtype=torch.float64)\n",
      "tensor([[2.1943],\n",
      "        [1.9729],\n",
      "        [1.7776],\n",
      "        [1.7182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3388]],\n",
      "\n",
      "        [[1.6028]],\n",
      "\n",
      "        [[1.2862]],\n",
      "\n",
      "        [[2.1215]]], dtype=torch.float64)\n",
      "tensor([[2.3726],\n",
      "        [2.4189],\n",
      "        [2.1834],\n",
      "        [1.8055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.8148]],\n",
      "\n",
      "        [[2.9303]],\n",
      "\n",
      "        [[2.1238]],\n",
      "\n",
      "        [[1.6536]]], dtype=torch.float64)\n",
      "tensor([[1.9654],\n",
      "        [1.9434],\n",
      "        [2.4138],\n",
      "        [2.1495]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3555]],\n",
      "\n",
      "        [[1.9944]],\n",
      "\n",
      "        [[2.6750]],\n",
      "\n",
      "        [[2.7189]]], dtype=torch.float64)\n",
      "tensor([[2.0166],\n",
      "        [1.3480],\n",
      "        [1.4284],\n",
      "        [1.6078]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9887]],\n",
      "\n",
      "        [[1.0447]],\n",
      "\n",
      "        [[1.0077]],\n",
      "\n",
      "        [[1.5623]]], dtype=torch.float64)\n",
      "tensor([[1.7125],\n",
      "        [1.6948],\n",
      "        [1.6901],\n",
      "        [1.5884]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7530]],\n",
      "\n",
      "        [[2.1192]],\n",
      "\n",
      "        [[1.7010]],\n",
      "\n",
      "        [[1.2353]]], dtype=torch.float64)\n",
      "tensor([[1.5801],\n",
      "        [1.5706],\n",
      "        [2.1189],\n",
      "        [2.1652]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8437]],\n",
      "\n",
      "        [[1.6883]],\n",
      "\n",
      "        [[2.3341]],\n",
      "\n",
      "        [[2.6634]]], dtype=torch.float64)\n",
      "tensor([[2.3917],\n",
      "        [1.8290],\n",
      "        [1.6687],\n",
      "        [1.7143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2232]],\n",
      "\n",
      "        [[1.1706]],\n",
      "\n",
      "        [[1.1059]],\n",
      "\n",
      "        [[1.3463]]], dtype=torch.float64)\n",
      "tensor([[1.7149],\n",
      "        [1.7146],\n",
      "        [1.5252],\n",
      "        [1.4451]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7922]],\n",
      "\n",
      "        [[1.8881]],\n",
      "\n",
      "        [[1.6016]],\n",
      "\n",
      "        [[1.0516]]], dtype=torch.float64)\n",
      "tensor([[1.2525],\n",
      "        [1.4114],\n",
      "        [2.0015],\n",
      "        [2.2352]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6761]],\n",
      "\n",
      "        [[1.6917]],\n",
      "\n",
      "        [[2.3272]],\n",
      "\n",
      "        [[2.7859]]], dtype=torch.float64)\n",
      "tensor([[2.2232],\n",
      "        [1.8478],\n",
      "        [1.5777],\n",
      "        [1.5049]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2937]],\n",
      "\n",
      "        [[1.4976]],\n",
      "\n",
      "        [[1.1833]],\n",
      "\n",
      "        [[1.3659]]], dtype=torch.float64)\n",
      "tensor([[1.3811],\n",
      "        [1.2027],\n",
      "        [1.0199],\n",
      "        [1.1046]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8743]],\n",
      "\n",
      "        [[0.9650]],\n",
      "\n",
      "        [[0.9234]],\n",
      "\n",
      "        [[0.8899]]], dtype=torch.float64)\n",
      "tensor([[1.1915],\n",
      "        [1.0929],\n",
      "        [0.8069],\n",
      "        [0.9519]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7582]],\n",
      "\n",
      "        [[0.9442]],\n",
      "\n",
      "        [[1.3035]],\n",
      "\n",
      "        [[1.7842]]], dtype=torch.float64)\n",
      "tensor([[0.8485],\n",
      "        [0.7053],\n",
      "        [0.7242],\n",
      "        [0.7828]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2700]],\n",
      "\n",
      "        [[0.5444]],\n",
      "\n",
      "        [[0.1562]],\n",
      "\n",
      "        [[0.8968]]], dtype=torch.float64)\n",
      "tensor([[1.0970],\n",
      "        [0.8802],\n",
      "        [0.9067],\n",
      "        [0.8033]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5854]],\n",
      "\n",
      "        [[1.7391]],\n",
      "\n",
      "        [[1.3821]],\n",
      "\n",
      "        [[0.6553]]], dtype=torch.float64)\n",
      "tensor([[0.7448],\n",
      "        [0.7587],\n",
      "        [1.2188],\n",
      "        [1.0832]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2521]],\n",
      "\n",
      "        [[1.2677]],\n",
      "\n",
      "        [[1.8731]],\n",
      "\n",
      "        [[2.0534]]], dtype=torch.float64)\n",
      "tensor([[1.1506],\n",
      "        [1.3336],\n",
      "        [1.2461],\n",
      "        [1.3208]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6513]],\n",
      "\n",
      "        [[1.1649]],\n",
      "\n",
      "        [[0.6969]],\n",
      "\n",
      "        [[1.5577]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.24092:  30%|██▉       | 912/3067 [00:03<00:06, 309.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7780],\n",
      "        [1.8920],\n",
      "        [1.8393],\n",
      "        [1.3178]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3942]],\n",
      "\n",
      "        [[2.7166]],\n",
      "\n",
      "        [[2.3711]],\n",
      "\n",
      "        [[1.4179]]], dtype=torch.float64)\n",
      "tensor([[1.3958],\n",
      "        [1.5117],\n",
      "        [1.7781],\n",
      "        [1.7159]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4052]],\n",
      "\n",
      "        [[1.4560]],\n",
      "\n",
      "        [[2.1446]],\n",
      "\n",
      "        [[1.4398]]], dtype=torch.float64)\n",
      "tensor([[1.2405],\n",
      "        [1.3250],\n",
      "        [1.5485],\n",
      "        [1.5169]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2122]],\n",
      "\n",
      "        [[1.0794]],\n",
      "\n",
      "        [[0.9615]],\n",
      "\n",
      "        [[1.0990]]], dtype=torch.float64)\n",
      "tensor([[1.3899],\n",
      "        [1.0595],\n",
      "        [0.8742],\n",
      "        [0.9997]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2423]],\n",
      "\n",
      "        [[0.9939]],\n",
      "\n",
      "        [[0.7743]],\n",
      "\n",
      "        [[0.7350]]], dtype=torch.float64)\n",
      "tensor([[1.1305],\n",
      "        [1.1331],\n",
      "        [0.8617],\n",
      "        [0.6564]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7015]],\n",
      "\n",
      "        [[0.7766]],\n",
      "\n",
      "        [[1.1764]],\n",
      "\n",
      "        [[1.1175]]], dtype=torch.float64)\n",
      "tensor([[0.5170],\n",
      "        [0.4957],\n",
      "        [0.4892],\n",
      "        [0.5294]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7304]],\n",
      "\n",
      "        [[0.3896]],\n",
      "\n",
      "        [[0.1319]],\n",
      "\n",
      "        [[0.4439]]], dtype=torch.float64)\n",
      "tensor([[0.5920],\n",
      "        [0.5564],\n",
      "        [0.6863],\n",
      "        [0.6062]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0435]],\n",
      "\n",
      "        [[1.4167]],\n",
      "\n",
      "        [[0.9580]],\n",
      "\n",
      "        [[0.3434]]], dtype=torch.float64)\n",
      "tensor([[0.5916],\n",
      "        [0.5894],\n",
      "        [0.7782],\n",
      "        [1.0323]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2036]],\n",
      "\n",
      "        [[0.3907]],\n",
      "\n",
      "        [[1.2665]],\n",
      "\n",
      "        [[0.8725]]], dtype=torch.float64)\n",
      "tensor([[0.6325],\n",
      "        [0.6494],\n",
      "        [0.8804],\n",
      "        [1.0113]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6842]],\n",
      "\n",
      "        [[0.4936]],\n",
      "\n",
      "        [[0.4728]],\n",
      "\n",
      "        [[0.8691]]], dtype=torch.float64)\n",
      "tensor([[1.1635],\n",
      "        [1.2021],\n",
      "        [1.0429],\n",
      "        [0.9166]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2908]],\n",
      "\n",
      "        [[1.5149]],\n",
      "\n",
      "        [[1.0216]],\n",
      "\n",
      "        [[0.7200]]], dtype=torch.float64)\n",
      "tensor([[1.0002],\n",
      "        [0.9232],\n",
      "        [1.2367],\n",
      "        [0.9759]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3792]],\n",
      "\n",
      "        [[0.8564]],\n",
      "\n",
      "        [[0.8991]],\n",
      "\n",
      "        [[1.2735]]], dtype=torch.float64)\n",
      "tensor([[0.8724],\n",
      "        [0.9069],\n",
      "        [0.9020],\n",
      "        [0.8815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7963]],\n",
      "\n",
      "        [[0.6241]],\n",
      "\n",
      "        [[0.4000]],\n",
      "\n",
      "        [[0.7073]]], dtype=torch.float64)\n",
      "tensor([[0.8810],\n",
      "        [0.4810],\n",
      "        [0.7766],\n",
      "        [0.5182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8818]],\n",
      "\n",
      "        [[1.1094]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[0.3722]]], dtype=torch.float64)\n",
      "tensor([[0.7625],\n",
      "        [0.7556],\n",
      "        [0.6603],\n",
      "        [0.8673]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2532]],\n",
      "\n",
      "        [[0.6703]],\n",
      "\n",
      "        [[1.1545]],\n",
      "\n",
      "        [[1.4479]]], dtype=torch.float64)\n",
      "tensor([[0.8190],\n",
      "        [0.6602],\n",
      "        [0.6096],\n",
      "        [0.6719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8321]],\n",
      "\n",
      "        [[0.3364]],\n",
      "\n",
      "        [[0.0580]],\n",
      "\n",
      "        [[0.8517]]], dtype=torch.float64)\n",
      "tensor([[1.2409],\n",
      "        [1.2810],\n",
      "        [1.1719],\n",
      "        [1.0245]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5993]],\n",
      "\n",
      "        [[1.6536]],\n",
      "\n",
      "        [[1.3324]],\n",
      "\n",
      "        [[0.8390]]], dtype=torch.float64)\n",
      "tensor([[0.9431],\n",
      "        [0.9472],\n",
      "        [1.4586],\n",
      "        [1.5780]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4612]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[1.9806]],\n",
      "\n",
      "        [[2.0014]]], dtype=torch.float64)\n",
      "tensor([[1.5886],\n",
      "        [1.2409],\n",
      "        [1.2339],\n",
      "        [1.2135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7322]],\n",
      "\n",
      "        [[1.1082]],\n",
      "\n",
      "        [[0.8286]],\n",
      "\n",
      "        [[1.1302]]], dtype=torch.float64)\n",
      "tensor([[1.3817],\n",
      "        [1.2583],\n",
      "        [0.9303],\n",
      "        [0.8663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5253]],\n",
      "\n",
      "        [[1.6721]],\n",
      "\n",
      "        [[0.8205]],\n",
      "\n",
      "        [[0.7628]]], dtype=torch.float64)\n",
      "tensor([[1.1446],\n",
      "        [1.1092],\n",
      "        [0.8351],\n",
      "        [0.7589]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7385]],\n",
      "\n",
      "        [[0.6784]],\n",
      "\n",
      "        [[0.8598]],\n",
      "\n",
      "        [[0.7616]]], dtype=torch.float64)\n",
      "tensor([[0.6969],\n",
      "        [0.5897],\n",
      "        [0.5741],\n",
      "        [0.5130]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6507]],\n",
      "\n",
      "        [[0.2867]],\n",
      "\n",
      "        [[0.0360]],\n",
      "\n",
      "        [[0.6207]]], dtype=torch.float64)\n",
      "tensor([[1.0786],\n",
      "        [0.9678],\n",
      "        [1.0433],\n",
      "        [0.6994]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4190]],\n",
      "\n",
      "        [[1.4352]],\n",
      "\n",
      "        [[1.1152]],\n",
      "\n",
      "        [[0.5964]]], dtype=torch.float64)\n",
      "tensor([[0.7264],\n",
      "        [0.6367],\n",
      "        [1.1700],\n",
      "        [0.9296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2694]],\n",
      "\n",
      "        [[0.9095]],\n",
      "\n",
      "        [[1.4167]],\n",
      "\n",
      "        [[1.3012]]], dtype=torch.float64)\n",
      "tensor([[0.5670],\n",
      "        [0.6398],\n",
      "        [0.8788],\n",
      "        [0.8040]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6611]],\n",
      "\n",
      "        [[0.6646]],\n",
      "\n",
      "        [[0.5456]],\n",
      "\n",
      "        [[0.6207]]], dtype=torch.float64)\n",
      "tensor([[0.6491],\n",
      "        [0.3749],\n",
      "        [0.4896],\n",
      "        [0.5979]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5687]],\n",
      "\n",
      "        [[0.5606]],\n",
      "\n",
      "        [[0.5606]],\n",
      "\n",
      "        [[0.5687]]], dtype=torch.float64)\n",
      "tensor([[0.8279],\n",
      "        [0.8312],\n",
      "        [0.8409],\n",
      "        [0.8897]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5918]],\n",
      "\n",
      "        [[0.6981]],\n",
      "\n",
      "        [[1.3405]],\n",
      "\n",
      "        [[1.4687]]], dtype=torch.float64)\n",
      "tensor([[1.0149],\n",
      "        [0.9269],\n",
      "        [0.8169],\n",
      "        [0.6395]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1579]],\n",
      "\n",
      "        [[0.6807]],\n",
      "\n",
      "        [[0.3214]],\n",
      "\n",
      "        [[0.8610]]], dtype=torch.float64)\n",
      "tensor([[1.1089],\n",
      "        [1.0659],\n",
      "        [1.0159],\n",
      "        [0.7226]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4237]],\n",
      "\n",
      "        [[1.4595]],\n",
      "\n",
      "        [[0.9465]],\n",
      "\n",
      "        [[0.6334]]], dtype=torch.float64)\n",
      "tensor([[0.7476],\n",
      "        [0.8052],\n",
      "        [0.9145],\n",
      "        [0.9823]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5456]],\n",
      "\n",
      "        [[0.7790]],\n",
      "\n",
      "        [[1.2307]],\n",
      "\n",
      "        [[1.3416]]], dtype=torch.float64)\n",
      "tensor([[0.9230],\n",
      "        [0.8041],\n",
      "        [0.8789],\n",
      "        [0.7684]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0227]],\n",
      "\n",
      "        [[0.6565]],\n",
      "\n",
      "        [[0.3861]],\n",
      "\n",
      "        [[0.9696]]], dtype=torch.float64)\n",
      "tensor([[1.1887],\n",
      "        [1.2610],\n",
      "        [1.0689],\n",
      "        [0.8709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6051]],\n",
      "\n",
      "        [[1.7934]],\n",
      "\n",
      "        [[1.2261]],\n",
      "\n",
      "        [[0.6969]]], dtype=torch.float64)\n",
      "tensor([[0.8233],\n",
      "        [0.7411],\n",
      "        [0.8971],\n",
      "        [1.0699]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3896]],\n",
      "\n",
      "        [[0.7778]],\n",
      "\n",
      "        [[0.9592]],\n",
      "\n",
      "        [[1.5069]]], dtype=torch.float64)\n",
      "tensor([[1.1251],\n",
      "        [0.9757],\n",
      "        [0.8833],\n",
      "        [0.8331]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1776]],\n",
      "\n",
      "        [[0.6981]],\n",
      "\n",
      "        [[0.4705]],\n",
      "\n",
      "        [[0.5791]]], dtype=torch.float64)\n",
      "tensor([[0.7670],\n",
      "        [0.7763],\n",
      "        [0.7420],\n",
      "        [0.7675]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7743]],\n",
      "\n",
      "        [[1.1903]],\n",
      "\n",
      "        [[0.7709]],\n",
      "\n",
      "        [[0.7108]]], dtype=torch.float64)\n",
      "tensor([[0.9735],\n",
      "        [0.9094],\n",
      "        [1.0514],\n",
      "        [0.5952]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6184]],\n",
      "\n",
      "        [[0.7651]],\n",
      "\n",
      "        [[1.2111]],\n",
      "\n",
      "        [[0.9788]]], dtype=torch.float64)\n",
      "tensor([[0.6098],\n",
      "        [0.5447],\n",
      "        [0.9008],\n",
      "        [0.8033]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6519]],\n",
      "\n",
      "        [[0.5594]],\n",
      "\n",
      "        [[0.5456]],\n",
      "\n",
      "        [[0.7847]]], dtype=torch.float64)\n",
      "tensor([[0.7453],\n",
      "        [0.7105],\n",
      "        [0.7037],\n",
      "        [0.5966]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9060]],\n",
      "\n",
      "        [[1.1302]],\n",
      "\n",
      "        [[0.8529]],\n",
      "\n",
      "        [[0.5675]]], dtype=torch.float64)\n",
      "tensor([[0.7097],\n",
      "        [0.7343],\n",
      "        [0.5944],\n",
      "        [0.6369]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5571]],\n",
      "\n",
      "        [[0.5375]],\n",
      "\n",
      "        [[0.6796]],\n",
      "\n",
      "        [[0.9800]]], dtype=torch.float64)\n",
      "tensor([[0.7993],\n",
      "        [0.6577],\n",
      "        [0.7224],\n",
      "        [0.6436]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7200]],\n",
      "\n",
      "        [[0.4589]],\n",
      "\n",
      "        [[0.3283]],\n",
      "\n",
      "        [[0.5421]]], dtype=torch.float64)\n",
      "tensor([[0.8381],\n",
      "        [0.8195],\n",
      "        [0.6132],\n",
      "        [0.4771]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0898]],\n",
      "\n",
      "        [[0.9800]],\n",
      "\n",
      "        [[0.6322]],\n",
      "\n",
      "        [[0.5051]]], dtype=torch.float64)\n",
      "tensor([[0.7792],\n",
      "        [0.7211],\n",
      "        [0.7756],\n",
      "        [0.4598]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3734]],\n",
      "\n",
      "        [[0.5305]],\n",
      "\n",
      "        [[0.8229]],\n",
      "\n",
      "        [[0.5664]]], dtype=torch.float64)\n",
      "tensor([[0.2382],\n",
      "        [0.3843],\n",
      "        [0.5947],\n",
      "        [0.7431]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4219]],\n",
      "\n",
      "        [[0.3156]],\n",
      "\n",
      "        [[0.4612]],\n",
      "\n",
      "        [[0.6784]]], dtype=torch.float64)\n",
      "tensor([[0.9028],\n",
      "        [0.7822],\n",
      "        [0.7827],\n",
      "        [0.7775]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8772]],\n",
      "\n",
      "        [[1.0713]],\n",
      "\n",
      "        [[0.8217]],\n",
      "\n",
      "        [[0.6149]]], dtype=torch.float64)\n",
      "tensor([[0.7300],\n",
      "        [0.6954],\n",
      "        [0.6302],\n",
      "        [0.7385]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4150]],\n",
      "\n",
      "        [[0.7015]],\n",
      "\n",
      "        [[1.1290]],\n",
      "\n",
      "        [[1.4098]]], dtype=torch.float64)\n",
      "tensor([[0.7147],\n",
      "        [0.5112],\n",
      "        [0.4388],\n",
      "        [0.4396]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8610]],\n",
      "\n",
      "        [[ 0.2255]],\n",
      "\n",
      "        [[-0.0113]],\n",
      "\n",
      "        [[ 0.7062]]], dtype=torch.float64)\n",
      "tensor([[1.0100],\n",
      "        [1.1191],\n",
      "        [1.2648],\n",
      "        [0.8486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5485]],\n",
      "\n",
      "        [[1.8766]],\n",
      "\n",
      "        [[1.1660]],\n",
      "\n",
      "        [[0.5594]]], dtype=torch.float64)\n",
      "tensor([[0.7726],\n",
      "        [0.7494],\n",
      "        [1.5273],\n",
      "        [1.7494]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2983]],\n",
      "\n",
      "        [[0.9869]],\n",
      "\n",
      "        [[2.0349]],\n",
      "\n",
      "        [[2.2452]]], dtype=torch.float64)\n",
      "tensor([[1.6643],\n",
      "        [1.3347],\n",
      "        [1.2131],\n",
      "        [1.1664]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6270]],\n",
      "\n",
      "        [[0.9661]],\n",
      "\n",
      "        [[0.7316]],\n",
      "\n",
      "        [[1.4190]]], dtype=torch.float64)\n",
      "tensor([[1.9051],\n",
      "        [1.8219],\n",
      "        [1.4095],\n",
      "        [0.9036]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0857]],\n",
      "\n",
      "        [[2.3434]],\n",
      "\n",
      "        [[0.9488]],\n",
      "\n",
      "        [[0.8148]]], dtype=torch.float64)\n",
      "tensor([[1.0495],\n",
      "        [1.0281],\n",
      "        [1.3844],\n",
      "        [1.3267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6842]],\n",
      "\n",
      "        [[1.1267]],\n",
      "\n",
      "        [[1.2388]],\n",
      "\n",
      "        [[1.5461]]], dtype=torch.float64)\n",
      "tensor([[1.2463],\n",
      "        [1.0595],\n",
      "        [1.0929],\n",
      "        [0.9449]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3902]],\n",
      "\n",
      "        [[0.9234]],\n",
      "\n",
      "        [[0.7697]],\n",
      "\n",
      "        [[0.9361]]], dtype=torch.float64)\n",
      "tensor([[0.9516],\n",
      "        [0.8598],\n",
      "        [0.4858],\n",
      "        [0.4215]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3809]],\n",
      "\n",
      "        [[1.3751]],\n",
      "\n",
      "        [[0.6888]],\n",
      "\n",
      "        [[0.4254]]], dtype=torch.float64)\n",
      "tensor([[0.6267],\n",
      "        [0.5281],\n",
      "        [0.6467],\n",
      "        [0.5497]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2983]],\n",
      "\n",
      "        [[0.6807]],\n",
      "\n",
      "        [[1.0459]],\n",
      "\n",
      "        [[1.0978]]], dtype=torch.float64)\n",
      "tensor([[0.5903],\n",
      "        [0.4685],\n",
      "        [0.6100],\n",
      "        [0.6582]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7085]],\n",
      "\n",
      "        [[0.4034]],\n",
      "\n",
      "        [[0.4762]],\n",
      "\n",
      "        [[0.4924]]], dtype=torch.float64)\n",
      "tensor([[0.9601],\n",
      "        [1.2040],\n",
      "        [0.9891],\n",
      "        [1.0618]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5473]],\n",
      "\n",
      "        [[1.4595]],\n",
      "\n",
      "        [[1.2480]],\n",
      "\n",
      "        [[0.9615]]], dtype=torch.float64)\n",
      "tensor([[1.2535],\n",
      "        [1.3275],\n",
      "        [1.2103],\n",
      "        [1.0898]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9084]],\n",
      "\n",
      "        [[1.2134]],\n",
      "\n",
      "        [[1.3335]],\n",
      "\n",
      "        [[1.4352]]], dtype=torch.float64)\n",
      "tensor([[0.8088],\n",
      "        [0.4263],\n",
      "        [0.5129],\n",
      "        [0.4324]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6773]],\n",
      "\n",
      "        [[0.4219]],\n",
      "\n",
      "        [[0.2371]],\n",
      "\n",
      "        [[0.4520]]], dtype=torch.float64)\n",
      "tensor([[0.3854],\n",
      "        [0.3166],\n",
      "        [0.2240],\n",
      "        [0.1975]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7593]],\n",
      "\n",
      "        [[0.9280]],\n",
      "\n",
      "        [[0.2440]],\n",
      "\n",
      "        [[0.0672]]], dtype=torch.float64)\n",
      "tensor([[0.2574],\n",
      "        [0.2683],\n",
      "        [0.3765],\n",
      "        [0.3504]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0125]],\n",
      "\n",
      "        [[ 0.1146]],\n",
      "\n",
      "        [[ 0.5190]],\n",
      "\n",
      "        [[ 0.6530]]], dtype=torch.float64)\n",
      "tensor([[ 0.1923],\n",
      "        [ 0.3865],\n",
      "        [ 0.2011],\n",
      "        [-0.0463]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2763]],\n",
      "\n",
      "        [[ 0.0753]],\n",
      "\n",
      "        [[-0.1870]],\n",
      "\n",
      "        [[-0.1847]]], dtype=torch.float64)\n",
      "tensor([[-0.1868],\n",
      "        [-0.0269],\n",
      "        [-0.0806],\n",
      "        [ 0.1633]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2012]],\n",
      "\n",
      "        [[ 0.2105]],\n",
      "\n",
      "        [[-0.0148]],\n",
      "\n",
      "        [[ 0.0753]]], dtype=torch.float64)\n",
      "tensor([[0.3552],\n",
      "        [0.3302],\n",
      "        [0.2654],\n",
      "        [0.2445]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1238]],\n",
      "\n",
      "        [[0.1181]],\n",
      "\n",
      "        [[0.5825]],\n",
      "\n",
      "        [[0.8598]]], dtype=torch.float64)\n",
      "tensor([[0.2395],\n",
      "        [0.2184],\n",
      "        [0.3873],\n",
      "        [0.3283]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3249]],\n",
      "\n",
      "        [[0.0695]],\n",
      "\n",
      "        [[0.1446]],\n",
      "\n",
      "        [[0.1562]]], dtype=torch.float64)\n",
      "tensor([[0.2642],\n",
      "        [0.2220],\n",
      "        [0.3705],\n",
      "        [0.3255]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5317]],\n",
      "\n",
      "        [[0.4577]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.1851]]], dtype=torch.float64)\n",
      "tensor([[0.4398],\n",
      "        [0.4036],\n",
      "        [0.4554],\n",
      "        [0.2312]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1400]],\n",
      "\n",
      "        [[0.4855]],\n",
      "\n",
      "        [[0.6207]],\n",
      "\n",
      "        [[0.7397]]], dtype=torch.float64)\n",
      "tensor([[0.3248],\n",
      "        [0.3678],\n",
      "        [0.5625],\n",
      "        [0.4634]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.24092:  32%|███▏      | 984/3067 [00:03<00:06, 330.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4254]],\n",
      "\n",
      "        [[0.3341]],\n",
      "\n",
      "        [[0.1146]],\n",
      "\n",
      "        [[0.3515]]], dtype=torch.float64)\n",
      "tensor([[0.5642],\n",
      "        [0.4127],\n",
      "        [0.2060],\n",
      "        [0.2598]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6992]],\n",
      "\n",
      "        [[0.8021]],\n",
      "\n",
      "        [[0.4705]],\n",
      "\n",
      "        [[0.1839]]], dtype=torch.float64)\n",
      "tensor([[0.3374],\n",
      "        [0.2784],\n",
      "        [0.0649],\n",
      "        [0.2780]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0372]],\n",
      "\n",
      "        [[0.1250]],\n",
      "\n",
      "        [[0.3538]],\n",
      "\n",
      "        [[0.7709]]], dtype=torch.float64)\n",
      "tensor([[ 0.1447],\n",
      "        [-0.2043],\n",
      "        [-0.3726],\n",
      "        [-0.3330]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1435]],\n",
      "\n",
      "        [[-0.3118]],\n",
      "\n",
      "        [[-0.5267]],\n",
      "\n",
      "        [[-0.3314]]], dtype=torch.float64)\n",
      "tensor([[0.1622],\n",
      "        [0.3818],\n",
      "        [0.1560],\n",
      "        [0.0955]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6542]],\n",
      "\n",
      "        [[ 0.6946]],\n",
      "\n",
      "        [[ 0.3110]],\n",
      "\n",
      "        [[-0.1361]]], dtype=torch.float64)\n",
      "tensor([[-0.2470],\n",
      "        [-0.3907],\n",
      "        [ 0.2342],\n",
      "        [ 0.3896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4885]],\n",
      "\n",
      "        [[-0.4042]],\n",
      "\n",
      "        [[ 0.7501]],\n",
      "\n",
      "        [[ 0.7385]]], dtype=torch.float64)\n",
      "tensor([[ 0.1990],\n",
      "        [ 0.2622],\n",
      "        [-0.1404],\n",
      "        [-0.1112]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3769]],\n",
      "\n",
      "        [[ 0.0210]],\n",
      "\n",
      "        [[-0.3568]],\n",
      "\n",
      "        [[ 0.2567]]], dtype=torch.float64)\n",
      "tensor([[0.4804],\n",
      "        [0.5414],\n",
      "        [0.3824],\n",
      "        [0.2579]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8494]],\n",
      "\n",
      "        [[0.8541]],\n",
      "\n",
      "        [[0.5340]],\n",
      "\n",
      "        [[0.3942]]], dtype=torch.float64)\n",
      "tensor([[0.5415],\n",
      "        [0.4404],\n",
      "        [0.7528],\n",
      "        [0.5528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3087]],\n",
      "\n",
      "        [[0.5467]],\n",
      "\n",
      "        [[0.9049]],\n",
      "\n",
      "        [[0.7593]]], dtype=torch.float64)\n",
      "tensor([[0.3796],\n",
      "        [0.4695],\n",
      "        [0.6707],\n",
      "        [0.6590]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4416]],\n",
      "\n",
      "        [[0.4150]],\n",
      "\n",
      "        [[0.3965]],\n",
      "\n",
      "        [[0.6137]]], dtype=torch.float64)\n",
      "tensor([[0.7311],\n",
      "        [0.4260],\n",
      "        [0.3463],\n",
      "        [0.4466]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8159]],\n",
      "\n",
      "        [[0.7027]],\n",
      "\n",
      "        [[0.4439]],\n",
      "\n",
      "        [[0.4092]]], dtype=torch.float64)\n",
      "tensor([[0.7798],\n",
      "        [0.5893],\n",
      "        [0.6772],\n",
      "        [0.7085]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3260]],\n",
      "\n",
      "        [[0.4266]],\n",
      "\n",
      "        [[1.0227]],\n",
      "\n",
      "        [[1.1071]]], dtype=torch.float64)\n",
      "tensor([[0.5602],\n",
      "        [0.4761],\n",
      "        [0.3752],\n",
      "        [0.2016]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5144]],\n",
      "\n",
      "        [[ 0.1354]],\n",
      "\n",
      "        [[-0.0680]],\n",
      "\n",
      "        [[-0.0264]]], dtype=torch.float64)\n",
      "tensor([[0.7212],\n",
      "        [0.9836],\n",
      "        [0.7917],\n",
      "        [0.5390]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1568]],\n",
      "\n",
      "        [[1.3000]],\n",
      "\n",
      "        [[0.6935]],\n",
      "\n",
      "        [[0.2763]]], dtype=torch.float64)\n",
      "tensor([[0.4941],\n",
      "        [0.2843],\n",
      "        [0.9173],\n",
      "        [1.1205]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0183]],\n",
      "\n",
      "        [[ 0.1527]],\n",
      "\n",
      "        [[ 1.4907]],\n",
      "\n",
      "        [[ 1.2342]]], dtype=torch.float64)\n",
      "tensor([[0.8636],\n",
      "        [0.7321],\n",
      "        [0.8543],\n",
      "        [0.6888]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8529]],\n",
      "\n",
      "        [[0.6311]],\n",
      "\n",
      "        [[0.4323]],\n",
      "\n",
      "        [[0.3838]]], dtype=torch.float64)\n",
      "tensor([[0.4965],\n",
      "        [0.4034],\n",
      "        [0.3384],\n",
      "        [0.3221]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7015]],\n",
      "\n",
      "        [[0.8737]],\n",
      "\n",
      "        [[0.3965]],\n",
      "\n",
      "        [[0.0799]]], dtype=torch.float64)\n",
      "tensor([[0.3128],\n",
      "        [0.3441],\n",
      "        [0.4550],\n",
      "        [0.4626]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0968]],\n",
      "\n",
      "        [[ 0.1851]],\n",
      "\n",
      "        [[ 0.5536]],\n",
      "\n",
      "        [[ 0.7108]]], dtype=torch.float64)\n",
      "tensor([[0.5459],\n",
      "        [0.7653],\n",
      "        [0.9279],\n",
      "        [0.8369]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7686]],\n",
      "\n",
      "        [[0.7385]],\n",
      "\n",
      "        [[0.7304]],\n",
      "\n",
      "        [[0.1585]]], dtype=torch.float64)\n",
      "tensor([[0.3517],\n",
      "        [0.3956],\n",
      "        [0.2632],\n",
      "        [0.3799]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8240]],\n",
      "\n",
      "        [[0.7963]],\n",
      "\n",
      "        [[0.3734]],\n",
      "\n",
      "        [[0.2301]]], dtype=torch.float64)\n",
      "tensor([[0.3541],\n",
      "        [0.3282],\n",
      "        [0.3893],\n",
      "        [0.2778]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2151]],\n",
      "\n",
      "        [[0.4508]],\n",
      "\n",
      "        [[0.6484]],\n",
      "\n",
      "        [[0.5895]]], dtype=torch.float64)\n",
      "tensor([[0.1762],\n",
      "        [0.3141],\n",
      "        [0.4196],\n",
      "        [0.3509]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3283]],\n",
      "\n",
      "        [[0.1932]],\n",
      "\n",
      "        [[0.1077]],\n",
      "\n",
      "        [[0.2717]]], dtype=torch.float64)\n",
      "tensor([[0.1531],\n",
      "        [0.0752],\n",
      "        [0.0232],\n",
      "        [0.0972]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4358]],\n",
      "\n",
      "        [[ 0.4959]],\n",
      "\n",
      "        [[ 0.1030]],\n",
      "\n",
      "        [[-0.0726]]], dtype=torch.float64)\n",
      "tensor([[-0.0894],\n",
      "        [-0.2427],\n",
      "        [-0.0938],\n",
      "        [-0.0606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3892]],\n",
      "\n",
      "        [[ 0.0302]],\n",
      "\n",
      "        [[ 0.2810]],\n",
      "\n",
      "        [[ 0.3907]]], dtype=torch.float64)\n",
      "tensor([[-0.0542],\n",
      "        [-0.2707],\n",
      "        [-0.2562],\n",
      "        [-0.2910]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0291]],\n",
      "\n",
      "        [[-0.3603]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-0.1454]]], dtype=torch.float64)\n",
      "tensor([[ 0.0901],\n",
      "        [ 0.1083],\n",
      "        [ 0.0548],\n",
      "        [-0.1594]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5652]],\n",
      "\n",
      "        [[ 0.6045]],\n",
      "\n",
      "        [[ 0.0638]],\n",
      "\n",
      "        [[-0.2944]]], dtype=torch.float64)\n",
      "tensor([[-0.1193],\n",
      "        [-0.0511],\n",
      "        [ 0.3875],\n",
      "        [ 0.3315]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3002]],\n",
      "\n",
      "        [[-0.0321]],\n",
      "\n",
      "        [[ 0.6935]],\n",
      "\n",
      "        [[ 0.9892]]], dtype=torch.float64)\n",
      "tensor([[ 0.3340],\n",
      "        [ 0.0754],\n",
      "        [-0.1241],\n",
      "        [-0.1887]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3815]],\n",
      "\n",
      "        [[-0.1188]],\n",
      "\n",
      "        [[-0.3799]],\n",
      "\n",
      "        [[ 0.0718]]], dtype=torch.float64)\n",
      "tensor([[0.6521],\n",
      "        [0.6540],\n",
      "        [0.5224],\n",
      "        [0.2441]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1094]],\n",
      "\n",
      "        [[1.2145]],\n",
      "\n",
      "        [[0.5929]],\n",
      "\n",
      "        [[0.0233]]], dtype=torch.float64)\n",
      "tensor([[ 0.1083],\n",
      "        [-0.0551],\n",
      "        [ 0.3610],\n",
      "        [ 0.8527]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2782]],\n",
      "\n",
      "        [[-0.2494]],\n",
      "\n",
      "        [[ 1.1545]],\n",
      "\n",
      "        [[ 1.5184]]], dtype=torch.float64)\n",
      "tensor([[ 0.7453],\n",
      "        [ 0.4036],\n",
      "        [ 0.1604],\n",
      "        [-0.0191]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6380]],\n",
      "\n",
      "        [[ 0.1677]],\n",
      "\n",
      "        [[-0.1997]],\n",
      "\n",
      "        [[-0.0217]]], dtype=torch.float64)\n",
      "tensor([[0.6555],\n",
      "        [1.0319],\n",
      "        [0.7495],\n",
      "        [0.4488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3335]],\n",
      "\n",
      "        [[1.5600]],\n",
      "\n",
      "        [[0.7847]],\n",
      "\n",
      "        [[0.4277]]], dtype=torch.float64)\n",
      "tensor([[0.5662],\n",
      "        [0.6209],\n",
      "        [1.0467],\n",
      "        [0.9761]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3122]],\n",
      "\n",
      "        [[0.7212]],\n",
      "\n",
      "        [[1.4144]],\n",
      "\n",
      "        [[1.3578]]], dtype=torch.float64)\n",
      "tensor([[0.6084],\n",
      "        [0.4222],\n",
      "        [0.4885],\n",
      "        [0.4945]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6137]],\n",
      "\n",
      "        [[0.4797]],\n",
      "\n",
      "        [[0.3688]],\n",
      "\n",
      "        [[0.3734]]], dtype=torch.float64)\n",
      "tensor([[ 0.4234],\n",
      "        [ 0.1118],\n",
      "        [-0.0964],\n",
      "        [-0.1226]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1331]],\n",
      "\n",
      "        [[ 0.0314]],\n",
      "\n",
      "        [[-0.1627]],\n",
      "\n",
      "        [[-0.1858]]], dtype=torch.float64)\n",
      "tensor([[ 0.0056],\n",
      "        [-0.0255],\n",
      "        [ 0.0668],\n",
      "        [-0.0614]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2089]],\n",
      "\n",
      "        [[-0.1269]],\n",
      "\n",
      "        [[ 0.1042]],\n",
      "\n",
      "        [[ 0.3237]]], dtype=torch.float64)\n",
      "tensor([[-0.0417],\n",
      "        [-0.1113],\n",
      "        [ 0.1210],\n",
      "        [ 0.1802]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0425]],\n",
      "\n",
      "        [[-0.0368]],\n",
      "\n",
      "        [[-0.0206]],\n",
      "\n",
      "        [[-0.0957]]], dtype=torch.float64)\n",
      "tensor([[-0.0766],\n",
      "        [-0.2016],\n",
      "        [-0.1818],\n",
      "        [-0.0291]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0610]],\n",
      "\n",
      "        [[-0.1373]],\n",
      "\n",
      "        [[-0.1488]],\n",
      "\n",
      "        [[-0.1084]]], dtype=torch.float64)\n",
      "tensor([[0.2169],\n",
      "        [0.2024],\n",
      "        [0.1170],\n",
      "        [0.0785]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0772]],\n",
      "\n",
      "        [[ 0.0406]],\n",
      "\n",
      "        [[ 0.1423]],\n",
      "\n",
      "        [[ 0.1019]]], dtype=torch.float64)\n",
      "tensor([[-0.1091],\n",
      "        [-0.0548],\n",
      "        [-0.0170],\n",
      "        [-0.0714]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0564]],\n",
      "\n",
      "        [[-0.0876]],\n",
      "\n",
      "        [[-0.1708]],\n",
      "\n",
      "        [[-0.1927]]], dtype=torch.float64)\n",
      "tensor([[-0.0424],\n",
      "        [-0.1432],\n",
      "        [-0.2473],\n",
      "        [-0.2220]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0175]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[-0.1569]],\n",
      "\n",
      "        [[-0.2494]]], dtype=torch.float64)\n",
      "tensor([[-0.1348],\n",
      "        [-0.1702],\n",
      "        [ 0.0067],\n",
      "        [ 0.0588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3349]],\n",
      "\n",
      "        [[-0.2355]],\n",
      "\n",
      "        [[ 0.1446]],\n",
      "\n",
      "        [[ 0.2001]]], dtype=torch.float64)\n",
      "tensor([[-0.0089],\n",
      "        [-0.1792],\n",
      "        [-0.0643],\n",
      "        [-0.0479]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0680]],\n",
      "\n",
      "        [[-0.1927]],\n",
      "\n",
      "        [[-0.2378]],\n",
      "\n",
      "        [[-0.0495]]], dtype=torch.float64)\n",
      "tensor([[0.2968],\n",
      "        [0.2822],\n",
      "        [0.1458],\n",
      "        [0.1465]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4335]],\n",
      "\n",
      "        [[0.3722]],\n",
      "\n",
      "        [[0.1585]],\n",
      "\n",
      "        [[0.0314]]], dtype=torch.float64)\n",
      "tensor([[0.2908],\n",
      "        [0.3335],\n",
      "        [0.3939],\n",
      "        [0.3271]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0302]],\n",
      "\n",
      "        [[0.1527]],\n",
      "\n",
      "        [[0.3746]],\n",
      "\n",
      "        [[0.4150]]], dtype=torch.float64)\n",
      "tensor([[0.2517],\n",
      "        [0.3958],\n",
      "        [0.4671],\n",
      "        [0.4370]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3780]],\n",
      "\n",
      "        [[0.3145]],\n",
      "\n",
      "        [[0.1342]],\n",
      "\n",
      "        [[0.4497]]], dtype=torch.float64)\n",
      "tensor([[0.6150],\n",
      "        [0.7509],\n",
      "        [0.3741],\n",
      "        [0.1977]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0343]],\n",
      "\n",
      "        [[0.9580]],\n",
      "\n",
      "        [[0.2197]],\n",
      "\n",
      "        [[0.0383]]], dtype=torch.float64)\n",
      "tensor([[0.2318],\n",
      "        [0.1884],\n",
      "        [0.4433],\n",
      "        [0.4625]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1188]],\n",
      "\n",
      "        [[ 0.1539]],\n",
      "\n",
      "        [[ 0.6911]],\n",
      "\n",
      "        [[ 0.5571]]], dtype=torch.float64)\n",
      "tensor([[0.1817],\n",
      "        [0.1002],\n",
      "        [0.1761],\n",
      "        [0.1634]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1585]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[-0.1280]],\n",
      "\n",
      "        [[ 0.0834]]], dtype=torch.float64)\n",
      "tensor([[0.4704],\n",
      "        [0.6413],\n",
      "        [0.4786],\n",
      "        [0.4822]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8645]],\n",
      "\n",
      "        [[0.9188]],\n",
      "\n",
      "        [[0.5814]],\n",
      "\n",
      "        [[0.3988]]], dtype=torch.float64)\n",
      "tensor([[0.5772],\n",
      "        [0.4676],\n",
      "        [0.6734],\n",
      "        [0.6334]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3099]],\n",
      "\n",
      "        [[0.3260]],\n",
      "\n",
      "        [[0.9627]],\n",
      "\n",
      "        [[0.8159]]], dtype=torch.float64)\n",
      "tensor([[0.3803],\n",
      "        [0.3540],\n",
      "        [0.4197],\n",
      "        [0.2681]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4312]],\n",
      "\n",
      "        [[ 0.1874]],\n",
      "\n",
      "        [[-0.0033]],\n",
      "\n",
      "        [[ 0.0718]]], dtype=torch.float64)\n",
      "tensor([[0.3625],\n",
      "        [0.4088],\n",
      "        [0.3524],\n",
      "        [0.4909]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6449]],\n",
      "\n",
      "        [[0.6992]],\n",
      "\n",
      "        [[0.5317]],\n",
      "\n",
      "        [[0.3919]]], dtype=torch.float64)\n",
      "tensor([[0.5882],\n",
      "        [0.2091],\n",
      "        [0.4284],\n",
      "        [0.4292]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1250]],\n",
      "\n",
      "        [[0.1204]],\n",
      "\n",
      "        [[0.6172]],\n",
      "\n",
      "        [[0.8333]]], dtype=torch.float64)\n",
      "tensor([[ 0.2465],\n",
      "        [-0.0400],\n",
      "        [-0.0358],\n",
      "        [-0.3694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3480]],\n",
      "\n",
      "        [[-0.0818]],\n",
      "\n",
      "        [[-0.4620]],\n",
      "\n",
      "        [[-0.4273]]], dtype=torch.float64)\n",
      "tensor([[ 0.0778],\n",
      "        [ 0.4635],\n",
      "        [ 0.1507],\n",
      "        [-0.1935]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6507]],\n",
      "\n",
      "        [[ 0.9153]],\n",
      "\n",
      "        [[ 0.1689]],\n",
      "\n",
      "        [[-0.3002]]], dtype=torch.float64)\n",
      "tensor([[-0.4375],\n",
      "        [-0.5984],\n",
      "        [-0.4767],\n",
      "        [ 0.1030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7947]],\n",
      "\n",
      "        [[-0.8340]],\n",
      "\n",
      "        [[-0.0241]],\n",
      "\n",
      "        [[ 0.3965]]], dtype=torch.float64)\n",
      "tensor([[-0.1606],\n",
      "        [-0.3519],\n",
      "        [-0.5745],\n",
      "        [-0.7128]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1015]],\n",
      "\n",
      "        [[-0.6549]],\n",
      "\n",
      "        [[-0.9045]],\n",
      "\n",
      "        [[-1.0316]]], dtype=torch.float64)\n",
      "tensor([[-0.5347],\n",
      "        [-0.0088],\n",
      "        [-0.1820],\n",
      "        [-0.4868]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0014]],\n",
      "\n",
      "        [[ 0.3156]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[-0.5671]]], dtype=torch.float64)\n",
      "tensor([[-0.5534],\n",
      "        [-0.5142],\n",
      "        [-0.5899],\n",
      "        [-0.6462]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7242]],\n",
      "\n",
      "        [[-0.6919]],\n",
      "\n",
      "        [[-0.5359]],\n",
      "\n",
      "        [[-0.5324]]], dtype=torch.float64)\n",
      "tensor([[-0.6579],\n",
      "        [-0.5476],\n",
      "        [-0.4318],\n",
      "        [-0.5139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.5683]],\n",
      "\n",
      "        [[-0.5440]],\n",
      "\n",
      "        [[-0.5798]]], dtype=torch.float64)\n",
      "tensor([[-0.5106],\n",
      "        [-0.3132],\n",
      "        [-0.4911],\n",
      "        [-0.5873]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4181]],\n",
      "\n",
      "        [[-0.0795]],\n",
      "\n",
      "        [[-0.5405]],\n",
      "\n",
      "        [[-0.8340]]], dtype=torch.float64)\n",
      "tensor([[-0.4984],\n",
      "        [-0.4327],\n",
      "        [-0.4158],\n",
      "        [-0.1055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6561]],\n",
      "\n",
      "        [[-0.6919]],\n",
      "\n",
      "        [[-0.1523]],\n",
      "\n",
      "        [[ 0.0799]]], dtype=torch.float64)\n",
      "tensor([[-0.2819],\n",
      "        [-0.1828],\n",
      "        [-0.0563],\n",
      "        [-0.0442]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1315]],\n",
      "\n",
      "        [[-0.1858]],\n",
      "\n",
      "        [[-0.2031]],\n",
      "\n",
      "        [[-0.1604]]], dtype=torch.float64)\n",
      "tensor([[-0.1314],\n",
      "        [-0.1122],\n",
      "        [-0.0816],\n",
      "        [-0.1271]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0372]],\n",
      "\n",
      "        [[ 0.0557]],\n",
      "\n",
      "        [[-0.1304]],\n",
      "\n",
      "        [[-0.2505]]], dtype=torch.float64)\n",
      "tensor([[-0.0741],\n",
      "        [-0.0120],\n",
      "        [-0.0749],\n",
      "        [-0.2278]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2875]],\n",
      "\n",
      "        [[-0.3037]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[-0.4284]]], dtype=torch.float64)\n",
      "tensor([[-0.6360],\n",
      "        [-0.6072],\n",
      "        [-0.5133],\n",
      "        [-0.4749]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5775]],\n",
      "\n",
      "        [[-0.5544]],\n",
      "\n",
      "        [[-0.5243]],\n",
      "\n",
      "        [[-0.5555]]], dtype=torch.float64)\n",
      "tensor([[-0.5757],\n",
      "        [-0.3853],\n",
      "        [-0.5097],\n",
      "        [-0.6220]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3568]],\n",
      "\n",
      "        [[-0.1338]],\n",
      "\n",
      "        [[-0.4342]],\n",
      "\n",
      "        [[-0.7716]]], dtype=torch.float64)\n",
      "tensor([[-0.7001],\n",
      "        [-0.8023],\n",
      "        [-0.6533],\n",
      "        [-0.3884]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2349]],\n",
      "\n",
      "        [[-1.1621]],\n",
      "\n",
      "        [[-0.6468]],\n",
      "\n",
      "        [[-0.2309]]], dtype=torch.float64)\n",
      "tensor([[-0.7161],\n",
      "        [-0.7589],\n",
      "        [-0.6875],\n",
      "        [-0.4677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8975]],\n",
      "\n",
      "        [[-1.1772]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-0.4828]]], dtype=torch.float64)\n",
      "tensor([[-0.2597],\n",
      "        [-0.3205],\n",
      "        [-0.5164],\n",
      "        [-0.5479]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3603]],\n",
      "\n",
      "        [[-0.4030]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-0.7057]]], dtype=torch.float64)\n",
      "tensor([[-0.4249],\n",
      "        [-0.2967],\n",
      "        [-0.3101],\n",
      "        [-0.4524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.3857]],\n",
      "\n",
      "        [[-0.3765]],\n",
      "\n",
      "        [[-0.3418]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.22833:  34%|███▍      | 1053/3067 [00:03<00:06, 330.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6500],\n",
      "        [-0.6448],\n",
      "        [-0.5712],\n",
      "        [-0.5678]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6780]],\n",
      "\n",
      "        [[-0.7473]],\n",
      "\n",
      "        [[-0.7092]],\n",
      "\n",
      "        [[-0.6191]]], dtype=torch.float64)\n",
      "tensor([[-0.2903],\n",
      "        [-0.6243],\n",
      "        [-0.6738],\n",
      "        [-0.5484]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3326]],\n",
      "\n",
      "        [[-0.2956]],\n",
      "\n",
      "        [[-0.6064]],\n",
      "\n",
      "        [[-0.7508]]], dtype=torch.float64)\n",
      "tensor([[-0.6316],\n",
      "        [-0.6820],\n",
      "        [-0.2784],\n",
      "        [-0.3376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9103]],\n",
      "\n",
      "        [[-0.7612]],\n",
      "\n",
      "        [[-0.0864]],\n",
      "\n",
      "        [[-0.3118]]], dtype=torch.float64)\n",
      "tensor([[-0.6089],\n",
      "        [-0.6632],\n",
      "        [-0.7124],\n",
      "        [-0.8268]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5544]],\n",
      "\n",
      "        [[-0.8883]],\n",
      "\n",
      "        [[-1.1668]],\n",
      "\n",
      "        [[-1.0651]]], dtype=torch.float64)\n",
      "tensor([[-0.4491],\n",
      "        [-0.0375],\n",
      "        [-0.1981],\n",
      "        [-0.0588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1015]],\n",
      "\n",
      "        [[ 0.0256]],\n",
      "\n",
      "        [[ 0.0718]],\n",
      "\n",
      "        [[-0.0079]]], dtype=torch.float64)\n",
      "tensor([[ 0.0313],\n",
      "        [-0.1484],\n",
      "        [-0.1326],\n",
      "        [-0.4352]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1061]],\n",
      "\n",
      "        [[-0.2147]],\n",
      "\n",
      "        [[ 0.0256]],\n",
      "\n",
      "        [[-0.1396]]], dtype=torch.float64)\n",
      "tensor([[-0.5881],\n",
      "        [-0.5542],\n",
      "        [-0.6263],\n",
      "        [-0.6758]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4851]],\n",
      "\n",
      "        [[-0.6977]],\n",
      "\n",
      "        [[-0.9207]],\n",
      "\n",
      "        [[-0.6445]]], dtype=torch.float64)\n",
      "tensor([[-0.5612],\n",
      "        [-0.5639],\n",
      "        [-0.6782],\n",
      "        [-0.7725]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3476]],\n",
      "\n",
      "        [[-0.2297]],\n",
      "\n",
      "        [[-0.6491]],\n",
      "\n",
      "        [[-1.0685]]], dtype=torch.float64)\n",
      "tensor([[-0.7035],\n",
      "        [-0.5097],\n",
      "        [-0.5446],\n",
      "        [-0.5468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5879]],\n",
      "\n",
      "        [[-0.6168]],\n",
      "\n",
      "        [[-0.2424]],\n",
      "\n",
      "        [[-0.3129]]], dtype=torch.float64)\n",
      "tensor([[-0.6414],\n",
      "        [-0.7275],\n",
      "        [-0.7576],\n",
      "        [-0.6520]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6295]],\n",
      "\n",
      "        [[-0.9472]],\n",
      "\n",
      "        [[-1.0015]],\n",
      "\n",
      "        [[-0.8190]]], dtype=torch.float64)\n",
      "tensor([[-0.1709],\n",
      "        [-0.2908],\n",
      "        [-0.4471],\n",
      "        [-0.4004]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0113]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[-0.2089]],\n",
      "\n",
      "        [[-0.2378]]], dtype=torch.float64)\n",
      "tensor([[-0.3599],\n",
      "        [-0.1158],\n",
      "        [ 0.0964],\n",
      "        [-0.0164]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3094]],\n",
      "\n",
      "        [[-0.1211]],\n",
      "\n",
      "        [[ 0.5594]],\n",
      "\n",
      "        [[ 0.2717]]], dtype=torch.float64)\n",
      "tensor([[-0.3050],\n",
      "        [-0.4434],\n",
      "        [-0.5532],\n",
      "        [-0.6199]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2517]],\n",
      "\n",
      "        [[-0.5937]],\n",
      "\n",
      "        [[-0.7670]],\n",
      "\n",
      "        [[-0.6907]]], dtype=torch.float64)\n",
      "tensor([[-0.1897],\n",
      "        [ 0.2414],\n",
      "        [-0.0117],\n",
      "        [-0.1840]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3572]],\n",
      "\n",
      "        [[ 0.5987]],\n",
      "\n",
      "        [[-0.0252]],\n",
      "\n",
      "        [[-0.1627]]], dtype=torch.float64)\n",
      "tensor([[-0.2545],\n",
      "        [-0.2691],\n",
      "        [ 0.1061],\n",
      "        [ 0.1700]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4654]],\n",
      "\n",
      "        [[-0.1523]],\n",
      "\n",
      "        [[ 0.3237]],\n",
      "\n",
      "        [[ 0.5063]]], dtype=torch.float64)\n",
      "tensor([[-0.0248],\n",
      "        [-0.0393],\n",
      "        [-0.2365],\n",
      "        [-0.4139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0095]],\n",
      "\n",
      "        [[-0.1003]],\n",
      "\n",
      "        [[-0.3765]],\n",
      "\n",
      "        [[-0.5463]]], dtype=torch.float64)\n",
      "tensor([[-0.2088],\n",
      "        [ 0.2191],\n",
      "        [-0.0007],\n",
      "        [-0.2072]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2671]],\n",
      "\n",
      "        [[ 0.4832]],\n",
      "\n",
      "        [[-0.0645]],\n",
      "\n",
      "        [[-0.2759]]], dtype=torch.float64)\n",
      "tensor([[-0.2189],\n",
      "        [-0.3788],\n",
      "        [-0.2527],\n",
      "        [-0.0169]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4643]],\n",
      "\n",
      "        [[-0.5278]],\n",
      "\n",
      "        [[ 0.0672]],\n",
      "\n",
      "        [[ 0.1654]]], dtype=torch.float64)\n",
      "tensor([[-0.2184],\n",
      "        [-0.3996],\n",
      "        [-0.2384],\n",
      "        [-0.2486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1904]],\n",
      "\n",
      "        [[-0.3672]],\n",
      "\n",
      "        [[-0.3926]],\n",
      "\n",
      "        [[-0.3626]]], dtype=torch.float64)\n",
      "tensor([[-0.3449],\n",
      "        [-0.1275],\n",
      "        [-0.3281],\n",
      "        [-0.4042]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2401]],\n",
      "\n",
      "        [[-0.0148]],\n",
      "\n",
      "        [[-0.3464]],\n",
      "\n",
      "        [[-0.2378]]], dtype=torch.float64)\n",
      "tensor([[-0.0151],\n",
      "        [ 0.1527],\n",
      "        [ 0.0422],\n",
      "        [ 0.0376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1003]],\n",
      "\n",
      "        [[ 0.0649]],\n",
      "\n",
      "        [[ 0.3018]],\n",
      "\n",
      "        [[ 0.3307]]], dtype=torch.float64)\n",
      "tensor([[0.1457],\n",
      "        [0.3076],\n",
      "        [0.3513],\n",
      "        [0.4296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3468]],\n",
      "\n",
      "        [[0.2891]],\n",
      "\n",
      "        [[0.3954]],\n",
      "\n",
      "        [[0.5744]]], dtype=torch.float64)\n",
      "tensor([[0.3533],\n",
      "        [0.3212],\n",
      "        [0.3401],\n",
      "        [0.5110]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8009]],\n",
      "\n",
      "        [[0.7951]],\n",
      "\n",
      "        [[0.6958]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[0.4527],\n",
      "        [0.2942],\n",
      "        [0.1807],\n",
      "        [0.0952]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5097]],\n",
      "\n",
      "        [[0.4393]],\n",
      "\n",
      "        [[0.5225]],\n",
      "\n",
      "        [[0.4728]]], dtype=torch.float64)\n",
      "tensor([[0.1520],\n",
      "        [0.3757],\n",
      "        [0.5062],\n",
      "        [0.3189]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3538]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.3665]],\n",
      "\n",
      "        [[0.3884]]], dtype=torch.float64)\n",
      "tensor([[-0.0426],\n",
      "        [-0.1807],\n",
      "        [-0.2808],\n",
      "        [-0.2239]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0129]],\n",
      "\n",
      "        [[-0.1766]],\n",
      "\n",
      "        [[-0.2182]],\n",
      "\n",
      "        [[-0.3949]]], dtype=torch.float64)\n",
      "tensor([[-0.2721],\n",
      "        [-0.3562],\n",
      "        [-0.4823],\n",
      "        [-0.6576]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4469]],\n",
      "\n",
      "        [[-0.5012]],\n",
      "\n",
      "        [[-0.5498]],\n",
      "\n",
      "        [[-0.6699]]], dtype=torch.float64)\n",
      "tensor([[-0.7295],\n",
      "        [-0.6578],\n",
      "        [-0.6311],\n",
      "        [-0.6841]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7855]],\n",
      "\n",
      "        [[-0.8502]],\n",
      "\n",
      "        [[-0.9299]],\n",
      "\n",
      "        [[-0.8791]]], dtype=torch.float64)\n",
      "tensor([[-0.6652],\n",
      "        [-0.6435],\n",
      "        [-0.6141],\n",
      "        [-0.5982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7161]],\n",
      "\n",
      "        [[-0.7092]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.8525]]], dtype=torch.float64)\n",
      "tensor([[-0.6023],\n",
      "        [-0.6214],\n",
      "        [-0.5461],\n",
      "        [-0.2874]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8594]],\n",
      "\n",
      "        [[-0.8560]],\n",
      "\n",
      "        [[-0.3014]],\n",
      "\n",
      "        [[-0.2078]]], dtype=torch.float64)\n",
      "tensor([[-0.4277],\n",
      "        [-0.5922],\n",
      "        [-0.6558],\n",
      "        [-0.5430]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6029]],\n",
      "\n",
      "        [[-1.0570]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-0.7589]]], dtype=torch.float64)\n",
      "tensor([[-0.3572],\n",
      "        [-0.0971],\n",
      "        [-0.2849],\n",
      "        [-0.2317]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0356]],\n",
      "\n",
      "        [[-0.1003]],\n",
      "\n",
      "        [[-0.2863]],\n",
      "\n",
      "        [[-0.5498]]], dtype=torch.float64)\n",
      "tensor([[-0.5753],\n",
      "        [-0.5322],\n",
      "        [-0.3394],\n",
      "        [-0.5977]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7520]],\n",
      "\n",
      "        [[-0.6977]],\n",
      "\n",
      "        [[-0.3522]],\n",
      "\n",
      "        [[-0.4435]]], dtype=torch.float64)\n",
      "tensor([[-0.3946],\n",
      "        [-0.2470],\n",
      "        [ 0.0128],\n",
      "        [-0.0509]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3776]],\n",
      "\n",
      "        [[-0.2459]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[-0.0229]]], dtype=torch.float64)\n",
      "tensor([[-0.0495],\n",
      "        [-0.0564],\n",
      "        [-0.0335],\n",
      "        [ 0.2069]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0614]],\n",
      "\n",
      "        [[0.0418]],\n",
      "\n",
      "        [[0.0799]],\n",
      "\n",
      "        [[0.2763]]], dtype=torch.float64)\n",
      "tensor([[0.4590],\n",
      "        [0.4442],\n",
      "        [0.4015],\n",
      "        [0.2638]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4323]],\n",
      "\n",
      "        [[0.5571]],\n",
      "\n",
      "        [[0.7073]],\n",
      "\n",
      "        [[0.5837]]], dtype=torch.float64)\n",
      "tensor([[0.2380],\n",
      "        [0.4155],\n",
      "        [0.5365],\n",
      "        [0.3236]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5225]],\n",
      "\n",
      "        [[0.5536]],\n",
      "\n",
      "        [[0.2775]],\n",
      "\n",
      "        [[0.3260]]], dtype=torch.float64)\n",
      "tensor([[0.4127],\n",
      "        [0.4578],\n",
      "        [0.2498],\n",
      "        [0.2609]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8621]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.4566]],\n",
      "\n",
      "        [[0.2255]]], dtype=torch.float64)\n",
      "tensor([[ 0.4135],\n",
      "        [ 0.2046],\n",
      "        [-0.0095],\n",
      "        [-0.3504]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3156]],\n",
      "\n",
      "        [[ 0.1285]],\n",
      "\n",
      "        [[-0.0021]],\n",
      "\n",
      "        [[-0.2632]]], dtype=torch.float64)\n",
      "tensor([[-0.4939],\n",
      "        [-0.6157],\n",
      "        [-0.5442],\n",
      "        [-0.6161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3869]],\n",
      "\n",
      "        [[-0.5856]],\n",
      "\n",
      "        [[-0.6122]],\n",
      "\n",
      "        [[-0.6156]]], dtype=torch.float64)\n",
      "tensor([[-0.7491],\n",
      "        [-0.8767],\n",
      "        [-0.8985],\n",
      "        [-0.7832]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6618]],\n",
      "\n",
      "        [[-0.7393]],\n",
      "\n",
      "        [[-0.7855]],\n",
      "\n",
      "        [[-0.8155]]], dtype=torch.float64)\n",
      "tensor([[-0.7215],\n",
      "        [-0.6797],\n",
      "        [-0.7481],\n",
      "        [-0.8103]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8236]],\n",
      "\n",
      "        [[-0.8328]],\n",
      "\n",
      "        [[-0.8028]],\n",
      "\n",
      "        [[-0.7936]]], dtype=torch.float64)\n",
      "tensor([[-0.7911],\n",
      "        [-0.6461],\n",
      "        [-0.5592],\n",
      "        [-0.5585]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7959]],\n",
      "\n",
      "        [[-0.7681]],\n",
      "\n",
      "        [[-0.7265]],\n",
      "\n",
      "        [[-0.7023]]], dtype=torch.float64)\n",
      "tensor([[-0.6079],\n",
      "        [-0.6020],\n",
      "        [-0.5995],\n",
      "        [-0.5073]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6480]],\n",
      "\n",
      "        [[-0.6064]],\n",
      "\n",
      "        [[-0.6399]],\n",
      "\n",
      "        [[-0.6734]]], dtype=torch.float64)\n",
      "tensor([[-0.4578],\n",
      "        [-0.4858],\n",
      "        [-0.4618],\n",
      "        [-0.4436]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7254]],\n",
      "\n",
      "        [[-0.6769]],\n",
      "\n",
      "        [[-0.4134]],\n",
      "\n",
      "        [[-0.3996]]], dtype=torch.float64)\n",
      "tensor([[-0.5075],\n",
      "        [-0.4724],\n",
      "        [-0.3919],\n",
      "        [-0.5109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4677]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.6353]],\n",
      "\n",
      "        [[-0.8941]]], dtype=torch.float64)\n",
      "tensor([[-0.5843],\n",
      "        [-0.3436],\n",
      "        [-0.6552],\n",
      "        [-0.8550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4331]],\n",
      "\n",
      "        [[-0.4157]],\n",
      "\n",
      "        [[-0.8999]],\n",
      "\n",
      "        [[-1.1956]]], dtype=torch.float64)\n",
      "tensor([[-0.8604],\n",
      "        [-0.9428],\n",
      "        [-1.0119],\n",
      "        [-0.9333]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2349]],\n",
      "\n",
      "        [[-1.2823]],\n",
      "\n",
      "        [[-1.1598]],\n",
      "\n",
      "        [[-0.7543]]], dtype=torch.float64)\n",
      "tensor([[-0.8406],\n",
      "        [-0.7346],\n",
      "        [-0.7979],\n",
      "        [-0.6993]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.8236]],\n",
      "\n",
      "        [[-0.8444]]], dtype=torch.float64)\n",
      "tensor([[-0.7930],\n",
      "        [-1.0051],\n",
      "        [-0.9017],\n",
      "        [-0.8572]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0397]],\n",
      "\n",
      "        [[-1.0593]],\n",
      "\n",
      "        [[-1.0558]],\n",
      "\n",
      "        [[-1.0397]]], dtype=torch.float64)\n",
      "tensor([[-0.7979],\n",
      "        [-0.8380],\n",
      "        [-0.9538],\n",
      "        [-0.9055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9911]],\n",
      "\n",
      "        [[-0.9426]],\n",
      "\n",
      "        [[-0.8594]],\n",
      "\n",
      "        [[-0.8305]]], dtype=torch.float64)\n",
      "tensor([[-0.8651],\n",
      "        [-0.7348],\n",
      "        [-0.8079],\n",
      "        [-0.8925]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7739]],\n",
      "\n",
      "        [[-0.9103]],\n",
      "\n",
      "        [[-1.0397]],\n",
      "\n",
      "        [[-0.9992]]], dtype=torch.float64)\n",
      "tensor([[-0.9047],\n",
      "        [-0.9495],\n",
      "        [-1.0094],\n",
      "        [-0.9409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8802]],\n",
      "\n",
      "        [[-1.0119]],\n",
      "\n",
      "        [[-1.1182]],\n",
      "\n",
      "        [[-1.1529]]], dtype=torch.float64)\n",
      "tensor([[-0.9402],\n",
      "        [-1.0196],\n",
      "        [-0.9727],\n",
      "        [-0.9546]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3886]],\n",
      "\n",
      "        [[-1.2580]],\n",
      "\n",
      "        [[-0.8375]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-1.0250],\n",
      "        [-1.0521],\n",
      "        [-0.9168],\n",
      "        [-0.9703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1402]],\n",
      "\n",
      "        [[-1.1598]],\n",
      "\n",
      "        [[-1.1772]],\n",
      "\n",
      "        [[-1.1644]]], dtype=torch.float64)\n",
      "tensor([[-1.0614],\n",
      "        [-1.2046],\n",
      "        [-1.2691],\n",
      "        [-1.2716]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2315]],\n",
      "\n",
      "        [[-1.2962]],\n",
      "\n",
      "        [[-1.3112]],\n",
      "\n",
      "        [[-1.5827]]], dtype=torch.float64)\n",
      "tensor([[-1.3121],\n",
      "        [-1.3860],\n",
      "        [-1.3967],\n",
      "        [-1.4485]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8554]],\n",
      "\n",
      "        [[-1.7306]],\n",
      "\n",
      "        [[-1.5018]],\n",
      "\n",
      "        [[-1.5908]]], dtype=torch.float64)\n",
      "tensor([[-1.6297],\n",
      "        [-1.5249],\n",
      "        [-1.4700],\n",
      "        [-1.5671]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8935]],\n",
      "\n",
      "        [[-1.7699]],\n",
      "\n",
      "        [[-1.9108]],\n",
      "\n",
      "        [[-1.8138]]], dtype=torch.float64)\n",
      "tensor([[-1.5647],\n",
      "        [-1.5148],\n",
      "        [-1.5972],\n",
      "        [-1.4894]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4637]],\n",
      "\n",
      "        [[-1.5076]],\n",
      "\n",
      "        [[-1.5700]],\n",
      "\n",
      "        [[-1.6231]]], dtype=torch.float64)\n",
      "tensor([[-1.4762],\n",
      "        [-1.5009],\n",
      "        [-1.5663],\n",
      "        [-1.6093]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4764]],\n",
      "\n",
      "        [[-1.4949]],\n",
      "\n",
      "        [[-1.3944]],\n",
      "\n",
      "        [[-1.4914]]], dtype=torch.float64)\n",
      "tensor([[-1.6231],\n",
      "        [-1.5874],\n",
      "        [-1.4417],\n",
      "        [-1.5039]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5411]],\n",
      "\n",
      "        [[-1.5504]],\n",
      "\n",
      "        [[-1.5411]],\n",
      "\n",
      "        [[-1.5492]]], dtype=torch.float64)\n",
      "tensor([[-1.6402],\n",
      "        [-1.8345],\n",
      "        [-1.9221],\n",
      "        [-2.0677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5954]],\n",
      "\n",
      "        [[-1.7225]],\n",
      "\n",
      "        [[-1.9143]],\n",
      "\n",
      "        [[-2.1153]]], dtype=torch.float64)\n",
      "tensor([[-2.2000],\n",
      "        [-2.2596],\n",
      "        [-2.3569],\n",
      "        [-2.3858]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3649]],\n",
      "\n",
      "        [[-2.4261]],\n",
      "\n",
      "        [[-2.2424]],\n",
      "\n",
      "        [[-2.3060]]], dtype=torch.float64)\n",
      "tensor([[-2.4012],\n",
      "        [-2.3620],\n",
      "        [-2.0268],\n",
      "        [-2.2547]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3869]],\n",
      "\n",
      "        [[-2.4054]],\n",
      "\n",
      "        [[-2.4181]],\n",
      "\n",
      "        [[-2.6283]]], dtype=torch.float64)\n",
      "tensor([[-2.2817],\n",
      "        [-2.3171],\n",
      "        [-2.2861],\n",
      "        [-2.1595]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2390]],\n",
      "\n",
      "        [[-2.3175]],\n",
      "\n",
      "        [[-2.2817]],\n",
      "\n",
      "        [[-2.2783]]], dtype=torch.float64)\n",
      "tensor([[-2.1872],\n",
      "        [-2.3822],\n",
      "        [-2.4817],\n",
      "        [-2.1435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6318]],\n",
      "\n",
      "        [[-2.8571]],\n",
      "\n",
      "        [[-2.1777]],\n",
      "\n",
      "        [[-2.1789]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.21354:  37%|███▋      | 1121/3067 [00:03<00:05, 330.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4440],\n",
      "        [-2.4274],\n",
      "        [-2.4653],\n",
      "        [-2.5418]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4088]],\n",
      "\n",
      "        [[-2.6549]],\n",
      "\n",
      "        [[-2.6723]],\n",
      "\n",
      "        [[-2.6769]]], dtype=torch.float64)\n",
      "tensor([[-2.3711],\n",
      "        [-1.8910],\n",
      "        [-2.0208],\n",
      "        [-1.7742]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8588]],\n",
      "\n",
      "        [[-1.8045]],\n",
      "\n",
      "        [[-1.8508]],\n",
      "\n",
      "        [[-1.6070]]], dtype=torch.float64)\n",
      "tensor([[-1.4594],\n",
      "        [-1.4289],\n",
      "        [-1.5872],\n",
      "        [-1.6421]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4614]],\n",
      "\n",
      "        [[-1.4337]],\n",
      "\n",
      "        [[-1.3331]],\n",
      "\n",
      "        [[-1.2083]]], dtype=torch.float64)\n",
      "tensor([[-1.4941],\n",
      "        [-1.3533],\n",
      "        [-1.3122],\n",
      "        [-1.3868]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0789]],\n",
      "\n",
      "        [[-1.1656]],\n",
      "\n",
      "        [[-1.1506]],\n",
      "\n",
      "        [[-1.2777]]], dtype=torch.float64)\n",
      "tensor([[-1.6599],\n",
      "        [-1.7016],\n",
      "        [-1.6697],\n",
      "        [-1.6226]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1841]],\n",
      "\n",
      "        [[-1.1760]],\n",
      "\n",
      "        [[-1.2638]],\n",
      "\n",
      "        [[-1.4105]]], dtype=torch.float64)\n",
      "tensor([[-1.6722],\n",
      "        [-1.7655],\n",
      "        [-1.8219],\n",
      "        [-1.8733]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5099]],\n",
      "\n",
      "        [[-1.5261]],\n",
      "\n",
      "        [[-1.4683]],\n",
      "\n",
      "        [[-1.4891]]], dtype=torch.float64)\n",
      "tensor([[-1.9458],\n",
      "        [-1.7866],\n",
      "        [-1.6979],\n",
      "        [-1.6608]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5769]],\n",
      "\n",
      "        [[-1.5792]],\n",
      "\n",
      "        [[-1.5400]],\n",
      "\n",
      "        [[-1.4649]]], dtype=torch.float64)\n",
      "tensor([[-1.6256],\n",
      "        [-1.6741],\n",
      "        [-1.6801],\n",
      "        [-1.6702]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3643]],\n",
      "\n",
      "        [[-1.3181]],\n",
      "\n",
      "        [[-1.4510]],\n",
      "\n",
      "        [[-1.5261]]], dtype=torch.float64)\n",
      "tensor([[-1.5663],\n",
      "        [-1.4758],\n",
      "        [-1.3819],\n",
      "        [-1.5182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5064]],\n",
      "\n",
      "        [[-1.2985]],\n",
      "\n",
      "        [[-1.1032]],\n",
      "\n",
      "        [[-1.1587]]], dtype=torch.float64)\n",
      "tensor([[-1.5088],\n",
      "        [-1.3816],\n",
      "        [-1.2563],\n",
      "        [-1.4213]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2199]],\n",
      "\n",
      "        [[-1.2349]],\n",
      "\n",
      "        [[-1.2673]],\n",
      "\n",
      "        [[-1.4949]]], dtype=torch.float64)\n",
      "tensor([[-1.4748],\n",
      "        [-1.3947],\n",
      "        [-1.3935],\n",
      "        [-1.1424]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2338]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.2049]],\n",
      "\n",
      "        [[-1.0535]]], dtype=torch.float64)\n",
      "tensor([[-0.7459],\n",
      "        [-0.8671],\n",
      "        [-0.8295],\n",
      "        [-0.9172]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9726]],\n",
      "\n",
      "        [[-0.8005]],\n",
      "\n",
      "        [[-0.5902]],\n",
      "\n",
      "        [[-0.6422]]], dtype=torch.float64)\n",
      "tensor([[-0.8529],\n",
      "        [-0.7543],\n",
      "        [-0.8307],\n",
      "        [-0.9917]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6330]],\n",
      "\n",
      "        [[-0.7832]],\n",
      "\n",
      "        [[-1.0154]],\n",
      "\n",
      "        [[-0.8964]]], dtype=torch.float64)\n",
      "tensor([[-1.0372],\n",
      "        [-1.1236],\n",
      "        [-1.3691],\n",
      "        [-1.5667]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9091]],\n",
      "\n",
      "        [[-1.1228]],\n",
      "\n",
      "        [[-1.3505]],\n",
      "\n",
      "        [[-1.6151]]], dtype=torch.float64)\n",
      "tensor([[-1.3954],\n",
      "        [-1.5906],\n",
      "        [-1.6387],\n",
      "        [-1.6409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8554]],\n",
      "\n",
      "        [[-1.9906]],\n",
      "\n",
      "        [[-1.6566]],\n",
      "\n",
      "        [[-1.7410]]], dtype=torch.float64)\n",
      "tensor([[-1.4690],\n",
      "        [-1.4051],\n",
      "        [-1.4652],\n",
      "        [-1.4721]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7098]],\n",
      "\n",
      "        [[-1.7341]],\n",
      "\n",
      "        [[-1.8716]],\n",
      "\n",
      "        [[-1.8103]]], dtype=torch.float64)\n",
      "tensor([[-1.5066],\n",
      "        [-1.4374],\n",
      "        [-1.5247],\n",
      "        [-1.4756]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4914]],\n",
      "\n",
      "        [[-1.5007]],\n",
      "\n",
      "        [[-1.6717]],\n",
      "\n",
      "        [[-1.8057]]], dtype=torch.float64)\n",
      "tensor([[-1.4825],\n",
      "        [-1.5163],\n",
      "        [-1.5946],\n",
      "        [-1.5973]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8600]],\n",
      "\n",
      "        [[-1.8773]],\n",
      "\n",
      "        [[-1.7606]],\n",
      "\n",
      "        [[-1.7433]]], dtype=torch.float64)\n",
      "tensor([[-1.5932],\n",
      "        [-1.5074],\n",
      "        [-1.4409],\n",
      "        [-1.4767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7641]],\n",
      "\n",
      "        [[-1.7745]],\n",
      "\n",
      "        [[-1.7699]],\n",
      "\n",
      "        [[-2.0818]]], dtype=torch.float64)\n",
      "tensor([[-1.5713],\n",
      "        [-1.5999],\n",
      "        [-1.4237],\n",
      "        [-1.3427]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7410]],\n",
      "\n",
      "        [[-1.6959]],\n",
      "\n",
      "        [[-1.5665]],\n",
      "\n",
      "        [[-1.6139]]], dtype=torch.float64)\n",
      "tensor([[-1.3372],\n",
      "        [-1.4221],\n",
      "        [-1.4624],\n",
      "        [-1.5235]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5665]],\n",
      "\n",
      "        [[-1.6185]],\n",
      "\n",
      "        [[-1.4787]],\n",
      "\n",
      "        [[-1.6705]]], dtype=torch.float64)\n",
      "tensor([[-1.6541],\n",
      "        [-1.5837],\n",
      "        [-1.7266],\n",
      "        [-1.9821]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6982]],\n",
      "\n",
      "        [[-1.9986]],\n",
      "\n",
      "        [[-2.4562]],\n",
      "\n",
      "        [[-2.4781]]], dtype=torch.float64)\n",
      "tensor([[-2.0022],\n",
      "        [-1.6700],\n",
      "        [-1.9092],\n",
      "        [-1.8459]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0010]],\n",
      "\n",
      "        [[-1.8034]],\n",
      "\n",
      "        [[-1.9628]],\n",
      "\n",
      "        [[-2.1361]]], dtype=torch.float64)\n",
      "tensor([[-1.9258],\n",
      "        [-1.7401],\n",
      "        [-1.4748],\n",
      "        [-1.4621]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1593]],\n",
      "\n",
      "        [[-1.8045]],\n",
      "\n",
      "        [[-1.2627]],\n",
      "\n",
      "        [[-1.2684]]], dtype=torch.float64)\n",
      "tensor([[-1.4048],\n",
      "        [-1.1303],\n",
      "        [-0.6489],\n",
      "        [-1.3667]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3181]],\n",
      "\n",
      "        [[-0.9865]],\n",
      "\n",
      "        [[-0.7104]],\n",
      "\n",
      "        [[-1.2569]]], dtype=torch.float64)\n",
      "tensor([[-1.4715],\n",
      "        [-1.7325],\n",
      "        [-1.7093],\n",
      "        [-1.6580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2511]],\n",
      "\n",
      "        [[-1.4960]],\n",
      "\n",
      "        [[-1.5330]],\n",
      "\n",
      "        [[-1.8554]]], dtype=torch.float64)\n",
      "tensor([[-1.8192],\n",
      "        [-1.7577],\n",
      "        [-1.6913],\n",
      "        [-1.5138]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8450]],\n",
      "\n",
      "        [[-1.7040]],\n",
      "\n",
      "        [[-1.3320]],\n",
      "\n",
      "        [[-1.2800]]], dtype=torch.float64)\n",
      "tensor([[-1.5745],\n",
      "        [-1.4691],\n",
      "        [-1.2846],\n",
      "        [-1.3825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3262]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.2153]],\n",
      "\n",
      "        [[-1.2141]]], dtype=torch.float64)\n",
      "tensor([[-1.3731],\n",
      "        [-1.3175],\n",
      "        [-1.2176],\n",
      "        [-1.2272]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0940]],\n",
      "\n",
      "        [[-1.0477]],\n",
      "\n",
      "        [[-1.0836]],\n",
      "\n",
      "        [[-1.0928]]], dtype=torch.float64)\n",
      "tensor([[-1.1826],\n",
      "        [-1.2476],\n",
      "        [-1.3793],\n",
      "        [-1.4368]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0524]],\n",
      "\n",
      "        [[-1.1471]],\n",
      "\n",
      "        [[-0.9842]],\n",
      "\n",
      "        [[-1.2026]]], dtype=torch.float64)\n",
      "tensor([[-1.4162],\n",
      "        [-1.3686],\n",
      "        [-1.3771],\n",
      "        [-1.4306]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2280]],\n",
      "\n",
      "        [[-1.2534]],\n",
      "\n",
      "        [[-1.2869]],\n",
      "\n",
      "        [[-1.3100]]], dtype=torch.float64)\n",
      "tensor([[-1.4977],\n",
      "        [-1.5876],\n",
      "        [-1.7112],\n",
      "        [-1.6361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3019]],\n",
      "\n",
      "        [[-1.4452]],\n",
      "\n",
      "        [[-1.5492]],\n",
      "\n",
      "        [[-1.6047]]], dtype=torch.float64)\n",
      "tensor([[-1.7411],\n",
      "        [-1.6852],\n",
      "        [-1.9339],\n",
      "        [-1.9122]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7676]],\n",
      "\n",
      "        [[-1.7514]],\n",
      "\n",
      "        [[-1.7872]],\n",
      "\n",
      "        [[-1.9455]]], dtype=torch.float64)\n",
      "tensor([[-2.2243],\n",
      "        [-2.2586],\n",
      "        [-2.2897],\n",
      "        [-2.3909]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2216]],\n",
      "\n",
      "        [[-2.3880]],\n",
      "\n",
      "        [[-2.6827]],\n",
      "\n",
      "        [[-2.6283]]], dtype=torch.float64)\n",
      "tensor([[-2.2785],\n",
      "        [-1.9983],\n",
      "        [-1.8913],\n",
      "        [-1.8407]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0934]],\n",
      "\n",
      "        [[-1.7999]],\n",
      "\n",
      "        [[-1.8508]],\n",
      "\n",
      "        [[-1.8843]]], dtype=torch.float64)\n",
      "tensor([[-1.8358],\n",
      "        [-1.6982],\n",
      "        [-1.6272],\n",
      "        [-1.5344]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9189]],\n",
      "\n",
      "        [[-1.7052]],\n",
      "\n",
      "        [[-1.4556]],\n",
      "\n",
      "        [[-1.3366]]], dtype=torch.float64)\n",
      "tensor([[-1.4832],\n",
      "        [-1.3555],\n",
      "        [-1.3603],\n",
      "        [-1.3787]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4071]],\n",
      "\n",
      "        [[-1.4025]],\n",
      "\n",
      "        [[-1.3713]],\n",
      "\n",
      "        [[-1.5249]]], dtype=torch.float64)\n",
      "tensor([[-1.6893],\n",
      "        [-1.8761],\n",
      "        [-2.0885],\n",
      "        [-2.1157]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5654]],\n",
      "\n",
      "        [[-1.9559]],\n",
      "\n",
      "        [[-2.2413]],\n",
      "\n",
      "        [[-2.2621]]], dtype=torch.float64)\n",
      "tensor([[-2.2011],\n",
      "        [-2.4413],\n",
      "        [-2.4815],\n",
      "        [-2.3024]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.5717]],\n",
      "\n",
      "        [[-2.7785]],\n",
      "\n",
      "        [[-2.4805]],\n",
      "\n",
      "        [[-2.3938]]], dtype=torch.float64)\n",
      "tensor([[-2.5705],\n",
      "        [-2.3958],\n",
      "        [-2.2168],\n",
      "        [-2.1729]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6884]],\n",
      "\n",
      "        [[-2.5948]],\n",
      "\n",
      "        [[-2.5024]],\n",
      "\n",
      "        [[-2.3707]]], dtype=torch.float64)\n",
      "tensor([[-2.1840],\n",
      "        [-2.0803],\n",
      "        [-1.9305],\n",
      "        [-2.1882]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1627]],\n",
      "\n",
      "        [[-1.9490]],\n",
      "\n",
      "        [[-2.1246]],\n",
      "\n",
      "        [[-2.2817]]], dtype=torch.float64)\n",
      "tensor([[-2.0169],\n",
      "        [-1.7887],\n",
      "        [-1.6141],\n",
      "        [-1.4148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0021]],\n",
      "\n",
      "        [[-1.7433]],\n",
      "\n",
      "        [[-1.3146]],\n",
      "\n",
      "        [[-1.1009]]], dtype=torch.float64)\n",
      "tensor([[-1.3835],\n",
      "        [-1.3909],\n",
      "        [-1.4470],\n",
      "        [-1.2570]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2153]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.3516]],\n",
      "\n",
      "        [[-1.1090]]], dtype=torch.float64)\n",
      "tensor([[-1.1958],\n",
      "        [-1.0973],\n",
      "        [-1.2250],\n",
      "        [-1.1974]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8305]],\n",
      "\n",
      "        [[-0.9160]],\n",
      "\n",
      "        [[-1.0062]],\n",
      "\n",
      "        [[-1.0316]]], dtype=torch.float64)\n",
      "tensor([[-1.1998],\n",
      "        [-1.2555],\n",
      "        [-1.3344],\n",
      "        [-1.4015]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1610]],\n",
      "\n",
      "        [[-1.0893]],\n",
      "\n",
      "        [[-1.0108]],\n",
      "\n",
      "        [[-1.1783]]], dtype=torch.float64)\n",
      "tensor([[-1.4109],\n",
      "        [-1.3444],\n",
      "        [-1.2131],\n",
      "        [-1.2671]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1413]],\n",
      "\n",
      "        [[-1.1321]],\n",
      "\n",
      "        [[-1.1702]],\n",
      "\n",
      "        [[-1.2026]]], dtype=torch.float64)\n",
      "tensor([[-1.3213],\n",
      "        [-1.3967],\n",
      "        [-1.5570],\n",
      "        [-1.5869]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9946]],\n",
      "\n",
      "        [[-1.2638]],\n",
      "\n",
      "        [[-1.5076]],\n",
      "\n",
      "        [[-1.5711]]], dtype=torch.float64)\n",
      "tensor([[-1.5529],\n",
      "        [-1.7734],\n",
      "        [-1.7626],\n",
      "        [-1.5137]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7710]],\n",
      "\n",
      "        [[-2.0564]],\n",
      "\n",
      "        [[-1.5099]],\n",
      "\n",
      "        [[-1.4926]]], dtype=torch.float64)\n",
      "tensor([[-1.7164],\n",
      "        [-1.9124],\n",
      "        [-1.8950],\n",
      "        [-1.8131]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8993]],\n",
      "\n",
      "        [[-2.1662]],\n",
      "\n",
      "        [[-1.9894]],\n",
      "\n",
      "        [[-2.1500]]], dtype=torch.float64)\n",
      "tensor([[-1.9177],\n",
      "        [-1.6630],\n",
      "        [-1.8260],\n",
      "        [-1.7077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7699]],\n",
      "\n",
      "        [[-1.7190]],\n",
      "\n",
      "        [[-1.8866]],\n",
      "\n",
      "        [[-1.5885]]], dtype=torch.float64)\n",
      "tensor([[-1.3386],\n",
      "        [-1.1347],\n",
      "        [-0.9900],\n",
      "        [-0.8084]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2257]],\n",
      "\n",
      "        [[-0.9842]],\n",
      "\n",
      "        [[-0.7104]],\n",
      "\n",
      "        [[-0.6168]]], dtype=torch.float64)\n",
      "tensor([[-0.7288],\n",
      "        [-0.3877],\n",
      "        [-0.0366],\n",
      "        [-0.2324]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5509]],\n",
      "\n",
      "        [[-0.2031]],\n",
      "\n",
      "        [[-0.2043]],\n",
      "\n",
      "        [[-0.4978]]], dtype=torch.float64)\n",
      "tensor([[-0.6429],\n",
      "        [-0.5397],\n",
      "        [-0.4985],\n",
      "        [-0.2585]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6468]],\n",
      "\n",
      "        [[-0.4400]],\n",
      "\n",
      "        [[-0.5347]],\n",
      "\n",
      "        [[-0.3198]]], dtype=torch.float64)\n",
      "tensor([[-0.3096],\n",
      "        [-0.1957],\n",
      "        [-0.1677],\n",
      "        [ 0.0460]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4481]],\n",
      "\n",
      "        [[-0.2413]],\n",
      "\n",
      "        [[ 0.0487]],\n",
      "\n",
      "        [[-0.0402]]], dtype=torch.float64)\n",
      "tensor([[-0.2568],\n",
      "        [-0.0623],\n",
      "        [-0.1316],\n",
      "        [-0.0813]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0060]],\n",
      "\n",
      "        [[-0.3499]],\n",
      "\n",
      "        [[-0.2655]],\n",
      "\n",
      "        [[-0.3326]]], dtype=torch.float64)\n",
      "tensor([[-0.0678],\n",
      "        [-0.6631],\n",
      "        [-0.7393],\n",
      "        [-0.8504]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0425]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.8513]]], dtype=torch.float64)\n",
      "tensor([[-0.9822],\n",
      "        [-1.2440],\n",
      "        [-1.3086],\n",
      "        [-1.3001]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2858]],\n",
      "\n",
      "        [[-1.4568]],\n",
      "\n",
      "        [[-1.3401]],\n",
      "\n",
      "        [[-1.3181]]], dtype=torch.float64)\n",
      "tensor([[-1.4293],\n",
      "        [-1.4428],\n",
      "        [-1.3706],\n",
      "        [-1.2331]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4822]],\n",
      "\n",
      "        [[-1.5573]],\n",
      "\n",
      "        [[-1.4637]],\n",
      "\n",
      "        [[-1.3516]]], dtype=torch.float64)\n",
      "tensor([[-1.1385],\n",
      "        [-0.7807],\n",
      "        [-0.8944],\n",
      "        [-0.8041]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0246]],\n",
      "\n",
      "        [[-0.7531]],\n",
      "\n",
      "        [[-0.8721]],\n",
      "\n",
      "        [[-0.6861]]], dtype=torch.float64)\n",
      "tensor([[-0.5128],\n",
      "        [-0.6237],\n",
      "        [-0.7522],\n",
      "        [-0.8173]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5752]],\n",
      "\n",
      "        [[-0.6098]],\n",
      "\n",
      "        [[-0.5879]],\n",
      "\n",
      "        [[-0.6295]]], dtype=torch.float64)\n",
      "tensor([[-0.8766],\n",
      "        [-0.5564],\n",
      "        [-0.3568],\n",
      "        [-0.3159]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7057]],\n",
      "\n",
      "        [[-0.6133]],\n",
      "\n",
      "        [[-0.4770]],\n",
      "\n",
      "        [[-0.5105]]], dtype=torch.float64)\n",
      "tensor([[-0.4555],\n",
      "        [-0.3784],\n",
      "        [-0.1525],\n",
      "        [ 0.0795]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4573]],\n",
      "\n",
      "        [[-0.3141]],\n",
      "\n",
      "        [[-0.1223]],\n",
      "\n",
      "        [[-0.0934]]], dtype=torch.float64)\n",
      "tensor([[0.1699],\n",
      "        [0.1968],\n",
      "        [0.1361],\n",
      "        [0.1426]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0044]],\n",
      "\n",
      "        [[ 0.1342]],\n",
      "\n",
      "        [[ 0.3029]],\n",
      "\n",
      "        [[ 0.1469]]], dtype=torch.float64)\n",
      "tensor([[ 0.0854],\n",
      "        [-0.0143],\n",
      "        [ 0.1018],\n",
      "        [-0.2360]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0441]],\n",
      "\n",
      "        [[-0.0160]],\n",
      "\n",
      "        [[-0.2343]],\n",
      "\n",
      "        [[-0.3118]]], dtype=torch.float64)\n",
      "tensor([[-0.3190],\n",
      "        [-0.2812],\n",
      "        [-0.3037],\n",
      "        [-0.0829]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0472]],\n",
      "\n",
      "        [[-0.1384]],\n",
      "\n",
      "        [[-0.1500]],\n",
      "\n",
      "        [[-0.2447]]], dtype=torch.float64)\n",
      "tensor([[-0.2636],\n",
      "        [-0.3260],\n",
      "        [-0.3884],\n",
      "        [-0.1410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2667]],\n",
      "\n",
      "        [[-0.4920]],\n",
      "\n",
      "        [[-0.1292]],\n",
      "\n",
      "        [[-0.1904]]], dtype=torch.float64)\n",
      "tensor([[-0.6437],\n",
      "        [-0.8670],\n",
      "        [-1.0388],\n",
      "        [-1.0872]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-1.0177]],\n",
      "\n",
      "        [[-1.2026]],\n",
      "\n",
      "        [[-1.2615]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #1 - Loss = 0.21354:  38%|███▊      | 1155/3067 [00:03<00:05, 324.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1639],\n",
      "        [-0.3659],\n",
      "        [-0.6458],\n",
      "        [-0.7924]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8375]],\n",
      "\n",
      "        [[-0.1500]],\n",
      "\n",
      "        [[-0.7462]],\n",
      "\n",
      "        [[-0.7092]]], dtype=torch.float64)\n",
      "tensor([[-0.4460],\n",
      "        [-0.3279],\n",
      "        [-0.3330],\n",
      "        [-0.1840]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3441]],\n",
      "\n",
      "        [[-0.4550]],\n",
      "\n",
      "        [[-0.1858]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[-0.4308],\n",
      "        [-0.5598],\n",
      "        [-0.7668],\n",
      "        [-0.8074]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5059]],\n",
      "\n",
      "        [[-0.5960]],\n",
      "\n",
      "        [[-0.9172]],\n",
      "\n",
      "        [[-0.9426]]], dtype=torch.float64)\n",
      "tensor([[-0.9174],\n",
      "        [-0.9906],\n",
      "        [-1.0271],\n",
      "        [-0.9856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8051]],\n",
      "\n",
      "        [[-0.8248]],\n",
      "\n",
      "        [[-1.0316]],\n",
      "\n",
      "        [[-1.0246]]], dtype=torch.float64)\n",
      "tensor([[-0.9146],\n",
      "        [-0.9647],\n",
      "        [-1.0522],\n",
      "        [-1.2571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0628]],\n",
      "\n",
      "        [[-1.0789]],\n",
      "\n",
      "        [[-1.0963]],\n",
      "\n",
      "        [[-1.2060]]], dtype=torch.float64)\n",
      "tensor([[-1.2907],\n",
      "        [-1.2325],\n",
      "        [-1.2163],\n",
      "        [-1.2849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2407]],\n",
      "\n",
      "        [[-1.2650]],\n",
      "\n",
      "        [[-1.3019]],\n",
      "\n",
      "        [[-1.3435]]], dtype=torch.float64)\n",
      "tensor([[-1.3314],\n",
      "        [-1.3823],\n",
      "        [-1.3489],\n",
      "        [-1.2686]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2569]],\n",
      "\n",
      "        [[-1.2823]],\n",
      "\n",
      "        [[-1.3412]],\n",
      "\n",
      "        [[-1.3274]]], dtype=torch.float64)\n",
      "tensor([[-1.2077],\n",
      "        [-1.2505],\n",
      "        [-1.2361],\n",
      "        [-1.2261]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3401]],\n",
      "\n",
      "        [[-1.3874]],\n",
      "\n",
      "        [[-1.1876]],\n",
      "\n",
      "        [[-1.1032]]], dtype=torch.float64)\n",
      "tensor([[-1.3493],\n",
      "        [-1.4299],\n",
      "        [-1.3433],\n",
      "        [-1.2361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4637]],\n",
      "\n",
      "        [[-1.6162]],\n",
      "\n",
      "        [[-1.5215]],\n",
      "\n",
      "        [[-1.3967]]], dtype=torch.float64)\n",
      "tensor([[-1.0751],\n",
      "        [-1.0742],\n",
      "        [-1.0267],\n",
      "        [-0.9248]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9010]],\n",
      "\n",
      "        [[-0.9726]],\n",
      "\n",
      "        [[-1.0027]],\n",
      "\n",
      "        [[-1.0246]]], dtype=torch.float64)\n",
      "tensor([[-0.8989],\n",
      "        [-0.8876],\n",
      "        [-1.0014],\n",
      "        [-0.9061]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0166]],\n",
      "\n",
      "        [[-1.0270]],\n",
      "\n",
      "        [[-0.9507]],\n",
      "\n",
      "        [[-0.9900]]], dtype=torch.float64)\n",
      "tensor([[-0.9624],\n",
      "        [-0.8641],\n",
      "        [-0.8476],\n",
      "        [-0.7696]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9888]],\n",
      "\n",
      "        [[-0.9553]],\n",
      "\n",
      "        [[-0.9518]],\n",
      "\n",
      "        [[-0.9056]]], dtype=torch.float64)\n",
      "tensor([[-0.8539],\n",
      "        [-1.0568],\n",
      "        [-1.0416],\n",
      "        [-0.9778]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8560]],\n",
      "\n",
      "        [[-0.9438]],\n",
      "\n",
      "        [[-1.0200]],\n",
      "\n",
      "        [[-0.9553]]], dtype=torch.float64)\n",
      "tensor([[-0.8972],\n",
      "        [-0.8695],\n",
      "        [-1.0591],\n",
      "        [-1.1150]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0258]],\n",
      "\n",
      "        [[-1.0778]],\n",
      "\n",
      "        [[-0.9542]],\n",
      "\n",
      "        [[-1.0246]]], dtype=torch.float64)\n",
      "tensor([[-1.0428],\n",
      "        [-1.1149],\n",
      "        [-1.2083],\n",
      "        [-1.2884]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1171]],\n",
      "\n",
      "        [[-1.2176]],\n",
      "\n",
      "        [[-1.3643]],\n",
      "\n",
      "        [[-1.4233]]], dtype=torch.float64)\n",
      "tensor([[-1.4013],\n",
      "        [-1.3890],\n",
      "        [-1.4036],\n",
      "        [-1.3711]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3955]],\n",
      "\n",
      "        [[-1.4152]],\n",
      "\n",
      "        [[-1.3817]],\n",
      "\n",
      "        [[-1.4868]]], dtype=torch.float64)\n",
      "tensor([[-1.4762],\n",
      "        [-1.4229],\n",
      "        [-1.3765],\n",
      "        [-1.3115]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5284]],\n",
      "\n",
      "        [[-1.4406]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.1899]]], dtype=torch.float64)\n",
      "tensor([[-1.3599],\n",
      "        [-1.4952],\n",
      "        [-1.6038],\n",
      "        [-1.7710]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4313]],\n",
      "\n",
      "        [[-1.7329]],\n",
      "\n",
      "        [[-1.9952]],\n",
      "\n",
      "        [[-2.1812]]], dtype=torch.float64)\n",
      "tensor([[-1.6975],\n",
      "        [-1.3356],\n",
      "        [-1.5106],\n",
      "        [-1.6457]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4868]],\n",
      "\n",
      "        [[-1.2557]],\n",
      "\n",
      "        [[-1.6670]],\n",
      "\n",
      "        [[-1.9131]]], dtype=torch.float64)\n",
      "tensor([[-1.6788],\n",
      "        [-1.6377],\n",
      "        [-1.6743],\n",
      "        [-1.6201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8508]],\n",
      "\n",
      "        [[-1.8103]],\n",
      "\n",
      "        [[-1.7110]],\n",
      "\n",
      "        [[-1.6601]]], dtype=torch.float64)\n",
      "tensor([[-1.6952],\n",
      "        [-1.6866],\n",
      "        [-1.6118],\n",
      "        [-1.6971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7294]],\n",
      "\n",
      "        [[-1.7953]],\n",
      "\n",
      "        [[-1.8981]],\n",
      "\n",
      "        [[-1.9490]]], dtype=torch.float64)\n",
      "tensor([[-1.7715],\n",
      "        [-1.6199],\n",
      "        [-1.7970],\n",
      "        [-1.7313]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6266]],\n",
      "\n",
      "        [[-1.5746]],\n",
      "\n",
      "        [[-1.7965]],\n",
      "\n",
      "        [[-1.8450]]], dtype=torch.float64)\n",
      "tensor([[-1.7350],\n",
      "        [-1.7854],\n",
      "        [-1.8817],\n",
      "        [-1.4183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0056]],\n",
      "\n",
      "        [[-2.0218]],\n",
      "\n",
      "        [[-1.5134]],\n",
      "\n",
      "        [[-1.1171]]], dtype=torch.float64)\n",
      "tensor([[-1.5476],\n",
      "        [-1.8442],\n",
      "        [-1.7696],\n",
      "        [-1.6301]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6613]],\n",
      "\n",
      "        [[-2.0044]],\n",
      "\n",
      "        [[-1.8069]],\n",
      "\n",
      "        [[-1.5954]]], dtype=torch.float64)\n",
      "tensor([[-1.4386],\n",
      "        [-1.1227],\n",
      "        [-1.3789],\n",
      "        [-1.4377]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0940]],\n",
      "\n",
      "        [[-0.9137]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.3505]]], dtype=torch.float64)\n",
      "tensor([[-1.3516],\n",
      "        [-1.1632],\n",
      "        [-1.1821],\n",
      "        [-1.2155]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3539]],\n",
      "\n",
      "        [[-1.1564]],\n",
      "\n",
      "        [[-1.0304]],\n",
      "\n",
      "        [[-0.8271]]], dtype=torch.float64)\n",
      "tensor([[-1.0496],\n",
      "        [-1.1042],\n",
      "        [-0.9300],\n",
      "        [-0.7733]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9253]],\n",
      "\n",
      "        [[-1.0616]],\n",
      "\n",
      "        [[-0.9911]],\n",
      "\n",
      "        [[-0.8594]]], dtype=torch.float64)\n",
      "tensor([[-0.6253],\n",
      "        [-0.5630],\n",
      "        [-0.4897],\n",
      "        [-0.2815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5648]],\n",
      "\n",
      "        [[-0.5139]],\n",
      "\n",
      "        [[-0.2806]],\n",
      "\n",
      "        [[-0.1927]]], dtype=torch.float64)\n",
      "tensor([[-0.0251],\n",
      "        [-0.0410],\n",
      "        [ 0.1207],\n",
      "        [-0.0553]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1673]],\n",
      "\n",
      "        [[-0.2320]],\n",
      "\n",
      "        [[-0.0113]],\n",
      "\n",
      "        [[-0.0148]]], dtype=torch.float64)\n",
      "tensor([[-0.0774],\n",
      "        [-0.0079],\n",
      "        [ 0.2214],\n",
      "        [ 0.2144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0680]],\n",
      "\n",
      "        [[-0.0460]],\n",
      "\n",
      "        [[ 0.0002]],\n",
      "\n",
      "        [[-0.0391]]], dtype=torch.float64)\n",
      "tensor([[-0.0782],\n",
      "        [-0.0689],\n",
      "        [-0.3828],\n",
      "        [-0.6670]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0406]],\n",
      "\n",
      "        [[ 0.2128]],\n",
      "\n",
      "        [[-0.4377]],\n",
      "\n",
      "        [[-0.7670]]], dtype=torch.float64)\n",
      "tensor([[-0.8683],\n",
      "        [-0.9945],\n",
      "        [-0.9001],\n",
      "        [-0.0277]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8964]],\n",
      "\n",
      "        [[-1.1552]],\n",
      "\n",
      "        [[-0.2540]],\n",
      "\n",
      "        [[ 0.0996]]], dtype=torch.float64)\n",
      "tensor([[-0.5158],\n",
      "        [-0.3495],\n",
      "        [-0.3119],\n",
      "        [-0.1847]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2956]],\n",
      "\n",
      "        [[-0.2182]],\n",
      "\n",
      "        [[-0.2921]],\n",
      "\n",
      "        [[-0.3314]]], dtype=torch.float64)\n",
      "tensor([[-0.5610],\n",
      "        [-0.5517],\n",
      "        [-0.8191],\n",
      "        [-1.2022]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1696]],\n",
      "\n",
      "        [[-0.1569]],\n",
      "\n",
      "        [[-0.8629]],\n",
      "\n",
      "        [[-1.3285]]], dtype=torch.float64)\n",
      "tensor([[-1.3199],\n",
      "        [-1.4306],\n",
      "        [-1.1888],\n",
      "        [-0.6030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4718]],\n",
      "\n",
      "        [[-1.5654]],\n",
      "\n",
      "        [[-0.6815]],\n",
      "\n",
      "        [[-0.3707]]], dtype=torch.float64)\n",
      "tensor([[-0.9503],\n",
      "        [-1.2650],\n",
      "        [-1.3903],\n",
      "        [-1.4106]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9611]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.5515]],\n",
      "\n",
      "        [[-1.4683]]], dtype=torch.float64)\n",
      "tensor([[-1.1818],\n",
      "        [-0.2348],\n",
      "        [-0.6773],\n",
      "        [-0.7180]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5047]],\n",
      "\n",
      "        [[-0.0934]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-0.6826]]], dtype=torch.float64)\n",
      "tensor([[-0.0764],\n",
      "        [-0.1259],\n",
      "        [-0.0703],\n",
      "        [-0.1037]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3210]],\n",
      "\n",
      "        [[-0.2551]],\n",
      "\n",
      "        [[ 0.1273]],\n",
      "\n",
      "        [[ 0.1365]]], dtype=torch.float64)\n",
      "tensor([[-0.1537],\n",
      "        [-0.5282],\n",
      "        [-1.0191],\n",
      "        [-1.1578]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2702]],\n",
      "\n",
      "        [[-0.6942]],\n",
      "\n",
      "        [[-1.1286]],\n",
      "\n",
      "        [[-1.2661]]], dtype=torch.float64)\n",
      "tensor([[-1.2303],\n",
      "        [-1.2004],\n",
      "        [-1.0962],\n",
      "        [-1.0441]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1679]],\n",
      "\n",
      "        [[-1.0027]],\n",
      "\n",
      "        [[-1.2083]],\n",
      "\n",
      "        [[-1.1159]]], dtype=torch.float64)\n",
      "tensor([[-0.8868],\n",
      "        [-0.8392],\n",
      "        [-0.8427],\n",
      "        [-0.7011]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0558]],\n",
      "\n",
      "        [[-0.9634]],\n",
      "\n",
      "        [[-0.8028]],\n",
      "\n",
      "        [[-0.6665]]], dtype=torch.float64)\n",
      "tensor([[-0.6886],\n",
      "        [-0.7189],\n",
      "        [-0.7790],\n",
      "        [-0.7835]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7624]],\n",
      "\n",
      "        [[-0.8814]],\n",
      "\n",
      "        [[-1.0015]],\n",
      "\n",
      "        [[-0.9888]]], dtype=torch.float64)\n",
      "tensor([[-0.7904],\n",
      "        [-0.6151],\n",
      "        [-0.7981],\n",
      "        [-0.8639]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6711]],\n",
      "\n",
      "        [[-0.6584]],\n",
      "\n",
      "        [[-0.8409]],\n",
      "\n",
      "        [[-0.8560]]], dtype=torch.float64)\n",
      "tensor([[-0.7233],\n",
      "        [-0.7758],\n",
      "        [-0.7858],\n",
      "        [-0.8080]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9368]],\n",
      "\n",
      "        [[-1.0085]],\n",
      "\n",
      "        [[-0.8120]],\n",
      "\n",
      "        [[-0.8721]]], dtype=torch.float64)\n",
      "tensor([[-0.9497],\n",
      "        [-0.9411],\n",
      "        [-0.7976],\n",
      "        [-0.8492]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9703]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-0.9796]],\n",
      "\n",
      "        [[-1.0189]]], dtype=torch.float64)\n",
      "tensor([[-0.7308],\n",
      "        [-0.2092],\n",
      "        [-0.6992],\n",
      "        [-1.0357]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3915]],\n",
      "\n",
      "        [[-0.2621]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[-1.2511]]], dtype=torch.float64)\n",
      "tensor([[-1.1145],\n",
      "        [-1.1110],\n",
      "        [-1.1599],\n",
      "        [-1.2024]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3285]],\n",
      "\n",
      "        [[-1.2696]],\n",
      "\n",
      "        [[-1.2211]],\n",
      "\n",
      "        [[-1.2869]]], dtype=torch.float64)\n",
      "tensor([[-1.2344],\n",
      "        [-1.1784],\n",
      "        [-1.1569],\n",
      "        [-1.1963]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3042]],\n",
      "\n",
      "        [[-1.3412]],\n",
      "\n",
      "        [[-1.4117]],\n",
      "\n",
      "        [[-1.4198]]], dtype=torch.float64)\n",
      "tensor([[-1.2720],\n",
      "        [-1.3458],\n",
      "        [-1.3386],\n",
      "        [-1.2950]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3435]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.4105]],\n",
      "\n",
      "        [[-1.4429]]], dtype=torch.float64)\n",
      "tensor([[-1.2222],\n",
      "        [-1.2901],\n",
      "        [-1.3295],\n",
      "        [-1.3821]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4406]],\n",
      "\n",
      "        [[-1.4602]],\n",
      "\n",
      "        [[-1.4221]],\n",
      "\n",
      "        [[-1.3770]]], dtype=torch.float64)\n",
      "tensor([[-1.3893],\n",
      "        [-1.3911],\n",
      "        [-1.4179],\n",
      "        [-1.5531]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3967]],\n",
      "\n",
      "        [[-1.4960]],\n",
      "\n",
      "        [[-1.6497]],\n",
      "\n",
      "        [[-1.7502]]], dtype=torch.float64)\n",
      "tensor([[-1.7263],\n",
      "        [-1.8173],\n",
      "        [-1.8274],\n",
      "        [-1.7334]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7549]],\n",
      "\n",
      "        [[-1.7988]],\n",
      "\n",
      "        [[-1.9051]],\n",
      "\n",
      "        [[-2.0807]]], dtype=torch.float64)\n",
      "tensor([[-1.9564],\n",
      "        [-2.0188],\n",
      "        [-1.9988],\n",
      "        [-1.9068]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2655]],\n",
      "\n",
      "        [[-2.2309]],\n",
      "\n",
      "        [[-1.9397]],\n",
      "\n",
      "        [[-1.8415]]], dtype=torch.float64)\n",
      "tensor([[-1.9351],\n",
      "        [-2.0101],\n",
      "        [-2.0705],\n",
      "        [-2.1227]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0229]],\n",
      "\n",
      "        [[-2.2436]],\n",
      "\n",
      "        [[-2.4158]],\n",
      "\n",
      "        [[-2.3776]]], dtype=torch.float64)\n",
      "tensor([[-2.2260],\n",
      "        [-2.0097],\n",
      "        [-2.0093],\n",
      "        [-2.0709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1974]],\n",
      "\n",
      "        [[-1.7826]],\n",
      "\n",
      "        [[-2.0495]],\n",
      "\n",
      "        [[-2.4019]]], dtype=torch.float64)\n",
      "tensor([[-2.2457],\n",
      "        [-2.3888],\n",
      "        [-2.1479],\n",
      "        [-1.7406]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6341]],\n",
      "\n",
      "        [[-2.6803]],\n",
      "\n",
      "        [[-1.8057]],\n",
      "\n",
      "        [[-1.3574]]], dtype=torch.float64)\n",
      "tensor([[-1.8561],\n",
      "        [-2.0151],\n",
      "        [-2.1073],\n",
      "        [-2.0056]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8854]],\n",
      "\n",
      "        [[-2.1824]],\n",
      "\n",
      "        [[-2.3418]],\n",
      "\n",
      "        [[-1.8669]]], dtype=torch.float64)\n",
      "tensor([[-1.5741],\n",
      "        [-1.1701],\n",
      "        [-1.3200],\n",
      "        [-1.3796]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8918]],\n",
      "\n",
      "        [[-0.4620]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-1.1009]]], dtype=torch.float64)\n",
      "tensor([[-1.4035],\n",
      "        [-1.6361],\n",
      "        [-1.3578],\n",
      "        [-1.0996]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4649]],\n",
      "\n",
      "        [[-1.4360]],\n",
      "\n",
      "        [[-0.5740]],\n",
      "\n",
      "        [[-0.5359]]], dtype=torch.float64)\n",
      "tensor([[-1.3514],\n",
      "        [-1.4826],\n",
      "        [-1.5259],\n",
      "        [-1.6619]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1228]],\n",
      "\n",
      "        [[-1.4348]],\n",
      "\n",
      "        [[-1.5376]],\n",
      "\n",
      "        [[-1.5665]]], dtype=torch.float64)\n",
      "tensor([[-1.3344],\n",
      "        [-0.7193],\n",
      "        [-1.1133],\n",
      "        [-1.1926]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6064]],\n",
      "\n",
      "        [[-0.2505]],\n",
      "\n",
      "        [[-0.8779]],\n",
      "\n",
      "        [[-1.1598]]], dtype=torch.float64)\n",
      "tensor([[-1.2170],\n",
      "        [-1.1844],\n",
      "        [-1.0029],\n",
      "        [-0.5685]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2892]],\n",
      "\n",
      "        [[-1.2187]],\n",
      "\n",
      "        [[-0.8120]],\n",
      "\n",
      "        [[-0.4296]]], dtype=torch.float64)\n",
      "tensor([[-0.6724],\n",
      "        [-0.9394],\n",
      "        [-1.0491],\n",
      "        [-1.3174]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7046]],\n",
      "\n",
      "        [[-1.0616]],\n",
      "\n",
      "        [[-1.3574]],\n",
      "\n",
      "        [[-1.4718]]], dtype=torch.float64)\n",
      "tensor([[-1.0677],\n",
      "        [-0.5773],\n",
      "        [-0.7060],\n",
      "        [-0.9109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5128]],\n",
      "\n",
      "        [[-0.2413]],\n",
      "\n",
      "        [[-0.6618]],\n",
      "\n",
      "        [[-1.0454]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.20435:  40%|███▉      | 1221/3067 [00:03<00:05, 323.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0746],\n",
      "        [-1.1936],\n",
      "        [-1.2619],\n",
      "        [-1.1464]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2881]],\n",
      "\n",
      "        [[-1.3274]],\n",
      "\n",
      "        [[-1.0905]],\n",
      "\n",
      "        [[-0.7127]]], dtype=torch.float64)\n",
      "tensor([[-1.0756],\n",
      "        [-1.1738],\n",
      "        [-1.3710],\n",
      "        [-1.4903]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9079]],\n",
      "\n",
      "        [[-1.1887]],\n",
      "\n",
      "        [[-1.5157]],\n",
      "\n",
      "        [[-1.5792]]], dtype=torch.float64)\n",
      "tensor([[-1.3884],\n",
      "        [-0.9818],\n",
      "        [-1.1529],\n",
      "        [-1.1683]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8698]],\n",
      "\n",
      "        [[-0.4758]],\n",
      "\n",
      "        [[-0.9045]],\n",
      "\n",
      "        [[-1.2661]]], dtype=torch.float64)\n",
      "tensor([[-1.3043],\n",
      "        [-1.3950],\n",
      "        [-1.3721],\n",
      "        [-1.1567]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4568]],\n",
      "\n",
      "        [[-1.5561]],\n",
      "\n",
      "        [[-1.0720]],\n",
      "\n",
      "        [[-0.7312]]], dtype=torch.float64)\n",
      "tensor([[-1.0651],\n",
      "        [-1.1832],\n",
      "        [-1.2187],\n",
      "        [-1.3807]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9646]],\n",
      "\n",
      "        [[-1.3077]],\n",
      "\n",
      "        [[-1.5711]],\n",
      "\n",
      "        [[-1.4926]]], dtype=torch.float64)\n",
      "tensor([[-1.0110],\n",
      "        [-0.5238],\n",
      "        [-0.7999],\n",
      "        [-1.1059]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6746]],\n",
      "\n",
      "        [[-0.3845]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.4129]]], dtype=torch.float64)\n",
      "tensor([[-1.1387],\n",
      "        [-1.2391],\n",
      "        [-0.9289],\n",
      "        [-0.5818]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5457]],\n",
      "\n",
      "        [[-1.6624]],\n",
      "\n",
      "        [[-0.5001]],\n",
      "\n",
      "        [[-0.2702]]], dtype=torch.float64)\n",
      "tensor([[-0.6864],\n",
      "        [-1.0234],\n",
      "        [-0.9041],\n",
      "        [-0.9950]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1125]],\n",
      "\n",
      "        [[-1.2996]],\n",
      "\n",
      "        [[-1.2153]],\n",
      "\n",
      "        [[-1.2130]]], dtype=torch.float64)\n",
      "tensor([[-0.9856],\n",
      "        [-0.9945],\n",
      "        [-1.1086],\n",
      "        [-1.1407]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7843]],\n",
      "\n",
      "        [[-0.6757]],\n",
      "\n",
      "        [[-1.0212]],\n",
      "\n",
      "        [[-1.4903]]], dtype=torch.float64)\n",
      "tensor([[-1.2386],\n",
      "        [-1.4157],\n",
      "        [-1.0032],\n",
      "        [-0.7089]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7167]],\n",
      "\n",
      "        [[-1.5434]],\n",
      "\n",
      "        [[-0.7612]],\n",
      "\n",
      "        [[-0.4562]]], dtype=torch.float64)\n",
      "tensor([[-0.9512],\n",
      "        [-1.0578],\n",
      "        [-1.0817],\n",
      "        [-1.1317]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0293]],\n",
      "\n",
      "        [[-1.2777]],\n",
      "\n",
      "        [[-1.4498]],\n",
      "\n",
      "        [[-1.2927]]], dtype=torch.float64)\n",
      "tensor([[-0.7602],\n",
      "        [-0.3025],\n",
      "        [-0.5093],\n",
      "        [-0.7252]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2817]],\n",
      "\n",
      "        [[ 0.0406]],\n",
      "\n",
      "        [[-0.5648]],\n",
      "\n",
      "        [[-1.0142]]], dtype=torch.float64)\n",
      "tensor([[-0.8989],\n",
      "        [-0.9312],\n",
      "        [ 0.1111],\n",
      "        [ 0.2018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1829]],\n",
      "\n",
      "        [[-1.0616]],\n",
      "\n",
      "        [[ 0.3041]],\n",
      "\n",
      "        [[ 0.3607]]], dtype=torch.float64)\n",
      "tensor([[ 0.0291],\n",
      "        [-0.1252],\n",
      "        [-0.3339],\n",
      "        [-0.4206]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0425]],\n",
      "\n",
      "        [[-0.3152]],\n",
      "\n",
      "        [[-0.6965]],\n",
      "\n",
      "        [[-0.6457]]], dtype=torch.float64)\n",
      "tensor([[-0.0517],\n",
      "        [-0.0626],\n",
      "        [-0.2135],\n",
      "        [-0.0254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1396]],\n",
      "\n",
      "        [[ 0.0164]],\n",
      "\n",
      "        [[-0.1015]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[ 0.1367],\n",
      "        [ 0.1147],\n",
      "        [ 0.0246],\n",
      "        [-0.1417]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2378]],\n",
      "\n",
      "        [[-0.1927]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[ 0.0210]]], dtype=torch.float64)\n",
      "tensor([[-0.1726],\n",
      "        [-0.3660],\n",
      "        [-0.5744],\n",
      "        [-0.7346]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3464]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-1.0362]],\n",
      "\n",
      "        [[-1.0154]]], dtype=torch.float64)\n",
      "tensor([[-0.2508],\n",
      "        [ 0.1988],\n",
      "        [ 0.0068],\n",
      "        [-0.4251]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2140]],\n",
      "\n",
      "        [[ 0.5640]],\n",
      "\n",
      "        [[-0.1673]],\n",
      "\n",
      "        [[-0.8063]]], dtype=torch.float64)\n",
      "tensor([[-0.5457],\n",
      "        [-0.6734],\n",
      "        [ 0.1071],\n",
      "        [ 0.3119]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7554]],\n",
      "\n",
      "        [[-0.5267]],\n",
      "\n",
      "        [[ 0.4312]],\n",
      "\n",
      "        [[ 0.6715]]], dtype=torch.float64)\n",
      "tensor([[ 0.2371],\n",
      "        [ 0.1467],\n",
      "        [ 0.1030],\n",
      "        [-0.0020]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3191]],\n",
      "\n",
      "        [[ 0.0095]],\n",
      "\n",
      "        [[-0.1604]],\n",
      "\n",
      "        [[-0.3522]]], dtype=torch.float64)\n",
      "tensor([[0.1624],\n",
      "        [0.2684],\n",
      "        [0.2298],\n",
      "        [0.3583]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3064]],\n",
      "\n",
      "        [[ 0.3133]],\n",
      "\n",
      "        [[ 0.1215]],\n",
      "\n",
      "        [[-0.1015]]], dtype=torch.float64)\n",
      "tensor([[0.2922],\n",
      "        [0.1434],\n",
      "        [0.1907],\n",
      "        [0.2315]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2482]],\n",
      "\n",
      "        [[-0.2263]],\n",
      "\n",
      "        [[ 0.4127]],\n",
      "\n",
      "        [[ 0.3272]]], dtype=torch.float64)\n",
      "tensor([[-0.0667],\n",
      "        [-0.1920],\n",
      "        [-0.1521],\n",
      "        [-0.3770]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1997]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.5174]],\n",
      "\n",
      "        [[-0.6653]]], dtype=torch.float64)\n",
      "tensor([[-0.4999],\n",
      "        [-0.5400],\n",
      "        [-0.5438],\n",
      "        [-0.2584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6849]],\n",
      "\n",
      "        [[-0.5324]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.2008]]], dtype=torch.float64)\n",
      "tensor([[-0.0062],\n",
      "        [-0.1024],\n",
      "        [-0.2774],\n",
      "        [-0.5138]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3233]],\n",
      "\n",
      "        [[-0.4261]],\n",
      "\n",
      "        [[-0.5278]],\n",
      "\n",
      "        [[-0.6561]]], dtype=torch.float64)\n",
      "tensor([[-0.5979],\n",
      "        [-0.5524],\n",
      "        [-0.4697],\n",
      "        [-0.3409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7300]],\n",
      "\n",
      "        [[-0.7520]],\n",
      "\n",
      "        [[-0.6722]],\n",
      "\n",
      "        [[-0.5740]]], dtype=torch.float64)\n",
      "tensor([[-0.4522],\n",
      "        [-0.5878],\n",
      "        [-0.5926],\n",
      "        [-0.5122]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5659]],\n",
      "\n",
      "        [[-0.5983]],\n",
      "\n",
      "        [[-0.7300]],\n",
      "\n",
      "        [[-0.7196]]], dtype=torch.float64)\n",
      "tensor([[-0.4570],\n",
      "        [-0.6128],\n",
      "        [-0.7623],\n",
      "        [-0.5871]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8294]],\n",
      "\n",
      "        [[-0.8929]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[-0.2863]]], dtype=torch.float64)\n",
      "tensor([[-0.6236],\n",
      "        [-0.8089],\n",
      "        [-0.8796],\n",
      "        [-0.9584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6468]],\n",
      "\n",
      "        [[-1.2673]],\n",
      "\n",
      "        [[-1.4441]],\n",
      "\n",
      "        [[-1.3551]]], dtype=torch.float64)\n",
      "tensor([[-0.6142],\n",
      "        [-0.4917],\n",
      "        [-0.4743],\n",
      "        [-0.6186]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3429]],\n",
      "\n",
      "        [[-0.2863]],\n",
      "\n",
      "        [[-0.5544]],\n",
      "\n",
      "        [[-0.9750]]], dtype=torch.float64)\n",
      "tensor([[-0.7897],\n",
      "        [-0.8776],\n",
      "        [-0.4488],\n",
      "        [ 0.0071]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3528]],\n",
      "\n",
      "        [[-0.9923]],\n",
      "\n",
      "        [[-0.0310]],\n",
      "\n",
      "        [[ 0.2405]]], dtype=torch.float64)\n",
      "tensor([[-0.1545],\n",
      "        [-0.5097],\n",
      "        [-0.7457],\n",
      "        [-0.8299]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3869]],\n",
      "\n",
      "        [[-0.9750]],\n",
      "\n",
      "        [[-1.2107]],\n",
      "\n",
      "        [[-0.8895]]], dtype=torch.float64)\n",
      "tensor([[-0.2024],\n",
      "        [ 0.0762],\n",
      "        [ 0.1339],\n",
      "        [-0.3235]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3896]],\n",
      "\n",
      "        [[ 0.5987]],\n",
      "\n",
      "        [[-0.0957]],\n",
      "\n",
      "        [[-0.7358]]], dtype=torch.float64)\n",
      "tensor([[-0.5818],\n",
      "        [-0.7026],\n",
      "        [ 0.0279],\n",
      "        [ 0.1208]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9819]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[ 0.2648]],\n",
      "\n",
      "        [[ 0.4797]]], dtype=torch.float64)\n",
      "tensor([[ 0.0668],\n",
      "        [-0.3457],\n",
      "        [-0.5862],\n",
      "        [-0.6961]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 2.0721e-04]],\n",
      "\n",
      "        [[-6.6531e-01]],\n",
      "\n",
      "        [[-9.9691e-01]],\n",
      "\n",
      "        [[-7.2192e-01]]], dtype=torch.float64)\n",
      "tensor([[ 0.0244],\n",
      "        [ 0.3368],\n",
      "        [ 0.2533],\n",
      "        [-0.1056]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3237]],\n",
      "\n",
      "        [[ 0.5987]],\n",
      "\n",
      "        [[ 0.1458]],\n",
      "\n",
      "        [[-0.5856]]], dtype=torch.float64)\n",
      "tensor([[-0.4379],\n",
      "        [-0.5874],\n",
      "        [ 0.0800],\n",
      "        [ 0.1751]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8305]],\n",
      "\n",
      "        [[-0.8167]],\n",
      "\n",
      "        [[ 0.4450]],\n",
      "\n",
      "        [[ 0.4901]]], dtype=torch.float64)\n",
      "tensor([[ 0.0583],\n",
      "        [-0.0010],\n",
      "        [-0.2425],\n",
      "        [-0.5408]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1100]],\n",
      "\n",
      "        [[-0.1893]],\n",
      "\n",
      "        [[-0.4550]],\n",
      "\n",
      "        [[-0.5463]]], dtype=torch.float64)\n",
      "tensor([[-0.5862],\n",
      "        [-0.6015],\n",
      "        [-0.7458],\n",
      "        [-0.6365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4388]],\n",
      "\n",
      "        [[-0.7462]],\n",
      "\n",
      "        [[-0.7878]],\n",
      "\n",
      "        [[-0.8328]]], dtype=torch.float64)\n",
      "tensor([[-0.7413],\n",
      "        [-0.8057],\n",
      "        [-0.3855],\n",
      "        [-0.2563]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2095]],\n",
      "\n",
      "        [[-1.2476]],\n",
      "\n",
      "        [[-0.2632]],\n",
      "\n",
      "        [[ 0.0406]]], dtype=torch.float64)\n",
      "tensor([[-0.4190],\n",
      "        [-0.6629],\n",
      "        [-0.7577],\n",
      "        [-0.7967]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4296]],\n",
      "\n",
      "        [[-0.9345]],\n",
      "\n",
      "        [[-1.1737]],\n",
      "\n",
      "        [[-0.8513]]], dtype=torch.float64)\n",
      "tensor([[-0.3034],\n",
      "        [-0.2530],\n",
      "        [-0.4706],\n",
      "        [-0.6379]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1169]],\n",
      "\n",
      "        [[ 0.3503]],\n",
      "\n",
      "        [[-0.3788]],\n",
      "\n",
      "        [[-0.8848]]], dtype=torch.float64)\n",
      "tensor([[-0.7722],\n",
      "        [-0.8563],\n",
      "        [-0.1295],\n",
      "        [ 0.1109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2927]],\n",
      "\n",
      "        [[-0.9045]],\n",
      "\n",
      "        [[ 0.3538]],\n",
      "\n",
      "        [[ 0.7928]]], dtype=torch.float64)\n",
      "tensor([[ 0.0341],\n",
      "        [-0.4491],\n",
      "        [-0.6653],\n",
      "        [-0.7155]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0510]],\n",
      "\n",
      "        [[-0.5717]],\n",
      "\n",
      "        [[-1.0327]],\n",
      "\n",
      "        [[-0.7185]]], dtype=torch.float64)\n",
      "tensor([[0.1419],\n",
      "        [0.2403],\n",
      "        [0.1565],\n",
      "        [0.1933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7974]],\n",
      "\n",
      "        [[ 0.8610]],\n",
      "\n",
      "        [[ 0.4011]],\n",
      "\n",
      "        [[-0.0633]]], dtype=torch.float64)\n",
      "tensor([[0.2410],\n",
      "        [0.2399],\n",
      "        [0.2367],\n",
      "        [0.2241]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0784]],\n",
      "\n",
      "        [[ 0.1354]],\n",
      "\n",
      "        [[ 0.3445]],\n",
      "\n",
      "        [[ 0.2833]]], dtype=torch.float64)\n",
      "tensor([[0.2296],\n",
      "        [0.4136],\n",
      "        [0.5983],\n",
      "        [0.6219]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2914]],\n",
      "\n",
      "        [[0.2787]],\n",
      "\n",
      "        [[0.3445]],\n",
      "\n",
      "        [[0.4612]]], dtype=torch.float64)\n",
      "tensor([[0.4119],\n",
      "        [0.3596],\n",
      "        [0.4355],\n",
      "        [0.5166]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7917]],\n",
      "\n",
      "        [[0.7397]],\n",
      "\n",
      "        [[0.5063]],\n",
      "\n",
      "        [[0.2891]]], dtype=torch.float64)\n",
      "tensor([[0.4336],\n",
      "        [0.3598],\n",
      "        [0.6566],\n",
      "        [0.8129]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0449]],\n",
      "\n",
      "        [[ 0.1712]],\n",
      "\n",
      "        [[ 1.1117]],\n",
      "\n",
      "        [[ 1.4202]]], dtype=torch.float64)\n",
      "tensor([[0.7557],\n",
      "        [0.4779],\n",
      "        [0.4411],\n",
      "        [0.2575]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8517]],\n",
      "\n",
      "        [[0.2290]],\n",
      "\n",
      "        [[0.0164]],\n",
      "\n",
      "        [[0.3746]]], dtype=torch.float64)\n",
      "tensor([[0.7287],\n",
      "        [0.9130],\n",
      "        [0.6320],\n",
      "        [0.5193]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4410]],\n",
      "\n",
      "        [[1.5357]],\n",
      "\n",
      "        [[0.8275]],\n",
      "\n",
      "        [[0.4335]]], dtype=torch.float64)\n",
      "tensor([[ 0.6142],\n",
      "        [ 0.3769],\n",
      "        [-0.0150],\n",
      "        [ 0.0327]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1435]],\n",
      "\n",
      "        [[-0.1881]],\n",
      "\n",
      "        [[ 0.0083]],\n",
      "\n",
      "        [[ 0.2602]]], dtype=torch.float64)\n",
      "tensor([[ 0.0840],\n",
      "        [-0.2393],\n",
      "        [-0.2595],\n",
      "        [-0.2580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1477]],\n",
      "\n",
      "        [[-0.4712]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.4620]]], dtype=torch.float64)\n",
      "tensor([[0.0929],\n",
      "        [0.0825],\n",
      "        [0.0971],\n",
      "        [0.2464]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3353]],\n",
      "\n",
      "        [[0.4681]],\n",
      "\n",
      "        [[0.3133]],\n",
      "\n",
      "        [[0.1851]]], dtype=torch.float64)\n",
      "tensor([[0.3371],\n",
      "        [0.4530],\n",
      "        [0.6242],\n",
      "        [0.6341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0356]],\n",
      "\n",
      "        [[ 0.2093]],\n",
      "\n",
      "        [[ 0.9292]],\n",
      "\n",
      "        [[ 0.9788]]], dtype=torch.float64)\n",
      "tensor([[0.5871],\n",
      "        [0.7030],\n",
      "        [0.6899],\n",
      "        [0.5587]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7859]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.0476]],\n",
      "\n",
      "        [[0.6854]]], dtype=torch.float64)\n",
      "tensor([[1.0772],\n",
      "        [0.6912],\n",
      "        [0.3489],\n",
      "        [0.1962]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.3509]],\n",
      "\n",
      "        [[ 1.0539]],\n",
      "\n",
      "        [[ 0.2532]],\n",
      "\n",
      "        [[-0.1096]]], dtype=torch.float64)\n",
      "tensor([[ 0.0637],\n",
      "        [-0.1836],\n",
      "        [-0.0393],\n",
      "        [ 0.1106]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4504]],\n",
      "\n",
      "        [[-0.0714]],\n",
      "\n",
      "        [[ 0.3006]],\n",
      "\n",
      "        [[ 0.8217]]], dtype=torch.float64)\n",
      "tensor([[ 0.2796],\n",
      "        [ 0.3756],\n",
      "        [ 0.0399],\n",
      "        [-0.0060]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4716]],\n",
      "\n",
      "        [[ 0.0626]],\n",
      "\n",
      "        [[-0.3845]],\n",
      "\n",
      "        [[-0.2644]]], dtype=torch.float64)\n",
      "tensor([[-0.0465],\n",
      "        [ 0.1359],\n",
      "        [ 0.0384],\n",
      "        [-0.1579]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2070]],\n",
      "\n",
      "        [[ 0.5097]],\n",
      "\n",
      "        [[ 0.0626]],\n",
      "\n",
      "        [[-0.5186]]], dtype=torch.float64)\n",
      "tensor([[-0.4221],\n",
      "        [-0.4832],\n",
      "        [ 0.2175],\n",
      "        [ 0.2482]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9091]],\n",
      "\n",
      "        [[-0.4238]],\n",
      "\n",
      "        [[ 0.5109]],\n",
      "\n",
      "        [[ 0.7674]]], dtype=torch.float64)\n",
      "tensor([[ 0.2669],\n",
      "        [ 0.0595],\n",
      "        [-0.1466],\n",
      "        [-0.2405]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3584]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.6849]],\n",
      "\n",
      "        [[-0.2482]]], dtype=torch.float64)\n",
      "tensor([[0.4245],\n",
      "        [0.5908],\n",
      "        [0.5463],\n",
      "        [0.4009]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0724]],\n",
      "\n",
      "        [[1.2065]],\n",
      "\n",
      "        [[0.6773]],\n",
      "\n",
      "        [[0.1689]]], dtype=torch.float64)\n",
      "tensor([[ 0.4383],\n",
      "        [ 0.2705],\n",
      "        [-0.2364],\n",
      "        [-0.2279]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2856]],\n",
      "\n",
      "        [[-0.1696]],\n",
      "\n",
      "        [[-0.1361]],\n",
      "\n",
      "        [[ 0.0718]]], dtype=torch.float64)\n",
      "tensor([[-0.5631],\n",
      "        [-0.4732],\n",
      "        [-0.3682],\n",
      "        [-0.4066]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4077]],\n",
      "\n",
      "        [[-0.6087]],\n",
      "\n",
      "        [[-0.5983]],\n",
      "\n",
      "        [[-0.4654]]], dtype=torch.float64)\n",
      "tensor([[-0.4195],\n",
      "        [-0.2818],\n",
      "        [-0.4022],\n",
      "        [-0.4950]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2182]],\n",
      "\n",
      "        [[ 0.1342]],\n",
      "\n",
      "        [[-0.1234]],\n",
      "\n",
      "        [[-0.5648]]], dtype=torch.float64)\n",
      "tensor([[-0.4241],\n",
      "        [-0.4991],\n",
      "        [-0.3075],\n",
      "        [-0.3130]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7265]],\n",
      "\n",
      "        [[-0.5313]],\n",
      "\n",
      "        [[-0.1038]],\n",
      "\n",
      "        [[-0.0160]]], dtype=torch.float64)\n",
      "tensor([[-0.4919],\n",
      "        [-0.3768],\n",
      "        [-0.3816],\n",
      "        [-0.2871]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2759]],\n",
      "\n",
      "        [[-0.5174]],\n",
      "\n",
      "        [[-0.7404]],\n",
      "\n",
      "        [[-0.4770]]], dtype=torch.float64)\n",
      "tensor([[-0.3009],\n",
      "        [-0.1875],\n",
      "        [-0.3456],\n",
      "        [-0.0923]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1361]],\n",
      "\n",
      "        [[ 0.1781]],\n",
      "\n",
      "        [[-0.0541]],\n",
      "\n",
      "        [[-0.2933]]], dtype=torch.float64)\n",
      "tensor([[-0.0431],\n",
      "        [ 0.0105],\n",
      "        [ 0.1765],\n",
      "        [ 0.0178]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4354]],\n",
      "\n",
      "        [[ 0.1111]],\n",
      "\n",
      "        [[ 0.2914]],\n",
      "\n",
      "        [[ 0.2440]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.20723:  42%|████▏     | 1295/3067 [00:04<00:05, 343.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0111],\n",
      "        [ 0.0387],\n",
      "        [ 0.0574],\n",
      "        [ 0.0921]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1030]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.3788]],\n",
      "\n",
      "        [[-0.2598]]], dtype=torch.float64)\n",
      "tensor([[ 0.2547],\n",
      "        [ 0.2228],\n",
      "        [ 0.0609],\n",
      "        [-0.0466]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4866]],\n",
      "\n",
      "        [[ 0.5017]],\n",
      "\n",
      "        [[ 0.3156]],\n",
      "\n",
      "        [[-0.4585]]], dtype=torch.float64)\n",
      "tensor([[-0.3707],\n",
      "        [-0.4080],\n",
      "        [ 0.3094],\n",
      "        [ 0.3450]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9033]],\n",
      "\n",
      "        [[-0.2494]],\n",
      "\n",
      "        [[ 0.7339]],\n",
      "\n",
      "        [[ 0.9372]]], dtype=torch.float64)\n",
      "tensor([[ 0.2132],\n",
      "        [ 0.2482],\n",
      "        [-0.1153],\n",
      "        [-0.2341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4508]],\n",
      "\n",
      "        [[-0.1038]],\n",
      "\n",
      "        [[-0.7034]],\n",
      "\n",
      "        [[-0.0414]]], dtype=torch.float64)\n",
      "tensor([[0.4875],\n",
      "        [0.4706],\n",
      "        [0.3869],\n",
      "        [0.3322]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.0077]],\n",
      "\n",
      "        [[ 1.1706]],\n",
      "\n",
      "        [[ 0.7778]],\n",
      "\n",
      "        [[-0.0841]]], dtype=torch.float64)\n",
      "tensor([[-0.0517],\n",
      "        [-0.1658],\n",
      "        [ 0.5900],\n",
      "        [ 0.6696]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5255]],\n",
      "\n",
      "        [[ 0.0580]],\n",
      "\n",
      "        [[ 1.2007]],\n",
      "\n",
      "        [[ 1.3474]]], dtype=torch.float64)\n",
      "tensor([[0.5269],\n",
      "        [0.5100],\n",
      "        [0.3127],\n",
      "        [0.2089]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8737]],\n",
      "\n",
      "        [[ 0.1423]],\n",
      "\n",
      "        [[-0.2990]],\n",
      "\n",
      "        [[ 0.2891]]], dtype=torch.float64)\n",
      "tensor([[0.6654],\n",
      "        [0.7102],\n",
      "        [0.6661],\n",
      "        [0.5297]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3382]],\n",
      "\n",
      "        [[1.4387]],\n",
      "\n",
      "        [[0.9580]],\n",
      "\n",
      "        [[0.1573]]], dtype=torch.float64)\n",
      "tensor([[0.2766],\n",
      "        [0.2111],\n",
      "        [0.6290],\n",
      "        [0.7859]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2817]],\n",
      "\n",
      "        [[ 0.3214]],\n",
      "\n",
      "        [[ 1.3035]],\n",
      "\n",
      "        [[ 1.5057]]], dtype=torch.float64)\n",
      "tensor([[0.7605],\n",
      "        [0.6191],\n",
      "        [0.3815],\n",
      "        [0.2721]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.0632]],\n",
      "\n",
      "        [[ 0.3249]],\n",
      "\n",
      "        [[-0.2078]],\n",
      "\n",
      "        [[ 0.4439]]], dtype=torch.float64)\n",
      "tensor([[0.6769],\n",
      "        [0.7957],\n",
      "        [0.6007],\n",
      "        [0.5316]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3035]],\n",
      "\n",
      "        [[1.4826]],\n",
      "\n",
      "        [[1.0516]],\n",
      "\n",
      "        [[0.6738]]], dtype=torch.float64)\n",
      "tensor([[0.5194],\n",
      "        [0.3508],\n",
      "        [0.5166],\n",
      "        [0.4990]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1539]],\n",
      "\n",
      "        [[0.3191]],\n",
      "\n",
      "        [[1.0031]],\n",
      "\n",
      "        [[1.1094]]], dtype=torch.float64)\n",
      "tensor([[0.4891],\n",
      "        [0.3906],\n",
      "        [0.1715],\n",
      "        [0.0653]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7593]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[-0.5290]],\n",
      "\n",
      "        [[ 0.2163]]], dtype=torch.float64)\n",
      "tensor([[0.3951],\n",
      "        [0.2869],\n",
      "        [0.2731],\n",
      "        [0.2867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7443]],\n",
      "\n",
      "        [[ 0.7270]],\n",
      "\n",
      "        [[ 0.4427]],\n",
      "\n",
      "        [[-0.1766]]], dtype=torch.float64)\n",
      "tensor([[0.1895],\n",
      "        [0.1269],\n",
      "        [0.3483],\n",
      "        [0.3064]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5290]],\n",
      "\n",
      "        [[-0.0553]],\n",
      "\n",
      "        [[ 0.4866]],\n",
      "\n",
      "        [[ 0.0175]]], dtype=torch.float64)\n",
      "tensor([[0.1150],\n",
      "        [0.2549],\n",
      "        [0.3794],\n",
      "        [0.3436]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0302]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[-0.1211]],\n",
      "\n",
      "        [[-0.0541]]], dtype=torch.float64)\n",
      "tensor([[0.3912],\n",
      "        [0.3236],\n",
      "        [0.2702],\n",
      "        [0.3619]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3283]],\n",
      "\n",
      "        [[0.4658]],\n",
      "\n",
      "        [[0.3249]],\n",
      "\n",
      "        [[0.0487]]], dtype=torch.float64)\n",
      "tensor([[0.4206],\n",
      "        [0.4578],\n",
      "        [0.7120],\n",
      "        [0.6531]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0449]],\n",
      "\n",
      "        [[ 0.1851]],\n",
      "\n",
      "        [[ 0.8806]],\n",
      "\n",
      "        [[ 1.0320]]], dtype=torch.float64)\n",
      "tensor([[0.6886],\n",
      "        [0.3827],\n",
      "        [0.4332],\n",
      "        [0.3570]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4115]],\n",
      "\n",
      "        [[ 0.0372]],\n",
      "\n",
      "        [[-0.2170]],\n",
      "\n",
      "        [[ 0.2960]]], dtype=torch.float64)\n",
      "tensor([[0.6705],\n",
      "        [0.7019],\n",
      "        [0.5926],\n",
      "        [0.4970]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2261]],\n",
      "\n",
      "        [[1.0724]],\n",
      "\n",
      "        [[0.8171]],\n",
      "\n",
      "        [[0.3838]]], dtype=torch.float64)\n",
      "tensor([[0.4828],\n",
      "        [0.2697],\n",
      "        [0.4374],\n",
      "        [0.5084]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0079]],\n",
      "\n",
      "        [[ 0.1215]],\n",
      "\n",
      "        [[ 0.7824]],\n",
      "\n",
      "        [[ 1.0077]]], dtype=torch.float64)\n",
      "tensor([[ 0.3410],\n",
      "        [-0.0133],\n",
      "        [-0.2224],\n",
      "        [-0.2835]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5814]],\n",
      "\n",
      "        [[-0.0553]],\n",
      "\n",
      "        [[-0.5313]],\n",
      "\n",
      "        [[-0.2447]]], dtype=torch.float64)\n",
      "tensor([[ 0.0703],\n",
      "        [ 0.0317],\n",
      "        [ 0.0059],\n",
      "        [-0.2730]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3561]],\n",
      "\n",
      "        [[ 0.5710]],\n",
      "\n",
      "        [[ 0.1874]],\n",
      "\n",
      "        [[-0.3210]]], dtype=torch.float64)\n",
      "tensor([[-0.3256],\n",
      "        [-0.4004],\n",
      "        [-0.2374],\n",
      "        [-0.2454]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6780]],\n",
      "\n",
      "        [[-0.6237]],\n",
      "\n",
      "        [[-0.2390]],\n",
      "\n",
      "        [[-0.1904]]], dtype=torch.float64)\n",
      "tensor([[-0.4047],\n",
      "        [-0.4286],\n",
      "        [-0.4667],\n",
      "        [-0.5528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3210]],\n",
      "\n",
      "        [[-0.5151]],\n",
      "\n",
      "        [[-0.7381]],\n",
      "\n",
      "        [[-0.8432]]], dtype=torch.float64)\n",
      "tensor([[-0.4574],\n",
      "        [-0.4544],\n",
      "        [-0.4468],\n",
      "        [-0.5947]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2875]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[-1.0385]]], dtype=torch.float64)\n",
      "tensor([[-0.6361],\n",
      "        [-0.4589],\n",
      "        [ 0.0643],\n",
      "        [-0.0806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2777]],\n",
      "\n",
      "        [[-0.5382]],\n",
      "\n",
      "        [[ 0.1238]],\n",
      "\n",
      "        [[-0.3187]]], dtype=torch.float64)\n",
      "tensor([[-0.2835],\n",
      "        [-0.2118],\n",
      "        [-0.2060],\n",
      "        [-0.3322]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3730]],\n",
      "\n",
      "        [[-0.5948]],\n",
      "\n",
      "        [[-0.9923]],\n",
      "\n",
      "        [[-0.4181]]], dtype=torch.float64)\n",
      "tensor([[0.2999],\n",
      "        [0.2874],\n",
      "        [0.2094],\n",
      "        [0.0196]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3711]],\n",
      "\n",
      "        [[ 0.5895]],\n",
      "\n",
      "        [[ 0.2012]],\n",
      "\n",
      "        [[-0.3996]]], dtype=torch.float64)\n",
      "tensor([[-0.2499],\n",
      "        [-0.1051],\n",
      "        [ 0.6144],\n",
      "        [ 0.6455]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8687]],\n",
      "\n",
      "        [[ 0.0510]],\n",
      "\n",
      "        [[ 0.9500]],\n",
      "\n",
      "        [[ 1.3220]]], dtype=torch.float64)\n",
      "tensor([[0.6774],\n",
      "        [0.4963],\n",
      "        [0.2567],\n",
      "        [0.3968]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8714]],\n",
      "\n",
      "        [[ 0.1828]],\n",
      "\n",
      "        [[-0.5290]],\n",
      "\n",
      "        [[ 0.4959]]], dtype=torch.float64)\n",
      "tensor([[0.8230],\n",
      "        [0.8425],\n",
      "        [0.7530],\n",
      "        [0.6016]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4791]],\n",
      "\n",
      "        [[1.6062]],\n",
      "\n",
      "        [[1.0285]],\n",
      "\n",
      "        [[0.4508]]], dtype=torch.float64)\n",
      "tensor([[0.4558],\n",
      "        [0.3652],\n",
      "        [0.7291],\n",
      "        [0.8003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3811]],\n",
      "\n",
      "        [[ 0.4150]],\n",
      "\n",
      "        [[ 1.1221]],\n",
      "\n",
      "        [[ 1.2492]]], dtype=torch.float64)\n",
      "tensor([[0.8434],\n",
      "        [0.6870],\n",
      "        [0.5993],\n",
      "        [0.5078]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9534]],\n",
      "\n",
      "        [[ 0.3803]],\n",
      "\n",
      "        [[-0.0194]],\n",
      "\n",
      "        [[ 0.6264]]], dtype=torch.float64)\n",
      "tensor([[0.9157],\n",
      "        [0.9061],\n",
      "        [0.9023],\n",
      "        [0.7353]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3347]],\n",
      "\n",
      "        [[1.6282]],\n",
      "\n",
      "        [[1.1036]],\n",
      "\n",
      "        [[0.5698]]], dtype=torch.float64)\n",
      "tensor([[0.5040],\n",
      "        [0.5306],\n",
      "        [1.0388],\n",
      "        [1.0881]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2424]],\n",
      "\n",
      "        [[ 0.7408]],\n",
      "\n",
      "        [[ 1.6917]],\n",
      "\n",
      "        [[ 1.8038]]], dtype=torch.float64)\n",
      "tensor([[1.0308],\n",
      "        [0.7849],\n",
      "        [0.6310],\n",
      "        [0.6001]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2966]],\n",
      "\n",
      "        [[0.4046]],\n",
      "\n",
      "        [[0.0395]],\n",
      "\n",
      "        [[0.8413]]], dtype=torch.float64)\n",
      "tensor([[1.1742],\n",
      "        [1.1344],\n",
      "        [0.7820],\n",
      "        [0.7450]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5357]],\n",
      "\n",
      "        [[1.6039]],\n",
      "\n",
      "        [[0.7108]],\n",
      "\n",
      "        [[0.3272]]], dtype=torch.float64)\n",
      "tensor([[0.7525],\n",
      "        [0.7206],\n",
      "        [0.9750],\n",
      "        [1.0869]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1747]],\n",
      "\n",
      "        [[0.3526]],\n",
      "\n",
      "        [[1.2376]],\n",
      "\n",
      "        [[0.8205]]], dtype=torch.float64)\n",
      "tensor([[0.6545],\n",
      "        [0.5288],\n",
      "        [0.4749],\n",
      "        [0.5217]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5225]],\n",
      "\n",
      "        [[ 0.1042]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[ 0.3630]]], dtype=torch.float64)\n",
      "tensor([[0.4856],\n",
      "        [0.5440],\n",
      "        [0.5116],\n",
      "        [0.4177]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7246]],\n",
      "\n",
      "        [[1.0112]],\n",
      "\n",
      "        [[0.6184]],\n",
      "\n",
      "        [[0.0048]]], dtype=torch.float64)\n",
      "tensor([[0.2116],\n",
      "        [0.3249],\n",
      "        [0.8204],\n",
      "        [0.7201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3025]],\n",
      "\n",
      "        [[ 0.4196]],\n",
      "\n",
      "        [[ 1.1568]],\n",
      "\n",
      "        [[ 0.8541]]], dtype=torch.float64)\n",
      "tensor([[0.4240],\n",
      "        [0.3727],\n",
      "        [0.3830],\n",
      "        [0.4564]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2902]],\n",
      "\n",
      "        [[-0.0402]],\n",
      "\n",
      "        [[-0.2101]],\n",
      "\n",
      "        [[ 0.1100]]], dtype=torch.float64)\n",
      "tensor([[0.2564],\n",
      "        [0.2524],\n",
      "        [0.3996],\n",
      "        [0.2112]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4266]],\n",
      "\n",
      "        [[ 0.5271]],\n",
      "\n",
      "        [[-0.0264]],\n",
      "\n",
      "        [[-0.2840]]], dtype=torch.float64)\n",
      "tensor([[0.1861],\n",
      "        [0.3917],\n",
      "        [0.3836],\n",
      "        [0.3033]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3834]],\n",
      "\n",
      "        [[ 0.0695]],\n",
      "\n",
      "        [[ 0.5086]],\n",
      "\n",
      "        [[ 0.4323]]], dtype=torch.float64)\n",
      "tensor([[0.3913],\n",
      "        [0.4288],\n",
      "        [0.6372],\n",
      "        [0.7463]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2486]],\n",
      "\n",
      "        [[0.1885]],\n",
      "\n",
      "        [[0.2602]],\n",
      "\n",
      "        [[0.5756]]], dtype=torch.float64)\n",
      "tensor([[0.7377],\n",
      "        [0.6500],\n",
      "        [0.6244],\n",
      "        [0.5056]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8448]],\n",
      "\n",
      "        [[0.9650]],\n",
      "\n",
      "        [[0.5906]],\n",
      "\n",
      "        [[0.1654]]], dtype=torch.float64)\n",
      "tensor([[0.4720],\n",
      "        [0.4423],\n",
      "        [0.9448],\n",
      "        [0.9751]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2043]],\n",
      "\n",
      "        [[ 0.4739]],\n",
      "\n",
      "        [[ 1.4283]],\n",
      "\n",
      "        [[ 1.6790]]], dtype=torch.float64)\n",
      "tensor([[0.9168],\n",
      "        [0.7005],\n",
      "        [0.5425],\n",
      "        [0.5488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1429]],\n",
      "\n",
      "        [[0.4393]],\n",
      "\n",
      "        [[0.0129]],\n",
      "\n",
      "        [[0.7755]]], dtype=torch.float64)\n",
      "tensor([[1.1529],\n",
      "        [1.0320],\n",
      "        [0.9417],\n",
      "        [0.6427]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1914]],\n",
      "\n",
      "        [[1.7114]],\n",
      "\n",
      "        [[0.5999]],\n",
      "\n",
      "        [[0.4543]]], dtype=torch.float64)\n",
      "tensor([[0.7546],\n",
      "        [0.7480],\n",
      "        [1.0035],\n",
      "        [0.7017]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2821]],\n",
      "\n",
      "        [[0.5941]],\n",
      "\n",
      "        [[1.2920]],\n",
      "\n",
      "        [[1.1198]]], dtype=torch.float64)\n",
      "tensor([[0.8919],\n",
      "        [0.7616],\n",
      "        [0.6792],\n",
      "        [0.6988]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9003]],\n",
      "\n",
      "        [[0.4058]],\n",
      "\n",
      "        [[0.1550]],\n",
      "\n",
      "        [[0.6207]]], dtype=torch.float64)\n",
      "tensor([[0.9392],\n",
      "        [0.9786],\n",
      "        [0.9987],\n",
      "        [0.8313]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3312]],\n",
      "\n",
      "        [[1.4537]],\n",
      "\n",
      "        [[1.0435]],\n",
      "\n",
      "        [[0.5952]]], dtype=torch.float64)\n",
      "tensor([[0.8086],\n",
      "        [0.8571],\n",
      "        [1.2139],\n",
      "        [1.0713]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4497]],\n",
      "\n",
      "        [[1.1337]],\n",
      "\n",
      "        [[1.6813]],\n",
      "\n",
      "        [[1.7033]]], dtype=torch.float64)\n",
      "tensor([[0.9617],\n",
      "        [0.6701],\n",
      "        [0.5090],\n",
      "        [0.6088]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7974]],\n",
      "\n",
      "        [[0.3919]],\n",
      "\n",
      "        [[0.0591]],\n",
      "\n",
      "        [[0.6380]]], dtype=torch.float64)\n",
      "tensor([[0.6343],\n",
      "        [0.6366],\n",
      "        [0.7532],\n",
      "        [0.6115]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1487]],\n",
      "\n",
      "        [[1.4884]],\n",
      "\n",
      "        [[0.9453]],\n",
      "\n",
      "        [[0.2821]]], dtype=torch.float64)\n",
      "tensor([[0.4551],\n",
      "        [0.5242],\n",
      "        [1.0431],\n",
      "        [0.7748]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2390]],\n",
      "\n",
      "        [[ 1.0054]],\n",
      "\n",
      "        [[ 1.7437]],\n",
      "\n",
      "        [[ 1.1591]]], dtype=torch.float64)\n",
      "tensor([[0.4377],\n",
      "        [0.2462],\n",
      "        [0.1513],\n",
      "        [0.4029]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5432]],\n",
      "\n",
      "        [[ 0.2567]],\n",
      "\n",
      "        [[-0.5521]],\n",
      "\n",
      "        [[ 0.3480]]], dtype=torch.float64)\n",
      "tensor([[0.4689],\n",
      "        [0.5253],\n",
      "        [0.4867],\n",
      "        [0.3765]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7212]],\n",
      "\n",
      "        [[1.0331]],\n",
      "\n",
      "        [[0.6646]],\n",
      "\n",
      "        [[0.1851]]], dtype=torch.float64)\n",
      "tensor([[0.2291],\n",
      "        [0.5508],\n",
      "        [1.0788],\n",
      "        [1.0492]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3603]],\n",
      "\n",
      "        [[ 0.9037]],\n",
      "\n",
      "        [[ 1.7738]],\n",
      "\n",
      "        [[ 1.8177]]], dtype=torch.float64)\n",
      "tensor([[0.7395],\n",
      "        [0.7384],\n",
      "        [0.5829],\n",
      "        [0.5671]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1325]],\n",
      "\n",
      "        [[0.5837]],\n",
      "\n",
      "        [[0.0788]],\n",
      "\n",
      "        [[0.7293]]], dtype=torch.float64)\n",
      "tensor([[0.4641],\n",
      "        [0.3487],\n",
      "        [0.2760],\n",
      "        [0.2747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8344]],\n",
      "\n",
      "        [[0.7154]],\n",
      "\n",
      "        [[0.3307]],\n",
      "\n",
      "        [[0.0730]]], dtype=torch.float64)\n",
      "tensor([[0.2968],\n",
      "        [0.3975],\n",
      "        [0.5497],\n",
      "        [0.3939]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2817]],\n",
      "\n",
      "        [[ 0.4208]],\n",
      "\n",
      "        [[ 0.7582]],\n",
      "\n",
      "        [[ 0.9118]]], dtype=torch.float64)\n",
      "tensor([[0.5005],\n",
      "        [0.4503],\n",
      "        [0.5000],\n",
      "        [0.6482]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5872]],\n",
      "\n",
      "        [[0.1493]],\n",
      "\n",
      "        [[0.1828]],\n",
      "\n",
      "        [[0.7582]]], dtype=torch.float64)\n",
      "tensor([[0.7588],\n",
      "        [0.7708],\n",
      "        [0.9174],\n",
      "        [0.7956]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2931]],\n",
      "\n",
      "        [[1.6212]],\n",
      "\n",
      "        [[1.2030]],\n",
      "\n",
      "        [[0.6623]]], dtype=torch.float64)\n",
      "tensor([[0.6987],\n",
      "        [0.7721],\n",
      "        [1.2572],\n",
      "        [1.3642]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1181]],\n",
      "\n",
      "        [[1.1464]],\n",
      "\n",
      "        [[1.9251]],\n",
      "\n",
      "        [[2.2694]]], dtype=torch.float64)\n",
      "tensor([[1.4866],\n",
      "        [1.1089],\n",
      "        [1.1180],\n",
      "        [1.1013]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9078]],\n",
      "\n",
      "        [[1.1961]],\n",
      "\n",
      "        [[0.6553]],\n",
      "\n",
      "        [[1.5149]]], dtype=torch.float64)\n",
      "tensor([[1.4053],\n",
      "        [1.0935],\n",
      "        [0.7535],\n",
      "        [0.7227]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4040]],\n",
      "\n",
      "        [[1.3139]],\n",
      "\n",
      "        [[0.7420]],\n",
      "\n",
      "        [[0.4820]]], dtype=torch.float64)\n",
      "tensor([[0.6396],\n",
      "        [0.5590],\n",
      "        [0.3529],\n",
      "        [0.2231]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0545]],\n",
      "\n",
      "        [[-0.0229]],\n",
      "\n",
      "        [[ 0.1042]],\n",
      "\n",
      "        [[ 0.4104]]], dtype=torch.float64)\n",
      "tensor([[0.3729],\n",
      "        [0.5145],\n",
      "        [0.5518],\n",
      "        [0.6676]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4092]],\n",
      "\n",
      "        [[0.3815]],\n",
      "\n",
      "        [[0.0626]],\n",
      "\n",
      "        [[0.4439]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.20723:  45%|████▍     | 1365/3067 [00:04<00:05, 339.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5282],\n",
      "        [0.6359],\n",
      "        [0.7667],\n",
      "        [0.7052]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9026]],\n",
      "\n",
      "        [[1.2365]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[0.6241]]], dtype=torch.float64)\n",
      "tensor([[0.7295],\n",
      "        [0.8062],\n",
      "        [0.8078],\n",
      "        [0.9857]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2879]],\n",
      "\n",
      "        [[0.7454]],\n",
      "\n",
      "        [[1.2423]],\n",
      "\n",
      "        [[1.5727]]], dtype=torch.float64)\n",
      "tensor([[1.0968],\n",
      "        [0.9771],\n",
      "        [1.0397],\n",
      "        [0.9929]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3959]],\n",
      "\n",
      "        [[0.7766]],\n",
      "\n",
      "        [[0.6287]],\n",
      "\n",
      "        [[1.1186]]], dtype=torch.float64)\n",
      "tensor([[1.3300],\n",
      "        [1.4279],\n",
      "        [1.4277],\n",
      "        [1.3623]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7067]],\n",
      "\n",
      "        [[1.9609]],\n",
      "\n",
      "        [[1.7033]],\n",
      "\n",
      "        [[1.3139]]], dtype=torch.float64)\n",
      "tensor([[1.3092],\n",
      "        [1.2900],\n",
      "        [1.6720],\n",
      "        [1.6534]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7454]],\n",
      "\n",
      "        [[1.5115]],\n",
      "\n",
      "        [[2.0256]],\n",
      "\n",
      "        [[2.2105]]], dtype=torch.float64)\n",
      "tensor([[1.3339],\n",
      "        [1.1886],\n",
      "        [1.1150],\n",
      "        [1.1042]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1071]],\n",
      "\n",
      "        [[0.8541]],\n",
      "\n",
      "        [[0.5768]],\n",
      "\n",
      "        [[1.3428]]], dtype=torch.float64)\n",
      "tensor([[1.6084],\n",
      "        [1.2086],\n",
      "        [0.8382],\n",
      "        [0.9699]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8246]],\n",
      "\n",
      "        [[1.0805]],\n",
      "\n",
      "        [[1.0355]],\n",
      "\n",
      "        [[0.6854]]], dtype=torch.float64)\n",
      "tensor([[1.0124],\n",
      "        [1.2349],\n",
      "        [1.2614],\n",
      "        [1.2984]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5074]],\n",
      "\n",
      "        [[1.3359]],\n",
      "\n",
      "        [[1.5265]],\n",
      "\n",
      "        [[1.2157]]], dtype=torch.float64)\n",
      "tensor([[1.0367],\n",
      "        [1.2061],\n",
      "        [1.2332],\n",
      "        [1.1603]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2977]],\n",
      "\n",
      "        [[1.0031]],\n",
      "\n",
      "        [[0.7582]],\n",
      "\n",
      "        [[0.8205]]], dtype=torch.float64)\n",
      "tensor([[1.1439],\n",
      "        [0.8561],\n",
      "        [0.3321],\n",
      "        [0.5199]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1764]],\n",
      "\n",
      "        [[0.5294]],\n",
      "\n",
      "        [[0.4115]],\n",
      "\n",
      "        [[0.3873]]], dtype=torch.float64)\n",
      "tensor([[0.5676],\n",
      "        [0.7523],\n",
      "        [0.7159],\n",
      "        [0.6342]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1989]],\n",
      "\n",
      "        [[0.7790]],\n",
      "\n",
      "        [[0.9557]],\n",
      "\n",
      "        [[1.0482]]], dtype=torch.float64)\n",
      "tensor([[0.6551],\n",
      "        [0.7219],\n",
      "        [0.4853],\n",
      "        [0.6565]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7616]],\n",
      "\n",
      "        [[ 0.1735]],\n",
      "\n",
      "        [[-0.0922]],\n",
      "\n",
      "        [[ 0.5479]]], dtype=torch.float64)\n",
      "tensor([[0.8857],\n",
      "        [0.8284],\n",
      "        [0.7441],\n",
      "        [0.7926]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9569]],\n",
      "\n",
      "        [[1.0435]],\n",
      "\n",
      "        [[0.7917]],\n",
      "\n",
      "        [[0.4647]]], dtype=torch.float64)\n",
      "tensor([[0.7036],\n",
      "        [0.7535],\n",
      "        [0.9782],\n",
      "        [0.6362]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0765]],\n",
      "\n",
      "        [[0.8980]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[0.7258]]], dtype=torch.float64)\n",
      "tensor([[0.6749],\n",
      "        [0.7302],\n",
      "        [0.7623],\n",
      "        [0.6754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6264]],\n",
      "\n",
      "        [[0.3942]],\n",
      "\n",
      "        [[0.1296]],\n",
      "\n",
      "        [[0.5225]]], dtype=torch.float64)\n",
      "tensor([[0.9515],\n",
      "        [0.8490],\n",
      "        [0.8849],\n",
      "        [0.7887]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1175]],\n",
      "\n",
      "        [[1.2561]],\n",
      "\n",
      "        [[0.9557]],\n",
      "\n",
      "        [[0.3653]]], dtype=torch.float64)\n",
      "tensor([[0.6631],\n",
      "        [0.7171],\n",
      "        [1.0589],\n",
      "        [0.8511]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0753]],\n",
      "\n",
      "        [[0.7917]],\n",
      "\n",
      "        [[1.2527]],\n",
      "\n",
      "        [[1.1568]]], dtype=torch.float64)\n",
      "tensor([[0.8157],\n",
      "        [0.8144],\n",
      "        [0.7592],\n",
      "        [0.8748]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9661]],\n",
      "\n",
      "        [[0.4323]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.7478]]], dtype=torch.float64)\n",
      "tensor([[1.0700],\n",
      "        [0.8362],\n",
      "        [1.1091],\n",
      "        [1.0296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4063]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[1.0193]],\n",
      "\n",
      "        [[0.6738]]], dtype=torch.float64)\n",
      "tensor([[1.0195],\n",
      "        [0.9970],\n",
      "        [1.1868],\n",
      "        [1.1487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5028]],\n",
      "\n",
      "        [[1.0031]],\n",
      "\n",
      "        [[1.5392]],\n",
      "\n",
      "        [[1.7564]]], dtype=torch.float64)\n",
      "tensor([[1.2676],\n",
      "        [1.0038],\n",
      "        [1.0389],\n",
      "        [1.1178]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2018]],\n",
      "\n",
      "        [[0.7015]],\n",
      "\n",
      "        [[0.5536]],\n",
      "\n",
      "        [[1.3543]]], dtype=torch.float64)\n",
      "tensor([[1.3927],\n",
      "        [1.2472],\n",
      "        [1.0738],\n",
      "        [0.7312]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7102]],\n",
      "\n",
      "        [[1.3659]],\n",
      "\n",
      "        [[0.6438]],\n",
      "\n",
      "        [[0.5386]]], dtype=torch.float64)\n",
      "tensor([[0.7301],\n",
      "        [0.7210],\n",
      "        [0.7480],\n",
      "        [0.7828]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2452]],\n",
      "\n",
      "        [[0.7270]],\n",
      "\n",
      "        [[1.1695]],\n",
      "\n",
      "        [[1.3197]]], dtype=torch.float64)\n",
      "tensor([[0.8838],\n",
      "        [0.8655],\n",
      "        [0.8202],\n",
      "        [0.9030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1221]],\n",
      "\n",
      "        [[0.5155]],\n",
      "\n",
      "        [[0.4554]],\n",
      "\n",
      "        [[0.8321]]], dtype=torch.float64)\n",
      "tensor([[0.8497],\n",
      "        [0.4486],\n",
      "        [0.4421],\n",
      "        [0.3997]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9684]],\n",
      "\n",
      "        [[0.7778]],\n",
      "\n",
      "        [[0.6114]],\n",
      "\n",
      "        [[0.2024]]], dtype=torch.float64)\n",
      "tensor([[0.4761],\n",
      "        [0.6077],\n",
      "        [0.4661],\n",
      "        [0.2765]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1897]],\n",
      "\n",
      "        [[0.4393]],\n",
      "\n",
      "        [[0.5814]],\n",
      "\n",
      "        [[0.7246]]], dtype=torch.float64)\n",
      "tensor([[0.3221],\n",
      "        [0.4282],\n",
      "        [0.6088],\n",
      "        [0.6195]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5282]],\n",
      "\n",
      "        [[0.3977]],\n",
      "\n",
      "        [[0.1908]],\n",
      "\n",
      "        [[0.6519]]], dtype=torch.float64)\n",
      "tensor([[0.7035],\n",
      "        [0.5629],\n",
      "        [0.4769],\n",
      "        [0.5481]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9777]],\n",
      "\n",
      "        [[0.4612]],\n",
      "\n",
      "        [[0.5213]],\n",
      "\n",
      "        [[0.3919]]], dtype=torch.float64)\n",
      "tensor([[0.7715],\n",
      "        [0.7848],\n",
      "        [0.8030],\n",
      "        [0.8631]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3330]],\n",
      "\n",
      "        [[0.6623]],\n",
      "\n",
      "        [[0.9107]],\n",
      "\n",
      "        [[1.4248]]], dtype=torch.float64)\n",
      "tensor([[1.0542],\n",
      "        [0.9056],\n",
      "        [0.9549],\n",
      "        [0.8784]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2423]],\n",
      "\n",
      "        [[0.7882]],\n",
      "\n",
      "        [[0.5710]],\n",
      "\n",
      "        [[0.7454]]], dtype=torch.float64)\n",
      "tensor([[1.2300],\n",
      "        [1.3181],\n",
      "        [0.7020],\n",
      "        [0.6357]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6363]],\n",
      "\n",
      "        [[0.8506]],\n",
      "\n",
      "        [[0.8887]],\n",
      "\n",
      "        [[0.5040]]], dtype=torch.float64)\n",
      "tensor([[0.7297],\n",
      "        [0.8115],\n",
      "        [0.9152],\n",
      "        [0.8112]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3214]],\n",
      "\n",
      "        [[0.9303]],\n",
      "\n",
      "        [[1.1568]],\n",
      "\n",
      "        [[1.3624]]], dtype=torch.float64)\n",
      "tensor([[0.5207],\n",
      "        [0.5353],\n",
      "        [0.6451],\n",
      "        [0.6754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6773]],\n",
      "\n",
      "        [[0.4046]],\n",
      "\n",
      "        [[0.2405]],\n",
      "\n",
      "        [[0.6426]]], dtype=torch.float64)\n",
      "tensor([[0.5592],\n",
      "        [0.4482],\n",
      "        [0.3188],\n",
      "        [0.4308]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8148]],\n",
      "\n",
      "        [[0.3711]],\n",
      "\n",
      "        [[0.3595]],\n",
      "\n",
      "        [[0.1481]]], dtype=torch.float64)\n",
      "tensor([[0.4954],\n",
      "        [0.6301],\n",
      "        [0.6002],\n",
      "        [0.3831]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0453]],\n",
      "\n",
      "        [[0.6368]],\n",
      "\n",
      "        [[0.8529]],\n",
      "\n",
      "        [[0.5167]]], dtype=torch.float64)\n",
      "tensor([[0.3161],\n",
      "        [0.5414],\n",
      "        [0.7572],\n",
      "        [0.9016]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3907]],\n",
      "\n",
      "        [[0.2694]],\n",
      "\n",
      "        [[0.4427]],\n",
      "\n",
      "        [[0.8945]]], dtype=torch.float64)\n",
      "tensor([[0.8612],\n",
      "        [0.8704],\n",
      "        [0.9984],\n",
      "        [0.9176]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1568]],\n",
      "\n",
      "        [[1.5635]],\n",
      "\n",
      "        [[1.2920]],\n",
      "\n",
      "        [[0.6946]]], dtype=torch.float64)\n",
      "tensor([[0.8286],\n",
      "        [0.9131],\n",
      "        [1.2460],\n",
      "        [1.2734]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3630]],\n",
      "\n",
      "        [[1.2180]],\n",
      "\n",
      "        [[1.7171]],\n",
      "\n",
      "        [[2.0048]]], dtype=torch.float64)\n",
      "tensor([[1.2473],\n",
      "        [1.0643],\n",
      "        [0.9087],\n",
      "        [0.9808]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5831]],\n",
      "\n",
      "        [[0.8818]],\n",
      "\n",
      "        [[0.4393]],\n",
      "\n",
      "        [[1.3763]]], dtype=torch.float64)\n",
      "tensor([[1.2996],\n",
      "        [1.3462],\n",
      "        [1.2818],\n",
      "        [1.0913]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9517]],\n",
      "\n",
      "        [[2.0927]],\n",
      "\n",
      "        [[1.6802]],\n",
      "\n",
      "        [[0.9407]]], dtype=torch.float64)\n",
      "tensor([[0.8813],\n",
      "        [0.8296],\n",
      "        [1.3769],\n",
      "        [1.3834]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3930]],\n",
      "\n",
      "        [[1.3520]],\n",
      "\n",
      "        [[2.0695]],\n",
      "\n",
      "        [[2.2128]]], dtype=torch.float64)\n",
      "tensor([[1.2037],\n",
      "        [0.8872],\n",
      "        [0.8762],\n",
      "        [0.5609]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1880]],\n",
      "\n",
      "        [[0.9765]],\n",
      "\n",
      "        [[0.3734]],\n",
      "\n",
      "        [[0.2059]]], dtype=torch.float64)\n",
      "tensor([[0.2711],\n",
      "        [0.3372],\n",
      "        [0.5297],\n",
      "        [0.4901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3237]],\n",
      "\n",
      "        [[0.8506]],\n",
      "\n",
      "        [[0.6241]],\n",
      "\n",
      "        [[0.0060]]], dtype=torch.float64)\n",
      "tensor([[0.4702],\n",
      "        [0.4807],\n",
      "        [0.4018],\n",
      "        [0.2765]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1639]],\n",
      "\n",
      "        [[ 0.2648]],\n",
      "\n",
      "        [[ 0.7720]],\n",
      "\n",
      "        [[ 0.5918]]], dtype=torch.float64)\n",
      "tensor([[0.2794],\n",
      "        [0.3710],\n",
      "        [0.4658],\n",
      "        [0.4056]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2567]],\n",
      "\n",
      "        [[0.1689]],\n",
      "\n",
      "        [[0.0557]],\n",
      "\n",
      "        [[0.3295]]], dtype=torch.float64)\n",
      "tensor([[0.3388],\n",
      "        [0.0695],\n",
      "        [0.2003],\n",
      "        [0.3331]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2683]],\n",
      "\n",
      "        [[0.4150]],\n",
      "\n",
      "        [[0.1620]],\n",
      "\n",
      "        [[0.0718]]], dtype=torch.float64)\n",
      "tensor([[0.4050],\n",
      "        [0.2607],\n",
      "        [0.2271],\n",
      "        [0.1429]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0164]],\n",
      "\n",
      "        [[0.1227]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.3873]]], dtype=torch.float64)\n",
      "tensor([[0.2090],\n",
      "        [0.4548],\n",
      "        [0.6593],\n",
      "        [0.7788]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2914]],\n",
      "\n",
      "        [[0.2625]],\n",
      "\n",
      "        [[0.2798]],\n",
      "\n",
      "        [[0.3792]]], dtype=torch.float64)\n",
      "tensor([[0.6239],\n",
      "        [0.7316],\n",
      "        [0.7110],\n",
      "        [0.7811]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8772]],\n",
      "\n",
      "        [[0.8471]],\n",
      "\n",
      "        [[0.8309]],\n",
      "\n",
      "        [[0.5225]]], dtype=torch.float64)\n",
      "tensor([[0.8454],\n",
      "        [0.8387],\n",
      "        [0.7621],\n",
      "        [0.8212]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4843]],\n",
      "\n",
      "        [[0.5086]],\n",
      "\n",
      "        [[0.7674]],\n",
      "\n",
      "        [[1.1545]]], dtype=torch.float64)\n",
      "tensor([[0.9396],\n",
      "        [0.8036],\n",
      "        [0.7186],\n",
      "        [0.7071]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9604]],\n",
      "\n",
      "        [[0.4705]],\n",
      "\n",
      "        [[0.2833]],\n",
      "\n",
      "        [[0.7859]]], dtype=torch.float64)\n",
      "tensor([[1.4536],\n",
      "        [1.2506],\n",
      "        [1.3214],\n",
      "        [1.0552]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1146]],\n",
      "\n",
      "        [[1.4040]],\n",
      "\n",
      "        [[1.4398]],\n",
      "\n",
      "        [[1.1002]]], dtype=torch.float64)\n",
      "tensor([[0.9655],\n",
      "        [0.9422],\n",
      "        [1.2632],\n",
      "        [1.3479]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5109]],\n",
      "\n",
      "        [[1.1418]],\n",
      "\n",
      "        [[1.7969]],\n",
      "\n",
      "        [[1.9702]]], dtype=torch.float64)\n",
      "tensor([[1.3551],\n",
      "        [0.8260],\n",
      "        [0.9960],\n",
      "        [0.9675]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4595]],\n",
      "\n",
      "        [[0.7940]],\n",
      "\n",
      "        [[0.7200]],\n",
      "\n",
      "        [[0.8552]]], dtype=torch.float64)\n",
      "tensor([[0.9742],\n",
      "        [0.9496],\n",
      "        [1.0367],\n",
      "        [0.8823]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3208]],\n",
      "\n",
      "        [[1.5103]],\n",
      "\n",
      "        [[1.1845]],\n",
      "\n",
      "        [[0.6033]]], dtype=torch.float64)\n",
      "tensor([[0.8706],\n",
      "        [0.9546],\n",
      "        [1.3870],\n",
      "        [1.5791]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4566]],\n",
      "\n",
      "        [[1.2608]],\n",
      "\n",
      "        [[1.9274]],\n",
      "\n",
      "        [[2.1054]]], dtype=torch.float64)\n",
      "tensor([[1.4589],\n",
      "        [1.2329],\n",
      "        [1.1899],\n",
      "        [1.1850]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5635]],\n",
      "\n",
      "        [[1.1452]],\n",
      "\n",
      "        [[0.8275]],\n",
      "\n",
      "        [[1.1891]]], dtype=torch.float64)\n",
      "tensor([[1.3579],\n",
      "        [1.4526],\n",
      "        [1.0470],\n",
      "        [0.9200]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6548]],\n",
      "\n",
      "        [[1.8269]],\n",
      "\n",
      "        [[0.8517]],\n",
      "\n",
      "        [[0.7766]]], dtype=torch.float64)\n",
      "tensor([[1.1185],\n",
      "        [1.0071],\n",
      "        [1.1060],\n",
      "        [1.1094]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7027]],\n",
      "\n",
      "        [[1.0978]],\n",
      "\n",
      "        [[1.4768]],\n",
      "\n",
      "        [[1.6409]]], dtype=torch.float64)\n",
      "tensor([[1.1759],\n",
      "        [0.9923],\n",
      "        [0.8912],\n",
      "        [0.9398]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2457]],\n",
      "\n",
      "        [[0.6010]],\n",
      "\n",
      "        [[0.2856]],\n",
      "\n",
      "        [[1.1325]]], dtype=torch.float64)\n",
      "tensor([[1.4522],\n",
      "        [1.4163],\n",
      "        [1.4233],\n",
      "        [1.0964]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7807]],\n",
      "\n",
      "        [[1.8558]],\n",
      "\n",
      "        [[1.5450]],\n",
      "\n",
      "        [[1.0193]]], dtype=torch.float64)\n",
      "tensor([[1.1660],\n",
      "        [1.1451],\n",
      "        [1.4728],\n",
      "        [1.5669]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8425]],\n",
      "\n",
      "        [[1.3278]],\n",
      "\n",
      "        [[1.7102]],\n",
      "\n",
      "        [[1.7530]]], dtype=torch.float64)\n",
      "tensor([[1.1299],\n",
      "        [1.0434],\n",
      "        [0.8708],\n",
      "        [0.8096]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9881]],\n",
      "\n",
      "        [[0.7686]],\n",
      "\n",
      "        [[0.4693]],\n",
      "\n",
      "        [[0.5132]]], dtype=torch.float64)\n",
      "tensor([[0.7181],\n",
      "        [0.6220],\n",
      "        [0.6390],\n",
      "        [0.6904]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8460]],\n",
      "\n",
      "        [[1.0424]],\n",
      "\n",
      "        [[0.6680]],\n",
      "\n",
      "        [[0.4000]]], dtype=torch.float64)\n",
      "tensor([[0.7932],\n",
      "        [0.7170],\n",
      "        [0.8531],\n",
      "        [0.7531]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2717]],\n",
      "\n",
      "        [[0.5744]],\n",
      "\n",
      "        [[1.0447]],\n",
      "\n",
      "        [[0.9176]]], dtype=torch.float64)\n",
      "tensor([[0.6188],\n",
      "        [0.7306],\n",
      "        [0.9291],\n",
      "        [0.8847]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7039]],\n",
      "\n",
      "        [[0.6218]],\n",
      "\n",
      "        [[0.2428]],\n",
      "\n",
      "        [[0.9326]]], dtype=torch.float64)\n",
      "tensor([[1.2527],\n",
      "        [1.1461],\n",
      "        [1.1890],\n",
      "        [0.9971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4190]],\n",
      "\n",
      "        [[1.6444]],\n",
      "\n",
      "        [[1.3520]],\n",
      "\n",
      "        [[0.9985]]], dtype=torch.float64)\n",
      "tensor([[1.0745],\n",
      "        [1.1391],\n",
      "        [0.9999],\n",
      "        [0.9208]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8876]],\n",
      "\n",
      "        [[1.2515]],\n",
      "\n",
      "        [[1.1649]],\n",
      "\n",
      "        [[0.8194]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.20616:  47%|████▋     | 1434/3067 [00:04<00:04, 327.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5523],\n",
      "        [0.5086],\n",
      "        [0.7345],\n",
      "        [0.8401]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4601]],\n",
      "\n",
      "        [[0.3445]],\n",
      "\n",
      "        [[0.3203]],\n",
      "\n",
      "        [[0.6819]]], dtype=torch.float64)\n",
      "tensor([[0.7373],\n",
      "        [0.6565],\n",
      "        [0.6495],\n",
      "        [0.5802]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0563]],\n",
      "\n",
      "        [[0.9488]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[0.2255]]], dtype=torch.float64)\n",
      "tensor([[0.5447],\n",
      "        [0.6722],\n",
      "        [1.1107],\n",
      "        [1.1608]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0372]],\n",
      "\n",
      "        [[0.6438]],\n",
      "\n",
      "        [[1.4318]],\n",
      "\n",
      "        [[1.5600]]], dtype=torch.float64)\n",
      "tensor([[1.1799],\n",
      "        [1.0046],\n",
      "        [1.0646],\n",
      "        [0.9289]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2480]],\n",
      "\n",
      "        [[1.0239]],\n",
      "\n",
      "        [[0.7223]],\n",
      "\n",
      "        [[0.8795]]], dtype=torch.float64)\n",
      "tensor([[1.0308],\n",
      "        [0.9972],\n",
      "        [0.8673],\n",
      "        [0.8387]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2665]],\n",
      "\n",
      "        [[1.3382]],\n",
      "\n",
      "        [[1.1418]],\n",
      "\n",
      "        [[0.7154]]], dtype=torch.float64)\n",
      "tensor([[0.8263],\n",
      "        [0.8150],\n",
      "        [0.9788],\n",
      "        [0.6253]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6068]],\n",
      "\n",
      "        [[0.8749]],\n",
      "\n",
      "        [[1.2053]],\n",
      "\n",
      "        [[0.6311]]], dtype=torch.float64)\n",
      "tensor([[0.4329],\n",
      "        [0.5760],\n",
      "        [0.5408],\n",
      "        [0.5702]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5432]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.3179]],\n",
      "\n",
      "        [[0.4081]]], dtype=torch.float64)\n",
      "tensor([[0.4122],\n",
      "        [0.3843],\n",
      "        [0.4337],\n",
      "        [0.4320]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6218]],\n",
      "\n",
      "        [[0.8852]],\n",
      "\n",
      "        [[0.5606]],\n",
      "\n",
      "        [[0.1770]]], dtype=torch.float64)\n",
      "tensor([[0.4854],\n",
      "        [0.5183],\n",
      "        [0.4523],\n",
      "        [0.3385]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0476]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.6842]],\n",
      "\n",
      "        [[0.7766]]], dtype=torch.float64)\n",
      "tensor([[0.4090],\n",
      "        [0.4868],\n",
      "        [0.5895],\n",
      "        [0.5577]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4762]],\n",
      "\n",
      "        [[0.3653]],\n",
      "\n",
      "        [[0.1862]],\n",
      "\n",
      "        [[0.5964]]], dtype=torch.float64)\n",
      "tensor([[0.5310],\n",
      "        [0.4003],\n",
      "        [0.4069],\n",
      "        [0.5130]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6807]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[0.4531]],\n",
      "\n",
      "        [[0.2116]]], dtype=torch.float64)\n",
      "tensor([[0.5297],\n",
      "        [0.6820],\n",
      "        [0.4949],\n",
      "        [0.4913]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1862]],\n",
      "\n",
      "        [[0.5097]],\n",
      "\n",
      "        [[0.5144]],\n",
      "\n",
      "        [[0.6958]]], dtype=torch.float64)\n",
      "tensor([[0.5968],\n",
      "        [0.6193],\n",
      "        [0.4744],\n",
      "        [0.4538]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5848]],\n",
      "\n",
      "        [[ 0.2336]],\n",
      "\n",
      "        [[-0.1523]],\n",
      "\n",
      "        [[ 0.4266]]], dtype=torch.float64)\n",
      "tensor([[1.0694],\n",
      "        [1.1306],\n",
      "        [1.0495],\n",
      "        [0.9628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3994]],\n",
      "\n",
      "        [[1.5727]],\n",
      "\n",
      "        [[1.1452]],\n",
      "\n",
      "        [[0.8194]]], dtype=torch.float64)\n",
      "tensor([[0.9836],\n",
      "        [0.9056],\n",
      "        [1.2748],\n",
      "        [1.2901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4728]],\n",
      "\n",
      "        [[1.0736]],\n",
      "\n",
      "        [[1.6143]],\n",
      "\n",
      "        [[1.7171]]], dtype=torch.float64)\n",
      "tensor([[1.2670],\n",
      "        [1.0870],\n",
      "        [0.9212],\n",
      "        [0.9447]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3162]],\n",
      "\n",
      "        [[0.7189]],\n",
      "\n",
      "        [[0.2810]],\n",
      "\n",
      "        [[0.8448]]], dtype=torch.float64)\n",
      "tensor([[1.2845],\n",
      "        [1.1827],\n",
      "        [1.1431],\n",
      "        [1.0485]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4560]],\n",
      "\n",
      "        [[1.5646]],\n",
      "\n",
      "        [[1.1914]],\n",
      "\n",
      "        [[0.8679]]], dtype=torch.float64)\n",
      "tensor([[1.1283],\n",
      "        [1.0040],\n",
      "        [0.9096],\n",
      "        [0.8435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6230]],\n",
      "\n",
      "        [[0.8598]],\n",
      "\n",
      "        [[1.0262]],\n",
      "\n",
      "        [[1.1764]]], dtype=torch.float64)\n",
      "tensor([[0.8142],\n",
      "        [0.6761],\n",
      "        [0.7717],\n",
      "        [0.7243]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8552]],\n",
      "\n",
      "        [[0.5121]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.3538]]], dtype=torch.float64)\n",
      "tensor([[0.2911],\n",
      "        [0.2123],\n",
      "        [0.3180],\n",
      "        [0.4520]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4427]],\n",
      "\n",
      "        [[0.4785]],\n",
      "\n",
      "        [[0.4612]],\n",
      "\n",
      "        [[0.4173]]], dtype=torch.float64)\n",
      "tensor([[0.5573],\n",
      "        [0.4942],\n",
      "        [0.4172],\n",
      "        [0.4599]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3075]],\n",
      "\n",
      "        [[0.2151]],\n",
      "\n",
      "        [[0.4878]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[0.4234],\n",
      "        [0.6451],\n",
      "        [0.8390],\n",
      "        [0.8709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5144]],\n",
      "\n",
      "        [[0.4878]],\n",
      "\n",
      "        [[0.4312]],\n",
      "\n",
      "        [[0.5560]]], dtype=torch.float64)\n",
      "tensor([[0.8126],\n",
      "        [0.7843],\n",
      "        [0.8747],\n",
      "        [0.7474]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8621]],\n",
      "\n",
      "        [[0.9026]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.4312]]], dtype=torch.float64)\n",
      "tensor([[0.7995],\n",
      "        [0.7900],\n",
      "        [1.0882],\n",
      "        [1.3314]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3965]],\n",
      "\n",
      "        [[0.4474]],\n",
      "\n",
      "        [[1.3104]],\n",
      "\n",
      "        [[1.6767]]], dtype=torch.float64)\n",
      "tensor([[1.3701],\n",
      "        [1.1393],\n",
      "        [1.0473],\n",
      "        [0.8960]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3543]],\n",
      "\n",
      "        [[0.9268]],\n",
      "\n",
      "        [[0.4358]],\n",
      "\n",
      "        [[1.1394]]], dtype=torch.float64)\n",
      "tensor([[1.5813],\n",
      "        [1.7260],\n",
      "        [1.3843],\n",
      "        [1.1817]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9783]],\n",
      "\n",
      "        [[1.8662]],\n",
      "\n",
      "        [[1.5577]],\n",
      "\n",
      "        [[0.9292]]], dtype=torch.float64)\n",
      "tensor([[1.2165],\n",
      "        [1.1656],\n",
      "        [1.1849],\n",
      "        [1.2265]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8575]],\n",
      "\n",
      "        [[1.0274]],\n",
      "\n",
      "        [[1.4941]],\n",
      "\n",
      "        [[1.8026]]], dtype=torch.float64)\n",
      "tensor([[1.3641],\n",
      "        [1.0613],\n",
      "        [0.9708],\n",
      "        [1.0048]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3601]],\n",
      "\n",
      "        [[0.7454]],\n",
      "\n",
      "        [[0.7443]],\n",
      "\n",
      "        [[0.7917]]], dtype=torch.float64)\n",
      "tensor([[1.1821],\n",
      "        [1.3460],\n",
      "        [1.3050],\n",
      "        [1.1363]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3844]],\n",
      "\n",
      "        [[1.7911]],\n",
      "\n",
      "        [[1.4537]],\n",
      "\n",
      "        [[0.9465]]], dtype=torch.float64)\n",
      "tensor([[1.0764],\n",
      "        [1.0109],\n",
      "        [1.6005],\n",
      "        [1.5762]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7108]],\n",
      "\n",
      "        [[1.3128]],\n",
      "\n",
      "        [[1.8858]],\n",
      "\n",
      "        [[2.0187]]], dtype=torch.float64)\n",
      "tensor([[1.4720],\n",
      "        [1.2692],\n",
      "        [1.3751],\n",
      "        [1.1281]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6963]],\n",
      "\n",
      "        [[1.4768]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[0.7027]]], dtype=torch.float64)\n",
      "tensor([[0.8300],\n",
      "        [0.7172],\n",
      "        [0.7665],\n",
      "        [0.6153]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9488]],\n",
      "\n",
      "        [[1.2920]],\n",
      "\n",
      "        [[1.0089]],\n",
      "\n",
      "        [[0.4104]]], dtype=torch.float64)\n",
      "tensor([[0.6380],\n",
      "        [0.6084],\n",
      "        [0.8061],\n",
      "        [0.4686]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2394]],\n",
      "\n",
      "        [[0.9453]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[1.0158]]], dtype=torch.float64)\n",
      "tensor([[0.3922],\n",
      "        [0.3669],\n",
      "        [0.6030],\n",
      "        [0.6701]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4058]],\n",
      "\n",
      "        [[0.3283]],\n",
      "\n",
      "        [[0.3237]],\n",
      "\n",
      "        [[0.6264]]], dtype=torch.float64)\n",
      "tensor([[0.5591],\n",
      "        [0.4205],\n",
      "        [0.3471],\n",
      "        [0.3179]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6449]],\n",
      "\n",
      "        [[0.3954]],\n",
      "\n",
      "        [[0.3006]],\n",
      "\n",
      "        [[0.2798]]], dtype=torch.float64)\n",
      "tensor([[0.5003],\n",
      "        [0.4949],\n",
      "        [0.4535],\n",
      "        [0.4541]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1562]],\n",
      "\n",
      "        [[0.3491]],\n",
      "\n",
      "        [[0.7535]],\n",
      "\n",
      "        [[0.8922]]], dtype=torch.float64)\n",
      "tensor([[0.5308],\n",
      "        [0.6438],\n",
      "        [0.7894],\n",
      "        [0.8482]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6149]],\n",
      "\n",
      "        [[0.6010]],\n",
      "\n",
      "        [[0.6438]],\n",
      "\n",
      "        [[0.8656]]], dtype=torch.float64)\n",
      "tensor([[0.8912],\n",
      "        [1.1079],\n",
      "        [0.9700],\n",
      "        [0.9058]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4006]],\n",
      "\n",
      "        [[1.5450]],\n",
      "\n",
      "        [[1.1799]],\n",
      "\n",
      "        [[0.7039]]], dtype=torch.float64)\n",
      "tensor([[0.7973],\n",
      "        [0.8460],\n",
      "        [0.9654],\n",
      "        [0.9155]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6657]],\n",
      "\n",
      "        [[1.1140]],\n",
      "\n",
      "        [[1.0505]],\n",
      "\n",
      "        [[1.3255]]], dtype=torch.float64)\n",
      "tensor([[0.7910],\n",
      "        [0.8108],\n",
      "        [0.9377],\n",
      "        [0.9341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9049]],\n",
      "\n",
      "        [[0.7466]],\n",
      "\n",
      "        [[0.6992]],\n",
      "\n",
      "        [[0.8344]]], dtype=torch.float64)\n",
      "tensor([[0.9540],\n",
      "        [0.8517],\n",
      "        [0.8504],\n",
      "        [0.7684]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0713]],\n",
      "\n",
      "        [[1.1533]],\n",
      "\n",
      "        [[0.9638]],\n",
      "\n",
      "        [[0.6761]]], dtype=torch.float64)\n",
      "tensor([[0.9314],\n",
      "        [0.9771],\n",
      "        [1.3952],\n",
      "        [1.4632]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6611]],\n",
      "\n",
      "        [[1.1718]],\n",
      "\n",
      "        [[1.7414]],\n",
      "\n",
      "        [[1.8304]]], dtype=torch.float64)\n",
      "tensor([[0.9204],\n",
      "        [0.8840],\n",
      "        [0.8862],\n",
      "        [0.7614]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9534]],\n",
      "\n",
      "        [[0.7859]],\n",
      "\n",
      "        [[0.4300]],\n",
      "\n",
      "        [[0.6599]]], dtype=torch.float64)\n",
      "tensor([[0.8635],\n",
      "        [0.8207],\n",
      "        [0.9308],\n",
      "        [0.8010]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1175]],\n",
      "\n",
      "        [[1.3902]],\n",
      "\n",
      "        [[0.9557]],\n",
      "\n",
      "        [[0.5779]]], dtype=torch.float64)\n",
      "tensor([[0.8424],\n",
      "        [0.7012],\n",
      "        [1.0096],\n",
      "        [0.8555]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2867]],\n",
      "\n",
      "        [[0.6045]],\n",
      "\n",
      "        [[1.2885]],\n",
      "\n",
      "        [[1.1441]]], dtype=torch.float64)\n",
      "tensor([[0.8991],\n",
      "        [0.9274],\n",
      "        [0.9994],\n",
      "        [0.9514]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9696]],\n",
      "\n",
      "        [[0.7512]],\n",
      "\n",
      "        [[0.5837]],\n",
      "\n",
      "        [[1.0435]]], dtype=torch.float64)\n",
      "tensor([[1.2880],\n",
      "        [1.2510],\n",
      "        [1.2473],\n",
      "        [0.9890]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7287]],\n",
      "\n",
      "        [[1.8061]],\n",
      "\n",
      "        [[1.2007]],\n",
      "\n",
      "        [[0.8021]]], dtype=torch.float64)\n",
      "tensor([[0.9990],\n",
      "        [0.9706],\n",
      "        [1.5373],\n",
      "        [1.7773]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6842]],\n",
      "\n",
      "        [[1.1776]],\n",
      "\n",
      "        [[2.0418]],\n",
      "\n",
      "        [[2.2787]]], dtype=torch.float64)\n",
      "tensor([[1.5318],\n",
      "        [1.4792],\n",
      "        [1.4360],\n",
      "        [1.1300]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6363]],\n",
      "\n",
      "        [[1.3994]],\n",
      "\n",
      "        [[0.8633]],\n",
      "\n",
      "        [[1.0482]]], dtype=torch.float64)\n",
      "tensor([[1.3938],\n",
      "        [0.9171],\n",
      "        [0.8205],\n",
      "        [0.6620]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8240]],\n",
      "\n",
      "        [[1.2330]],\n",
      "\n",
      "        [[0.7963]],\n",
      "\n",
      "        [[0.4404]]], dtype=torch.float64)\n",
      "tensor([[0.6231],\n",
      "        [0.4202],\n",
      "        [1.0390],\n",
      "        [1.1689]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0418]],\n",
      "\n",
      "        [[0.4346]],\n",
      "\n",
      "        [[1.3185]],\n",
      "\n",
      "        [[1.6328]]], dtype=torch.float64)\n",
      "tensor([[1.1425],\n",
      "        [0.8652],\n",
      "        [0.7582],\n",
      "        [0.6513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1198]],\n",
      "\n",
      "        [[0.5467]],\n",
      "\n",
      "        [[0.2371]],\n",
      "\n",
      "        [[0.4866]]], dtype=torch.float64)\n",
      "tensor([[1.0460],\n",
      "        [1.5608],\n",
      "        [1.6008],\n",
      "        [1.3610]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7021]],\n",
      "\n",
      "        [[1.8477]],\n",
      "\n",
      "        [[1.6397]],\n",
      "\n",
      "        [[1.3324]]], dtype=torch.float64)\n",
      "tensor([[1.3565],\n",
      "        [1.3422],\n",
      "        [1.6569],\n",
      "        [1.4796]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9084]],\n",
      "\n",
      "        [[1.5542]],\n",
      "\n",
      "        [[1.7241]],\n",
      "\n",
      "        [[1.9424]]], dtype=torch.float64)\n",
      "tensor([[1.3021],\n",
      "        [1.1832],\n",
      "        [1.1260],\n",
      "        [1.1220]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3509]],\n",
      "\n",
      "        [[0.9372]],\n",
      "\n",
      "        [[0.7119]],\n",
      "\n",
      "        [[1.0147]]], dtype=torch.float64)\n",
      "tensor([[1.3003],\n",
      "        [1.7786],\n",
      "        [1.7909],\n",
      "        [1.6554]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6859]],\n",
      "\n",
      "        [[2.1319]],\n",
      "\n",
      "        [[1.7876]],\n",
      "\n",
      "        [[1.2839]]], dtype=torch.float64)\n",
      "tensor([[1.4366],\n",
      "        [1.3993],\n",
      "        [1.6715],\n",
      "        [1.9206]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0216]],\n",
      "\n",
      "        [[1.2735]],\n",
      "\n",
      "        [[2.1643]],\n",
      "\n",
      "        [[2.2509]]], dtype=torch.float64)\n",
      "tensor([[1.5703],\n",
      "        [0.8862],\n",
      "        [1.1297],\n",
      "        [0.9612]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9788]],\n",
      "\n",
      "        [[0.7662]],\n",
      "\n",
      "        [[0.7027]],\n",
      "\n",
      "        [[0.7454]]], dtype=torch.float64)\n",
      "tensor([[1.2207],\n",
      "        [1.4819],\n",
      "        [1.3590],\n",
      "        [1.2973]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5947]],\n",
      "\n",
      "        [[1.8870]],\n",
      "\n",
      "        [[1.5554]],\n",
      "\n",
      "        [[1.0747]]], dtype=torch.float64)\n",
      "tensor([[1.2517],\n",
      "        [1.2504],\n",
      "        [1.8662],\n",
      "        [2.1550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9176]],\n",
      "\n",
      "        [[1.3347]],\n",
      "\n",
      "        [[2.3723]],\n",
      "\n",
      "        [[2.7466]]], dtype=torch.float64)\n",
      "tensor([[1.8767],\n",
      "        [1.4789],\n",
      "        [1.1334],\n",
      "        [0.8647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1007]],\n",
      "\n",
      "        [[1.1233]],\n",
      "\n",
      "        [[1.0031]],\n",
      "\n",
      "        [[0.4266]]], dtype=torch.float64)\n",
      "tensor([[0.5509],\n",
      "        [0.4320],\n",
      "        [0.5138],\n",
      "        [0.5764]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4993]],\n",
      "\n",
      "        [[0.6368]],\n",
      "\n",
      "        [[0.5317]],\n",
      "\n",
      "        [[0.4000]]], dtype=torch.float64)\n",
      "tensor([[0.6529],\n",
      "        [0.6513],\n",
      "        [0.7156],\n",
      "        [0.6292]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.20404:  49%|████▉     | 1500/3067 [00:04<00:04, 322.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2151]],\n",
      "\n",
      "        [[0.6253]],\n",
      "\n",
      "        [[0.8887]],\n",
      "\n",
      "        [[1.0482]]], dtype=torch.float64)\n",
      "tensor([[0.6620],\n",
      "        [0.6150],\n",
      "        [0.6380],\n",
      "        [0.5537]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7397]],\n",
      "\n",
      "        [[0.4520]],\n",
      "\n",
      "        [[0.2821]],\n",
      "\n",
      "        [[0.6576]]], dtype=torch.float64)\n",
      "tensor([[0.6856],\n",
      "        [0.5674],\n",
      "        [0.4278],\n",
      "        [0.4246]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9349]],\n",
      "\n",
      "        [[1.0840]],\n",
      "\n",
      "        [[0.5664]],\n",
      "\n",
      "        [[0.3145]]], dtype=torch.float64)\n",
      "tensor([[0.4380],\n",
      "        [0.2855],\n",
      "        [0.4436],\n",
      "        [0.2545]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0056]],\n",
      "\n",
      "        [[ 0.4485]],\n",
      "\n",
      "        [[ 0.6218]],\n",
      "\n",
      "        [[ 0.7166]]], dtype=torch.float64)\n",
      "tensor([[ 0.2921],\n",
      "        [ 0.3100],\n",
      "        [-0.0505],\n",
      "        [-0.0830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5305]],\n",
      "\n",
      "        [[-0.0772]],\n",
      "\n",
      "        [[-0.4192]],\n",
      "\n",
      "        [[-0.0691]]], dtype=torch.float64)\n",
      "tensor([[0.3699],\n",
      "        [0.4956],\n",
      "        [0.4567],\n",
      "        [0.3179]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8252]],\n",
      "\n",
      "        [[ 1.1279]],\n",
      "\n",
      "        [[ 0.4751]],\n",
      "\n",
      "        [[-0.0033]]], dtype=torch.float64)\n",
      "tensor([[0.1804],\n",
      "        [0.3317],\n",
      "        [0.6781],\n",
      "        [0.7120]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1153]],\n",
      "\n",
      "        [[ 0.4485]],\n",
      "\n",
      "        [[ 1.1210]],\n",
      "\n",
      "        [[ 1.2885]]], dtype=torch.float64)\n",
      "tensor([[0.5825],\n",
      "        [0.4627],\n",
      "        [0.4025],\n",
      "        [0.2255]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7535]],\n",
      "\n",
      "        [[ 0.2787]],\n",
      "\n",
      "        [[-0.1049]],\n",
      "\n",
      "        [[ 0.0198]]], dtype=torch.float64)\n",
      "tensor([[0.8107],\n",
      "        [1.0914],\n",
      "        [1.0069],\n",
      "        [0.7914]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4572]],\n",
      "\n",
      "        [[1.8789]],\n",
      "\n",
      "        [[1.1822]],\n",
      "\n",
      "        [[0.6149]]], dtype=torch.float64)\n",
      "tensor([[0.6790],\n",
      "        [0.6158],\n",
      "        [1.2488],\n",
      "        [1.4587]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2267]],\n",
      "\n",
      "        [[0.8182]],\n",
      "\n",
      "        [[1.9078]],\n",
      "\n",
      "        [[2.1065]]], dtype=torch.float64)\n",
      "tensor([[1.2776],\n",
      "        [1.0406],\n",
      "        [0.9503],\n",
      "        [0.8907]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4341]],\n",
      "\n",
      "        [[0.9060]],\n",
      "\n",
      "        [[0.6068]],\n",
      "\n",
      "        [[0.8205]]], dtype=torch.float64)\n",
      "tensor([[1.3578],\n",
      "        [1.4938],\n",
      "        [1.3705],\n",
      "        [1.0111]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9944]],\n",
      "\n",
      "        [[2.2151]],\n",
      "\n",
      "        [[1.4780]],\n",
      "\n",
      "        [[1.0100]]], dtype=torch.float64)\n",
      "tensor([[1.1866],\n",
      "        [1.2278],\n",
      "        [1.0742],\n",
      "        [0.5207]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9719]],\n",
      "\n",
      "        [[1.0528]],\n",
      "\n",
      "        [[1.1787]],\n",
      "\n",
      "        [[1.0655]]], dtype=torch.float64)\n",
      "tensor([[0.6283],\n",
      "        [0.5441],\n",
      "        [0.6173],\n",
      "        [0.6587]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7859]],\n",
      "\n",
      "        [[0.3584]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.6391]]], dtype=torch.float64)\n",
      "tensor([[0.7790],\n",
      "        [0.7415],\n",
      "        [0.7764],\n",
      "        [0.8079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0690]],\n",
      "\n",
      "        [[1.2804]],\n",
      "\n",
      "        [[0.9222]],\n",
      "\n",
      "        [[0.8852]]], dtype=torch.float64)\n",
      "tensor([[1.0004],\n",
      "        [0.8649],\n",
      "        [0.5237],\n",
      "        [0.3608]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7709]],\n",
      "\n",
      "        [[0.4647]],\n",
      "\n",
      "        [[0.7743]],\n",
      "\n",
      "        [[0.7974]]], dtype=torch.float64)\n",
      "tensor([[0.3437],\n",
      "        [0.5042],\n",
      "        [0.6549],\n",
      "        [0.5548]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5583]],\n",
      "\n",
      "        [[0.3387]],\n",
      "\n",
      "        [[0.2648]],\n",
      "\n",
      "        [[0.2763]]], dtype=torch.float64)\n",
      "tensor([[0.4275],\n",
      "        [0.2441],\n",
      "        [0.2214],\n",
      "        [0.5115]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3468]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.3457]]], dtype=torch.float64)\n",
      "tensor([[0.6139],\n",
      "        [0.6486],\n",
      "        [0.7947],\n",
      "        [0.7611]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2717]],\n",
      "\n",
      "        [[0.6114]],\n",
      "\n",
      "        [[0.9037]],\n",
      "\n",
      "        [[1.0297]]], dtype=torch.float64)\n",
      "tensor([[0.7662],\n",
      "        [0.9379],\n",
      "        [1.1911],\n",
      "        [1.2016]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8783]],\n",
      "\n",
      "        [[0.8298]],\n",
      "\n",
      "        [[0.7558]],\n",
      "\n",
      "        [[1.0100]]], dtype=torch.float64)\n",
      "tensor([[1.4458],\n",
      "        [1.4838],\n",
      "        [1.3390],\n",
      "        [1.3124]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5646]],\n",
      "\n",
      "        [[1.8731]],\n",
      "\n",
      "        [[1.3832]],\n",
      "\n",
      "        [[1.1337]]], dtype=torch.float64)\n",
      "tensor([[1.3994],\n",
      "        [1.3598],\n",
      "        [1.7639],\n",
      "        [1.6947]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0054]],\n",
      "\n",
      "        [[1.1441]],\n",
      "\n",
      "        [[2.1354]],\n",
      "\n",
      "        [[2.0175]]], dtype=torch.float64)\n",
      "tensor([[0.6894],\n",
      "        [0.8243],\n",
      "        [0.8849],\n",
      "        [0.8321]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7859]],\n",
      "\n",
      "        [[0.6738]],\n",
      "\n",
      "        [[0.4601]],\n",
      "\n",
      "        [[0.7547]]], dtype=torch.float64)\n",
      "tensor([[0.8803],\n",
      "        [0.8200],\n",
      "        [0.9791],\n",
      "        [1.0316]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0459]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[1.0528]],\n",
      "\n",
      "        [[0.9627]]], dtype=torch.float64)\n",
      "tensor([[1.1675],\n",
      "        [1.0857],\n",
      "        [1.2049],\n",
      "        [1.0834]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7917]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[1.2873]],\n",
      "\n",
      "        [[1.3405]]], dtype=torch.float64)\n",
      "tensor([[0.7224],\n",
      "        [0.6450],\n",
      "        [0.7211],\n",
      "        [0.6416]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7917]],\n",
      "\n",
      "        [[0.4739]],\n",
      "\n",
      "        [[0.3122]],\n",
      "\n",
      "        [[0.6553]]], dtype=torch.float64)\n",
      "tensor([[0.5684],\n",
      "        [0.5848],\n",
      "        [0.3592],\n",
      "        [0.4348]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8679]],\n",
      "\n",
      "        [[0.9731]],\n",
      "\n",
      "        [[0.3803]],\n",
      "\n",
      "        [[0.1331]]], dtype=torch.float64)\n",
      "tensor([[0.3704],\n",
      "        [0.2937],\n",
      "        [0.5979],\n",
      "        [0.5197]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1130]],\n",
      "\n",
      "        [[ 0.4208]],\n",
      "\n",
      "        [[ 0.7697]],\n",
      "\n",
      "        [[ 0.9338]]], dtype=torch.float64)\n",
      "tensor([[ 0.3787],\n",
      "        [ 0.2569],\n",
      "        [ 0.0310],\n",
      "        [-0.1202]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3422]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.3372]],\n",
      "\n",
      "        [[-0.0264]]], dtype=torch.float64)\n",
      "tensor([[0.5375],\n",
      "        [0.6596],\n",
      "        [0.4449],\n",
      "        [0.5832]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8587]],\n",
      "\n",
      "        [[1.0563]],\n",
      "\n",
      "        [[0.6311]],\n",
      "\n",
      "        [[0.3283]]], dtype=torch.float64)\n",
      "tensor([[0.6068],\n",
      "        [0.6959],\n",
      "        [1.1728],\n",
      "        [1.2004]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3630]],\n",
      "\n",
      "        [[0.8691]],\n",
      "\n",
      "        [[1.3070]],\n",
      "\n",
      "        [[1.3509]]], dtype=torch.float64)\n",
      "tensor([[0.8454],\n",
      "        [0.8578],\n",
      "        [0.9885],\n",
      "        [0.9096]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7824]],\n",
      "\n",
      "        [[0.6842]],\n",
      "\n",
      "        [[0.5999]],\n",
      "\n",
      "        [[0.4936]]], dtype=torch.float64)\n",
      "tensor([[0.7000],\n",
      "        [0.3237],\n",
      "        [0.1284],\n",
      "        [0.2503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4728]],\n",
      "\n",
      "        [[0.2509]],\n",
      "\n",
      "        [[0.1654]],\n",
      "\n",
      "        [[0.0857]]], dtype=torch.float64)\n",
      "tensor([[0.3306],\n",
      "        [0.3328],\n",
      "        [0.4975],\n",
      "        [0.4953]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0241]],\n",
      "\n",
      "        [[ 0.1065]],\n",
      "\n",
      "        [[ 0.5236]],\n",
      "\n",
      "        [[ 0.5768]]], dtype=torch.float64)\n",
      "tensor([[ 0.2245],\n",
      "        [ 0.3089],\n",
      "        [ 0.1120],\n",
      "        [-0.1138]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3214]],\n",
      "\n",
      "        [[-0.1165]],\n",
      "\n",
      "        [[-0.3533]],\n",
      "\n",
      "        [[-0.3533]]], dtype=torch.float64)\n",
      "tensor([[0.5644],\n",
      "        [0.6245],\n",
      "        [0.3947],\n",
      "        [0.2270]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8356]],\n",
      "\n",
      "        [[ 1.0528]],\n",
      "\n",
      "        [[ 0.3411]],\n",
      "\n",
      "        [[-0.1454]]], dtype=torch.float64)\n",
      "tensor([[ 0.1094],\n",
      "        [-0.0794],\n",
      "        [ 0.5549],\n",
      "        [ 0.7399]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3372]],\n",
      "\n",
      "        [[-0.0968]],\n",
      "\n",
      "        [[ 0.8437]],\n",
      "\n",
      "        [[ 1.2434]]], dtype=torch.float64)\n",
      "tensor([[0.5209],\n",
      "        [0.3983],\n",
      "        [0.4027],\n",
      "        [0.4100]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5236]],\n",
      "\n",
      "        [[ 0.0453]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[ 0.3052]]], dtype=torch.float64)\n",
      "tensor([[0.6160],\n",
      "        [0.5331],\n",
      "        [0.3467],\n",
      "        [0.3982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9719]],\n",
      "\n",
      "        [[0.9014]],\n",
      "\n",
      "        [[0.5294]],\n",
      "\n",
      "        [[0.0834]]], dtype=torch.float64)\n",
      "tensor([[0.2170],\n",
      "        [0.1216],\n",
      "        [0.3748],\n",
      "        [0.3875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1800]],\n",
      "\n",
      "        [[ 0.2694]],\n",
      "\n",
      "        [[ 0.6565]],\n",
      "\n",
      "        [[ 0.8749]]], dtype=torch.float64)\n",
      "tensor([[ 0.2218],\n",
      "        [-0.0577],\n",
      "        [-0.1823],\n",
      "        [-0.2301]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1758]],\n",
      "\n",
      "        [[-0.2297]],\n",
      "\n",
      "        [[-0.4943]],\n",
      "\n",
      "        [[-0.2135]]], dtype=torch.float64)\n",
      "tensor([[0.4787],\n",
      "        [0.7169],\n",
      "        [0.5409],\n",
      "        [0.2603]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9372]],\n",
      "\n",
      "        [[1.2400]],\n",
      "\n",
      "        [[0.5721]],\n",
      "\n",
      "        [[0.0095]]], dtype=torch.float64)\n",
      "tensor([[ 0.0099],\n",
      "        [-0.1327],\n",
      "        [ 0.6914],\n",
      "        [ 0.9677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2551]],\n",
      "\n",
      "        [[-0.1408]],\n",
      "\n",
      "        [[ 1.2665]],\n",
      "\n",
      "        [[ 1.4780]]], dtype=torch.float64)\n",
      "tensor([[0.7228],\n",
      "        [0.5150],\n",
      "        [0.4395],\n",
      "        [0.3053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6958]],\n",
      "\n",
      "        [[ 0.2371]],\n",
      "\n",
      "        [[-0.0113]],\n",
      "\n",
      "        [[ 0.2810]]], dtype=torch.float64)\n",
      "tensor([[0.8487],\n",
      "        [1.1978],\n",
      "        [0.9162],\n",
      "        [0.6961]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5034]],\n",
      "\n",
      "        [[1.8038]],\n",
      "\n",
      "        [[0.9708]],\n",
      "\n",
      "        [[0.4947]]], dtype=torch.float64)\n",
      "tensor([[0.7070],\n",
      "        [0.6567],\n",
      "        [0.9249],\n",
      "        [0.9646]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2648]],\n",
      "\n",
      "        [[0.3515]],\n",
      "\n",
      "        [[1.2261]],\n",
      "\n",
      "        [[1.2215]]], dtype=torch.float64)\n",
      "tensor([[0.6243],\n",
      "        [0.7174],\n",
      "        [0.8217],\n",
      "        [0.8713]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7836]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.4693]],\n",
      "\n",
      "        [[0.5918]]], dtype=torch.float64)\n",
      "tensor([[0.8335],\n",
      "        [0.8106],\n",
      "        [0.5034],\n",
      "        [0.4663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9534]],\n",
      "\n",
      "        [[1.2018]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[0.2717]]], dtype=torch.float64)\n",
      "tensor([[0.5350],\n",
      "        [0.4082],\n",
      "        [0.5634],\n",
      "        [1.0030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0499]],\n",
      "\n",
      "        [[0.0441]],\n",
      "\n",
      "        [[1.2654]],\n",
      "\n",
      "        [[1.5115]]], dtype=torch.float64)\n",
      "tensor([[0.6842],\n",
      "        [0.4642],\n",
      "        [0.4625],\n",
      "        [0.2418]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7270]],\n",
      "\n",
      "        [[ 0.2024]],\n",
      "\n",
      "        [[-0.0599]],\n",
      "\n",
      "        [[-0.1315]]], dtype=torch.float64)\n",
      "tensor([[0.7473],\n",
      "        [1.1710],\n",
      "        [0.7837],\n",
      "        [0.5606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4838]],\n",
      "\n",
      "        [[1.8569]],\n",
      "\n",
      "        [[0.8795]],\n",
      "\n",
      "        [[0.2163]]], dtype=torch.float64)\n",
      "tensor([[0.4717],\n",
      "        [0.3058],\n",
      "        [0.7899],\n",
      "        [1.1719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0587]],\n",
      "\n",
      "        [[ 0.3191]],\n",
      "\n",
      "        [[ 1.5981]],\n",
      "\n",
      "        [[ 1.7102]]], dtype=torch.float64)\n",
      "tensor([[0.7540],\n",
      "        [0.5629],\n",
      "        [0.5337],\n",
      "        [0.3530]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9164]],\n",
      "\n",
      "        [[ 0.2833]],\n",
      "\n",
      "        [[-0.0321]],\n",
      "\n",
      "        [[ 0.2787]]], dtype=torch.float64)\n",
      "tensor([[0.7424],\n",
      "        [1.0712],\n",
      "        [0.7810],\n",
      "        [0.4971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5427]],\n",
      "\n",
      "        [[1.7599]],\n",
      "\n",
      "        [[0.8621]],\n",
      "\n",
      "        [[0.2463]]], dtype=torch.float64)\n",
      "tensor([[0.5436],\n",
      "        [0.3765],\n",
      "        [0.8336],\n",
      "        [0.9891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0499]],\n",
      "\n",
      "        [[0.4011]],\n",
      "\n",
      "        [[1.5843]],\n",
      "\n",
      "        [[1.6097]]], dtype=torch.float64)\n",
      "tensor([[0.7528],\n",
      "        [0.6204],\n",
      "        [0.6609],\n",
      "        [0.5683]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8725]],\n",
      "\n",
      "        [[0.4277]],\n",
      "\n",
      "        [[0.3099]],\n",
      "\n",
      "        [[0.5952]]], dtype=torch.float64)\n",
      "tensor([[0.9548],\n",
      "        [1.0188],\n",
      "        [0.7508],\n",
      "        [0.6598]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6640]],\n",
      "\n",
      "        [[1.6051]],\n",
      "\n",
      "        [[0.9708]],\n",
      "\n",
      "        [[0.6958]]], dtype=torch.float64)\n",
      "tensor([[0.7735],\n",
      "        [0.8660],\n",
      "        [0.7054],\n",
      "        [0.4848]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6865]],\n",
      "\n",
      "        [[0.8078]],\n",
      "\n",
      "        [[0.9372]],\n",
      "\n",
      "        [[0.8956]]], dtype=torch.float64)\n",
      "tensor([[0.4560],\n",
      "        [0.6886],\n",
      "        [0.7141],\n",
      "        [0.6586]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7917]],\n",
      "\n",
      "        [[0.6056]],\n",
      "\n",
      "        [[0.3607]],\n",
      "\n",
      "        [[0.7593]]], dtype=torch.float64)\n",
      "tensor([[ 0.6375],\n",
      "        [ 0.5890],\n",
      "        [ 0.1671],\n",
      "        [-0.1640]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9927]],\n",
      "\n",
      "        [[ 0.9996]],\n",
      "\n",
      "        [[-0.1223]],\n",
      "\n",
      "        [[-0.1130]]], dtype=torch.float64)\n",
      "tensor([[-0.0317],\n",
      "        [-0.1619],\n",
      "        [-0.0841],\n",
      "        [-0.2182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2794]],\n",
      "\n",
      "        [[-0.1442]],\n",
      "\n",
      "        [[ 0.1319]],\n",
      "\n",
      "        [[ 0.0014]]], dtype=torch.float64)\n",
      "tensor([[-0.2862],\n",
      "        [-0.1631],\n",
      "        [-0.1143],\n",
      "        [-0.3642]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0922]],\n",
      "\n",
      "        [[-0.1003]],\n",
      "\n",
      "        [[-0.2690]],\n",
      "\n",
      "        [[-0.4423]]], dtype=torch.float64)\n",
      "tensor([[-0.3132],\n",
      "        [-0.3629],\n",
      "        [-0.5955],\n",
      "        [-0.4808]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1200]],\n",
      "\n",
      "        [[-0.4181]],\n",
      "\n",
      "        [[-0.5151]],\n",
      "\n",
      "        [[-0.5347]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.20404:  51%|█████     | 1566/3067 [00:04<00:04, 318.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3555],\n",
      "        [-0.3560],\n",
      "        [-0.0339],\n",
      "        [ 0.0103]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6849]],\n",
      "\n",
      "        [[-0.4377]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[ 0.0996]]], dtype=torch.float64)\n",
      "tensor([[-0.3898],\n",
      "        [-0.1402],\n",
      "        [ 0.0934],\n",
      "        [ 0.2629]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1962]],\n",
      "\n",
      "        [[-0.2782]],\n",
      "\n",
      "        [[-0.2205]],\n",
      "\n",
      "        [[-0.0876]]], dtype=torch.float64)\n",
      "tensor([[0.3296],\n",
      "        [0.4268],\n",
      "        [0.5364],\n",
      "        [0.6982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3457]],\n",
      "\n",
      "        [[0.8679]],\n",
      "\n",
      "        [[0.9257]],\n",
      "\n",
      "        [[0.7397]]], dtype=torch.float64)\n",
      "tensor([[0.8574],\n",
      "        [0.8481],\n",
      "        [0.5300],\n",
      "        [0.3698]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6738]],\n",
      "\n",
      "        [[0.7212]],\n",
      "\n",
      "        [[0.7362]],\n",
      "\n",
      "        [[0.5213]]], dtype=torch.float64)\n",
      "tensor([[0.3811],\n",
      "        [0.5450],\n",
      "        [0.1829],\n",
      "        [0.2542]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5201]],\n",
      "\n",
      "        [[-0.0090]],\n",
      "\n",
      "        [[-0.0992]],\n",
      "\n",
      "        [[-0.0737]]], dtype=torch.float64)\n",
      "tensor([[ 0.0199],\n",
      "        [-0.1451],\n",
      "        [-0.1822],\n",
      "        [-0.1688]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0529]],\n",
      "\n",
      "        [[-0.0483]],\n",
      "\n",
      "        [[-0.1373]],\n",
      "\n",
      "        [[-0.2008]]], dtype=torch.float64)\n",
      "tensor([[ 0.0692],\n",
      "        [-0.1724],\n",
      "        [-0.0401],\n",
      "        [-0.1198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3453]],\n",
      "\n",
      "        [[-0.3741]],\n",
      "\n",
      "        [[ 0.2197]],\n",
      "\n",
      "        [[ 0.1943]]], dtype=torch.float64)\n",
      "tensor([[-0.4044],\n",
      "        [-0.4800],\n",
      "        [-0.4993],\n",
      "        [-0.6069]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4273]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-1.0454]],\n",
      "\n",
      "        [[-0.9576]]], dtype=torch.float64)\n",
      "tensor([[-0.4745],\n",
      "        [-0.4283],\n",
      "        [-0.6757],\n",
      "        [-0.7137]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4354]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.6491]],\n",
      "\n",
      "        [[-1.0258]]], dtype=torch.float64)\n",
      "tensor([[-0.7338],\n",
      "        [-0.7761],\n",
      "        [-0.6135],\n",
      "        [-0.0652]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2800]],\n",
      "\n",
      "        [[-1.2973]],\n",
      "\n",
      "        [[-0.1234]],\n",
      "\n",
      "        [[ 0.0799]]], dtype=torch.float64)\n",
      "tensor([[-0.5439],\n",
      "        [-0.6919],\n",
      "        [-0.7681],\n",
      "        [-0.7462]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5232]],\n",
      "\n",
      "        [[-0.9877]],\n",
      "\n",
      "        [[-1.2569]],\n",
      "\n",
      "        [[-0.8467]]], dtype=torch.float64)\n",
      "tensor([[-0.0979],\n",
      "        [ 0.2654],\n",
      "        [-0.0606],\n",
      "        [-0.4317]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3572]],\n",
      "\n",
      "        [[ 0.5144]],\n",
      "\n",
      "        [[-0.1200]],\n",
      "\n",
      "        [[-0.3568]]], dtype=torch.float64)\n",
      "tensor([[-0.3929],\n",
      "        [-0.5093],\n",
      "        [ 0.0758],\n",
      "        [ 0.0783]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6457]],\n",
      "\n",
      "        [[-0.7092]],\n",
      "\n",
      "        [[ 0.3930]],\n",
      "\n",
      "        [[ 0.2590]]], dtype=torch.float64)\n",
      "tensor([[-0.3000],\n",
      "        [-0.4998],\n",
      "        [-0.5071],\n",
      "        [-0.3177]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3222]],\n",
      "\n",
      "        [[-0.7554]],\n",
      "\n",
      "        [[-0.7624]],\n",
      "\n",
      "        [[-0.1292]]], dtype=torch.float64)\n",
      "tensor([[ 0.3819],\n",
      "        [ 0.4162],\n",
      "        [-0.2812],\n",
      "        [-0.3475]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8229]],\n",
      "\n",
      "        [[ 0.7928]],\n",
      "\n",
      "        [[-0.2933]],\n",
      "\n",
      "        [[-0.3557]]], dtype=torch.float64)\n",
      "tensor([[-0.1861],\n",
      "        [-0.0130],\n",
      "        [-0.1034],\n",
      "        [-0.2654]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[-0.3626]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[-0.1038]]], dtype=torch.float64)\n",
      "tensor([[-0.4977],\n",
      "        [-0.5231],\n",
      "        [-0.4156],\n",
      "        [-0.2641]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3741]],\n",
      "\n",
      "        [[-0.5960]],\n",
      "\n",
      "        [[-0.5036]],\n",
      "\n",
      "        [[-0.3961]]], dtype=torch.float64)\n",
      "tensor([[-0.3834],\n",
      "        [-0.3592],\n",
      "        [-0.6592],\n",
      "        [-0.7357]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1766]],\n",
      "\n",
      "        [[-0.2517]],\n",
      "\n",
      "        [[-0.6642]],\n",
      "\n",
      "        [[-1.0697]]], dtype=torch.float64)\n",
      "tensor([[-0.8220],\n",
      "        [-0.8233],\n",
      "        [-0.5783],\n",
      "        [-0.1874]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2915]],\n",
      "\n",
      "        [[-1.3262]],\n",
      "\n",
      "        [[-0.1280]],\n",
      "\n",
      "        [[-0.0922]]], dtype=torch.float64)\n",
      "tensor([[-0.6461],\n",
      "        [-0.8635],\n",
      "        [-0.8912],\n",
      "        [-0.8870]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7982]],\n",
      "\n",
      "        [[-1.1332]],\n",
      "\n",
      "        [[-1.3932]],\n",
      "\n",
      "        [[-1.4152]]], dtype=torch.float64)\n",
      "tensor([[-0.7155],\n",
      "        [-0.1207],\n",
      "        [-0.6316],\n",
      "        [-0.7708]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1858]],\n",
      "\n",
      "        [[ 0.0025]],\n",
      "\n",
      "        [[-0.6953]],\n",
      "\n",
      "        [[-0.9357]]], dtype=torch.float64)\n",
      "tensor([[-0.7802],\n",
      "        [-0.8522],\n",
      "        [-0.4846],\n",
      "        [-0.0398]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3146]],\n",
      "\n",
      "        [[-1.0570]],\n",
      "\n",
      "        [[-0.0183]],\n",
      "\n",
      "        [[ 0.1192]]], dtype=torch.float64)\n",
      "tensor([[-0.4368],\n",
      "        [-0.6248],\n",
      "        [-0.5324],\n",
      "        [-0.4856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5948]],\n",
      "\n",
      "        [[-0.6780]],\n",
      "\n",
      "        [[-0.6191]],\n",
      "\n",
      "        [[-0.3984]]], dtype=torch.float64)\n",
      "tensor([[ 0.0917],\n",
      "        [ 0.2919],\n",
      "        [-0.1442],\n",
      "        [-0.2489]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3191]],\n",
      "\n",
      "        [[ 0.3653]],\n",
      "\n",
      "        [[ 0.0603]],\n",
      "\n",
      "        [[-0.1789]]], dtype=torch.float64)\n",
      "tensor([[-0.3640],\n",
      "        [-0.4406],\n",
      "        [-0.2543],\n",
      "        [-0.0729]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4620]],\n",
      "\n",
      "        [[-0.3406]],\n",
      "\n",
      "        [[ 0.0822]],\n",
      "\n",
      "        [[ 0.0926]]], dtype=torch.float64)\n",
      "tensor([[-0.2499],\n",
      "        [-0.3148],\n",
      "        [-0.0322],\n",
      "        [ 0.0808]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1084]],\n",
      "\n",
      "        [[-0.1743]],\n",
      "\n",
      "        [[-0.1072]],\n",
      "\n",
      "        [[-0.1974]]], dtype=torch.float64)\n",
      "tensor([[ 0.0721],\n",
      "        [ 0.1357],\n",
      "        [-0.1436],\n",
      "        [-0.3450]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2891]],\n",
      "\n",
      "        [[ 0.4011]],\n",
      "\n",
      "        [[-0.0795]],\n",
      "\n",
      "        [[-0.5220]]], dtype=torch.float64)\n",
      "tensor([[-0.5434],\n",
      "        [-0.5269],\n",
      "        [-0.3731],\n",
      "        [-0.0311]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8352]],\n",
      "\n",
      "        [[-0.8328]],\n",
      "\n",
      "        [[-0.0680]],\n",
      "\n",
      "        [[ 0.2197]]], dtype=torch.float64)\n",
      "tensor([[-0.0470],\n",
      "        [ 0.0975],\n",
      "        [ 0.2450],\n",
      "        [-0.0012]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0545]],\n",
      "\n",
      "        [[ 0.0210]],\n",
      "\n",
      "        [[-0.0784]],\n",
      "\n",
      "        [[-0.1442]]], dtype=torch.float64)\n",
      "tensor([[ 0.2065],\n",
      "        [ 0.4436],\n",
      "        [ 0.0419],\n",
      "        [-0.2236]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5479]],\n",
      "\n",
      "        [[ 0.7258]],\n",
      "\n",
      "        [[ 0.0395]],\n",
      "\n",
      "        [[-0.3487]]], dtype=torch.float64)\n",
      "tensor([[-0.2573],\n",
      "        [-0.3323],\n",
      "        [-0.0459],\n",
      "        [ 0.3580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5093]],\n",
      "\n",
      "        [[-0.6214]],\n",
      "\n",
      "        [[ 0.5097]],\n",
      "\n",
      "        [[ 0.7651]]], dtype=torch.float64)\n",
      "tensor([[0.0485],\n",
      "        [0.0754],\n",
      "        [0.2952],\n",
      "        [0.1425]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2220]],\n",
      "\n",
      "        [[ 0.1250]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.1153]]], dtype=torch.float64)\n",
      "tensor([[0.0974],\n",
      "        [0.1976],\n",
      "        [0.1449],\n",
      "        [0.1528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2856]],\n",
      "\n",
      "        [[0.4485]],\n",
      "\n",
      "        [[0.2775]],\n",
      "\n",
      "        [[0.0141]]], dtype=torch.float64)\n",
      "tensor([[ 0.0883],\n",
      "        [-0.0466],\n",
      "        [ 0.0750],\n",
      "        [ 0.3920]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2540]],\n",
      "\n",
      "        [[-0.3337]],\n",
      "\n",
      "        [[ 0.6461]],\n",
      "\n",
      "        [[ 0.5178]]], dtype=torch.float64)\n",
      "tensor([[-0.0569],\n",
      "        [ 0.0768],\n",
      "        [ 0.0667],\n",
      "        [-0.1699]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0672]],\n",
      "\n",
      "        [[-0.1662]],\n",
      "\n",
      "        [[-0.2944]],\n",
      "\n",
      "        [[-0.5486]]], dtype=torch.float64)\n",
      "tensor([[ 0.0316],\n",
      "        [ 0.1126],\n",
      "        [-0.3024],\n",
      "        [-0.3315]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0256]],\n",
      "\n",
      "        [[ 0.1435]],\n",
      "\n",
      "        [[-0.3776]],\n",
      "\n",
      "        [[-0.5151]]], dtype=torch.float64)\n",
      "tensor([[-0.2500],\n",
      "        [-0.3769],\n",
      "        [-0.2368],\n",
      "        [ 0.2315]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6699]],\n",
      "\n",
      "        [[-0.7774]],\n",
      "\n",
      "        [[ 0.3318]],\n",
      "\n",
      "        [[ 0.4739]]], dtype=torch.float64)\n",
      "tensor([[ 0.0953],\n",
      "        [-0.2854],\n",
      "        [-0.2227],\n",
      "        [-0.2892]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1719]],\n",
      "\n",
      "        [[-0.4492]],\n",
      "\n",
      "        [[-0.5243]],\n",
      "\n",
      "        [[-0.3973]]], dtype=torch.float64)\n",
      "tensor([[ 0.0908],\n",
      "        [ 0.3172],\n",
      "        [-0.0212],\n",
      "        [-0.3246]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5225]],\n",
      "\n",
      "        [[ 0.5536]],\n",
      "\n",
      "        [[-0.2066]],\n",
      "\n",
      "        [[-0.5267]]], dtype=torch.float64)\n",
      "tensor([[-0.4080],\n",
      "        [-0.4207],\n",
      "        [-0.2422],\n",
      "        [ 0.1722]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7023]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[ 0.2301]],\n",
      "\n",
      "        [[ 0.4809]]], dtype=torch.float64)\n",
      "tensor([[-0.0576],\n",
      "        [-0.3468],\n",
      "        [-0.3963],\n",
      "        [-0.5961]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2020]],\n",
      "\n",
      "        [[-0.4724]],\n",
      "\n",
      "        [[-0.7358]],\n",
      "\n",
      "        [[-0.8675]]], dtype=torch.float64)\n",
      "tensor([[-0.3316],\n",
      "        [-0.0356],\n",
      "        [-0.1463],\n",
      "        [-0.2223]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1562]],\n",
      "\n",
      "        [[ 0.3064]],\n",
      "\n",
      "        [[-0.1789]],\n",
      "\n",
      "        [[-0.3429]]], dtype=torch.float64)\n",
      "tensor([[-0.2324],\n",
      "        [-0.5908],\n",
      "        [-0.3885],\n",
      "        [ 0.0236]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7681]],\n",
      "\n",
      "        [[-0.8941]],\n",
      "\n",
      "        [[ 0.1862]],\n",
      "\n",
      "        [[ 0.2798]]], dtype=torch.float64)\n",
      "tensor([[-0.1096],\n",
      "        [-0.4135],\n",
      "        [-0.3534],\n",
      "        [-0.3499]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1223]],\n",
      "\n",
      "        [[-0.4539]],\n",
      "\n",
      "        [[-0.4365]],\n",
      "\n",
      "        [[-0.5012]]], dtype=torch.float64)\n",
      "tensor([[-0.4936],\n",
      "        [-0.5424],\n",
      "        [-0.5337],\n",
      "        [-0.5134]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4400]],\n",
      "\n",
      "        [[-0.3741]],\n",
      "\n",
      "        [[-0.6607]],\n",
      "\n",
      "        [[-0.7115]]], dtype=torch.float64)\n",
      "tensor([[-0.4805],\n",
      "        [-0.5817],\n",
      "        [-0.5979],\n",
      "        [-0.2715]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8594]],\n",
      "\n",
      "        [[-0.9981]],\n",
      "\n",
      "        [[-0.1974]],\n",
      "\n",
      "        [[-0.0610]]], dtype=torch.float64)\n",
      "tensor([[-0.3650],\n",
      "        [-0.5492],\n",
      "        [-0.5946],\n",
      "        [-0.6030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4677]],\n",
      "\n",
      "        [[-0.8155]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-1.0628]]], dtype=torch.float64)\n",
      "tensor([[-0.7120],\n",
      "        [-0.3521],\n",
      "        [-0.7396],\n",
      "        [-0.7229]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4643]],\n",
      "\n",
      "        [[-0.3025]],\n",
      "\n",
      "        [[-0.7635]],\n",
      "\n",
      "        [[-0.8733]]], dtype=torch.float64)\n",
      "tensor([[-0.5689],\n",
      "        [-0.5267],\n",
      "        [-0.4937],\n",
      "        [-0.6240]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7912]],\n",
      "\n",
      "        [[-0.6930]],\n",
      "\n",
      "        [[-0.4955]],\n",
      "\n",
      "        [[-0.6041]]], dtype=torch.float64)\n",
      "tensor([[-0.7931],\n",
      "        [-0.7687],\n",
      "        [-0.6676],\n",
      "        [-0.7225]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7023]],\n",
      "\n",
      "        [[-0.7185]],\n",
      "\n",
      "        [[-0.8259]],\n",
      "\n",
      "        [[-1.0408]]], dtype=torch.float64)\n",
      "tensor([[-0.9316],\n",
      "        [-0.8416],\n",
      "        [-0.8137],\n",
      "        [-0.9013]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9865]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-0.7878]],\n",
      "\n",
      "        [[-1.1991]]], dtype=torch.float64)\n",
      "tensor([[-0.7708],\n",
      "        [-0.8298],\n",
      "        [-0.7274],\n",
      "        [-0.6034]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2107]],\n",
      "\n",
      "        [[-1.1829]],\n",
      "\n",
      "        [[-0.4562]],\n",
      "\n",
      "        [[-0.3707]]], dtype=torch.float64)\n",
      "tensor([[-0.8415],\n",
      "        [-0.8573],\n",
      "        [-0.8592],\n",
      "        [-0.9119]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9091]],\n",
      "\n",
      "        [[-1.1748]],\n",
      "\n",
      "        [[-1.3447]],\n",
      "\n",
      "        [[-1.4891]]], dtype=torch.float64)\n",
      "tensor([[-0.9297],\n",
      "        [-0.5271],\n",
      "        [-0.8585],\n",
      "        [-0.9518]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4989]],\n",
      "\n",
      "        [[-0.2886]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.3528]]], dtype=torch.float64)\n",
      "tensor([[-0.9623],\n",
      "        [-1.0380],\n",
      "        [-1.0334],\n",
      "        [-0.6767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4903]],\n",
      "\n",
      "        [[-1.4822]],\n",
      "\n",
      "        [[-0.6930]],\n",
      "\n",
      "        [[-0.5394]]], dtype=torch.float64)\n",
      "tensor([[-0.9436],\n",
      "        [-1.0812],\n",
      "        [-1.0714],\n",
      "        [-1.0793]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1078]],\n",
      "\n",
      "        [[-1.4741]],\n",
      "\n",
      "        [[-1.5215]],\n",
      "\n",
      "        [[-1.4152]]], dtype=torch.float64)\n",
      "tensor([[-1.1622],\n",
      "        [-1.2800],\n",
      "        [-1.3378],\n",
      "        [-1.1339]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3262]],\n",
      "\n",
      "        [[-1.3505]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.4290]]], dtype=torch.float64)\n",
      "tensor([[-1.0780],\n",
      "        [-1.1262],\n",
      "        [-1.1274],\n",
      "        [-1.1710]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4209]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.2754]],\n",
      "\n",
      "        [[-1.2199]]], dtype=torch.float64)\n",
      "tensor([[-1.2858],\n",
      "        [-1.1557],\n",
      "        [-1.0154],\n",
      "        [-0.9359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3204]],\n",
      "\n",
      "        [[-1.3944]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.2153]]], dtype=torch.float64)\n",
      "tensor([[-1.0004],\n",
      "        [-1.0608],\n",
      "        [-1.1761],\n",
      "        [-1.1297]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0073]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.2823]],\n",
      "\n",
      "        [[-1.1841]]], dtype=torch.float64)\n",
      "tensor([[-1.0231],\n",
      "        [-0.9480],\n",
      "        [-0.8562],\n",
      "        [-0.7580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1748]],\n",
      "\n",
      "        [[-1.0720]],\n",
      "\n",
      "        [[-0.5232]],\n",
      "\n",
      "        [[-0.4227]]], dtype=torch.float64)\n",
      "tensor([[-0.7437],\n",
      "        [-0.7243],\n",
      "        [-0.6234],\n",
      "        [-0.5694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5867]],\n",
      "\n",
      "        [[-0.6988]],\n",
      "\n",
      "        [[-0.7127]],\n",
      "\n",
      "        [[-0.6977]]], dtype=torch.float64)\n",
      "tensor([[-0.6931],\n",
      "        [-0.6105],\n",
      "        [-0.6230],\n",
      "        [-0.7692]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4319]],\n",
      "\n",
      "        [[-0.2193]],\n",
      "\n",
      "        [[-0.4735]],\n",
      "\n",
      "        [[-0.9888]]], dtype=torch.float64)\n",
      "tensor([[-0.8263],\n",
      "        [-0.8222],\n",
      "        [-0.9271],\n",
      "        [-0.8398]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0813]],\n",
      "\n",
      "        [[-1.1332]],\n",
      "\n",
      "        [[-0.7150]],\n",
      "\n",
      "        [[-0.4804]]], dtype=torch.float64)\n",
      "tensor([[-0.8734],\n",
      "        [-0.7304],\n",
      "        [-0.5585],\n",
      "        [-0.5657]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5787]],\n",
      "\n",
      "        [[-0.5879]],\n",
      "\n",
      "        [[-0.6630]],\n",
      "\n",
      "        [[-0.6676]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.20152:  53%|█████▎    | 1635/3067 [00:05<00:04, 326.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6792],\n",
      "        [-0.3996],\n",
      "        [-0.6901],\n",
      "        [-0.8100]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2886]],\n",
      "\n",
      "        [[-0.0102]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-0.8178]]], dtype=torch.float64)\n",
      "tensor([[-0.9263],\n",
      "        [-1.1016],\n",
      "        [-0.9658],\n",
      "        [-0.5297]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2580]],\n",
      "\n",
      "        [[-1.2187]],\n",
      "\n",
      "        [[-0.3014]],\n",
      "\n",
      "        [[-0.1870]]], dtype=torch.float64)\n",
      "tensor([[-0.8359],\n",
      "        [-0.9385],\n",
      "        [-1.0665],\n",
      "        [-1.1309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7820]],\n",
      "\n",
      "        [[-0.9634]],\n",
      "\n",
      "        [[-1.1991]],\n",
      "\n",
      "        [[-1.3019]]], dtype=torch.float64)\n",
      "tensor([[-1.0669],\n",
      "        [-0.5099],\n",
      "        [-0.8860],\n",
      "        [-1.0388]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3580]],\n",
      "\n",
      "        [[-0.1026]],\n",
      "\n",
      "        [[-0.7462]],\n",
      "\n",
      "        [[-1.0154]]], dtype=torch.float64)\n",
      "tensor([[-1.0759],\n",
      "        [-1.0750],\n",
      "        [-1.0701],\n",
      "        [-0.7553]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1876]],\n",
      "\n",
      "        [[-1.1806]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.3222]]], dtype=torch.float64)\n",
      "tensor([[-0.9371],\n",
      "        [-1.1026],\n",
      "        [-1.0724],\n",
      "        [-1.0140]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8918]],\n",
      "\n",
      "        [[-1.1148]],\n",
      "\n",
      "        [[-1.2280]],\n",
      "\n",
      "        [[-1.1772]]], dtype=torch.float64)\n",
      "tensor([[-0.7909],\n",
      "        [-0.7105],\n",
      "        [-1.2108],\n",
      "        [-0.9100]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0957]],\n",
      "\n",
      "        [[-0.7046]],\n",
      "\n",
      "        [[-0.9322]],\n",
      "\n",
      "        [[-0.6907]]], dtype=torch.float64)\n",
      "tensor([[-0.6132],\n",
      "        [-0.4050],\n",
      "        [-0.4648],\n",
      "        [-0.6098]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6018]],\n",
      "\n",
      "        [[-0.6353]],\n",
      "\n",
      "        [[-0.3880]],\n",
      "\n",
      "        [[-0.4435]]], dtype=torch.float64)\n",
      "tensor([[-0.6280],\n",
      "        [-0.4313],\n",
      "        [-0.4711],\n",
      "        [-0.4510]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3996]],\n",
      "\n",
      "        [[-0.4932]],\n",
      "\n",
      "        [[-0.5394]],\n",
      "\n",
      "        [[-0.5775]]], dtype=torch.float64)\n",
      "tensor([[-0.3974],\n",
      "        [-0.4922],\n",
      "        [-0.4098],\n",
      "        [-0.3611]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1592]],\n",
      "\n",
      "        [[-0.2436]],\n",
      "\n",
      "        [[-0.2008]],\n",
      "\n",
      "        [[-0.2933]]], dtype=torch.float64)\n",
      "tensor([[-0.3903],\n",
      "        [-0.5878],\n",
      "        [-0.6591],\n",
      "        [-0.6293]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4735]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.1269]],\n",
      "\n",
      "        [[-0.2944]]], dtype=torch.float64)\n",
      "tensor([[-0.9596],\n",
      "        [-1.1052],\n",
      "        [-1.1860],\n",
      "        [-1.1687]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9657]],\n",
      "\n",
      "        [[-1.3308]],\n",
      "\n",
      "        [[-1.4776]],\n",
      "\n",
      "        [[-1.4371]]], dtype=torch.float64)\n",
      "tensor([[-0.9261],\n",
      "        [-0.7298],\n",
      "        [-0.9938],\n",
      "        [-0.6677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3822]],\n",
      "\n",
      "        [[-0.8178]],\n",
      "\n",
      "        [[-0.9403]],\n",
      "\n",
      "        [[-0.6642]]], dtype=torch.float64)\n",
      "tensor([[-0.1551],\n",
      "        [-0.0124],\n",
      "        [-0.3840],\n",
      "        [-0.4879]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1003]],\n",
      "\n",
      "        [[-0.2332]],\n",
      "\n",
      "        [[-0.0703]],\n",
      "\n",
      "        [[-0.2725]]], dtype=torch.float64)\n",
      "tensor([[-0.8367],\n",
      "        [-0.9554],\n",
      "        [-0.9379],\n",
      "        [-0.7585]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9126]],\n",
      "\n",
      "        [[-1.3042]],\n",
      "\n",
      "        [[-1.4105]],\n",
      "\n",
      "        [[-1.0535]]], dtype=torch.float64)\n",
      "tensor([[-0.4979],\n",
      "        [-0.4650],\n",
      "        [-0.3049],\n",
      "        [-0.0629]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3788]],\n",
      "\n",
      "        [[-0.0784]],\n",
      "\n",
      "        [[-0.0841]],\n",
      "\n",
      "        [[ 0.0337]]], dtype=torch.float64)\n",
      "tensor([[ 0.1364],\n",
      "        [ 0.0056],\n",
      "        [ 0.0154],\n",
      "        [-0.3996]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0326]],\n",
      "\n",
      "        [[-0.0541]],\n",
      "\n",
      "        [[ 0.4081]],\n",
      "\n",
      "        [[-0.4342]]], dtype=torch.float64)\n",
      "tensor([[-0.7167],\n",
      "        [-0.7341],\n",
      "        [-0.8621],\n",
      "        [-0.8149]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5937]],\n",
      "\n",
      "        [[-0.8444]],\n",
      "\n",
      "        [[-1.1679]],\n",
      "\n",
      "        [[-1.0258]]], dtype=torch.float64)\n",
      "tensor([[-0.4721],\n",
      "        [-0.4589],\n",
      "        [-0.4636],\n",
      "        [-0.2718]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4053]],\n",
      "\n",
      "        [[-0.4146]],\n",
      "\n",
      "        [[-0.2621]],\n",
      "\n",
      "        [[-0.3129]]], dtype=torch.float64)\n",
      "tensor([[-0.2099],\n",
      "        [-0.1222],\n",
      "        [-0.3560],\n",
      "        [-0.5741]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2066]],\n",
      "\n",
      "        [[-0.1812]],\n",
      "\n",
      "        [[-0.2471]],\n",
      "\n",
      "        [[-0.3580]]], dtype=torch.float64)\n",
      "tensor([[-0.5564],\n",
      "        [-0.4649],\n",
      "        [-0.5379],\n",
      "        [-0.6714]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3025]],\n",
      "\n",
      "        [[-0.4169]],\n",
      "\n",
      "        [[-0.7323]],\n",
      "\n",
      "        [[-0.7843]]], dtype=torch.float64)\n",
      "tensor([[-0.7529],\n",
      "        [-0.8102],\n",
      "        [-0.8708],\n",
      "        [-0.9172]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6168]],\n",
      "\n",
      "        [[-0.7820]],\n",
      "\n",
      "        [[-0.9114]],\n",
      "\n",
      "        [[-0.9865]]], dtype=torch.float64)\n",
      "tensor([[-0.7499],\n",
      "        [-0.7441],\n",
      "        [-0.7912],\n",
      "        [-0.8203]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9992]],\n",
      "\n",
      "        [[-0.9750]],\n",
      "\n",
      "        [[-0.7046]],\n",
      "\n",
      "        [[-0.8167]]], dtype=torch.float64)\n",
      "tensor([[-0.8777],\n",
      "        [-0.8439],\n",
      "        [-0.7159],\n",
      "        [-0.6373]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9403]],\n",
      "\n",
      "        [[-0.8120]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[-0.7970]]], dtype=torch.float64)\n",
      "tensor([[-0.7024],\n",
      "        [-0.6644],\n",
      "        [-0.9206],\n",
      "        [-0.7218]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5394]],\n",
      "\n",
      "        [[-0.7658]],\n",
      "\n",
      "        [[-0.7023]],\n",
      "\n",
      "        [[-0.6376]]], dtype=torch.float64)\n",
      "tensor([[-0.6888],\n",
      "        [-0.5639],\n",
      "        [-0.7309],\n",
      "        [-0.6669]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5925]],\n",
      "\n",
      "        [[-0.5324]],\n",
      "\n",
      "        [[-0.4596]],\n",
      "\n",
      "        [[-0.5740]]], dtype=torch.float64)\n",
      "tensor([[-0.5192],\n",
      "        [-0.3329],\n",
      "        [-0.0734],\n",
      "        [ 0.0268]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4065]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[-0.1373]],\n",
      "\n",
      "        [[-0.4631]]], dtype=torch.float64)\n",
      "tensor([[-0.5452],\n",
      "        [-0.6903],\n",
      "        [-0.8362],\n",
      "        [-0.8353]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3245]],\n",
      "\n",
      "        [[-0.6792]],\n",
      "\n",
      "        [[-0.8178]],\n",
      "\n",
      "        [[-0.9657]]], dtype=torch.float64)\n",
      "tensor([[-0.6940],\n",
      "        [-0.6988],\n",
      "        [-0.7754],\n",
      "        [-0.8615]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8964]],\n",
      "\n",
      "        [[-0.9426]],\n",
      "\n",
      "        [[-0.5301]],\n",
      "\n",
      "        [[-0.7912]]], dtype=torch.float64)\n",
      "tensor([[-0.9976],\n",
      "        [-0.9113],\n",
      "        [-1.0557],\n",
      "        [-0.9473]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9449]],\n",
      "\n",
      "        [[-1.1009]],\n",
      "\n",
      "        [[-1.3066]],\n",
      "\n",
      "        [[-1.3736]]], dtype=torch.float64)\n",
      "tensor([[-1.0138],\n",
      "        [-0.9155],\n",
      "        [-1.0485],\n",
      "        [-1.0703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7982]],\n",
      "\n",
      "        [[-0.9484]],\n",
      "\n",
      "        [[-1.1644]],\n",
      "\n",
      "        [[-1.0893]]], dtype=torch.float64)\n",
      "tensor([[-0.5405],\n",
      "        [-0.4094],\n",
      "        [-0.4765],\n",
      "        [-0.4090]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7785]],\n",
      "\n",
      "        [[-0.6052]],\n",
      "\n",
      "        [[-0.3464]],\n",
      "\n",
      "        [[-0.3083]]], dtype=torch.float64)\n",
      "tensor([[-0.5998],\n",
      "        [-0.6928],\n",
      "        [-0.4217],\n",
      "        [-0.3416]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5579]],\n",
      "\n",
      "        [[-0.8109]],\n",
      "\n",
      "        [[-0.6538]],\n",
      "\n",
      "        [[-0.6642]]], dtype=torch.float64)\n",
      "tensor([[-0.4758],\n",
      "        [-0.5626],\n",
      "        [-0.4176],\n",
      "        [-0.3692]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.2979]],\n",
      "\n",
      "        [[-0.1881]],\n",
      "\n",
      "        [[-0.4238]]], dtype=torch.float64)\n",
      "tensor([[-0.4431],\n",
      "        [-0.3494],\n",
      "        [-0.2510],\n",
      "        [-0.3644]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4261]],\n",
      "\n",
      "        [[-0.4412]],\n",
      "\n",
      "        [[-0.1061]],\n",
      "\n",
      "        [[-0.4296]]], dtype=torch.float64)\n",
      "tensor([[-0.6600],\n",
      "        [-0.6419],\n",
      "        [-0.5643],\n",
      "        [-0.6985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4458]],\n",
      "\n",
      "        [[-0.6826]],\n",
      "\n",
      "        [[-0.6815]],\n",
      "\n",
      "        [[-0.6514]]], dtype=torch.float64)\n",
      "tensor([[-0.4704],\n",
      "        [-0.6048],\n",
      "        [-0.6483],\n",
      "        [-0.6128]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4781]],\n",
      "\n",
      "        [[-0.5128]],\n",
      "\n",
      "        [[-0.6295]],\n",
      "\n",
      "        [[-0.6133]]], dtype=torch.float64)\n",
      "tensor([[-0.5265],\n",
      "        [-0.4989],\n",
      "        [-0.5256],\n",
      "        [-0.4250]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7104]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-0.0437]]], dtype=torch.float64)\n",
      "tensor([[-0.8379],\n",
      "        [-0.8715],\n",
      "        [-0.8106],\n",
      "        [-0.8189]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7104]],\n",
      "\n",
      "        [[-0.7416]],\n",
      "\n",
      "        [[-0.7785]],\n",
      "\n",
      "        [[-0.8536]]], dtype=torch.float64)\n",
      "tensor([[-0.8410],\n",
      "        [-0.9779],\n",
      "        [-0.9121],\n",
      "        [-0.7810]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6861]],\n",
      "\n",
      "        [[-0.7924]],\n",
      "\n",
      "        [[-0.7346]],\n",
      "\n",
      "        [[-0.8213]]], dtype=torch.float64)\n",
      "tensor([[-0.7240],\n",
      "        [-0.8350],\n",
      "        [-0.8243],\n",
      "        [-0.9314]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9299]],\n",
      "\n",
      "        [[-0.9622]],\n",
      "\n",
      "        [[-0.8999]],\n",
      "\n",
      "        [[-0.8906]]], dtype=torch.float64)\n",
      "tensor([[-1.0325],\n",
      "        [-0.9864],\n",
      "        [-0.8142],\n",
      "        [-0.9502]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0420]],\n",
      "\n",
      "        [[-0.9726]],\n",
      "\n",
      "        [[-1.1564]],\n",
      "\n",
      "        [[-1.2707]]], dtype=torch.float64)\n",
      "tensor([[-0.8835],\n",
      "        [-1.0557],\n",
      "        [-1.0587],\n",
      "        [-0.8697]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0154]],\n",
      "\n",
      "        [[-1.0235]],\n",
      "\n",
      "        [[-1.0339]],\n",
      "\n",
      "        [[-1.0524]]], dtype=torch.float64)\n",
      "tensor([[-0.8867],\n",
      "        [-0.9085],\n",
      "        [-0.9550],\n",
      "        [-1.0230]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2488]],\n",
      "\n",
      "        [[-1.1182]],\n",
      "\n",
      "        [[-1.0789]],\n",
      "\n",
      "        [[-1.1228]]], dtype=torch.float64)\n",
      "tensor([[-1.0995],\n",
      "        [-0.8974],\n",
      "        [-0.7061],\n",
      "        [-0.7228]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1113]],\n",
      "\n",
      "        [[-0.7601]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.7716]]], dtype=torch.float64)\n",
      "tensor([[-0.7572],\n",
      "        [-0.8679],\n",
      "        [-0.9031],\n",
      "        [-0.7542]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7866]],\n",
      "\n",
      "        [[-0.8074]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.8444]]], dtype=torch.float64)\n",
      "tensor([[-0.6655],\n",
      "        [-0.6812],\n",
      "        [-0.7832],\n",
      "        [-0.7344]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8479]],\n",
      "\n",
      "        [[-0.9311]],\n",
      "\n",
      "        [[-0.7069]],\n",
      "\n",
      "        [[-0.7473]]], dtype=torch.float64)\n",
      "tensor([[-0.8420],\n",
      "        [-0.6862],\n",
      "        [-0.2600],\n",
      "        [-0.2939]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7185]],\n",
      "\n",
      "        [[-0.4181]],\n",
      "\n",
      "        [[-0.3892]],\n",
      "\n",
      "        [[-0.4134]]], dtype=torch.float64)\n",
      "tensor([[-0.3324],\n",
      "        [-0.2986],\n",
      "        [-0.4711],\n",
      "        [-0.3002]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2736]],\n",
      "\n",
      "        [[-0.2089]],\n",
      "\n",
      "        [[-0.3164]],\n",
      "\n",
      "        [[-0.3291]]], dtype=torch.float64)\n",
      "tensor([[-0.2790],\n",
      "        [-0.2077],\n",
      "        [-0.7972],\n",
      "        [-0.8280]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4019]],\n",
      "\n",
      "        [[-0.3314]],\n",
      "\n",
      "        [[-0.9010]],\n",
      "\n",
      "        [[-0.7023]]], dtype=torch.float64)\n",
      "tensor([[-0.8870],\n",
      "        [-0.8164],\n",
      "        [-0.7644],\n",
      "        [-0.5716]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-0.9287]],\n",
      "\n",
      "        [[-0.7878]],\n",
      "\n",
      "        [[-0.7716]]], dtype=torch.float64)\n",
      "tensor([[-0.5739],\n",
      "        [-0.5777],\n",
      "        [-0.7668],\n",
      "        [-0.4752]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.5729]],\n",
      "\n",
      "        [[-0.5093]],\n",
      "\n",
      "        [[-0.3730]]], dtype=torch.float64)\n",
      "tensor([[-0.3032],\n",
      "        [-0.1824],\n",
      "        [-0.3819],\n",
      "        [-0.3029]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2621]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.1696]],\n",
      "\n",
      "        [[-0.1165]]], dtype=torch.float64)\n",
      "tensor([[-0.4771],\n",
      "        [-0.2552],\n",
      "        [-0.1917],\n",
      "        [-0.2528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2678]],\n",
      "\n",
      "        [[-0.2759]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.3071]]], dtype=torch.float64)\n",
      "tensor([[-0.3067],\n",
      "        [-0.3923],\n",
      "        [-0.5045],\n",
      "        [-0.4481]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3014]],\n",
      "\n",
      "        [[-0.2436]],\n",
      "\n",
      "        [[-0.2551]],\n",
      "\n",
      "        [[-0.3510]]], dtype=torch.float64)\n",
      "tensor([[-0.3357],\n",
      "        [-0.3207],\n",
      "        [-0.3557],\n",
      "        [-0.5697]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4042]],\n",
      "\n",
      "        [[-0.5047]],\n",
      "\n",
      "        [[-0.3903]],\n",
      "\n",
      "        [[-0.5787]]], dtype=torch.float64)\n",
      "tensor([[-0.8163],\n",
      "        [-0.5905],\n",
      "        [-0.5523],\n",
      "        [-0.5656]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7208]],\n",
      "\n",
      "        [[-0.6156]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.6792]]], dtype=torch.float64)\n",
      "tensor([[-0.6619],\n",
      "        [-0.6667],\n",
      "        [-0.7022],\n",
      "        [-0.5510]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.5891]],\n",
      "\n",
      "        [[-0.7381]],\n",
      "\n",
      "        [[-0.6376]]], dtype=torch.float64)\n",
      "tensor([[-0.5281],\n",
      "        [-0.8016],\n",
      "        [-0.9735],\n",
      "        [-0.8820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8698]],\n",
      "\n",
      "        [[-0.9819]],\n",
      "\n",
      "        [[-0.8848]],\n",
      "\n",
      "        [[-0.7970]]], dtype=torch.float64)\n",
      "tensor([[-0.9164],\n",
      "        [-0.8037],\n",
      "        [-0.7285],\n",
      "        [-0.7651]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8016]],\n",
      "\n",
      "        [[-0.8710]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-1.0119]]], dtype=torch.float64)\n",
      "tensor([[-0.8508],\n",
      "        [-0.8226],\n",
      "        [-0.9032],\n",
      "        [-0.7755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7843]],\n",
      "\n",
      "        [[-0.7855]],\n",
      "\n",
      "        [[-0.8941]],\n",
      "\n",
      "        [[-0.7681]]], dtype=torch.float64)\n",
      "tensor([[-0.5254],\n",
      "        [-0.3528],\n",
      "        [-0.3365],\n",
      "        [-0.1256]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6410]],\n",
      "\n",
      "        [[-0.2574]],\n",
      "\n",
      "        [[ 0.0603]],\n",
      "\n",
      "        [[ 0.1932]]], dtype=torch.float64)\n",
      "tensor([[-0.0745],\n",
      "        [ 0.1247],\n",
      "        [ 0.2153],\n",
      "        [ 0.1388]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2128]],\n",
      "\n",
      "        [[0.3318]],\n",
      "\n",
      "        [[0.3295]],\n",
      "\n",
      "        [[0.2983]]], dtype=torch.float64)\n",
      "tensor([[-0.0963],\n",
      "        [-0.4054],\n",
      "        [-0.5160],\n",
      "        [-0.6198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1581]],\n",
      "\n",
      "        [[-0.3499]],\n",
      "\n",
      "        [[-0.4700]],\n",
      "\n",
      "        [[-0.5336]]], dtype=torch.float64)\n",
      "tensor([[-0.6352],\n",
      "        [-0.5812],\n",
      "        [-0.5171],\n",
      "        [-0.4403]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9137]],\n",
      "\n",
      "        [[-0.7820]],\n",
      "\n",
      "        [[-0.4573]],\n",
      "\n",
      "        [[-0.2228]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.19242:  55%|█████▌    | 1701/3067 [00:05<00:04, 310.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3890],\n",
      "        [-0.2186],\n",
      "        [-0.3846],\n",
      "        [-0.5276]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0957]],\n",
      "\n",
      "        [[-0.1777]],\n",
      "\n",
      "        [[-0.3892]],\n",
      "\n",
      "        [[-0.5047]]], dtype=torch.float64)\n",
      "tensor([[-0.6852],\n",
      "        [-0.6981],\n",
      "        [-0.7692],\n",
      "        [-0.5611]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4215]],\n",
      "\n",
      "        [[-0.5521]],\n",
      "\n",
      "        [[-0.5486]],\n",
      "\n",
      "        [[-0.6942]]], dtype=torch.float64)\n",
      "tensor([[-0.4810],\n",
      "        [-0.5557],\n",
      "        [-0.8219],\n",
      "        [-0.8987]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5994]],\n",
      "\n",
      "        [[-0.4666]],\n",
      "\n",
      "        [[-0.8617]],\n",
      "\n",
      "        [[-0.6052]]], dtype=torch.float64)\n",
      "tensor([[-0.8539],\n",
      "        [-0.8954],\n",
      "        [-0.7921],\n",
      "        [-0.8357]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7635]],\n",
      "\n",
      "        [[-0.6861]],\n",
      "\n",
      "        [[-0.9103]],\n",
      "\n",
      "        [[-0.8317]]], dtype=torch.float64)\n",
      "tensor([[-0.8205],\n",
      "        [-0.8991],\n",
      "        [-0.9394],\n",
      "        [-0.7648]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.7577]],\n",
      "\n",
      "        [[-0.7450]],\n",
      "\n",
      "        [[-0.7612]]], dtype=torch.float64)\n",
      "tensor([[-0.5988],\n",
      "        [-0.5780],\n",
      "        [-0.6292],\n",
      "        [-0.7260]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7231]],\n",
      "\n",
      "        [[-0.8294]],\n",
      "\n",
      "        [[-0.7242]],\n",
      "\n",
      "        [[-0.5012]]], dtype=torch.float64)\n",
      "tensor([[-0.6633],\n",
      "        [-0.6649],\n",
      "        [-0.5660],\n",
      "        [-0.6513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7023]],\n",
      "\n",
      "        [[-0.7265]],\n",
      "\n",
      "        [[-0.6711]],\n",
      "\n",
      "        [[-0.7762]]], dtype=torch.float64)\n",
      "tensor([[-0.6486],\n",
      "        [-0.6968],\n",
      "        [-0.7056],\n",
      "        [-0.5770]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5810]],\n",
      "\n",
      "        [[-0.6249]],\n",
      "\n",
      "        [[-0.6526]],\n",
      "\n",
      "        [[-0.7138]]], dtype=torch.float64)\n",
      "tensor([[-0.6124],\n",
      "        [-0.6532],\n",
      "        [-0.6349],\n",
      "        [-0.6892]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-0.7254]],\n",
      "\n",
      "        [[-0.6364]],\n",
      "\n",
      "        [[-0.7335]]], dtype=torch.float64)\n",
      "tensor([[-0.6820],\n",
      "        [-0.4539],\n",
      "        [-0.2327],\n",
      "        [-0.6353]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4758]],\n",
      "\n",
      "        [[-0.3383]],\n",
      "\n",
      "        [[-0.5359]],\n",
      "\n",
      "        [[-0.7566]]], dtype=torch.float64)\n",
      "tensor([[-0.6325],\n",
      "        [-0.6617],\n",
      "        [-0.6834],\n",
      "        [-0.6616]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4342]],\n",
      "\n",
      "        [[-0.4284]],\n",
      "\n",
      "        [[-0.5324]],\n",
      "\n",
      "        [[-0.5694]]], dtype=torch.float64)\n",
      "tensor([[-0.4684],\n",
      "        [-0.3650],\n",
      "        [-0.4955],\n",
      "        [-0.3820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5752]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-0.1951]],\n",
      "\n",
      "        [[-0.2159]]], dtype=torch.float64)\n",
      "tensor([[-0.4203],\n",
      "        [-0.2767],\n",
      "        [-0.1269],\n",
      "        [-0.1592]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2702]],\n",
      "\n",
      "        [[-0.3279]],\n",
      "\n",
      "        [[-0.3395]],\n",
      "\n",
      "        [[-0.3245]]], dtype=torch.float64)\n",
      "tensor([[-0.1531],\n",
      "        [-0.2444],\n",
      "        [-0.3153],\n",
      "        [-0.6233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2551]],\n",
      "\n",
      "        [[-0.2020]],\n",
      "\n",
      "        [[-0.7601]],\n",
      "\n",
      "        [[-0.7161]]], dtype=torch.float64)\n",
      "tensor([[-0.6432],\n",
      "        [-0.7486],\n",
      "        [-0.7840],\n",
      "        [-0.9367]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8040]],\n",
      "\n",
      "        [[-1.0373]],\n",
      "\n",
      "        [[-0.8328]],\n",
      "\n",
      "        [[-0.9079]]], dtype=torch.float64)\n",
      "tensor([[-0.8456],\n",
      "        [-0.7166],\n",
      "        [-0.7364],\n",
      "        [-0.7319]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8375]],\n",
      "\n",
      "        [[-0.8432]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-1.0397]]], dtype=torch.float64)\n",
      "tensor([[-0.8465],\n",
      "        [-0.9065],\n",
      "        [-1.0255],\n",
      "        [-0.9286]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7369]],\n",
      "\n",
      "        [[-0.8675]],\n",
      "\n",
      "        [[-1.1021]],\n",
      "\n",
      "        [[-1.2026]]], dtype=torch.float64)\n",
      "tensor([[-0.9188],\n",
      "        [-0.9621],\n",
      "        [-0.9929],\n",
      "        [-1.0940]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2927]],\n",
      "\n",
      "        [[-1.3562]],\n",
      "\n",
      "        [[-1.1159]],\n",
      "\n",
      "        [[-1.1286]]], dtype=torch.float64)\n",
      "tensor([[-1.2165],\n",
      "        [-1.1765],\n",
      "        [-1.1089],\n",
      "        [-1.1330]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3285]],\n",
      "\n",
      "        [[-1.3493]],\n",
      "\n",
      "        [[-1.4475]],\n",
      "\n",
      "        [[-1.5423]]], dtype=torch.float64)\n",
      "tensor([[-1.1600],\n",
      "        [-1.0930],\n",
      "        [-1.1533],\n",
      "        [-1.0613]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1691]],\n",
      "\n",
      "        [[-1.0096]],\n",
      "\n",
      "        [[-1.0570]],\n",
      "\n",
      "        [[-1.1356]]], dtype=torch.float64)\n",
      "tensor([[-0.8930],\n",
      "        [-0.9257],\n",
      "        [-0.9405],\n",
      "        [-1.0535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0974]],\n",
      "\n",
      "        [[-1.0639]],\n",
      "\n",
      "        [[-0.9911]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-1.0801],\n",
      "        [-1.1753],\n",
      "        [-1.2147],\n",
      "        [-1.3081]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0743]],\n",
      "\n",
      "        [[-1.4579]],\n",
      "\n",
      "        [[-1.6093]],\n",
      "\n",
      "        [[-1.7144]]], dtype=torch.float64)\n",
      "tensor([[-1.2108],\n",
      "        [-0.8357],\n",
      "        [-1.0600],\n",
      "        [-0.7326]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8871]],\n",
      "\n",
      "        [[-0.5301]],\n",
      "\n",
      "        [[-0.8409]],\n",
      "\n",
      "        [[-0.9195]]], dtype=torch.float64)\n",
      "tensor([[-0.6581],\n",
      "        [-0.6277],\n",
      "        [-0.6319],\n",
      "        [-0.5821]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8398]],\n",
      "\n",
      "        [[-0.8294]],\n",
      "\n",
      "        [[-0.7092]],\n",
      "\n",
      "        [[-0.4215]]], dtype=torch.float64)\n",
      "tensor([[-0.5765],\n",
      "        [-0.7048],\n",
      "        [-0.7036],\n",
      "        [-0.8695]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5371]],\n",
      "\n",
      "        [[-0.6907]],\n",
      "\n",
      "        [[-0.8375]],\n",
      "\n",
      "        [[-0.9657]]], dtype=torch.float64)\n",
      "tensor([[-0.8661],\n",
      "        [-0.9265],\n",
      "        [-1.0487],\n",
      "        [-0.9858]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8063]],\n",
      "\n",
      "        [[-0.7982]],\n",
      "\n",
      "        [[-1.0085]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-0.8616],\n",
      "        [-0.7976],\n",
      "        [-0.8740],\n",
      "        [-0.9066]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9114]],\n",
      "\n",
      "        [[-0.9888]],\n",
      "\n",
      "        [[-1.1044]],\n",
      "\n",
      "        [[-0.6283]]], dtype=torch.float64)\n",
      "tensor([[-0.6621],\n",
      "        [-0.5759],\n",
      "        [-0.7266],\n",
      "        [-0.8172]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5602]],\n",
      "\n",
      "        [[-0.9253]],\n",
      "\n",
      "        [[-0.6919]],\n",
      "\n",
      "        [[-0.6376]]], dtype=torch.float64)\n",
      "tensor([[-0.7886],\n",
      "        [-0.8226],\n",
      "        [-0.7366],\n",
      "        [-0.6954]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4966]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-0.4111]],\n",
      "\n",
      "        [[-0.6098]]], dtype=torch.float64)\n",
      "tensor([[-0.6974],\n",
      "        [-0.7667],\n",
      "        [-0.7943],\n",
      "        [-0.7782]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.8167]],\n",
      "\n",
      "        [[-0.4781]],\n",
      "\n",
      "        [[-0.5879]]], dtype=torch.float64)\n",
      "tensor([[-0.8742],\n",
      "        [-0.8589],\n",
      "        [-0.8294],\n",
      "        [-0.8293]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8606]],\n",
      "\n",
      "        [[-0.9807]],\n",
      "\n",
      "        [[-0.9484]],\n",
      "\n",
      "        [[-1.0027]]], dtype=torch.float64)\n",
      "tensor([[-0.9073],\n",
      "        [-0.9177],\n",
      "        [-0.9841],\n",
      "        [-0.9476]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7936]],\n",
      "\n",
      "        [[-0.7681]],\n",
      "\n",
      "        [[-0.8687]],\n",
      "\n",
      "        [[-0.9588]]], dtype=torch.float64)\n",
      "tensor([[-0.8727],\n",
      "        [-0.8665],\n",
      "        [-0.9415],\n",
      "        [-1.0963]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9357]],\n",
      "\n",
      "        [[-0.9565]],\n",
      "\n",
      "        [[-0.8791]],\n",
      "\n",
      "        [[-0.9114]]], dtype=torch.float64)\n",
      "tensor([[-1.2878],\n",
      "        [-1.1724],\n",
      "        [-1.1291],\n",
      "        [-1.1534]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1621]],\n",
      "\n",
      "        [[-1.1991]],\n",
      "\n",
      "        [[-1.3378]],\n",
      "\n",
      "        [[-1.5296]]], dtype=torch.float64)\n",
      "tensor([[-1.1901],\n",
      "        [-1.0993],\n",
      "        [-1.3199],\n",
      "        [-1.3532]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0466]],\n",
      "\n",
      "        [[-1.0570]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.4718]]], dtype=torch.float64)\n",
      "tensor([[-1.2102],\n",
      "        [-1.1713],\n",
      "        [-1.2017],\n",
      "        [-1.1628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3562]],\n",
      "\n",
      "        [[-1.3343]],\n",
      "\n",
      "        [[-1.0293]],\n",
      "\n",
      "        [[-1.1252]]], dtype=torch.float64)\n",
      "tensor([[-1.2037],\n",
      "        [-1.1464],\n",
      "        [-1.0386],\n",
      "        [-1.0694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2014]],\n",
      "\n",
      "        [[-1.1899]],\n",
      "\n",
      "        [[-1.1656]],\n",
      "\n",
      "        [[-1.2338]]], dtype=torch.float64)\n",
      "tensor([[-1.2905],\n",
      "        [-1.4833],\n",
      "        [-1.5709],\n",
      "        [-1.6594]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3008]],\n",
      "\n",
      "        [[-1.3643]],\n",
      "\n",
      "        [[-1.5076]],\n",
      "\n",
      "        [[-1.6694]]], dtype=torch.float64)\n",
      "tensor([[-1.6385],\n",
      "        [-1.7137],\n",
      "        [-1.7790],\n",
      "        [-1.8043]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7653]],\n",
      "\n",
      "        [[-1.8115]],\n",
      "\n",
      "        [[-1.7849]],\n",
      "\n",
      "        [[-1.6497]]], dtype=torch.float64)\n",
      "tensor([[-1.7840],\n",
      "        [-1.8671],\n",
      "        [-1.8454],\n",
      "        [-1.8262]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8011]],\n",
      "\n",
      "        [[-1.9744]],\n",
      "\n",
      "        [[-2.1073]],\n",
      "\n",
      "        [[-2.0899]]], dtype=torch.float64)\n",
      "tensor([[-1.8892],\n",
      "        [-1.7993],\n",
      "        [-1.8923],\n",
      "        [-1.9821]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7468]],\n",
      "\n",
      "        [[-1.5700]],\n",
      "\n",
      "        [[-1.8415]],\n",
      "\n",
      "        [[-2.1442]]], dtype=torch.float64)\n",
      "tensor([[-2.0512],\n",
      "        [-2.0863],\n",
      "        [-2.0813],\n",
      "        [-2.1114]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3568]],\n",
      "\n",
      "        [[-2.3915]],\n",
      "\n",
      "        [[-1.9397]],\n",
      "\n",
      "        [[-1.8496]]], dtype=torch.float64)\n",
      "tensor([[-2.2085],\n",
      "        [-2.2704],\n",
      "        [-2.1901],\n",
      "        [-2.2729]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2089]],\n",
      "\n",
      "        [[-2.4169]],\n",
      "\n",
      "        [[-2.5197]],\n",
      "\n",
      "        [[-2.6272]]], dtype=torch.float64)\n",
      "tensor([[-2.4070],\n",
      "        [-2.4374],\n",
      "        [-2.3629],\n",
      "        [-2.4194]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4493]],\n",
      "\n",
      "        [[-2.2170]],\n",
      "\n",
      "        [[-2.3649]],\n",
      "\n",
      "        [[-2.5648]]], dtype=torch.float64)\n",
      "tensor([[-2.4995],\n",
      "        [-2.5576],\n",
      "        [-2.6351],\n",
      "        [-2.5064]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.8121]],\n",
      "\n",
      "        [[-2.9056]],\n",
      "\n",
      "        [[-2.7404]],\n",
      "\n",
      "        [[-2.5047]]], dtype=torch.float64)\n",
      "tensor([[-2.5837],\n",
      "        [-2.5832],\n",
      "        [-2.6399],\n",
      "        [-2.7548]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.7300]],\n",
      "\n",
      "        [[-3.1078]],\n",
      "\n",
      "        [[-3.3378]],\n",
      "\n",
      "        [[-3.2268]]], dtype=torch.float64)\n",
      "tensor([[-2.6951],\n",
      "        [-2.2461],\n",
      "        [-2.3303],\n",
      "        [-2.4906]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4077]],\n",
      "\n",
      "        [[-2.0506]],\n",
      "\n",
      "        [[-2.3695]],\n",
      "\n",
      "        [[-2.7716]]], dtype=torch.float64)\n",
      "tensor([[-2.6486],\n",
      "        [-2.4979],\n",
      "        [-2.3749],\n",
      "        [-2.4456]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.7092]],\n",
      "\n",
      "        [[-2.6376]],\n",
      "\n",
      "        [[-2.1477]],\n",
      "\n",
      "        [[-2.1893]]], dtype=torch.float64)\n",
      "tensor([[-2.6073],\n",
      "        [-2.8165],\n",
      "        [-2.8438],\n",
      "        [-3.0144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.5787]],\n",
      "\n",
      "        [[-2.8640]],\n",
      "\n",
      "        [[-3.1922]],\n",
      "\n",
      "        [[-3.3216]]], dtype=torch.float64)\n",
      "tensor([[-2.9641],\n",
      "        [-2.5329],\n",
      "        [-2.7657],\n",
      "        [-2.8888]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3961]],\n",
      "\n",
      "        [[-2.1465]],\n",
      "\n",
      "        [[-2.5636]],\n",
      "\n",
      "        [[-2.9438]]], dtype=torch.float64)\n",
      "tensor([[-3.0711],\n",
      "        [-3.1019],\n",
      "        [-3.0371],\n",
      "        [-3.0282]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-3.2222]],\n",
      "\n",
      "        [[-3.0605]],\n",
      "\n",
      "        [[-2.6723]],\n",
      "\n",
      "        [[-2.6387]]], dtype=torch.float64)\n",
      "tensor([[-3.1381],\n",
      "        [-3.2656],\n",
      "        [-3.3231],\n",
      "        [-3.2670]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-3.0235]],\n",
      "\n",
      "        [[-3.2615]],\n",
      "\n",
      "        [[-3.4452]],\n",
      "\n",
      "        [[-3.2245]]], dtype=torch.float64)\n",
      "tensor([[-3.0817],\n",
      "        [-2.9818],\n",
      "        [-2.9190],\n",
      "        [-2.7329]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6803]],\n",
      "\n",
      "        [[-2.4493]],\n",
      "\n",
      "        [[-2.3199]],\n",
      "\n",
      "        [[-2.2124]]], dtype=torch.float64)\n",
      "tensor([[-2.4730],\n",
      "        [-2.4446],\n",
      "        [-2.5549],\n",
      "        [-2.5527]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2124]],\n",
      "\n",
      "        [[-2.2008]],\n",
      "\n",
      "        [[-2.1396]],\n",
      "\n",
      "        [[-2.0830]]], dtype=torch.float64)\n",
      "tensor([[-2.5254],\n",
      "        [-2.6586],\n",
      "        [-2.6976],\n",
      "        [-2.5470]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3742]],\n",
      "\n",
      "        [[-2.6942]],\n",
      "\n",
      "        [[-2.8929]],\n",
      "\n",
      "        [[-2.5267]]], dtype=torch.float64)\n",
      "tensor([[-2.1613],\n",
      "        [-1.9025],\n",
      "        [-2.0062],\n",
      "        [-2.2138]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7583]],\n",
      "\n",
      "        [[-1.6601]],\n",
      "\n",
      "        [[-1.6590]],\n",
      "\n",
      "        [[-1.9478]]], dtype=torch.float64)\n",
      "tensor([[-2.1275],\n",
      "        [-2.2432],\n",
      "        [-2.4898],\n",
      "        [-2.5155]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1893]],\n",
      "\n",
      "        [[-2.5648]],\n",
      "\n",
      "        [[-2.3418]],\n",
      "\n",
      "        [[-2.3279]]], dtype=torch.float64)\n",
      "tensor([[-2.5219],\n",
      "        [-2.5891],\n",
      "        [-2.5368],\n",
      "        [-2.3820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6480]],\n",
      "\n",
      "        [[-3.0790]],\n",
      "\n",
      "        [[-2.8779]],\n",
      "\n",
      "        [[-2.6526]]], dtype=torch.float64)\n",
      "tensor([[-2.2561],\n",
      "        [-2.3231],\n",
      "        [-2.3272],\n",
      "        [-2.4655]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2586]],\n",
      "\n",
      "        [[-2.2517]],\n",
      "\n",
      "        [[-2.5683]],\n",
      "\n",
      "        [[-2.9819]]], dtype=torch.float64)\n",
      "tensor([[-2.5237],\n",
      "        [-2.3477],\n",
      "        [-2.1360],\n",
      "        [-1.7298]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-3.1309]],\n",
      "\n",
      "        [[-2.8086]],\n",
      "\n",
      "        [[-2.0818]],\n",
      "\n",
      "        [[-1.6266]]], dtype=torch.float64)\n",
      "tensor([[-1.9862],\n",
      "        [-1.9887],\n",
      "        [-1.7188],\n",
      "        [-1.4337]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1812]],\n",
      "\n",
      "        [[-2.0506]],\n",
      "\n",
      "        [[-1.8554]],\n",
      "\n",
      "        [[-1.5400]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.19242:  58%|█████▊    | 1766/3067 [00:05<00:04, 316.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3091],\n",
      "        [-1.2671],\n",
      "        [-1.2752],\n",
      "        [-1.3150]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2222]],\n",
      "\n",
      "        [[-1.1829]],\n",
      "\n",
      "        [[-1.2985]],\n",
      "\n",
      "        [[-1.4313]]], dtype=torch.float64)\n",
      "tensor([[-1.2161],\n",
      "        [-1.2297],\n",
      "        [-1.1980],\n",
      "        [-0.9698]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4221]],\n",
      "\n",
      "        [[-1.3909]],\n",
      "\n",
      "        [[-1.0732]],\n",
      "\n",
      "        [[-0.8271]]], dtype=torch.float64)\n",
      "tensor([[-0.9620],\n",
      "        [-0.9991],\n",
      "        [-0.8625],\n",
      "        [-0.8152]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9334]],\n",
      "\n",
      "        [[-0.9634]],\n",
      "\n",
      "        [[-0.7393]],\n",
      "\n",
      "        [[-0.8560]]], dtype=torch.float64)\n",
      "tensor([[-0.8790],\n",
      "        [-0.9344],\n",
      "        [-0.9655],\n",
      "        [-0.9569]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6318]],\n",
      "\n",
      "        [[-0.5787]],\n",
      "\n",
      "        [[-0.8074]],\n",
      "\n",
      "        [[-0.9877]]], dtype=torch.float64)\n",
      "tensor([[-0.9454],\n",
      "        [-1.0782],\n",
      "        [-0.9948],\n",
      "        [-0.8789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0905]],\n",
      "\n",
      "        [[-1.1714]],\n",
      "\n",
      "        [[-0.7046]],\n",
      "\n",
      "        [[-0.5475]]], dtype=torch.float64)\n",
      "tensor([[-0.9303],\n",
      "        [-0.7453],\n",
      "        [-0.5723],\n",
      "        [-0.5392]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7705]],\n",
      "\n",
      "        [[-0.7912]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.5486]]], dtype=torch.float64)\n",
      "tensor([[-0.5394],\n",
      "        [-0.3987],\n",
      "        [-0.6686],\n",
      "        [-0.5561]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3441]],\n",
      "\n",
      "        [[-0.2967]],\n",
      "\n",
      "        [[-0.4758]],\n",
      "\n",
      "        [[-0.5544]]], dtype=torch.float64)\n",
      "tensor([[-0.5343],\n",
      "        [-0.5058],\n",
      "        [-0.3313],\n",
      "        [-0.3339]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7947]],\n",
      "\n",
      "        [[-0.5486]],\n",
      "\n",
      "        [[-0.1904]],\n",
      "\n",
      "        [[-0.3175]]], dtype=torch.float64)\n",
      "tensor([[-0.4695],\n",
      "        [-0.3393],\n",
      "        [-0.2819],\n",
      "        [-0.3834]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3834]],\n",
      "\n",
      "        [[-0.3268]],\n",
      "\n",
      "        [[-0.3973]],\n",
      "\n",
      "        [[-0.8502]]], dtype=torch.float64)\n",
      "tensor([[-0.7929],\n",
      "        [-0.8446],\n",
      "        [-0.8574],\n",
      "        [-0.8969]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5775]],\n",
      "\n",
      "        [[-0.5186]],\n",
      "\n",
      "        [[-0.7832]],\n",
      "\n",
      "        [[-0.9322]]], dtype=torch.float64)\n",
      "tensor([[-0.8895],\n",
      "        [-0.9384],\n",
      "        [-0.9974],\n",
      "        [-1.0245]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0108]],\n",
      "\n",
      "        [[-1.0015]],\n",
      "\n",
      "        [[-0.9033]],\n",
      "\n",
      "        [[-0.7138]]], dtype=torch.float64)\n",
      "tensor([[-1.1716],\n",
      "        [-1.2419],\n",
      "        [-1.2287],\n",
      "        [-1.1838]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1852]],\n",
      "\n",
      "        [[-1.3713]],\n",
      "\n",
      "        [[-1.4429]],\n",
      "\n",
      "        [[-1.2211]]], dtype=torch.float64)\n",
      "tensor([[-0.8238],\n",
      "        [-0.6228],\n",
      "        [-0.8135],\n",
      "        [-0.7846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6376]],\n",
      "\n",
      "        [[-0.6769]],\n",
      "\n",
      "        [[-0.7843]],\n",
      "\n",
      "        [[-0.7011]]], dtype=torch.float64)\n",
      "tensor([[-0.6318],\n",
      "        [-0.4655],\n",
      "        [-0.2891],\n",
      "        [-0.1559]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6953]],\n",
      "\n",
      "        [[-0.6676]],\n",
      "\n",
      "        [[-0.1546]],\n",
      "\n",
      "        [[ 0.0846]]], dtype=torch.float64)\n",
      "tensor([[-0.3936],\n",
      "        [-0.3445],\n",
      "        [-0.3698],\n",
      "        [-0.3006]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3822]],\n",
      "\n",
      "        [[-0.2066]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.4181]]], dtype=torch.float64)\n",
      "tensor([[-0.3419],\n",
      "        [-0.1542],\n",
      "        [-0.1183],\n",
      "        [-0.0480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0553]],\n",
      "\n",
      "        [[ 0.0037]],\n",
      "\n",
      "        [[-0.0934]],\n",
      "\n",
      "        [[-0.1292]]], dtype=torch.float64)\n",
      "tensor([[0.0759],\n",
      "        [0.1847],\n",
      "        [0.0382],\n",
      "        [0.0367]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0483]],\n",
      "\n",
      "        [[-0.0691]],\n",
      "\n",
      "        [[ 0.2763]],\n",
      "\n",
      "        [[ 0.2579]]], dtype=torch.float64)\n",
      "tensor([[ 0.0477],\n",
      "        [ 0.2704],\n",
      "        [-0.0838],\n",
      "        [-0.4730]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1631]],\n",
      "\n",
      "        [[-0.0657]],\n",
      "\n",
      "        [[-0.4492]],\n",
      "\n",
      "        [[-0.6283]]], dtype=torch.float64)\n",
      "tensor([[-0.3225],\n",
      "        [-0.3305],\n",
      "        [-0.4989],\n",
      "        [-0.5183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1927]],\n",
      "\n",
      "        [[-0.1535]],\n",
      "\n",
      "        [[-0.4088]],\n",
      "\n",
      "        [[-0.5012]]], dtype=torch.float64)\n",
      "tensor([[-0.4419],\n",
      "        [-0.6091],\n",
      "        [-0.5785],\n",
      "        [-0.5676]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6064]],\n",
      "\n",
      "        [[-0.6549]],\n",
      "\n",
      "        [[-0.4897]],\n",
      "\n",
      "        [[-0.3522]]], dtype=torch.float64)\n",
      "tensor([[-0.7454],\n",
      "        [-0.9320],\n",
      "        [-0.9635],\n",
      "        [-0.9742]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7312]],\n",
      "\n",
      "        [[-1.0963]],\n",
      "\n",
      "        [[-1.2788]],\n",
      "\n",
      "        [[-1.1275]]], dtype=torch.float64)\n",
      "tensor([[-0.6424],\n",
      "        [-0.5214],\n",
      "        [-0.5778],\n",
      "        [-0.5388]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3799]],\n",
      "\n",
      "        [[-0.3545]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.6491]]], dtype=torch.float64)\n",
      "tensor([[-0.4046],\n",
      "        [-0.2467],\n",
      "        [-0.2124],\n",
      "        [-0.1200]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5787]],\n",
      "\n",
      "        [[-0.3649]],\n",
      "\n",
      "        [[-0.1384]],\n",
      "\n",
      "        [[ 0.0256]]], dtype=torch.float64)\n",
      "tensor([[-0.0197],\n",
      "        [ 0.1349],\n",
      "        [ 0.3256],\n",
      "        [ 0.3183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0345]],\n",
      "\n",
      "        [[-0.0610]],\n",
      "\n",
      "        [[ 0.0326]],\n",
      "\n",
      "        [[ 0.0279]]], dtype=torch.float64)\n",
      "tensor([[0.0332],\n",
      "        [0.0569],\n",
      "        [0.1260],\n",
      "        [0.2093]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1423]],\n",
      "\n",
      "        [[0.1978]],\n",
      "\n",
      "        [[0.1631]],\n",
      "\n",
      "        [[0.0557]]], dtype=torch.float64)\n",
      "tensor([[0.3972],\n",
      "        [0.2861],\n",
      "        [0.0575],\n",
      "        [0.1811]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0206]],\n",
      "\n",
      "        [[ 0.0175]],\n",
      "\n",
      "        [[ 0.1608]],\n",
      "\n",
      "        [[ 0.5109]]], dtype=torch.float64)\n",
      "tensor([[0.2011],\n",
      "        [0.2833],\n",
      "        [0.2964],\n",
      "        [0.1656]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1077]],\n",
      "\n",
      "        [[-0.0137]],\n",
      "\n",
      "        [[-0.1084]],\n",
      "\n",
      "        [[-0.3788]]], dtype=torch.float64)\n",
      "tensor([[-0.1886],\n",
      "        [-0.1964],\n",
      "        [-0.2996],\n",
      "        [-0.4104]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2205]],\n",
      "\n",
      "        [[-0.0483]],\n",
      "\n",
      "        [[-0.3637]],\n",
      "\n",
      "        [[-0.6075]]], dtype=torch.float64)\n",
      "tensor([[-0.5328],\n",
      "        [-0.4359],\n",
      "        [-0.2274],\n",
      "        [-0.0637]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6861]],\n",
      "\n",
      "        [[-0.7808]],\n",
      "\n",
      "        [[-0.0576]],\n",
      "\n",
      "        [[ 0.1331]]], dtype=torch.float64)\n",
      "tensor([[-0.2259],\n",
      "        [-0.1028],\n",
      "        [-0.0133],\n",
      "        [-0.0726]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1615]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.3996]],\n",
      "\n",
      "        [[-0.4388]]], dtype=torch.float64)\n",
      "tensor([[-0.0832],\n",
      "        [-0.1367],\n",
      "        [-0.2537],\n",
      "        [-0.3084]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0888]],\n",
      "\n",
      "        [[ 0.0326]],\n",
      "\n",
      "        [[-0.1719]],\n",
      "\n",
      "        [[-0.4273]]], dtype=torch.float64)\n",
      "tensor([[-0.5294],\n",
      "        [-0.6688],\n",
      "        [-0.5520],\n",
      "        [-0.5384]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6526]],\n",
      "\n",
      "        [[-0.7762]],\n",
      "\n",
      "        [[-0.3961]],\n",
      "\n",
      "        [[-0.4446]]], dtype=torch.float64)\n",
      "tensor([[-0.5519],\n",
      "        [-0.5415],\n",
      "        [-0.4639],\n",
      "        [-0.6319]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5197]],\n",
      "\n",
      "        [[-0.6052]],\n",
      "\n",
      "        [[-0.7057]],\n",
      "\n",
      "        [[-0.9599]]], dtype=torch.float64)\n",
      "tensor([[-0.4907],\n",
      "        [-0.6188],\n",
      "        [-0.7637],\n",
      "        [-0.9423]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[-0.2690]],\n",
      "\n",
      "        [[-0.6815]],\n",
      "\n",
      "        [[-1.1587]]], dtype=torch.float64)\n",
      "tensor([[-1.0599],\n",
      "        [-1.0769],\n",
      "        [-0.6899],\n",
      "        [-0.2146]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3978]],\n",
      "\n",
      "        [[-1.2835]],\n",
      "\n",
      "        [[-0.1408]],\n",
      "\n",
      "        [[-0.1234]]], dtype=torch.float64)\n",
      "tensor([[-0.4184],\n",
      "        [-0.3939],\n",
      "        [-0.4361],\n",
      "        [-0.5759]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3337]],\n",
      "\n",
      "        [[-0.6156]],\n",
      "\n",
      "        [[-0.7196]],\n",
      "\n",
      "        [[-0.7034]]], dtype=torch.float64)\n",
      "tensor([[-0.4820],\n",
      "        [-0.2526],\n",
      "        [-0.5736],\n",
      "        [-0.5977]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2205]],\n",
      "\n",
      "        [[-0.1766]],\n",
      "\n",
      "        [[-0.7057]],\n",
      "\n",
      "        [[-0.7508]]], dtype=torch.float64)\n",
      "tensor([[-0.7384],\n",
      "        [-0.9187],\n",
      "        [-0.5084],\n",
      "        [-0.2551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1298]],\n",
      "\n",
      "        [[-1.0166]],\n",
      "\n",
      "        [[-0.1488]],\n",
      "\n",
      "        [[ 0.0048]]], dtype=torch.float64)\n",
      "tensor([[-0.3753],\n",
      "        [-0.5345],\n",
      "        [-0.5715],\n",
      "        [-0.2273]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4781]],\n",
      "\n",
      "        [[-0.7832]],\n",
      "\n",
      "        [[-0.6191]],\n",
      "\n",
      "        [[-0.3418]]], dtype=torch.float64)\n",
      "tensor([[-0.0875],\n",
      "        [-0.0604],\n",
      "        [-0.0187],\n",
      "        [ 0.1569]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1446]],\n",
      "\n",
      "        [[ 0.0880]],\n",
      "\n",
      "        [[-0.0437]],\n",
      "\n",
      "        [[-0.0194]]], dtype=torch.float64)\n",
      "tensor([[ 0.1237],\n",
      "        [-0.0048],\n",
      "        [-0.1875],\n",
      "        [-0.2210]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3268]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.1916]],\n",
      "\n",
      "        [[-0.1361]]], dtype=torch.float64)\n",
      "tensor([[-0.1061],\n",
      "        [-0.0769],\n",
      "        [ 0.1313],\n",
      "        [ 0.1302]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1985]],\n",
      "\n",
      "        [[-0.2528]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.1997]]], dtype=torch.float64)\n",
      "tensor([[-0.1371],\n",
      "        [-0.1266],\n",
      "        [-0.0366],\n",
      "        [ 0.0434]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0472]],\n",
      "\n",
      "        [[-0.0067]],\n",
      "\n",
      "        [[-0.1754]],\n",
      "\n",
      "        [[-0.1269]]], dtype=torch.float64)\n",
      "tensor([[ 0.0542],\n",
      "        [-0.1619],\n",
      "        [-0.2304],\n",
      "        [-0.2191]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[-0.4308]],\n",
      "\n",
      "        [[-0.2563]],\n",
      "\n",
      "        [[-0.1985]]], dtype=torch.float64)\n",
      "tensor([[-0.2520],\n",
      "        [-0.2176],\n",
      "        [-0.1549],\n",
      "        [-0.2830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2990]],\n",
      "\n",
      "        [[-0.3372]],\n",
      "\n",
      "        [[-0.4123]],\n",
      "\n",
      "        [[-0.4712]]], dtype=torch.float64)\n",
      "tensor([[-0.3136],\n",
      "        [-0.4346],\n",
      "        [-0.4417],\n",
      "        [-0.5143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3949]],\n",
      "\n",
      "        [[-0.3510]],\n",
      "\n",
      "        [[-0.4134]],\n",
      "\n",
      "        [[-0.4758]]], dtype=torch.float64)\n",
      "tensor([[-0.2846],\n",
      "        [-0.3228],\n",
      "        [-0.2811],\n",
      "        [ 0.0514]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5151]],\n",
      "\n",
      "        [[-0.5810]],\n",
      "\n",
      "        [[ 0.0083]],\n",
      "\n",
      "        [[ 0.6264]]], dtype=torch.float64)\n",
      "tensor([[ 0.0856],\n",
      "        [-0.3216],\n",
      "        [-0.5402],\n",
      "        [-0.6061]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0171]],\n",
      "\n",
      "        [[-0.6849]],\n",
      "\n",
      "        [[-0.8999]],\n",
      "\n",
      "        [[-0.4654]]], dtype=torch.float64)\n",
      "tensor([[0.1691],\n",
      "        [0.4892],\n",
      "        [0.2943],\n",
      "        [0.1455]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.2330]],\n",
      "\n",
      "        [[ 1.3983]],\n",
      "\n",
      "        [[ 0.6796]],\n",
      "\n",
      "        [[-0.1049]]], dtype=torch.float64)\n",
      "tensor([[-0.2351],\n",
      "        [-0.4088],\n",
      "        [ 0.3376],\n",
      "        [ 0.4545]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6110]],\n",
      "\n",
      "        [[-0.2990]],\n",
      "\n",
      "        [[ 1.2885]],\n",
      "\n",
      "        [[ 1.3093]]], dtype=torch.float64)\n",
      "tensor([[ 0.3766],\n",
      "        [ 0.3410],\n",
      "        [ 0.2443],\n",
      "        [-0.1569]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7813]],\n",
      "\n",
      "        [[ 0.3387]],\n",
      "\n",
      "        [[-0.2239]],\n",
      "\n",
      "        [[-0.1673]]], dtype=torch.float64)\n",
      "tensor([[ 0.1466],\n",
      "        [ 0.0665],\n",
      "        [-0.0434],\n",
      "        [ 0.0118]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8529]],\n",
      "\n",
      "        [[ 0.1920]],\n",
      "\n",
      "        [[-0.0807]],\n",
      "\n",
      "        [[-0.2055]]], dtype=torch.float64)\n",
      "tensor([[-0.1602],\n",
      "        [-0.4125],\n",
      "        [-0.5270],\n",
      "        [-0.2084]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5451]],\n",
      "\n",
      "        [[-0.4816]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[ 0.1805]]], dtype=torch.float64)\n",
      "tensor([[-0.4339],\n",
      "        [-0.8000],\n",
      "        [-0.9161],\n",
      "        [-0.9418]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3614]],\n",
      "\n",
      "        [[-0.9934]],\n",
      "\n",
      "        [[-1.2858]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-0.2543],\n",
      "        [-0.0305],\n",
      "        [-0.0787],\n",
      "        [-0.3033]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2891]],\n",
      "\n",
      "        [[ 0.5733]],\n",
      "\n",
      "        [[ 0.2001]],\n",
      "\n",
      "        [[-0.2355]]], dtype=torch.float64)\n",
      "tensor([[-0.1826],\n",
      "        [-0.4464],\n",
      "        [ 0.1184],\n",
      "        [ 0.3231]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5209]],\n",
      "\n",
      "        [[-0.4181]],\n",
      "\n",
      "        [[ 0.5421]],\n",
      "\n",
      "        [[ 0.7859]]], dtype=torch.float64)\n",
      "tensor([[ 0.1834],\n",
      "        [ 0.1487],\n",
      "        [-0.0145],\n",
      "        [-0.2144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2070]],\n",
      "\n",
      "        [[-0.2598]],\n",
      "\n",
      "        [[-0.5983]],\n",
      "\n",
      "        [[-0.3892]]], dtype=torch.float64)\n",
      "tensor([[0.1524],\n",
      "        [0.2171],\n",
      "        [0.0932],\n",
      "        [0.0699]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4393]],\n",
      "\n",
      "        [[ 0.5352]],\n",
      "\n",
      "        [[ 0.1597]],\n",
      "\n",
      "        [[-0.3487]]], dtype=torch.float64)\n",
      "tensor([[-0.2576],\n",
      "        [-0.3584],\n",
      "        [-0.0590],\n",
      "        [ 0.2265]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6942]],\n",
      "\n",
      "        [[-0.6491]],\n",
      "\n",
      "        [[ 0.3711]],\n",
      "\n",
      "        [[ 0.7142]]], dtype=torch.float64)\n",
      "tensor([[ 0.2309],\n",
      "        [ 0.0666],\n",
      "        [-0.2000],\n",
      "        [-0.4017]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2382]],\n",
      "\n",
      "        [[-0.3626]],\n",
      "\n",
      "        [[-0.6884]],\n",
      "\n",
      "        [[-0.7832]]], dtype=torch.float64)\n",
      "tensor([[0.1564],\n",
      "        [0.3787],\n",
      "        [0.3586],\n",
      "        [0.2864]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7119]],\n",
      "\n",
      "        [[ 0.9107]],\n",
      "\n",
      "        [[ 0.3515]],\n",
      "\n",
      "        [[-0.1881]]], dtype=torch.float64)\n",
      "tensor([[-0.0168],\n",
      "        [-0.3543],\n",
      "        [ 0.3155],\n",
      "        [ 0.3047]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6133]],\n",
      "\n",
      "        [[-0.3279]],\n",
      "\n",
      "        [[ 0.8309]],\n",
      "\n",
      "        [[ 1.0505]]], dtype=torch.float64)\n",
      "tensor([[ 0.2255],\n",
      "        [ 0.0953],\n",
      "        [-0.1477],\n",
      "        [-0.3798]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3884]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-0.4100]]], dtype=torch.float64)\n",
      "tensor([[ 0.1269],\n",
      "        [ 0.0395],\n",
      "        [-0.0426],\n",
      "        [-0.2588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2844]],\n",
      "\n",
      "        [[ 0.5144]],\n",
      "\n",
      "        [[ 0.0614]],\n",
      "\n",
      "        [[-0.5405]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.18953:  60%|█████▉    | 1831/3067 [00:05<00:03, 320.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4785],\n",
      "        [-0.5847],\n",
      "        [ 0.2569],\n",
      "        [ 0.4966]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8502]],\n",
      "\n",
      "        [[-0.6838]],\n",
      "\n",
      "        [[ 0.7801]],\n",
      "\n",
      "        [[ 1.0447]]], dtype=torch.float64)\n",
      "tensor([[ 0.4758],\n",
      "        [ 0.2375],\n",
      "        [ 0.0692],\n",
      "        [-0.1107]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4924]],\n",
      "\n",
      "        [[-0.0102]],\n",
      "\n",
      "        [[-0.4897]],\n",
      "\n",
      "        [[ 0.1169]]], dtype=torch.float64)\n",
      "tensor([[0.3208],\n",
      "        [0.4912],\n",
      "        [0.3413],\n",
      "        [0.2875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8055]],\n",
      "\n",
      "        [[1.1498]],\n",
      "\n",
      "        [[0.5952]],\n",
      "\n",
      "        [[0.3977]]], dtype=torch.float64)\n",
      "tensor([[ 0.3553],\n",
      "        [ 0.2239],\n",
      "        [-0.1183],\n",
      "        [-0.0784]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0996]],\n",
      "\n",
      "        [[-0.0934]],\n",
      "\n",
      "        [[ 0.0545]],\n",
      "\n",
      "        [[-0.0402]]], dtype=torch.float64)\n",
      "tensor([[-0.1767],\n",
      "        [-0.2076],\n",
      "        [-0.1039],\n",
      "        [ 0.0641]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3198]],\n",
      "\n",
      "        [[-0.3880]],\n",
      "\n",
      "        [[-0.3187]],\n",
      "\n",
      "        [[-0.1951]]], dtype=torch.float64)\n",
      "tensor([[-0.0438],\n",
      "        [-0.1016],\n",
      "        [-0.1618],\n",
      "        [-0.0677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0298]],\n",
      "\n",
      "        [[-0.0957]],\n",
      "\n",
      "        [[-0.0980]],\n",
      "\n",
      "        [[-0.0772]]], dtype=torch.float64)\n",
      "tensor([[ 0.0489],\n",
      "        [-0.0917],\n",
      "        [-0.0985],\n",
      "        [-0.4357]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2112]],\n",
      "\n",
      "        [[-0.0899]],\n",
      "\n",
      "        [[ 0.0395]],\n",
      "\n",
      "        [[-0.3580]]], dtype=torch.float64)\n",
      "tensor([[-0.5624],\n",
      "        [-0.6597],\n",
      "        [-0.6566],\n",
      "        [-0.6250]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8063]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-1.0350]],\n",
      "\n",
      "        [[-0.7011]]], dtype=torch.float64)\n",
      "tensor([[-0.4188],\n",
      "        [-0.2285],\n",
      "        [-0.4006],\n",
      "        [-0.4184]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2690]],\n",
      "\n",
      "        [[ 0.0060]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[-0.3429]]], dtype=torch.float64)\n",
      "tensor([[-0.2319],\n",
      "        [-0.2278],\n",
      "        [-0.0653],\n",
      "        [-0.0786]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3545]],\n",
      "\n",
      "        [[-0.3476]],\n",
      "\n",
      "        [[-0.1153]],\n",
      "\n",
      "        [[ 0.0684]]], dtype=torch.float64)\n",
      "tensor([[-0.1935],\n",
      "        [-0.2957],\n",
      "        [-0.3206],\n",
      "        [-0.3121]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1835]],\n",
      "\n",
      "        [[-0.5440]],\n",
      "\n",
      "        [[-0.6688]],\n",
      "\n",
      "        [[-0.4342]]], dtype=torch.float64)\n",
      "tensor([[ 0.2254],\n",
      "        [ 0.3825],\n",
      "        [ 0.2678],\n",
      "        [-0.0144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6091]],\n",
      "\n",
      "        [[ 0.9638]],\n",
      "\n",
      "        [[ 0.4150]],\n",
      "\n",
      "        [[-0.2852]]], dtype=torch.float64)\n",
      "tensor([[-0.1046],\n",
      "        [ 0.0389],\n",
      "        [ 0.1903],\n",
      "        [ 0.0174]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3337]],\n",
      "\n",
      "        [[-0.1107]],\n",
      "\n",
      "        [[ 0.3168]],\n",
      "\n",
      "        [[-0.1904]]], dtype=torch.float64)\n",
      "tensor([[-0.4353],\n",
      "        [-0.4922],\n",
      "        [-0.3799],\n",
      "        [-0.3393]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.5417]],\n",
      "\n",
      "        [[-0.6295]],\n",
      "\n",
      "        [[-0.6087]]], dtype=torch.float64)\n",
      "tensor([[-0.3264],\n",
      "        [-0.5115],\n",
      "        [-0.6103],\n",
      "        [-0.5486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5891]],\n",
      "\n",
      "        [[-0.5509]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[-0.6549]]], dtype=torch.float64)\n",
      "tensor([[-0.4608],\n",
      "        [-0.4764],\n",
      "        [-0.4525],\n",
      "        [-0.5470]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7450]],\n",
      "\n",
      "        [[-0.7566]],\n",
      "\n",
      "        [[-0.6803]],\n",
      "\n",
      "        [[-0.6145]]], dtype=torch.float64)\n",
      "tensor([[-0.5921],\n",
      "        [-0.6327],\n",
      "        [-0.6805],\n",
      "        [-0.4693]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6364]],\n",
      "\n",
      "        [[-1.1078]],\n",
      "\n",
      "        [[-0.9854]],\n",
      "\n",
      "        [[-0.7127]]], dtype=torch.float64)\n",
      "tensor([[-0.4239],\n",
      "        [-0.5596],\n",
      "        [-0.7761],\n",
      "        [-0.8233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5532]],\n",
      "\n",
      "        [[-0.4273]],\n",
      "\n",
      "        [[-0.8155]],\n",
      "\n",
      "        [[-1.0385]]], dtype=torch.float64)\n",
      "tensor([[-0.8271],\n",
      "        [-0.7541],\n",
      "        [-0.8456],\n",
      "        [-0.9036]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1841]],\n",
      "\n",
      "        [[-0.8952]],\n",
      "\n",
      "        [[-0.7312]],\n",
      "\n",
      "        [[-0.5359]]], dtype=torch.float64)\n",
      "tensor([[-0.7413],\n",
      "        [-0.9405],\n",
      "        [-0.9315],\n",
      "        [-0.7571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8652]],\n",
      "\n",
      "        [[-1.3250]],\n",
      "\n",
      "        [[-1.3539]],\n",
      "\n",
      "        [[-0.6572]]], dtype=torch.float64)\n",
      "tensor([[-0.1463],\n",
      "        [-0.2600],\n",
      "        [-0.3225],\n",
      "        [-0.2147]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2875]],\n",
      "\n",
      "        [[-0.2286]],\n",
      "\n",
      "        [[-0.2910]],\n",
      "\n",
      "        [[-0.1881]]], dtype=torch.float64)\n",
      "tensor([[0.1161],\n",
      "        [0.1982],\n",
      "        [0.3430],\n",
      "        [0.4312]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1315]],\n",
      "\n",
      "        [[ 0.0222]],\n",
      "\n",
      "        [[ 0.6091]],\n",
      "\n",
      "        [[ 1.0747]]], dtype=torch.float64)\n",
      "tensor([[0.4024],\n",
      "        [0.3191],\n",
      "        [0.3262],\n",
      "        [0.3058]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8390]],\n",
      "\n",
      "        [[ 0.3387]],\n",
      "\n",
      "        [[ 0.1169]],\n",
      "\n",
      "        [[-0.0044]]], dtype=torch.float64)\n",
      "tensor([[ 0.0611],\n",
      "        [-0.0311],\n",
      "        [-0.0969],\n",
      "        [-0.1275]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0707]],\n",
      "\n",
      "        [[ 0.0291]],\n",
      "\n",
      "        [[-0.1812]],\n",
      "\n",
      "        [[-0.2759]]], dtype=torch.float64)\n",
      "tensor([[-0.1041],\n",
      "        [-0.0281],\n",
      "        [ 0.2089],\n",
      "        [ 0.0983]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3406]],\n",
      "\n",
      "        [[-0.2910]],\n",
      "\n",
      "        [[ 0.3572]],\n",
      "\n",
      "        [[ 0.0014]]], dtype=torch.float64)\n",
      "tensor([[-0.2421],\n",
      "        [-0.2542],\n",
      "        [-0.2199],\n",
      "        [-0.2384]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2274]],\n",
      "\n",
      "        [[-0.3949]],\n",
      "\n",
      "        [[-0.5163]],\n",
      "\n",
      "        [[-0.3337]]], dtype=torch.float64)\n",
      "tensor([[-0.2023],\n",
      "        [-0.0307],\n",
      "        [-0.1708],\n",
      "        [-0.3828]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0603]],\n",
      "\n",
      "        [[ 0.2717]],\n",
      "\n",
      "        [[-0.1500]],\n",
      "\n",
      "        [[-0.7323]]], dtype=torch.float64)\n",
      "tensor([[-0.5983],\n",
      "        [-0.6665],\n",
      "        [-0.0199],\n",
      "        [-0.0609]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0350]],\n",
      "\n",
      "        [[-0.5867]],\n",
      "\n",
      "        [[ 0.1816]],\n",
      "\n",
      "        [[ 0.2671]]], dtype=torch.float64)\n",
      "tensor([[-0.1360],\n",
      "        [-0.3476],\n",
      "        [-0.3704],\n",
      "        [-0.4251]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0268]],\n",
      "\n",
      "        [[-0.2390]],\n",
      "\n",
      "        [[-0.4978]],\n",
      "\n",
      "        [[-0.4100]]], dtype=torch.float64)\n",
      "tensor([[-0.0998],\n",
      "        [-0.2389],\n",
      "        [-0.2376],\n",
      "        [-0.1449]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1273]],\n",
      "\n",
      "        [[ 0.1331]],\n",
      "\n",
      "        [[ 0.0256]],\n",
      "\n",
      "        [[-0.1558]]], dtype=torch.float64)\n",
      "tensor([[-0.2135],\n",
      "        [-0.2835],\n",
      "        [-0.4147],\n",
      "        [-0.4856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5220]],\n",
      "\n",
      "        [[-0.5082]],\n",
      "\n",
      "        [[-0.2193]],\n",
      "\n",
      "        [[-0.0853]]], dtype=torch.float64)\n",
      "tensor([[-0.5719],\n",
      "        [-0.5422],\n",
      "        [-0.6906],\n",
      "        [-0.7270]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4562]],\n",
      "\n",
      "        [[-0.7808]],\n",
      "\n",
      "        [[-1.1945]],\n",
      "\n",
      "        [[-0.6722]]], dtype=torch.float64)\n",
      "tensor([[-0.1619],\n",
      "        [-0.1622],\n",
      "        [-0.3396],\n",
      "        [-0.4853]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1546]],\n",
      "\n",
      "        [[ 0.1123]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[-0.5012]]], dtype=torch.float64)\n",
      "tensor([[-0.5093],\n",
      "        [-0.4585],\n",
      "        [ 0.1047],\n",
      "        [-0.0150]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7705]],\n",
      "\n",
      "        [[-0.3453]],\n",
      "\n",
      "        [[ 0.0799]],\n",
      "\n",
      "        [[ 0.1597]]], dtype=torch.float64)\n",
      "tensor([[-0.1773],\n",
      "        [-0.4061],\n",
      "        [-0.5650],\n",
      "        [-0.5896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0333]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.9819]],\n",
      "\n",
      "        [[-0.4839]]], dtype=torch.float64)\n",
      "tensor([[0.2699],\n",
      "        [0.2619],\n",
      "        [0.2374],\n",
      "        [0.0786]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6160]],\n",
      "\n",
      "        [[ 0.7374]],\n",
      "\n",
      "        [[ 0.3099]],\n",
      "\n",
      "        [[-0.1396]]], dtype=torch.float64)\n",
      "tensor([[0.0091],\n",
      "        [0.0069],\n",
      "        [0.2729],\n",
      "        [0.1676]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2621]],\n",
      "\n",
      "        [[-0.1442]],\n",
      "\n",
      "        [[ 0.3884]],\n",
      "\n",
      "        [[ 0.4693]]], dtype=torch.float64)\n",
      "tensor([[ 0.1094],\n",
      "        [-0.1251],\n",
      "        [-0.1601],\n",
      "        [-0.0568]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1469]],\n",
      "\n",
      "        [[-0.2216]],\n",
      "\n",
      "        [[-0.4735]],\n",
      "\n",
      "        [[ 0.2036]]], dtype=torch.float64)\n",
      "tensor([[ 0.2716],\n",
      "        [ 0.1859],\n",
      "        [-0.0087],\n",
      "        [-0.2347]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3803]],\n",
      "\n",
      "        [[ 0.4196]],\n",
      "\n",
      "        [[-0.2771]],\n",
      "\n",
      "        [[-0.1523]]], dtype=torch.float64)\n",
      "tensor([[-0.0636],\n",
      "        [ 0.0397],\n",
      "        [ 0.1635],\n",
      "        [ 0.0738]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4308]],\n",
      "\n",
      "        [[-0.0703]],\n",
      "\n",
      "        [[ 0.1966]],\n",
      "\n",
      "        [[ 0.3769]]], dtype=torch.float64)\n",
      "tensor([[ 0.0718],\n",
      "        [-0.1683],\n",
      "        [-0.2471],\n",
      "        [-0.1482]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0795]],\n",
      "\n",
      "        [[-0.3175]],\n",
      "\n",
      "        [[-0.6052]],\n",
      "\n",
      "        [[-0.2112]]], dtype=torch.float64)\n",
      "tensor([[ 0.1147],\n",
      "        [-0.0422],\n",
      "        [ 0.0163],\n",
      "        [-0.3226]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2625]],\n",
      "\n",
      "        [[ 0.3630]],\n",
      "\n",
      "        [[-0.1719]],\n",
      "\n",
      "        [[-0.4608]]], dtype=torch.float64)\n",
      "tensor([[-0.2239],\n",
      "        [-0.0101],\n",
      "        [ 0.1799],\n",
      "        [ 0.1030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4261]],\n",
      "\n",
      "        [[-0.0449]],\n",
      "\n",
      "        [[ 0.1874]],\n",
      "\n",
      "        [[ 0.2486]]], dtype=torch.float64)\n",
      "tensor([[ 0.0216],\n",
      "        [-0.1582],\n",
      "        [ 0.0564],\n",
      "        [ 0.1273]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0568]],\n",
      "\n",
      "        [[-0.2401]],\n",
      "\n",
      "        [[-0.1743]],\n",
      "\n",
      "        [[ 0.1157]]], dtype=torch.float64)\n",
      "tensor([[0.1229],\n",
      "        [0.1874],\n",
      "        [0.2870],\n",
      "        [0.3826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4034]],\n",
      "\n",
      "        [[0.6253]],\n",
      "\n",
      "        [[0.5640]],\n",
      "\n",
      "        [[0.4150]]], dtype=torch.float64)\n",
      "tensor([[0.4742],\n",
      "        [0.4424],\n",
      "        [0.6524],\n",
      "        [0.4552]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1573]],\n",
      "\n",
      "        [[0.5502]],\n",
      "\n",
      "        [[1.0666]],\n",
      "\n",
      "        [[0.9754]]], dtype=torch.float64)\n",
      "tensor([[0.4902],\n",
      "        [0.5409],\n",
      "        [0.5551],\n",
      "        [0.4694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7246]],\n",
      "\n",
      "        [[0.4034]],\n",
      "\n",
      "        [[0.0938]],\n",
      "\n",
      "        [[0.7443]]], dtype=torch.float64)\n",
      "tensor([[0.9145],\n",
      "        [0.9718],\n",
      "        [0.9454],\n",
      "        [0.7882]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5947]],\n",
      "\n",
      "        [[1.4791]],\n",
      "\n",
      "        [[1.3370]],\n",
      "\n",
      "        [[0.6322]]], dtype=torch.float64)\n",
      "tensor([[0.6921],\n",
      "        [0.7153],\n",
      "        [1.2530],\n",
      "        [1.4836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4924]],\n",
      "\n",
      "        [[0.8806]],\n",
      "\n",
      "        [[2.1758]],\n",
      "\n",
      "        [[2.3480]]], dtype=torch.float64)\n",
      "tensor([[1.3612],\n",
      "        [1.2027],\n",
      "        [0.9979],\n",
      "        [1.0415]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9448]],\n",
      "\n",
      "        [[1.2122]],\n",
      "\n",
      "        [[1.0239]],\n",
      "\n",
      "        [[1.4271]]], dtype=torch.float64)\n",
      "tensor([[1.3727],\n",
      "        [1.3333],\n",
      "        [0.9674],\n",
      "        [0.9389]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9471]],\n",
      "\n",
      "        [[2.0776]],\n",
      "\n",
      "        [[1.3671]],\n",
      "\n",
      "        [[0.8448]]], dtype=torch.float64)\n",
      "tensor([[0.9240],\n",
      "        [0.7954],\n",
      "        [1.0278],\n",
      "        [0.8374]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4520]],\n",
      "\n",
      "        [[1.0563]],\n",
      "\n",
      "        [[1.3775]],\n",
      "\n",
      "        [[1.4791]]], dtype=torch.float64)\n",
      "tensor([[0.9002],\n",
      "        [0.8310],\n",
      "        [0.7736],\n",
      "        [0.6459]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1568]],\n",
      "\n",
      "        [[0.7293]],\n",
      "\n",
      "        [[0.3457]],\n",
      "\n",
      "        [[0.3491]]], dtype=torch.float64)\n",
      "tensor([[0.7961],\n",
      "        [1.0936],\n",
      "        [1.1298],\n",
      "        [1.0498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1857]],\n",
      "\n",
      "        [[1.5854]],\n",
      "\n",
      "        [[1.2411]],\n",
      "\n",
      "        [[0.7316]]], dtype=torch.float64)\n",
      "tensor([[0.9594],\n",
      "        [0.8717],\n",
      "        [1.0550],\n",
      "        [1.2394]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3769]],\n",
      "\n",
      "        [[0.6958]],\n",
      "\n",
      "        [[1.4040]],\n",
      "\n",
      "        [[1.7784]]], dtype=torch.float64)\n",
      "tensor([[1.1779],\n",
      "        [1.0408],\n",
      "        [1.0704],\n",
      "        [0.9729]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0516]],\n",
      "\n",
      "        [[0.8541]],\n",
      "\n",
      "        [[0.5872]],\n",
      "\n",
      "        [[0.6449]]], dtype=torch.float64)\n",
      "tensor([[0.7474],\n",
      "        [0.8032],\n",
      "        [0.5256],\n",
      "        [0.5094]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7824]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.5640]],\n",
      "\n",
      "        [[0.0788]]], dtype=torch.float64)\n",
      "tensor([[0.3614],\n",
      "        [0.3648],\n",
      "        [0.9594],\n",
      "        [0.9783]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2286]],\n",
      "\n",
      "        [[ 0.3873]],\n",
      "\n",
      "        [[ 1.1949]],\n",
      "\n",
      "        [[ 1.3751]]], dtype=torch.float64)\n",
      "tensor([[0.9328],\n",
      "        [0.7046],\n",
      "        [0.6390],\n",
      "        [0.5557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9338]],\n",
      "\n",
      "        [[0.3826]],\n",
      "\n",
      "        [[0.0672]],\n",
      "\n",
      "        [[0.3457]]], dtype=torch.float64)\n",
      "tensor([[ 0.6897],\n",
      "        [ 0.5695],\n",
      "        [ 0.0551],\n",
      "        [-0.0619]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5883]],\n",
      "\n",
      "        [[ 0.4185]],\n",
      "\n",
      "        [[-0.0899]],\n",
      "\n",
      "        [[-0.2910]]], dtype=torch.float64)\n",
      "tensor([[-0.1286],\n",
      "        [-0.0498],\n",
      "        [-0.0804],\n",
      "        [-0.0480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4284]],\n",
      "\n",
      "        [[-0.4019]],\n",
      "\n",
      "        [[-0.1800]],\n",
      "\n",
      "        [[-0.1396]]], dtype=torch.float64)\n",
      "tensor([[-0.1388],\n",
      "        [-0.1034],\n",
      "        [ 0.2017],\n",
      "        [ 0.2702]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2055]],\n",
      "\n",
      "        [[-0.2447]],\n",
      "\n",
      "        [[-0.2216]],\n",
      "\n",
      "        [[-0.0217]]], dtype=torch.float64)\n",
      "tensor([[0.3934],\n",
      "        [0.3652],\n",
      "        [0.3084],\n",
      "        [0.3942]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3468]],\n",
      "\n",
      "        [[ 0.3203]],\n",
      "\n",
      "        [[ 0.2140]],\n",
      "\n",
      "        [[-0.0668]]], dtype=torch.float64)\n",
      "tensor([[0.5115],\n",
      "        [0.6195],\n",
      "        [0.9536],\n",
      "        [1.0933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[ 0.1920]],\n",
      "\n",
      "        [[ 1.0482]],\n",
      "\n",
      "        [[ 1.3659]]], dtype=torch.float64)\n",
      "tensor([[0.9604],\n",
      "        [0.7566],\n",
      "        [0.6840],\n",
      "        [0.7254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8956]],\n",
      "\n",
      "        [[0.3896]],\n",
      "\n",
      "        [[0.0718]],\n",
      "\n",
      "        [[0.8032]]], dtype=torch.float64)\n",
      "tensor([[1.0888],\n",
      "        [1.1377],\n",
      "        [1.1480],\n",
      "        [1.0406]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9777]],\n",
      "\n",
      "        [[1.3463]],\n",
      "\n",
      "        [[1.1106]],\n",
      "\n",
      "        [[0.7350]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.18985:  62%|██████▏   | 1898/3067 [00:06<00:03, 322.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0653],\n",
      "        [1.0588],\n",
      "        [1.5984],\n",
      "        [1.5861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3965]],\n",
      "\n",
      "        [[1.2018]],\n",
      "\n",
      "        [[1.6420]],\n",
      "\n",
      "        [[1.9390]]], dtype=torch.float64)\n",
      "tensor([[1.6155],\n",
      "        [1.6141],\n",
      "        [1.6227],\n",
      "        [1.5984]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6732]],\n",
      "\n",
      "        [[1.2746]],\n",
      "\n",
      "        [[1.1984]],\n",
      "\n",
      "        [[1.5346]]], dtype=torch.float64)\n",
      "tensor([[1.8971],\n",
      "        [1.9113],\n",
      "        [1.3332],\n",
      "        [0.8059]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2348]],\n",
      "\n",
      "        [[2.3064]],\n",
      "\n",
      "        [[1.2203]],\n",
      "\n",
      "        [[0.4208]]], dtype=torch.float64)\n",
      "tensor([[0.7187],\n",
      "        [0.5309],\n",
      "        [0.2795],\n",
      "        [0.2674]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2983]],\n",
      "\n",
      "        [[0.0938]],\n",
      "\n",
      "        [[0.2463]],\n",
      "\n",
      "        [[0.4439]]], dtype=torch.float64)\n",
      "tensor([[0.2288],\n",
      "        [0.1574],\n",
      "        [0.0518],\n",
      "        [0.0194]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1072]],\n",
      "\n",
      "        [[-0.3626]],\n",
      "\n",
      "        [[-0.7450]],\n",
      "\n",
      "        [[-0.2759]]], dtype=torch.float64)\n",
      "tensor([[-0.0651],\n",
      "        [-0.1340],\n",
      "        [-0.0516],\n",
      "        [ 0.1303]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1361]],\n",
      "\n",
      "        [[ 0.1377]],\n",
      "\n",
      "        [[-0.0252]],\n",
      "\n",
      "        [[-0.4019]]], dtype=torch.float64)\n",
      "tensor([[-0.1876],\n",
      "        [-0.1343],\n",
      "        [ 0.4741],\n",
      "        [ 0.5152]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8617]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[ 0.5606]],\n",
      "\n",
      "        [[ 0.8668]]], dtype=torch.float64)\n",
      "tensor([[0.4461],\n",
      "        [0.3911],\n",
      "        [0.3339],\n",
      "        [0.4585]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4635]],\n",
      "\n",
      "        [[ 0.1319]],\n",
      "\n",
      "        [[-0.3580]],\n",
      "\n",
      "        [[ 0.5132]]], dtype=torch.float64)\n",
      "tensor([[ 0.6254],\n",
      "        [ 0.1787],\n",
      "        [ 0.0529],\n",
      "        [-0.0869]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9419]],\n",
      "\n",
      "        [[ 0.1712]],\n",
      "\n",
      "        [[-0.0564]],\n",
      "\n",
      "        [[-0.3568]]], dtype=torch.float64)\n",
      "tensor([[0.0449],\n",
      "        [0.1184],\n",
      "        [0.0200],\n",
      "        [0.0531]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2678]],\n",
      "\n",
      "        [[-0.1049]],\n",
      "\n",
      "        [[ 0.1608]],\n",
      "\n",
      "        [[ 0.1053]]], dtype=torch.float64)\n",
      "tensor([[-0.0238],\n",
      "        [-0.1498],\n",
      "        [-0.0872],\n",
      "        [ 0.1199]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1662]],\n",
      "\n",
      "        [[-0.4123]],\n",
      "\n",
      "        [[-0.6434]],\n",
      "\n",
      "        [[-0.1384]]], dtype=torch.float64)\n",
      "tensor([[0.1069],\n",
      "        [0.2329],\n",
      "        [0.1100],\n",
      "        [0.0231]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2486]],\n",
      "\n",
      "        [[ 0.4658]],\n",
      "\n",
      "        [[ 0.1677]],\n",
      "\n",
      "        [[-0.2471]]], dtype=torch.float64)\n",
      "tensor([[0.0101],\n",
      "        [0.2529],\n",
      "        [0.4369],\n",
      "        [0.3947]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3603]],\n",
      "\n",
      "        [[ 0.2336]],\n",
      "\n",
      "        [[ 0.7119]],\n",
      "\n",
      "        [[ 1.1117]]], dtype=torch.float64)\n",
      "tensor([[0.5375],\n",
      "        [0.4975],\n",
      "        [0.6771],\n",
      "        [0.6901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9014]],\n",
      "\n",
      "        [[0.5259]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.8090]]], dtype=torch.float64)\n",
      "tensor([[0.8658],\n",
      "        [0.8468],\n",
      "        [0.9133],\n",
      "        [0.8039]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2850]],\n",
      "\n",
      "        [[1.7021]],\n",
      "\n",
      "        [[1.3474]],\n",
      "\n",
      "        [[0.7605]]], dtype=torch.float64)\n",
      "tensor([[0.6835],\n",
      "        [0.7611],\n",
      "        [1.0547],\n",
      "        [1.2503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3260]],\n",
      "\n",
      "        [[1.1325]],\n",
      "\n",
      "        [[1.8142]],\n",
      "\n",
      "        [[2.2348]]], dtype=torch.float64)\n",
      "tensor([[1.1425],\n",
      "        [0.9842],\n",
      "        [0.8861],\n",
      "        [0.8334]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6270]],\n",
      "\n",
      "        [[1.2134]],\n",
      "\n",
      "        [[0.6022]],\n",
      "\n",
      "        [[1.0043]]], dtype=torch.float64)\n",
      "tensor([[1.0109],\n",
      "        [1.1750],\n",
      "        [1.1160],\n",
      "        [1.0532]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7807]],\n",
      "\n",
      "        [[1.8743]],\n",
      "\n",
      "        [[1.6420]],\n",
      "\n",
      "        [[1.1926]]], dtype=torch.float64)\n",
      "tensor([[0.9796],\n",
      "        [0.9300],\n",
      "        [1.3372],\n",
      "        [1.3456]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6230]],\n",
      "\n",
      "        [[1.3855]],\n",
      "\n",
      "        [[1.9679]],\n",
      "\n",
      "        [[2.1389]]], dtype=torch.float64)\n",
      "tensor([[1.3235],\n",
      "        [1.2393],\n",
      "        [1.1396],\n",
      "        [1.2541]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8489]],\n",
      "\n",
      "        [[1.2816]],\n",
      "\n",
      "        [[0.8494]],\n",
      "\n",
      "        [[1.4144]]], dtype=torch.float64)\n",
      "tensor([[1.4686],\n",
      "        [1.4866],\n",
      "        [1.3837],\n",
      "        [1.2606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9760]],\n",
      "\n",
      "        [[2.1585]],\n",
      "\n",
      "        [[1.8292]],\n",
      "\n",
      "        [[1.2007]]], dtype=torch.float64)\n",
      "tensor([[1.3729],\n",
      "        [1.1611],\n",
      "        [1.2625],\n",
      "        [1.1109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8321]],\n",
      "\n",
      "        [[0.8922]],\n",
      "\n",
      "        [[1.4780]],\n",
      "\n",
      "        [[1.6559]]], dtype=torch.float64)\n",
      "tensor([[1.0407],\n",
      "        [0.8726],\n",
      "        [0.7702],\n",
      "        [0.7398]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3104]],\n",
      "\n",
      "        [[0.7443]],\n",
      "\n",
      "        [[0.2775]],\n",
      "\n",
      "        [[0.6241]]], dtype=torch.float64)\n",
      "tensor([[0.8179],\n",
      "        [0.8381],\n",
      "        [0.9376],\n",
      "        [0.7580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1140]],\n",
      "\n",
      "        [[1.3555]],\n",
      "\n",
      "        [[1.0921]],\n",
      "\n",
      "        [[0.4242]]], dtype=torch.float64)\n",
      "tensor([[0.6721],\n",
      "        [0.7799],\n",
      "        [1.1506],\n",
      "        [1.0406]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0256]],\n",
      "\n",
      "        [[0.7189]],\n",
      "\n",
      "        [[1.2457]],\n",
      "\n",
      "        [[1.4121]]], dtype=torch.float64)\n",
      "tensor([[1.0695],\n",
      "        [0.9436],\n",
      "        [0.9366],\n",
      "        [1.0558]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1787]],\n",
      "\n",
      "        [[0.5906]],\n",
      "\n",
      "        [[0.4277]],\n",
      "\n",
      "        [[1.0147]]], dtype=torch.float64)\n",
      "tensor([[1.3029],\n",
      "        [1.1930],\n",
      "        [1.2519],\n",
      "        [0.9448]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2920]],\n",
      "\n",
      "        [[1.5600]],\n",
      "\n",
      "        [[1.1833]],\n",
      "\n",
      "        [[0.5929]]], dtype=torch.float64)\n",
      "tensor([[0.9451],\n",
      "        [0.9359],\n",
      "        [1.3902],\n",
      "        [1.3489]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3653]],\n",
      "\n",
      "        [[1.0701]],\n",
      "\n",
      "        [[1.5300]],\n",
      "\n",
      "        [[1.6351]]], dtype=torch.float64)\n",
      "tensor([[1.3461],\n",
      "        [1.1219],\n",
      "        [0.9669],\n",
      "        [0.9413]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3081]],\n",
      "\n",
      "        [[0.6553]],\n",
      "\n",
      "        [[0.2833]],\n",
      "\n",
      "        [[1.1256]]], dtype=torch.float64)\n",
      "tensor([[1.2928],\n",
      "        [1.2938],\n",
      "        [1.1411],\n",
      "        [0.8483]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5230]],\n",
      "\n",
      "        [[1.4098]],\n",
      "\n",
      "        [[0.9650]],\n",
      "\n",
      "        [[0.4566]]], dtype=torch.float64)\n",
      "tensor([[0.7389],\n",
      "        [0.8485],\n",
      "        [1.0817],\n",
      "        [1.2734]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1908]],\n",
      "\n",
      "        [[0.9349]],\n",
      "\n",
      "        [[1.3728]],\n",
      "\n",
      "        [[1.3948]]], dtype=torch.float64)\n",
      "tensor([[1.0132],\n",
      "        [0.8000],\n",
      "        [0.7667],\n",
      "        [0.8192]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8933]],\n",
      "\n",
      "        [[0.4011]],\n",
      "\n",
      "        [[0.0649]],\n",
      "\n",
      "        [[0.8922]]], dtype=torch.float64)\n",
      "tensor([[1.2256],\n",
      "        [1.1633],\n",
      "        [0.8548],\n",
      "        [0.7883]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4202]],\n",
      "\n",
      "        [[0.7743]],\n",
      "\n",
      "        [[0.6958]],\n",
      "\n",
      "        [[0.4404]]], dtype=torch.float64)\n",
      "tensor([[0.8126],\n",
      "        [0.7043],\n",
      "        [0.6101],\n",
      "        [0.4267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3237]],\n",
      "\n",
      "        [[0.3676]],\n",
      "\n",
      "        [[0.6507]],\n",
      "\n",
      "        [[0.4843]]], dtype=torch.float64)\n",
      "tensor([[0.3834],\n",
      "        [0.4224],\n",
      "        [0.4834],\n",
      "        [0.5927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3249]],\n",
      "\n",
      "        [[0.1365]],\n",
      "\n",
      "        [[0.0118]],\n",
      "\n",
      "        [[0.1689]]], dtype=torch.float64)\n",
      "tensor([[0.3248],\n",
      "        [0.4430],\n",
      "        [0.5793],\n",
      "        [0.4406]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6287]],\n",
      "\n",
      "        [[ 0.7593]],\n",
      "\n",
      "        [[ 0.4554]],\n",
      "\n",
      "        [[-0.0449]]], dtype=torch.float64)\n",
      "tensor([[0.2705],\n",
      "        [0.2754],\n",
      "        [0.3834],\n",
      "        [0.2524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3695]],\n",
      "\n",
      "        [[-0.1673]],\n",
      "\n",
      "        [[ 0.1400]],\n",
      "\n",
      "        [[ 0.2278]]], dtype=torch.float64)\n",
      "tensor([[0.2510],\n",
      "        [0.4732],\n",
      "        [0.6059],\n",
      "        [0.4826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1643]],\n",
      "\n",
      "        [[0.1885]],\n",
      "\n",
      "        [[0.0337]],\n",
      "\n",
      "        [[0.0430]]], dtype=torch.float64)\n",
      "tensor([[0.4543],\n",
      "        [0.5935],\n",
      "        [0.6777],\n",
      "        [0.6580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3538]],\n",
      "\n",
      "        [[0.6357]],\n",
      "\n",
      "        [[0.4589]],\n",
      "\n",
      "        [[0.2948]]], dtype=torch.float64)\n",
      "tensor([[0.3411],\n",
      "        [0.2075],\n",
      "        [0.1896],\n",
      "        [0.1351]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2678]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[ 0.2787]],\n",
      "\n",
      "        [[ 0.3930]]], dtype=torch.float64)\n",
      "tensor([[ 0.2334],\n",
      "        [ 0.0264],\n",
      "        [-0.1840],\n",
      "        [ 0.1524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2324]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.6503]],\n",
      "\n",
      "        [[-0.0726]]], dtype=torch.float64)\n",
      "tensor([[0.5781],\n",
      "        [0.5321],\n",
      "        [0.6009],\n",
      "        [0.7996]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7778]],\n",
      "\n",
      "        [[0.5929]],\n",
      "\n",
      "        [[0.6103]],\n",
      "\n",
      "        [[0.4162]]], dtype=torch.float64)\n",
      "tensor([[0.7847],\n",
      "        [0.7653],\n",
      "        [1.1662],\n",
      "        [1.0889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2463]],\n",
      "\n",
      "        [[0.7870]],\n",
      "\n",
      "        [[1.3416]],\n",
      "\n",
      "        [[1.1961]]], dtype=torch.float64)\n",
      "tensor([[1.1044],\n",
      "        [1.1645],\n",
      "        [1.2837],\n",
      "        [1.3669]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1418]],\n",
      "\n",
      "        [[1.0528]],\n",
      "\n",
      "        [[0.9188]],\n",
      "\n",
      "        [[1.2700]]], dtype=torch.float64)\n",
      "tensor([[1.1601],\n",
      "        [0.9286],\n",
      "        [0.8400],\n",
      "        [0.7936]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5681]],\n",
      "\n",
      "        [[1.4537]],\n",
      "\n",
      "        [[1.0874]],\n",
      "\n",
      "        [[0.7478]]], dtype=torch.float64)\n",
      "tensor([[0.9853],\n",
      "        [0.9184],\n",
      "        [0.7340],\n",
      "        [0.6160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6022]],\n",
      "\n",
      "        [[0.9234]],\n",
      "\n",
      "        [[1.2342]],\n",
      "\n",
      "        [[1.3428]]], dtype=torch.float64)\n",
      "tensor([[0.6813],\n",
      "        [0.5593],\n",
      "        [0.5883],\n",
      "        [0.6864]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8182]],\n",
      "\n",
      "        [[0.3480]],\n",
      "\n",
      "        [[0.1181]],\n",
      "\n",
      "        [[0.6842]]], dtype=torch.float64)\n",
      "tensor([[0.7131],\n",
      "        [0.6814],\n",
      "        [0.6852],\n",
      "        [0.7228]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0620]],\n",
      "\n",
      "        [[1.1510]],\n",
      "\n",
      "        [[0.9118]],\n",
      "\n",
      "        [[0.6807]]], dtype=torch.float64)\n",
      "tensor([[0.8446],\n",
      "        [0.8050],\n",
      "        [0.9628],\n",
      "        [0.7620]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4739]],\n",
      "\n",
      "        [[0.7304]],\n",
      "\n",
      "        [[1.0724]],\n",
      "\n",
      "        [[1.0193]]], dtype=torch.float64)\n",
      "tensor([[0.7786],\n",
      "        [0.4543],\n",
      "        [0.5180],\n",
      "        [0.5406]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4381]],\n",
      "\n",
      "        [[0.1238]],\n",
      "\n",
      "        [[0.0095]],\n",
      "\n",
      "        [[0.6415]]], dtype=torch.float64)\n",
      "tensor([[0.8200],\n",
      "        [0.8919],\n",
      "        [0.7856],\n",
      "        [0.7367]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0967]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[0.9292]],\n",
      "\n",
      "        [[0.6634]]], dtype=torch.float64)\n",
      "tensor([[0.7212],\n",
      "        [0.8102],\n",
      "        [0.7420],\n",
      "        [0.6628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5583]],\n",
      "\n",
      "        [[0.6391]],\n",
      "\n",
      "        [[0.8182]],\n",
      "\n",
      "        [[0.4647]]], dtype=torch.float64)\n",
      "tensor([[0.3579],\n",
      "        [0.4553],\n",
      "        [0.5332],\n",
      "        [0.5426]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3722]],\n",
      "\n",
      "        [[0.2116]],\n",
      "\n",
      "        [[0.1631]],\n",
      "\n",
      "        [[0.1816]]], dtype=torch.float64)\n",
      "tensor([[0.3632],\n",
      "        [0.3317],\n",
      "        [0.5695],\n",
      "        [0.4790]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2683]],\n",
      "\n",
      "        [[0.6010]],\n",
      "\n",
      "        [[0.4866]],\n",
      "\n",
      "        [[0.0892]]], dtype=torch.float64)\n",
      "tensor([[0.4337],\n",
      "        [0.5335],\n",
      "        [1.0990],\n",
      "        [1.1361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0980]],\n",
      "\n",
      "        [[ 0.5201]],\n",
      "\n",
      "        [[ 1.4144]],\n",
      "\n",
      "        [[ 1.5288]]], dtype=torch.float64)\n",
      "tensor([[1.1566],\n",
      "        [0.9595],\n",
      "        [0.9581],\n",
      "        [1.0139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4110]],\n",
      "\n",
      "        [[0.8067]],\n",
      "\n",
      "        [[0.4346]],\n",
      "\n",
      "        [[1.1533]]], dtype=torch.float64)\n",
      "tensor([[1.3994],\n",
      "        [1.0772],\n",
      "        [0.9725],\n",
      "        [0.7916]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7957]],\n",
      "\n",
      "        [[1.4502]],\n",
      "\n",
      "        [[1.1868]],\n",
      "\n",
      "        [[0.8333]]], dtype=torch.float64)\n",
      "tensor([[0.9168],\n",
      "        [0.8895],\n",
      "        [0.8492],\n",
      "        [0.9710]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6553]],\n",
      "\n",
      "        [[0.7501]],\n",
      "\n",
      "        [[1.2400]],\n",
      "\n",
      "        [[1.5912]]], dtype=torch.float64)\n",
      "tensor([[1.0892],\n",
      "        [0.8373],\n",
      "        [0.6946],\n",
      "        [0.9642]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3266]],\n",
      "\n",
      "        [[0.5490]],\n",
      "\n",
      "        [[0.2971]],\n",
      "\n",
      "        [[1.3174]]], dtype=torch.float64)\n",
      "tensor([[1.4443],\n",
      "        [1.7781],\n",
      "        [1.5471],\n",
      "        [1.0874]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1989]],\n",
      "\n",
      "        [[2.4531]],\n",
      "\n",
      "        [[1.6120]],\n",
      "\n",
      "        [[0.9881]]], dtype=torch.float64)\n",
      "tensor([[1.1111],\n",
      "        [1.0489],\n",
      "        [1.2781],\n",
      "        [1.2927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7062]],\n",
      "\n",
      "        [[1.0597]],\n",
      "\n",
      "        [[1.5381]],\n",
      "\n",
      "        [[1.6744]]], dtype=torch.float64)\n",
      "tensor([[1.3202],\n",
      "        [1.1922],\n",
      "        [1.1428],\n",
      "        [1.1515]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3405]],\n",
      "\n",
      "        [[0.8471]],\n",
      "\n",
      "        [[0.7801]],\n",
      "\n",
      "        [[0.8425]]], dtype=torch.float64)\n",
      "tensor([[1.0721],\n",
      "        [0.8737],\n",
      "        [0.8151],\n",
      "        [0.9198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0331]],\n",
      "\n",
      "        [[1.0262]],\n",
      "\n",
      "        [[0.9095]],\n",
      "\n",
      "        [[0.7489]]], dtype=torch.float64)\n",
      "tensor([[1.0286],\n",
      "        [0.9051],\n",
      "        [0.6996],\n",
      "        [0.6126]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6334]],\n",
      "\n",
      "        [[0.5271]],\n",
      "\n",
      "        [[0.7096]],\n",
      "\n",
      "        [[0.7304]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.18985:  64%|██████▍   | 1963/3067 [00:06<00:03, 319.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6389],\n",
      "        [0.8579],\n",
      "        [1.1063],\n",
      "        [1.1094]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7628]],\n",
      "\n",
      "        [[0.7570]],\n",
      "\n",
      "        [[0.6958]],\n",
      "\n",
      "        [[1.1706]]], dtype=torch.float64)\n",
      "tensor([[1.0715],\n",
      "        [0.9299],\n",
      "        [0.8574],\n",
      "        [0.6332]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3879]],\n",
      "\n",
      "        [[1.4167]],\n",
      "\n",
      "        [[0.9950]],\n",
      "\n",
      "        [[0.3179]]], dtype=torch.float64)\n",
      "tensor([[0.5808],\n",
      "        [0.7596],\n",
      "        [1.0443],\n",
      "        [0.9758]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0638]],\n",
      "\n",
      "        [[1.0170]],\n",
      "\n",
      "        [[1.4526]],\n",
      "\n",
      "        [[1.4375]]], dtype=torch.float64)\n",
      "tensor([[0.9637],\n",
      "        [0.8150],\n",
      "        [0.6787],\n",
      "        [0.8107]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0574]],\n",
      "\n",
      "        [[0.4913]],\n",
      "\n",
      "        [[0.1677]],\n",
      "\n",
      "        [[1.0019]]], dtype=torch.float64)\n",
      "tensor([[1.2263],\n",
      "        [1.0563],\n",
      "        [0.7658],\n",
      "        [0.4985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6120]],\n",
      "\n",
      "        [[1.4283]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[0.3676]]], dtype=torch.float64)\n",
      "tensor([[0.6194],\n",
      "        [0.6666],\n",
      "        [0.7416],\n",
      "        [0.5535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3907]],\n",
      "\n",
      "        [[0.6287]],\n",
      "\n",
      "        [[1.0516]],\n",
      "\n",
      "        [[1.0447]]], dtype=torch.float64)\n",
      "tensor([[0.4085],\n",
      "        [0.4045],\n",
      "        [0.5430],\n",
      "        [0.5743]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4138]],\n",
      "\n",
      "        [[0.3307]],\n",
      "\n",
      "        [[0.1296]],\n",
      "\n",
      "        [[0.4577]]], dtype=torch.float64)\n",
      "tensor([[0.4214],\n",
      "        [0.4150],\n",
      "        [0.6411],\n",
      "        [0.5089]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5906]],\n",
      "\n",
      "        [[1.0019]],\n",
      "\n",
      "        [[0.7547]],\n",
      "\n",
      "        [[0.1331]]], dtype=torch.float64)\n",
      "tensor([[0.4842],\n",
      "        [0.5849],\n",
      "        [1.0690],\n",
      "        [1.1355]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1408]],\n",
      "\n",
      "        [[ 0.6680]],\n",
      "\n",
      "        [[ 1.5438]],\n",
      "\n",
      "        [[ 1.4375]]], dtype=torch.float64)\n",
      "tensor([[1.1277],\n",
      "        [0.8633],\n",
      "        [1.0123],\n",
      "        [1.0608]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9234]],\n",
      "\n",
      "        [[0.8055]],\n",
      "\n",
      "        [[0.6068]],\n",
      "\n",
      "        [[1.1961]]], dtype=torch.float64)\n",
      "tensor([[1.3490],\n",
      "        [1.5851],\n",
      "        [1.6740],\n",
      "        [1.4637]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7195]],\n",
      "\n",
      "        [[2.0834]],\n",
      "\n",
      "        [[1.7634]],\n",
      "\n",
      "        [[1.3555]]], dtype=torch.float64)\n",
      "tensor([[1.3578],\n",
      "        [1.4568],\n",
      "        [2.0322],\n",
      "        [2.0461]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8980]],\n",
      "\n",
      "        [[1.8073]],\n",
      "\n",
      "        [[2.3884]],\n",
      "\n",
      "        [[2.5409]]], dtype=torch.float64)\n",
      "tensor([[1.9394],\n",
      "        [1.7257],\n",
      "        [1.6604],\n",
      "        [1.5786]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0326]],\n",
      "\n",
      "        [[1.5935]],\n",
      "\n",
      "        [[1.2157]],\n",
      "\n",
      "        [[1.5196]]], dtype=torch.float64)\n",
      "tensor([[1.7574],\n",
      "        [1.9533],\n",
      "        [1.8625],\n",
      "        [1.6520]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9852]],\n",
      "\n",
      "        [[2.3353]],\n",
      "\n",
      "        [[1.9378]],\n",
      "\n",
      "        [[1.1117]]], dtype=torch.float64)\n",
      "tensor([[1.3288],\n",
      "        [1.4489],\n",
      "        [1.1582],\n",
      "        [1.0255]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0482]],\n",
      "\n",
      "        [[1.3694]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[1.2885]]], dtype=torch.float64)\n",
      "tensor([[1.0651],\n",
      "        [0.9732],\n",
      "        [1.0272],\n",
      "        [0.9173]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0563]],\n",
      "\n",
      "        [[0.8171]],\n",
      "\n",
      "        [[0.7073]],\n",
      "\n",
      "        [[0.9384]]], dtype=torch.float64)\n",
      "tensor([[1.0865],\n",
      "        [0.7825],\n",
      "        [0.7111],\n",
      "        [0.8078]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2273]],\n",
      "\n",
      "        [[1.0805]],\n",
      "\n",
      "        [[0.7870]],\n",
      "\n",
      "        [[0.6773]]], dtype=torch.float64)\n",
      "tensor([[0.9628],\n",
      "        [1.0274],\n",
      "        [1.0725],\n",
      "        [1.0852]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6657]],\n",
      "\n",
      "        [[0.9188]],\n",
      "\n",
      "        [[1.1360]],\n",
      "\n",
      "        [[1.4664]]], dtype=torch.float64)\n",
      "tensor([[1.1347],\n",
      "        [1.2150],\n",
      "        [1.1870],\n",
      "        [1.1941]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3035]],\n",
      "\n",
      "        [[1.0297]],\n",
      "\n",
      "        [[0.7755]],\n",
      "\n",
      "        [[1.1464]]], dtype=torch.float64)\n",
      "tensor([[1.4490],\n",
      "        [1.4832],\n",
      "        [1.5001],\n",
      "        [1.4492]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7148]],\n",
      "\n",
      "        [[1.8870]],\n",
      "\n",
      "        [[1.6236]],\n",
      "\n",
      "        [[1.1926]]], dtype=torch.float64)\n",
      "tensor([[1.3486],\n",
      "        [1.3115],\n",
      "        [1.3801],\n",
      "        [1.1310]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9973]],\n",
      "\n",
      "        [[1.1880]],\n",
      "\n",
      "        [[1.4884]],\n",
      "\n",
      "        [[1.2862]]], dtype=torch.float64)\n",
      "tensor([[1.1367],\n",
      "        [1.1782],\n",
      "        [1.1870],\n",
      "        [1.1782]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2365]],\n",
      "\n",
      "        [[0.8852]],\n",
      "\n",
      "        [[0.8356]],\n",
      "\n",
      "        [[1.2157]]], dtype=torch.float64)\n",
      "tensor([[1.4628],\n",
      "        [1.3645],\n",
      "        [1.3095],\n",
      "        [1.2543]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1059]],\n",
      "\n",
      "        [[1.8766]],\n",
      "\n",
      "        [[1.4618]],\n",
      "\n",
      "        [[1.0147]]], dtype=torch.float64)\n",
      "tensor([[1.2416],\n",
      "        [1.2196],\n",
      "        [1.0670],\n",
      "        [1.2457]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9060]],\n",
      "\n",
      "        [[1.0528]],\n",
      "\n",
      "        [[1.2492]],\n",
      "\n",
      "        [[1.6351]]], dtype=torch.float64)\n",
      "tensor([[1.2563],\n",
      "        [1.1707],\n",
      "        [1.0297],\n",
      "        [1.0791]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4017]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.5999]],\n",
      "\n",
      "        [[1.4999]]], dtype=torch.float64)\n",
      "tensor([[1.4700],\n",
      "        [1.0564],\n",
      "        [1.2642],\n",
      "        [1.0951]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4329]],\n",
      "\n",
      "        [[1.6744]],\n",
      "\n",
      "        [[1.3093]],\n",
      "\n",
      "        [[0.9476]]], dtype=torch.float64)\n",
      "tensor([[0.9165],\n",
      "        [1.0489],\n",
      "        [1.1069],\n",
      "        [1.1213]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5375]],\n",
      "\n",
      "        [[1.0898]],\n",
      "\n",
      "        [[1.4826]],\n",
      "\n",
      "        [[1.5473]]], dtype=torch.float64)\n",
      "tensor([[1.0666],\n",
      "        [0.9333],\n",
      "        [1.0772],\n",
      "        [1.0918]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1660]],\n",
      "\n",
      "        [[0.8448]],\n",
      "\n",
      "        [[0.7466]],\n",
      "\n",
      "        [[1.3647]]], dtype=torch.float64)\n",
      "tensor([[1.2041],\n",
      "        [1.1695],\n",
      "        [1.0326],\n",
      "        [0.9493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5496]],\n",
      "\n",
      "        [[1.6386]],\n",
      "\n",
      "        [[1.1279]],\n",
      "\n",
      "        [[0.7720]]], dtype=torch.float64)\n",
      "tensor([[0.9579],\n",
      "        [0.9534],\n",
      "        [1.0583],\n",
      "        [0.9584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5825]],\n",
      "\n",
      "        [[1.0424]],\n",
      "\n",
      "        [[1.3128]],\n",
      "\n",
      "        [[1.3416]]], dtype=torch.float64)\n",
      "tensor([[0.8706],\n",
      "        [0.7326],\n",
      "        [0.7588],\n",
      "        [0.7656]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7616]],\n",
      "\n",
      "        [[0.6553]],\n",
      "\n",
      "        [[0.3029]],\n",
      "\n",
      "        [[0.7108]]], dtype=torch.float64)\n",
      "tensor([[0.7949],\n",
      "        [0.4404],\n",
      "        [0.5356],\n",
      "        [0.4769]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0840]],\n",
      "\n",
      "        [[0.2209]],\n",
      "\n",
      "        [[0.5444]],\n",
      "\n",
      "        [[0.1088]]], dtype=torch.float64)\n",
      "tensor([[0.5165],\n",
      "        [0.6003],\n",
      "        [0.7473],\n",
      "        [0.7447]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0799]],\n",
      "\n",
      "        [[0.3919]],\n",
      "\n",
      "        [[0.7200]],\n",
      "\n",
      "        [[0.9881]]], dtype=torch.float64)\n",
      "tensor([[0.7815],\n",
      "        [0.9018],\n",
      "        [0.9701],\n",
      "        [1.0101]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8679]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.6357]],\n",
      "\n",
      "        [[0.8760]]], dtype=torch.float64)\n",
      "tensor([[0.8330],\n",
      "        [0.7280],\n",
      "        [0.7165],\n",
      "        [0.6138]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9442]],\n",
      "\n",
      "        [[1.0170]],\n",
      "\n",
      "        [[0.6045]],\n",
      "\n",
      "        [[0.4219]]], dtype=torch.float64)\n",
      "tensor([[0.7257],\n",
      "        [0.8234],\n",
      "        [0.9234],\n",
      "        [0.7694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3734]],\n",
      "\n",
      "        [[0.9488]],\n",
      "\n",
      "        [[1.0701]],\n",
      "\n",
      "        [[1.0597]]], dtype=torch.float64)\n",
      "tensor([[0.6879],\n",
      "        [0.7172],\n",
      "        [0.8569],\n",
      "        [0.6407]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7085]],\n",
      "\n",
      "        [[0.6126]],\n",
      "\n",
      "        [[0.5421]],\n",
      "\n",
      "        [[0.7166]]], dtype=torch.float64)\n",
      "tensor([[0.6731],\n",
      "        [0.7008],\n",
      "        [0.7398],\n",
      "        [0.6944]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8714]],\n",
      "\n",
      "        [[1.0574]],\n",
      "\n",
      "        [[0.7316]],\n",
      "\n",
      "        [[0.4820]]], dtype=torch.float64)\n",
      "tensor([[0.8397],\n",
      "        [0.8208],\n",
      "        [0.8306],\n",
      "        [0.8802]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4497]],\n",
      "\n",
      "        [[0.7142]],\n",
      "\n",
      "        [[1.0158]],\n",
      "\n",
      "        [[1.1926]]], dtype=torch.float64)\n",
      "tensor([[0.5507],\n",
      "        [0.8020],\n",
      "        [0.9078],\n",
      "        [0.9901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7073]],\n",
      "\n",
      "        [[0.6634]],\n",
      "\n",
      "        [[0.6495]],\n",
      "\n",
      "        [[0.9927]]], dtype=torch.float64)\n",
      "tensor([[0.9734],\n",
      "        [1.2034],\n",
      "        [1.3031],\n",
      "        [1.2198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4988]],\n",
      "\n",
      "        [[1.6940]],\n",
      "\n",
      "        [[1.3439]],\n",
      "\n",
      "        [[1.1325]]], dtype=torch.float64)\n",
      "tensor([[1.2384],\n",
      "        [1.2314],\n",
      "        [1.0940],\n",
      "        [0.8730]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1325]],\n",
      "\n",
      "        [[1.2041]],\n",
      "\n",
      "        [[1.4133]],\n",
      "\n",
      "        [[1.3740]]], dtype=torch.float64)\n",
      "tensor([[0.6070],\n",
      "        [0.5510],\n",
      "        [0.8112],\n",
      "        [0.8405]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0112]],\n",
      "\n",
      "        [[0.5340]],\n",
      "\n",
      "        [[0.5109]],\n",
      "\n",
      "        [[0.8309]]], dtype=torch.float64)\n",
      "tensor([[0.8687],\n",
      "        [0.4885],\n",
      "        [0.6823],\n",
      "        [0.7322]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1857]],\n",
      "\n",
      "        [[0.8148]],\n",
      "\n",
      "        [[0.7570]],\n",
      "\n",
      "        [[0.5525]]], dtype=torch.float64)\n",
      "tensor([[0.7905],\n",
      "        [0.6112],\n",
      "        [0.5460],\n",
      "        [0.4965]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3260]],\n",
      "\n",
      "        [[0.4855]],\n",
      "\n",
      "        [[0.5121]],\n",
      "\n",
      "        [[0.8910]]], dtype=torch.float64)\n",
      "tensor([[0.4220],\n",
      "        [0.5647],\n",
      "        [0.6586],\n",
      "        [0.6493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6010]],\n",
      "\n",
      "        [[0.2763]],\n",
      "\n",
      "        [[0.2024]],\n",
      "\n",
      "        [[0.4450]]], dtype=torch.float64)\n",
      "tensor([[0.6471],\n",
      "        [0.5828],\n",
      "        [0.6510],\n",
      "        [0.5773]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7882]],\n",
      "\n",
      "        [[1.0435]],\n",
      "\n",
      "        [[0.8125]],\n",
      "\n",
      "        [[0.1758]]], dtype=torch.float64)\n",
      "tensor([[0.4332],\n",
      "        [0.5573],\n",
      "        [1.0630],\n",
      "        [1.3903]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1304]],\n",
      "\n",
      "        [[ 0.6900]],\n",
      "\n",
      "        [[ 1.4491]],\n",
      "\n",
      "        [[ 1.7714]]], dtype=torch.float64)\n",
      "tensor([[1.3202],\n",
      "        [1.1213],\n",
      "        [0.8362],\n",
      "        [0.8788]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4410]],\n",
      "\n",
      "        [[0.7108]],\n",
      "\n",
      "        [[0.2498]],\n",
      "\n",
      "        [[1.0447]]], dtype=torch.float64)\n",
      "tensor([[1.6049],\n",
      "        [1.7330],\n",
      "        [1.8158],\n",
      "        [1.5291]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9309]],\n",
      "\n",
      "        [[2.2660]],\n",
      "\n",
      "        [[1.8777]],\n",
      "\n",
      "        [[1.2400]]], dtype=torch.float64)\n",
      "tensor([[1.3052],\n",
      "        [1.2832],\n",
      "        [2.0013],\n",
      "        [2.1575]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7940]],\n",
      "\n",
      "        [[1.5207]],\n",
      "\n",
      "        [[2.4185]],\n",
      "\n",
      "        [[2.6669]]], dtype=torch.float64)\n",
      "tensor([[2.1625],\n",
      "        [1.8644],\n",
      "        [1.7352],\n",
      "        [1.6499]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0303]],\n",
      "\n",
      "        [[1.6582]],\n",
      "\n",
      "        [[1.1718]],\n",
      "\n",
      "        [[1.8743]]], dtype=torch.float64)\n",
      "tensor([[2.0378],\n",
      "        [2.0477],\n",
      "        [1.8555],\n",
      "        [1.6393]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3064]],\n",
      "\n",
      "        [[2.3665]],\n",
      "\n",
      "        [[1.9528]],\n",
      "\n",
      "        [[1.3740]]], dtype=torch.float64)\n",
      "tensor([[1.4477],\n",
      "        [1.3496],\n",
      "        [2.0963],\n",
      "        [2.1968]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9788]],\n",
      "\n",
      "        [[1.5877]],\n",
      "\n",
      "        [[2.5513]],\n",
      "\n",
      "        [[2.6311]]], dtype=torch.float64)\n",
      "tensor([[2.2752],\n",
      "        [1.8850],\n",
      "        [1.6796],\n",
      "        [1.6551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2833]],\n",
      "\n",
      "        [[1.6259]],\n",
      "\n",
      "        [[1.3520]],\n",
      "\n",
      "        [[1.7241]]], dtype=torch.float64)\n",
      "tensor([[1.5927],\n",
      "        [1.4146],\n",
      "        [1.4389],\n",
      "        [1.2206]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1776]],\n",
      "\n",
      "        [[1.8015]],\n",
      "\n",
      "        [[1.3058]],\n",
      "\n",
      "        [[1.1186]]], dtype=torch.float64)\n",
      "tensor([[1.3393],\n",
      "        [1.3584],\n",
      "        [1.1694],\n",
      "        [1.0329]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9950]],\n",
      "\n",
      "        [[1.2688]],\n",
      "\n",
      "        [[1.3370]],\n",
      "\n",
      "        [[1.5092]]], dtype=torch.float64)\n",
      "tensor([[0.8980],\n",
      "        [0.7181],\n",
      "        [0.7462],\n",
      "        [0.6789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9361]],\n",
      "\n",
      "        [[0.7223]],\n",
      "\n",
      "        [[0.2278]],\n",
      "\n",
      "        [[0.8841]]], dtype=torch.float64)\n",
      "tensor([[0.8853],\n",
      "        [0.9350],\n",
      "        [0.8823],\n",
      "        [0.7610]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1683]],\n",
      "\n",
      "        [[1.2735]],\n",
      "\n",
      "        [[1.0401]],\n",
      "\n",
      "        [[0.5201]]], dtype=torch.float64)\n",
      "tensor([[0.7256],\n",
      "        [0.7043],\n",
      "        [1.0697],\n",
      "        [1.0830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3746]],\n",
      "\n",
      "        [[0.8309]],\n",
      "\n",
      "        [[1.3532]],\n",
      "\n",
      "        [[1.4976]]], dtype=torch.float64)\n",
      "tensor([[0.9899],\n",
      "        [0.9801],\n",
      "        [0.8396],\n",
      "        [0.9192]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2896]],\n",
      "\n",
      "        [[0.6680]],\n",
      "\n",
      "        [[0.4520]],\n",
      "\n",
      "        [[1.1163]]], dtype=torch.float64)\n",
      "tensor([[1.3632],\n",
      "        [1.5995],\n",
      "        [1.6460],\n",
      "        [1.4296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7818]],\n",
      "\n",
      "        [[2.2013]],\n",
      "\n",
      "        [[1.8177]],\n",
      "\n",
      "        [[1.2862]]], dtype=torch.float64)\n",
      "tensor([[1.3384],\n",
      "        [1.3641],\n",
      "        [1.8134],\n",
      "        [1.8441]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0331]],\n",
      "\n",
      "        [[1.6467]],\n",
      "\n",
      "        [[2.2325]],\n",
      "\n",
      "        [[2.2833]]], dtype=torch.float64)\n",
      "tensor([[1.6194],\n",
      "        [1.5025],\n",
      "        [1.4474],\n",
      "        [1.2643]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8234]],\n",
      "\n",
      "        [[1.2931]],\n",
      "\n",
      "        [[1.0077]],\n",
      "\n",
      "        [[1.2041]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.18920:  66%|██████▋   | 2032/3067 [00:06<00:03, 329.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2956],\n",
      "        [1.3980],\n",
      "        [1.2859],\n",
      "        [1.2540]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5935]],\n",
      "\n",
      "        [[1.9159]],\n",
      "\n",
      "        [[1.3855]],\n",
      "\n",
      "        [[0.9430]]], dtype=torch.float64)\n",
      "tensor([[1.1077],\n",
      "        [1.0622],\n",
      "        [1.4777],\n",
      "        [1.5160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5606]],\n",
      "\n",
      "        [[1.1799]],\n",
      "\n",
      "        [[1.9598]],\n",
      "\n",
      "        [[2.1435]]], dtype=torch.float64)\n",
      "tensor([[1.4778],\n",
      "        [1.2009],\n",
      "        [1.1073],\n",
      "        [1.0772]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6490]],\n",
      "\n",
      "        [[0.9719]],\n",
      "\n",
      "        [[0.7212]],\n",
      "\n",
      "        [[0.7350]]], dtype=torch.float64)\n",
      "tensor([[1.1005],\n",
      "        [1.5035],\n",
      "        [1.4364],\n",
      "        [1.3700]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2619]],\n",
      "\n",
      "        [[1.8096]],\n",
      "\n",
      "        [[1.4445]],\n",
      "\n",
      "        [[1.0389]]], dtype=torch.float64)\n",
      "tensor([[1.4177],\n",
      "        [1.5603],\n",
      "        [1.4395],\n",
      "        [1.2978]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2816]],\n",
      "\n",
      "        [[1.3104]],\n",
      "\n",
      "        [[1.5820]],\n",
      "\n",
      "        [[1.5196]]], dtype=torch.float64)\n",
      "tensor([[1.1844],\n",
      "        [1.0713],\n",
      "        [1.1247],\n",
      "        [1.1040]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1937]],\n",
      "\n",
      "        [[0.8598]],\n",
      "\n",
      "        [[0.6703]],\n",
      "\n",
      "        [[0.9569]]], dtype=torch.float64)\n",
      "tensor([[1.0478],\n",
      "        [1.0253],\n",
      "        [0.9993],\n",
      "        [0.9218]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2319]],\n",
      "\n",
      "        [[1.3174]],\n",
      "\n",
      "        [[0.9569]],\n",
      "\n",
      "        [[0.7304]]], dtype=torch.float64)\n",
      "tensor([[1.0033],\n",
      "        [0.9623],\n",
      "        [0.9360],\n",
      "        [1.0156]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7015]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[1.3312]],\n",
      "\n",
      "        [[1.4872]]], dtype=torch.float64)\n",
      "tensor([[1.0670],\n",
      "        [1.0637],\n",
      "        [0.8295],\n",
      "        [0.7859]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1452]],\n",
      "\n",
      "        [[0.6380]],\n",
      "\n",
      "        [[0.2532]],\n",
      "\n",
      "        [[0.9661]]], dtype=torch.float64)\n",
      "tensor([[1.1864],\n",
      "        [1.0804],\n",
      "        [0.7517],\n",
      "        [0.9749]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4144]],\n",
      "\n",
      "        [[1.3532]],\n",
      "\n",
      "        [[1.0089]],\n",
      "\n",
      "        [[0.8610]]], dtype=torch.float64)\n",
      "tensor([[1.1137],\n",
      "        [0.9726],\n",
      "        [0.8721],\n",
      "        [0.5744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6565]],\n",
      "\n",
      "        [[0.6923]],\n",
      "\n",
      "        [[1.0170]],\n",
      "\n",
      "        [[1.0516]]], dtype=torch.float64)\n",
      "tensor([[0.5359],\n",
      "        [0.7486],\n",
      "        [0.9407],\n",
      "        [0.8517]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7766]],\n",
      "\n",
      "        [[0.6380]],\n",
      "\n",
      "        [[0.5386]],\n",
      "\n",
      "        [[0.6334]]], dtype=torch.float64)\n",
      "tensor([[0.7500],\n",
      "        [0.8739],\n",
      "        [0.7999],\n",
      "        [0.6807]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8298]],\n",
      "\n",
      "        [[1.2608]],\n",
      "\n",
      "        [[0.8795]],\n",
      "\n",
      "        [[0.2752]]], dtype=torch.float64)\n",
      "tensor([[0.6256],\n",
      "        [0.5367],\n",
      "        [0.9973],\n",
      "        [0.9370]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0841]],\n",
      "\n",
      "        [[ 0.6160]],\n",
      "\n",
      "        [[ 1.2527]],\n",
      "\n",
      "        [[ 1.4306]]], dtype=torch.float64)\n",
      "tensor([[0.7834],\n",
      "        [0.7007],\n",
      "        [0.8050],\n",
      "        [0.6087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0251]],\n",
      "\n",
      "        [[0.7501]],\n",
      "\n",
      "        [[0.2301]],\n",
      "\n",
      "        [[0.7293]]], dtype=torch.float64)\n",
      "tensor([[1.1757],\n",
      "        [1.0965],\n",
      "        [0.9205],\n",
      "        [0.7689]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4225]],\n",
      "\n",
      "        [[1.6166]],\n",
      "\n",
      "        [[1.1556]],\n",
      "\n",
      "        [[0.7651]]], dtype=torch.float64)\n",
      "tensor([[0.7248],\n",
      "        [0.5919],\n",
      "        [1.1887],\n",
      "        [1.2645]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1053]],\n",
      "\n",
      "        [[0.8021]],\n",
      "\n",
      "        [[1.6501]],\n",
      "\n",
      "        [[1.8154]]], dtype=torch.float64)\n",
      "tensor([[1.1269],\n",
      "        [0.9998],\n",
      "        [0.7940],\n",
      "        [0.6801]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3543]],\n",
      "\n",
      "        [[0.7004]],\n",
      "\n",
      "        [[0.3387]],\n",
      "\n",
      "        [[0.9835]]], dtype=torch.float64)\n",
      "tensor([[1.3839],\n",
      "        [1.4605],\n",
      "        [1.3721],\n",
      "        [1.1735]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7645]],\n",
      "\n",
      "        [[1.9424]],\n",
      "\n",
      "        [[1.5381]],\n",
      "\n",
      "        [[1.0620]]], dtype=torch.float64)\n",
      "tensor([[1.1445],\n",
      "        [1.0834],\n",
      "        [0.9673],\n",
      "        [0.8648]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9176]],\n",
      "\n",
      "        [[1.0170]],\n",
      "\n",
      "        [[0.8598]],\n",
      "\n",
      "        [[1.3451]]], dtype=torch.float64)\n",
      "tensor([[1.1978],\n",
      "        [0.9954],\n",
      "        [0.9559],\n",
      "        [0.7856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9257]],\n",
      "\n",
      "        [[0.5432]],\n",
      "\n",
      "        [[0.3307]],\n",
      "\n",
      "        [[0.4520]]], dtype=torch.float64)\n",
      "tensor([[1.3522],\n",
      "        [1.3845],\n",
      "        [1.3405],\n",
      "        [1.2106]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6363]],\n",
      "\n",
      "        [[1.8523]],\n",
      "\n",
      "        [[1.4156]],\n",
      "\n",
      "        [[0.7766]]], dtype=torch.float64)\n",
      "tensor([[1.0192],\n",
      "        [0.9415],\n",
      "        [1.6276],\n",
      "        [1.7991]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3965]],\n",
      "\n",
      "        [[1.0978]],\n",
      "\n",
      "        [[2.1805]],\n",
      "\n",
      "        [[2.4104]]], dtype=torch.float64)\n",
      "tensor([[1.7747],\n",
      "        [1.4956],\n",
      "        [1.3335],\n",
      "        [1.2755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9136]],\n",
      "\n",
      "        [[1.0955]],\n",
      "\n",
      "        [[0.7662]],\n",
      "\n",
      "        [[1.4895]]], dtype=torch.float64)\n",
      "tensor([[2.2060],\n",
      "        [2.5723],\n",
      "        [2.3202],\n",
      "        [1.8341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.7616]],\n",
      "\n",
      "        [[3.0528]],\n",
      "\n",
      "        [[2.4370]],\n",
      "\n",
      "        [[1.5196]]], dtype=torch.float64)\n",
      "tensor([[1.7465],\n",
      "        [1.7488],\n",
      "        [2.5923],\n",
      "        [2.6374]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3578]],\n",
      "\n",
      "        [[1.8743]],\n",
      "\n",
      "        [[2.9950]],\n",
      "\n",
      "        [[2.8783]]], dtype=torch.float64)\n",
      "tensor([[2.2847],\n",
      "        [1.9391],\n",
      "        [1.9007],\n",
      "        [1.6715]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0707]],\n",
      "\n",
      "        [[1.6132]],\n",
      "\n",
      "        [[1.2896]],\n",
      "\n",
      "        [[1.5392]]], dtype=torch.float64)\n",
      "tensor([[2.0674],\n",
      "        [2.1660],\n",
      "        [2.1016],\n",
      "        [1.8363]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3110]],\n",
      "\n",
      "        [[2.5121]],\n",
      "\n",
      "        [[2.1158]],\n",
      "\n",
      "        [[1.5404]]], dtype=torch.float64)\n",
      "tensor([[1.6941],\n",
      "        [1.5690],\n",
      "        [1.5389],\n",
      "        [1.4362]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2873]],\n",
      "\n",
      "        [[1.4387]],\n",
      "\n",
      "        [[1.7738]],\n",
      "\n",
      "        [[1.9575]]], dtype=torch.float64)\n",
      "tensor([[1.1031],\n",
      "        [1.0551],\n",
      "        [0.9194],\n",
      "        [0.8053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3844]],\n",
      "\n",
      "        [[0.8171]],\n",
      "\n",
      "        [[0.3665]],\n",
      "\n",
      "        [[0.8841]]], dtype=torch.float64)\n",
      "tensor([[1.2014],\n",
      "        [1.1774],\n",
      "        [1.1023],\n",
      "        [0.9245]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4884]],\n",
      "\n",
      "        [[1.7507]],\n",
      "\n",
      "        [[1.3151]],\n",
      "\n",
      "        [[0.6969]]], dtype=torch.float64)\n",
      "tensor([[0.9839],\n",
      "        [0.8645],\n",
      "        [1.0899],\n",
      "        [1.3541]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5167]],\n",
      "\n",
      "        [[0.6542]],\n",
      "\n",
      "        [[1.2746]],\n",
      "\n",
      "        [[1.5496]]], dtype=torch.float64)\n",
      "tensor([[1.1410],\n",
      "        [1.2183],\n",
      "        [1.4149],\n",
      "        [1.3007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1984]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[1.0158]],\n",
      "\n",
      "        [[1.3555]]], dtype=torch.float64)\n",
      "tensor([[1.4036],\n",
      "        [1.4469],\n",
      "        [1.1757],\n",
      "        [1.1737]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6490]],\n",
      "\n",
      "        [[1.8766]],\n",
      "\n",
      "        [[1.4294]],\n",
      "\n",
      "        [[1.1857]]], dtype=torch.float64)\n",
      "tensor([[1.0107],\n",
      "        [1.0650],\n",
      "        [0.9316],\n",
      "        [0.7333]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7200]],\n",
      "\n",
      "        [[1.0274]],\n",
      "\n",
      "        [[1.1140]],\n",
      "\n",
      "        [[1.0100]]], dtype=torch.float64)\n",
      "tensor([[0.6480],\n",
      "        [0.6636],\n",
      "        [0.8331],\n",
      "        [0.8703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6149]],\n",
      "\n",
      "        [[0.6391]],\n",
      "\n",
      "        [[0.5883]],\n",
      "\n",
      "        [[0.8055]]], dtype=torch.float64)\n",
      "tensor([[0.7731],\n",
      "        [0.8666],\n",
      "        [0.8511],\n",
      "        [0.7215]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0343]],\n",
      "\n",
      "        [[1.4502]],\n",
      "\n",
      "        [[0.8829]],\n",
      "\n",
      "        [[0.3515]]], dtype=torch.float64)\n",
      "tensor([[0.6408],\n",
      "        [0.6611],\n",
      "        [1.2502],\n",
      "        [1.3336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1724]],\n",
      "\n",
      "        [[0.6715]],\n",
      "\n",
      "        [[1.7322]],\n",
      "\n",
      "        [[1.8673]]], dtype=torch.float64)\n",
      "tensor([[1.2139],\n",
      "        [1.2907],\n",
      "        [1.1746],\n",
      "        [1.1488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4375]],\n",
      "\n",
      "        [[1.2111]],\n",
      "\n",
      "        [[0.7535]],\n",
      "\n",
      "        [[1.1152]]], dtype=torch.float64)\n",
      "tensor([[1.6521],\n",
      "        [1.5338],\n",
      "        [1.3783],\n",
      "        [1.3480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9667]],\n",
      "\n",
      "        [[2.0210]],\n",
      "\n",
      "        [[1.5311]],\n",
      "\n",
      "        [[1.1533]]], dtype=torch.float64)\n",
      "tensor([[1.3607],\n",
      "        [1.2930],\n",
      "        [1.4093],\n",
      "        [1.1916]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0435]],\n",
      "\n",
      "        [[1.0563]],\n",
      "\n",
      "        [[1.5184]],\n",
      "\n",
      "        [[1.4941]]], dtype=torch.float64)\n",
      "tensor([[0.9040],\n",
      "        [0.8457],\n",
      "        [1.0505],\n",
      "        [0.9646]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7558]],\n",
      "\n",
      "        [[0.7073]],\n",
      "\n",
      "        [[0.6022]],\n",
      "\n",
      "        [[0.7166]]], dtype=torch.float64)\n",
      "tensor([[0.8441],\n",
      "        [0.6556],\n",
      "        [0.7036],\n",
      "        [0.6303]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9049]],\n",
      "\n",
      "        [[1.0574]],\n",
      "\n",
      "        [[0.6727]],\n",
      "\n",
      "        [[0.4913]]], dtype=torch.float64)\n",
      "tensor([[0.8335],\n",
      "        [0.7154],\n",
      "        [0.6226],\n",
      "        [0.6031]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4462]],\n",
      "\n",
      "        [[0.4497]],\n",
      "\n",
      "        [[0.9026]],\n",
      "\n",
      "        [[0.9973]]], dtype=torch.float64)\n",
      "tensor([[0.6053],\n",
      "        [0.6126],\n",
      "        [0.5059],\n",
      "        [0.3424]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7662]],\n",
      "\n",
      "        [[ 0.2532]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[ 0.1955]]], dtype=torch.float64)\n",
      "tensor([[0.7937],\n",
      "        [0.9103],\n",
      "        [0.9287],\n",
      "        [0.7166]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1833]],\n",
      "\n",
      "        [[1.3890]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.4774]]], dtype=torch.float64)\n",
      "tensor([[0.7750],\n",
      "        [0.7258],\n",
      "        [1.1760],\n",
      "        [1.1078]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2371]],\n",
      "\n",
      "        [[0.7431]],\n",
      "\n",
      "        [[1.4549]],\n",
      "\n",
      "        [[1.5277]]], dtype=torch.float64)\n",
      "tensor([[0.8545],\n",
      "        [0.8232],\n",
      "        [0.7499],\n",
      "        [0.5984]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0551]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[0.2348]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[1.1188],\n",
      "        [1.0469],\n",
      "        [0.9130],\n",
      "        [0.7754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4098]],\n",
      "\n",
      "        [[1.5288]],\n",
      "\n",
      "        [[1.0424]],\n",
      "\n",
      "        [[0.4658]]], dtype=torch.float64)\n",
      "tensor([[0.7527],\n",
      "        [0.5975],\n",
      "        [0.8117],\n",
      "        [0.7183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1955]],\n",
      "\n",
      "        [[0.4577]],\n",
      "\n",
      "        [[0.8829]],\n",
      "\n",
      "        [[0.7951]]], dtype=torch.float64)\n",
      "tensor([[0.4750],\n",
      "        [0.5986],\n",
      "        [0.7358],\n",
      "        [0.5576]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5929]],\n",
      "\n",
      "        [[0.4728]],\n",
      "\n",
      "        [[0.3399]],\n",
      "\n",
      "        [[0.4474]]], dtype=torch.float64)\n",
      "tensor([[0.4689],\n",
      "        [0.4823],\n",
      "        [0.4164],\n",
      "        [0.3663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7570]],\n",
      "\n",
      "        [[ 1.0239]],\n",
      "\n",
      "        [[ 0.7015]],\n",
      "\n",
      "        [[-0.0668]]], dtype=torch.float64)\n",
      "tensor([[ 0.2080],\n",
      "        [-0.0174],\n",
      "        [ 0.6667],\n",
      "        [ 0.8996]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3291]],\n",
      "\n",
      "        [[ 0.0522]],\n",
      "\n",
      "        [[ 1.1868]],\n",
      "\n",
      "        [[ 1.5034]]], dtype=torch.float64)\n",
      "tensor([[0.8042],\n",
      "        [0.8286],\n",
      "        [0.9201],\n",
      "        [0.8877]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1487]],\n",
      "\n",
      "        [[0.6611]],\n",
      "\n",
      "        [[0.5733]],\n",
      "\n",
      "        [[1.0378]]], dtype=torch.float64)\n",
      "tensor([[1.2606],\n",
      "        [1.2125],\n",
      "        [1.1994],\n",
      "        [0.8889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7171]],\n",
      "\n",
      "        [[1.8188]],\n",
      "\n",
      "        [[1.3312]],\n",
      "\n",
      "        [[0.6819]]], dtype=torch.float64)\n",
      "tensor([[0.8397],\n",
      "        [0.6455],\n",
      "        [1.4442],\n",
      "        [1.6492]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3503]],\n",
      "\n",
      "        [[0.8980]],\n",
      "\n",
      "        [[1.9979]],\n",
      "\n",
      "        [[2.2613]]], dtype=torch.float64)\n",
      "tensor([[1.4421],\n",
      "        [1.2566],\n",
      "        [1.1764],\n",
      "        [1.0383]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5970]],\n",
      "\n",
      "        [[1.1256]],\n",
      "\n",
      "        [[0.7801]],\n",
      "\n",
      "        [[1.0886]]], dtype=torch.float64)\n",
      "tensor([[1.6009],\n",
      "        [1.5489],\n",
      "        [1.3161],\n",
      "        [1.1122]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3572]],\n",
      "\n",
      "        [[2.3168]],\n",
      "\n",
      "        [[1.6883]],\n",
      "\n",
      "        [[0.9003]]], dtype=torch.float64)\n",
      "tensor([[1.0035],\n",
      "        [0.8466],\n",
      "        [1.5355],\n",
      "        [1.4501]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4947]],\n",
      "\n",
      "        [[0.9164]],\n",
      "\n",
      "        [[1.8084]],\n",
      "\n",
      "        [[1.7229]]], dtype=torch.float64)\n",
      "tensor([[1.0510],\n",
      "        [0.8034],\n",
      "        [0.6487],\n",
      "        [0.6345]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9268]],\n",
      "\n",
      "        [[0.3907]],\n",
      "\n",
      "        [[0.3376]],\n",
      "\n",
      "        [[0.3838]]], dtype=torch.float64)\n",
      "tensor([[0.4948],\n",
      "        [0.2207],\n",
      "        [0.0468],\n",
      "        [0.2030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5791]],\n",
      "\n",
      "        [[0.1562]],\n",
      "\n",
      "        [[0.1377]],\n",
      "\n",
      "        [[0.0788]]], dtype=torch.float64)\n",
      "tensor([[0.2356],\n",
      "        [0.0535],\n",
      "        [0.4509],\n",
      "        [0.2985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0899]],\n",
      "\n",
      "        [[ 0.1701]],\n",
      "\n",
      "        [[ 0.6900]],\n",
      "\n",
      "        [[ 0.8298]]], dtype=torch.float64)\n",
      "tensor([[ 0.2231],\n",
      "        [ 0.0616],\n",
      "        [-0.1969],\n",
      "        [-0.1588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2463]],\n",
      "\n",
      "        [[-0.2632]],\n",
      "\n",
      "        [[-0.4978]],\n",
      "\n",
      "        [[ 0.0418]]], dtype=torch.float64)\n",
      "tensor([[0.6740],\n",
      "        [0.6423],\n",
      "        [0.6888],\n",
      "        [0.6043]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0054]],\n",
      "\n",
      "        [[1.0944]],\n",
      "\n",
      "        [[0.8760]],\n",
      "\n",
      "        [[0.4820]]], dtype=torch.float64)\n",
      "tensor([[0.6278],\n",
      "        [0.5019],\n",
      "        [0.4917],\n",
      "        [0.4994]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2625]],\n",
      "\n",
      "        [[0.4936]],\n",
      "\n",
      "        [[0.7951]],\n",
      "\n",
      "        [[0.9014]]], dtype=torch.float64)\n",
      "tensor([[0.4043],\n",
      "        [0.5539],\n",
      "        [0.4395],\n",
      "        [0.2147]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6461]],\n",
      "\n",
      "        [[ 0.1851]],\n",
      "\n",
      "        [[-0.1581]],\n",
      "\n",
      "        [[ 0.2220]]], dtype=torch.float64)\n",
      "tensor([[0.8601],\n",
      "        [0.9869],\n",
      "        [0.8174],\n",
      "        [0.5267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1926]],\n",
      "\n",
      "        [[1.3902]],\n",
      "\n",
      "        [[0.7974]],\n",
      "\n",
      "        [[0.2036]]], dtype=torch.float64)\n",
      "tensor([[0.4814],\n",
      "        [0.4840],\n",
      "        [0.8710],\n",
      "        [1.0376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0418]],\n",
      "\n",
      "        [[0.3630]],\n",
      "\n",
      "        [[1.2977]],\n",
      "\n",
      "        [[1.5531]]], dtype=torch.float64)\n",
      "tensor([[0.8981],\n",
      "        [0.7637],\n",
      "        [0.6966],\n",
      "        [0.5333]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.18888:  69%|██████▊   | 2105/3067 [00:06<00:02, 341.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9222]],\n",
      "\n",
      "        [[0.4497]],\n",
      "\n",
      "        [[0.1157]],\n",
      "\n",
      "        [[0.5225]]], dtype=torch.float64)\n",
      "tensor([[1.1600],\n",
      "        [1.1137],\n",
      "        [0.9235],\n",
      "        [0.4805]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6270]],\n",
      "\n",
      "        [[1.5542]],\n",
      "\n",
      "        [[0.9650]],\n",
      "\n",
      "        [[0.3041]]], dtype=torch.float64)\n",
      "tensor([[0.5406],\n",
      "        [0.2785],\n",
      "        [0.2978],\n",
      "        [0.2482]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1955]],\n",
      "\n",
      "        [[0.3364]],\n",
      "\n",
      "        [[0.6599]],\n",
      "\n",
      "        [[0.5675]]], dtype=torch.float64)\n",
      "tensor([[-0.0027],\n",
      "        [-0.0287],\n",
      "        [-0.1505],\n",
      "        [-0.3543]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0534]],\n",
      "\n",
      "        [[-0.1142]],\n",
      "\n",
      "        [[-0.5301]],\n",
      "\n",
      "        [[-0.1777]]], dtype=torch.float64)\n",
      "tensor([[0.3574],\n",
      "        [0.1587],\n",
      "        [0.0397],\n",
      "        [0.0118]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4936]],\n",
      "\n",
      "        [[ 0.6484]],\n",
      "\n",
      "        [[ 0.2174]],\n",
      "\n",
      "        [[-0.2609]]], dtype=torch.float64)\n",
      "tensor([[-0.2821],\n",
      "        [-0.3746],\n",
      "        [ 0.3983],\n",
      "        [ 0.4707]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5579]],\n",
      "\n",
      "        [[-0.3025]],\n",
      "\n",
      "        [[ 0.7743]],\n",
      "\n",
      "        [[ 0.9014]]], dtype=torch.float64)\n",
      "tensor([[0.3726],\n",
      "        [0.4263],\n",
      "        [0.5314],\n",
      "        [0.5800]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4566]],\n",
      "\n",
      "        [[0.2948]],\n",
      "\n",
      "        [[0.1100]],\n",
      "\n",
      "        [[0.3722]]], dtype=torch.float64)\n",
      "tensor([[ 0.3775],\n",
      "        [ 0.0583],\n",
      "        [ 0.1071],\n",
      "        [-0.0639]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4185]],\n",
      "\n",
      "        [[ 0.6415]],\n",
      "\n",
      "        [[ 0.1643]],\n",
      "\n",
      "        [[-0.3071]]], dtype=torch.float64)\n",
      "tensor([[-0.3593],\n",
      "        [-0.4117],\n",
      "        [ 0.1944],\n",
      "        [ 0.2589]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5821]],\n",
      "\n",
      "        [[-0.3973]],\n",
      "\n",
      "        [[ 0.4381]],\n",
      "\n",
      "        [[ 0.6080]]], dtype=torch.float64)\n",
      "tensor([[0.2159],\n",
      "        [0.1726],\n",
      "        [0.4437],\n",
      "        [0.4540]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3873]],\n",
      "\n",
      "        [[0.2301]],\n",
      "\n",
      "        [[0.1689]],\n",
      "\n",
      "        [[0.3746]]], dtype=torch.float64)\n",
      "tensor([[0.7994],\n",
      "        [0.8753],\n",
      "        [0.8421],\n",
      "        [0.5908]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0366]],\n",
      "\n",
      "        [[1.3312]],\n",
      "\n",
      "        [[0.7582]],\n",
      "\n",
      "        [[0.4462]]], dtype=torch.float64)\n",
      "tensor([[0.5949],\n",
      "        [0.6921],\n",
      "        [0.8913],\n",
      "        [1.0265]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3249]],\n",
      "\n",
      "        [[0.6461]],\n",
      "\n",
      "        [[1.2492]],\n",
      "\n",
      "        [[0.8483]]], dtype=torch.float64)\n",
      "tensor([[0.3966],\n",
      "        [0.5761],\n",
      "        [0.7157],\n",
      "        [0.6227]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5848]],\n",
      "\n",
      "        [[0.4670]],\n",
      "\n",
      "        [[0.3018]],\n",
      "\n",
      "        [[0.2983]]], dtype=torch.float64)\n",
      "tensor([[0.8969],\n",
      "        [1.0350],\n",
      "        [0.6428],\n",
      "        [0.6892]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4953]],\n",
      "\n",
      "        [[1.2920]],\n",
      "\n",
      "        [[0.8887]],\n",
      "\n",
      "        [[0.6299]]], dtype=torch.float64)\n",
      "tensor([[0.6000],\n",
      "        [0.5215],\n",
      "        [0.4396],\n",
      "        [0.3743]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1770]],\n",
      "\n",
      "        [[0.3260]],\n",
      "\n",
      "        [[0.6380]],\n",
      "\n",
      "        [[0.7350]]], dtype=torch.float64)\n",
      "tensor([[0.4149],\n",
      "        [0.4911],\n",
      "        [0.7404],\n",
      "        [0.6455]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3618]],\n",
      "\n",
      "        [[0.3722]],\n",
      "\n",
      "        [[0.3861]],\n",
      "\n",
      "        [[0.4404]]], dtype=torch.float64)\n",
      "tensor([[0.5223],\n",
      "        [0.4770],\n",
      "        [0.3276],\n",
      "        [0.2406]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8194]],\n",
      "\n",
      "        [[ 0.8494]],\n",
      "\n",
      "        [[ 0.4081]],\n",
      "\n",
      "        [[-0.0726]]], dtype=torch.float64)\n",
      "tensor([[ 0.0842],\n",
      "        [-0.0836],\n",
      "        [ 0.5825],\n",
      "        [ 0.5647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3314]],\n",
      "\n",
      "        [[-0.1488]],\n",
      "\n",
      "        [[ 0.9234]],\n",
      "\n",
      "        [[ 0.9546]]], dtype=torch.float64)\n",
      "tensor([[ 0.2724],\n",
      "        [ 0.1961],\n",
      "        [-0.0627],\n",
      "        [-0.3204]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3457]],\n",
      "\n",
      "        [[-0.0576]],\n",
      "\n",
      "        [[-0.4504]],\n",
      "\n",
      "        [[-0.1142]]], dtype=torch.float64)\n",
      "tensor([[ 0.3659],\n",
      "        [ 0.3658],\n",
      "        [ 0.0844],\n",
      "        [-0.2299]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6507]],\n",
      "\n",
      "        [[ 0.8067]],\n",
      "\n",
      "        [[ 0.0568]],\n",
      "\n",
      "        [[-0.3510]]], dtype=torch.float64)\n",
      "tensor([[-0.2208],\n",
      "        [-0.2549],\n",
      "        [ 0.4236],\n",
      "        [ 0.5513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4365]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[ 0.8125]],\n",
      "\n",
      "        [[ 0.9222]]], dtype=torch.float64)\n",
      "tensor([[0.3703],\n",
      "        [0.4090],\n",
      "        [0.3565],\n",
      "        [0.2580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4843]],\n",
      "\n",
      "        [[ 0.2336]],\n",
      "\n",
      "        [[-0.1696]],\n",
      "\n",
      "        [[ 0.1296]]], dtype=torch.float64)\n",
      "tensor([[0.6172],\n",
      "        [0.7157],\n",
      "        [0.3998],\n",
      "        [0.2557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1348]],\n",
      "\n",
      "        [[1.1071]],\n",
      "\n",
      "        [[0.5201]],\n",
      "\n",
      "        [[0.0025]]], dtype=torch.float64)\n",
      "tensor([[0.4546],\n",
      "        [0.4895],\n",
      "        [0.7328],\n",
      "        [0.5991]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0148]],\n",
      "\n",
      "        [[ 0.5017]],\n",
      "\n",
      "        [[ 1.1418]],\n",
      "\n",
      "        [[ 1.0181]]], dtype=torch.float64)\n",
      "tensor([[0.6170],\n",
      "        [0.6717],\n",
      "        [0.9548],\n",
      "        [0.8249]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7004]],\n",
      "\n",
      "        [[0.8078]],\n",
      "\n",
      "        [[0.5964]],\n",
      "\n",
      "        [[0.7200]]], dtype=torch.float64)\n",
      "tensor([[ 0.7176],\n",
      "        [ 0.2978],\n",
      "        [-0.0009],\n",
      "        [-0.1153]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9315]],\n",
      "\n",
      "        [[ 0.2879]],\n",
      "\n",
      "        [[-0.0587]],\n",
      "\n",
      "        [[-0.2355]]], dtype=torch.float64)\n",
      "tensor([[0.0133],\n",
      "        [0.1846],\n",
      "        [0.3869],\n",
      "        [0.4497]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2598]],\n",
      "\n",
      "        [[ 0.1620]],\n",
      "\n",
      "        [[ 0.4855]],\n",
      "\n",
      "        [[ 0.9188]]], dtype=torch.float64)\n",
      "tensor([[0.5625],\n",
      "        [0.8715],\n",
      "        [1.0478],\n",
      "        [1.0109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8795]],\n",
      "\n",
      "        [[0.8379]],\n",
      "\n",
      "        [[0.6831]],\n",
      "\n",
      "        [[0.9338]]], dtype=torch.float64)\n",
      "tensor([[0.8282],\n",
      "        [0.7321],\n",
      "        [0.0286],\n",
      "        [0.0301]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.2088]],\n",
      "\n",
      "        [[ 0.6299]],\n",
      "\n",
      "        [[ 0.0291]],\n",
      "\n",
      "        [[-0.0033]]], dtype=torch.float64)\n",
      "tensor([[ 0.2088],\n",
      "        [ 0.0707],\n",
      "        [-0.0424],\n",
      "        [-0.0974]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0714]],\n",
      "\n",
      "        [[-0.1003]],\n",
      "\n",
      "        [[ 0.3538]],\n",
      "\n",
      "        [[ 0.2983]]], dtype=torch.float64)\n",
      "tensor([[-0.1709],\n",
      "        [-0.0875],\n",
      "        [-0.1225],\n",
      "        [-0.3798]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0414]],\n",
      "\n",
      "        [[-0.1708]],\n",
      "\n",
      "        [[-0.3730]],\n",
      "\n",
      "        [[-0.3476]]], dtype=torch.float64)\n",
      "tensor([[ 0.0809],\n",
      "        [ 0.1317],\n",
      "        [-0.2007],\n",
      "        [-0.2777]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3179]],\n",
      "\n",
      "        [[ 0.4300]],\n",
      "\n",
      "        [[-0.1292]],\n",
      "\n",
      "        [[-0.3083]]], dtype=torch.float64)\n",
      "tensor([[-0.2925],\n",
      "        [-0.4116],\n",
      "        [ 0.0891],\n",
      "        [-0.0496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5683]],\n",
      "\n",
      "        [[-0.1904]],\n",
      "\n",
      "        [[ 0.4000]],\n",
      "\n",
      "        [[ 0.2475]]], dtype=torch.float64)\n",
      "tensor([[-0.3629],\n",
      "        [-0.4131],\n",
      "        [-0.5439],\n",
      "        [-0.6004]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1419]],\n",
      "\n",
      "        [[-0.6607]],\n",
      "\n",
      "        [[-0.8224]],\n",
      "\n",
      "        [[-0.7589]]], dtype=torch.float64)\n",
      "tensor([[-0.2355],\n",
      "        [-0.2332],\n",
      "        [-0.2572],\n",
      "        [-0.3167]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1111]],\n",
      "\n",
      "        [[ 0.1377]],\n",
      "\n",
      "        [[-0.0888]],\n",
      "\n",
      "        [[-0.5128]]], dtype=torch.float64)\n",
      "tensor([[-0.4602],\n",
      "        [-0.5196],\n",
      "        [ 0.0079],\n",
      "        [ 0.0509]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8190]],\n",
      "\n",
      "        [[-0.7115]],\n",
      "\n",
      "        [[ 0.2879]],\n",
      "\n",
      "        [[ 0.3260]]], dtype=torch.float64)\n",
      "tensor([[-0.2060],\n",
      "        [-0.3674],\n",
      "        [-0.5843],\n",
      "        [-0.6021]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1119]],\n",
      "\n",
      "        [[-0.5290]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[-0.4516]]], dtype=torch.float64)\n",
      "tensor([[0.2459],\n",
      "        [0.1772],\n",
      "        [0.0959],\n",
      "        [0.0646]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3850]],\n",
      "\n",
      "        [[ 0.1897]],\n",
      "\n",
      "        [[ 0.1966]],\n",
      "\n",
      "        [[-0.1350]]], dtype=torch.float64)\n",
      "tensor([[-0.0442],\n",
      "        [-0.1477],\n",
      "        [ 0.2283],\n",
      "        [ 0.2205]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3094]],\n",
      "\n",
      "        [[-0.3118]],\n",
      "\n",
      "        [[ 0.4531]],\n",
      "\n",
      "        [[ 0.4439]]], dtype=torch.float64)\n",
      "tensor([[-0.0098],\n",
      "        [-0.0252],\n",
      "        [ 0.2346],\n",
      "        [ 0.1211]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0603]],\n",
      "\n",
      "        [[-0.1234]],\n",
      "\n",
      "        [[-0.0090]],\n",
      "\n",
      "        [[-0.1350]]], dtype=torch.float64)\n",
      "tensor([[-0.0014],\n",
      "        [ 0.0089],\n",
      "        [-0.0995],\n",
      "        [-0.0401]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1816]],\n",
      "\n",
      "        [[ 0.1204]],\n",
      "\n",
      "        [[-0.1142]],\n",
      "\n",
      "        [[-0.1477]]], dtype=torch.float64)\n",
      "tensor([[ 0.1956],\n",
      "        [ 0.2288],\n",
      "        [-0.0553],\n",
      "        [-0.1568]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0968]],\n",
      "\n",
      "        [[ 0.2394]],\n",
      "\n",
      "        [[-0.0483]],\n",
      "\n",
      "        [[ 0.0222]]], dtype=torch.float64)\n",
      "tensor([[-0.1739],\n",
      "        [-0.3557],\n",
      "        [-0.4162],\n",
      "        [-0.4768]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2771]],\n",
      "\n",
      "        [[-0.5694]],\n",
      "\n",
      "        [[-0.6376]],\n",
      "\n",
      "        [[-0.5012]]], dtype=torch.float64)\n",
      "tensor([[ 0.1329],\n",
      "        [ 0.0679],\n",
      "        [-0.0620],\n",
      "        [ 0.0643]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2960]],\n",
      "\n",
      "        [[ 0.3387]],\n",
      "\n",
      "        [[ 0.2405]],\n",
      "\n",
      "        [[-0.1084]]], dtype=torch.float64)\n",
      "tensor([[-0.1471],\n",
      "        [-0.3401],\n",
      "        [ 0.2706],\n",
      "        [ 0.3213]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4862]],\n",
      "\n",
      "        [[-0.2863]],\n",
      "\n",
      "        [[ 0.7443]],\n",
      "\n",
      "        [[ 0.7420]]], dtype=torch.float64)\n",
      "tensor([[0.2280],\n",
      "        [0.3026],\n",
      "        [0.4065],\n",
      "        [0.3489]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4878]],\n",
      "\n",
      "        [[0.2278]],\n",
      "\n",
      "        [[0.2509]],\n",
      "\n",
      "        [[0.2197]]], dtype=torch.float64)\n",
      "tensor([[0.4195],\n",
      "        [0.5195],\n",
      "        [0.3043],\n",
      "        [0.3262]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8494]],\n",
      "\n",
      "        [[0.9072]],\n",
      "\n",
      "        [[0.4000]],\n",
      "\n",
      "        [[0.1469]]], dtype=torch.float64)\n",
      "tensor([[0.4440],\n",
      "        [0.2791],\n",
      "        [0.5481],\n",
      "        [1.0562]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0268]],\n",
      "\n",
      "        [[0.3226]],\n",
      "\n",
      "        [[1.4167]],\n",
      "\n",
      "        [[1.6871]]], dtype=torch.float64)\n",
      "tensor([[0.6699],\n",
      "        [0.4462],\n",
      "        [0.3726],\n",
      "        [0.0970]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7836]],\n",
      "\n",
      "        [[ 0.2740]],\n",
      "\n",
      "        [[-0.1211]],\n",
      "\n",
      "        [[-0.0472]]], dtype=torch.float64)\n",
      "tensor([[0.4860],\n",
      "        [1.0169],\n",
      "        [0.6443],\n",
      "        [0.4128]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3867]],\n",
      "\n",
      "        [[1.5531]],\n",
      "\n",
      "        [[0.6773]],\n",
      "\n",
      "        [[0.1666]]], dtype=torch.float64)\n",
      "tensor([[0.4125],\n",
      "        [0.0792],\n",
      "        [0.2068],\n",
      "        [0.7973]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0968]],\n",
      "\n",
      "        [[-0.2078]],\n",
      "\n",
      "        [[ 1.0435]],\n",
      "\n",
      "        [[ 1.2157]]], dtype=torch.float64)\n",
      "tensor([[0.4338],\n",
      "        [0.2430],\n",
      "        [0.0639],\n",
      "        [0.1185]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4485]],\n",
      "\n",
      "        [[-0.0818]],\n",
      "\n",
      "        [[-0.2124]],\n",
      "\n",
      "        [[-0.2205]]], dtype=torch.float64)\n",
      "tensor([[-0.0694],\n",
      "        [ 0.0126],\n",
      "        [-0.1358],\n",
      "        [ 0.0751]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0610]],\n",
      "\n",
      "        [[ 0.1781]],\n",
      "\n",
      "        [[ 0.1181]],\n",
      "\n",
      "        [[ 0.1227]]], dtype=torch.float64)\n",
      "tensor([[ 0.4339],\n",
      "        [ 0.3227],\n",
      "        [ 0.0612],\n",
      "        [-0.0381]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0869]],\n",
      "\n",
      "        [[0.0487]],\n",
      "\n",
      "        [[0.1654]],\n",
      "\n",
      "        [[0.2440]]], dtype=torch.float64)\n",
      "tensor([[-0.1731],\n",
      "        [-0.1797],\n",
      "        [ 0.0802],\n",
      "        [ 0.1049]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0183]],\n",
      "\n",
      "        [[-0.1592]],\n",
      "\n",
      "        [[-0.1939]],\n",
      "\n",
      "        [[-0.1939]]], dtype=torch.float64)\n",
      "tensor([[-0.0637],\n",
      "        [-0.2059],\n",
      "        [-0.2207],\n",
      "        [-0.1241]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1465]],\n",
      "\n",
      "        [[-0.1408]],\n",
      "\n",
      "        [[-0.1743]],\n",
      "\n",
      "        [[-0.1673]]], dtype=torch.float64)\n",
      "tensor([[ 0.1474],\n",
      "        [ 0.0497],\n",
      "        [-0.1035],\n",
      "        [-0.0273]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1569]],\n",
      "\n",
      "        [[-0.1604]],\n",
      "\n",
      "        [[ 0.1238]],\n",
      "\n",
      "        [[ 0.2012]]], dtype=torch.float64)\n",
      "tensor([[-0.0177],\n",
      "        [-0.0778],\n",
      "        [-0.2682],\n",
      "        [-0.5645]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0534]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.3672]],\n",
      "\n",
      "        [[-0.6977]]], dtype=torch.float64)\n",
      "tensor([[-0.6146],\n",
      "        [-0.7290],\n",
      "        [-0.8975],\n",
      "        [-0.8381]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5775]],\n",
      "\n",
      "        [[-0.5555]],\n",
      "\n",
      "        [[-0.9056]],\n",
      "\n",
      "        [[-1.0593]]], dtype=torch.float64)\n",
      "tensor([[-0.8427],\n",
      "        [-0.9040],\n",
      "        [-1.0104],\n",
      "        [-1.0140]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0605]],\n",
      "\n",
      "        [[-1.0755]],\n",
      "\n",
      "        [[-1.0605]],\n",
      "\n",
      "        [[-1.0131]]], dtype=torch.float64)\n",
      "tensor([[-0.8875],\n",
      "        [-0.6858],\n",
      "        [-0.6871],\n",
      "        [-0.8380]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0119]],\n",
      "\n",
      "        [[-0.9241]],\n",
      "\n",
      "        [[-1.0720]],\n",
      "\n",
      "        [[-1.0512]]], dtype=torch.float64)\n",
      "tensor([[-0.7983],\n",
      "        [-0.8102],\n",
      "        [-0.9326],\n",
      "        [-1.0114]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9322]],\n",
      "\n",
      "        [[-0.8583]],\n",
      "\n",
      "        [[-1.2592]],\n",
      "\n",
      "        [[-1.4360]]], dtype=torch.float64)\n",
      "tensor([[-0.9819],\n",
      "        [-1.0639],\n",
      "        [-0.9597],\n",
      "        [-0.6676]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5850]],\n",
      "\n",
      "        [[-1.7006]],\n",
      "\n",
      "        [[-0.7820]],\n",
      "\n",
      "        [[-0.7497]]], dtype=torch.float64)\n",
      "tensor([[-0.8564],\n",
      "        [-0.7386],\n",
      "        [-0.5915],\n",
      "        [-0.5205]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8687]],\n",
      "\n",
      "        [[-0.9530]],\n",
      "\n",
      "        [[-0.8028]],\n",
      "\n",
      "        [[-0.7716]]], dtype=torch.float64)\n",
      "tensor([[-0.5564],\n",
      "        [-0.5748],\n",
      "        [-0.5760],\n",
      "        [-0.5901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5798]],\n",
      "\n",
      "        [[-0.5451]],\n",
      "\n",
      "        [[-0.7034]],\n",
      "\n",
      "        [[-0.7855]]], dtype=torch.float64)\n",
      "tensor([[-0.6149],\n",
      "        [-0.8339],\n",
      "        [-0.3818],\n",
      "        [-0.1057]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9426]],\n",
      "\n",
      "        [[-0.9264]],\n",
      "\n",
      "        [[ 0.0245]],\n",
      "\n",
      "        [[-0.0171]]], dtype=torch.float64)\n",
      "tensor([[-0.4064],\n",
      "        [-0.5090],\n",
      "        [-0.4584],\n",
      "        [-0.3833]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4053]],\n",
      "\n",
      "        [[-0.8652]],\n",
      "\n",
      "        [[-0.6029]],\n",
      "\n",
      "        [[-0.5128]]], dtype=torch.float64)\n",
      "tensor([[-0.4580],\n",
      "        [-0.1026],\n",
      "        [-0.2228],\n",
      "        [ 0.0372]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3037]],\n",
      "\n",
      "        [[-0.1015]],\n",
      "\n",
      "        [[-0.1280]],\n",
      "\n",
      "        [[ 0.0753]]], dtype=torch.float64)\n",
      "tensor([[-0.1009],\n",
      "        [-0.4455],\n",
      "        [-0.3192],\n",
      "        [-0.2441]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2112]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.0368]],\n",
      "\n",
      "        [[ 0.0037]]], dtype=torch.float64)\n",
      "tensor([[-0.4148],\n",
      "        [-0.3252],\n",
      "        [-0.0910],\n",
      "        [-0.1593]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1546]],\n",
      "\n",
      "        [[-0.2725]],\n",
      "\n",
      "        [[-0.2447]],\n",
      "\n",
      "        [[-0.1800]]], dtype=torch.float64)\n",
      "tensor([[-0.3085],\n",
      "        [-0.1307],\n",
      "        [ 0.0532],\n",
      "        [-0.0240]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2621]],\n",
      "\n",
      "        [[ 0.1943]],\n",
      "\n",
      "        [[ 0.0395]],\n",
      "\n",
      "        [[-0.1442]]], dtype=torch.float64)\n",
      "tensor([[-0.0707],\n",
      "        [-0.1305],\n",
      "        [-0.1773],\n",
      "        [-0.2954]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2898]],\n",
      "\n",
      "        [[-0.3684]],\n",
      "\n",
      "        [[-0.1188]],\n",
      "\n",
      "        [[-0.0853]]], dtype=torch.float64)\n",
      "tensor([[-0.1647],\n",
      "        [ 0.1631],\n",
      "        [-0.0153],\n",
      "        [-0.1053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1504]],\n",
      "\n",
      "        [[ 0.0360]],\n",
      "\n",
      "        [[-0.1292]],\n",
      "\n",
      "        [[-0.1708]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.18888:  71%|███████   | 2175/3067 [00:06<00:02, 333.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2282],\n",
      "        [-0.3089],\n",
      "        [-0.5083],\n",
      "        [-0.4451]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0649]],\n",
      "\n",
      "        [[-0.1130]],\n",
      "\n",
      "        [[-0.4261]],\n",
      "\n",
      "        [[-0.4215]]], dtype=torch.float64)\n",
      "tensor([[-0.4547],\n",
      "        [-0.5512],\n",
      "        [-0.6143],\n",
      "        [-0.6342]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6145]],\n",
      "\n",
      "        [[-0.5787]],\n",
      "\n",
      "        [[-0.4423]],\n",
      "\n",
      "        [[-0.3522]]], dtype=torch.float64)\n",
      "tensor([[-0.7117],\n",
      "        [-0.3594],\n",
      "        [-0.2919],\n",
      "        [-0.2987]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5186]],\n",
      "\n",
      "        [[-0.3869]],\n",
      "\n",
      "        [[-0.3510]],\n",
      "\n",
      "        [[-0.2101]]], dtype=torch.float64)\n",
      "tensor([[-0.1843],\n",
      "        [-0.1631],\n",
      "        [-0.0562],\n",
      "        [ 0.0305]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1238]],\n",
      "\n",
      "        [[ 0.1100]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[-0.0564]]], dtype=torch.float64)\n",
      "tensor([[-0.1993],\n",
      "        [-0.2392],\n",
      "        [-0.2067],\n",
      "        [-0.2524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3834]],\n",
      "\n",
      "        [[-0.2112]],\n",
      "\n",
      "        [[-0.0576]],\n",
      "\n",
      "        [[-0.0680]]], dtype=torch.float64)\n",
      "tensor([[-0.2738],\n",
      "        [-0.2091],\n",
      "        [-0.1916],\n",
      "        [-0.1209]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1442]],\n",
      "\n",
      "        [[-0.1523]],\n",
      "\n",
      "        [[-0.2182]],\n",
      "\n",
      "        [[-0.2471]]], dtype=torch.float64)\n",
      "tensor([[-0.1099],\n",
      "        [-0.2680],\n",
      "        [-0.5371],\n",
      "        [-0.4606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1238]],\n",
      "\n",
      "        [[-0.0079]],\n",
      "\n",
      "        [[-0.4007]],\n",
      "\n",
      "        [[-0.5301]]], dtype=torch.float64)\n",
      "tensor([[-0.4281],\n",
      "        [-0.2592],\n",
      "        [-0.1514],\n",
      "        [-0.2690]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4227]],\n",
      "\n",
      "        [[-0.3522]],\n",
      "\n",
      "        [[ 0.0464]],\n",
      "\n",
      "        [[-0.2135]]], dtype=torch.float64)\n",
      "tensor([[-0.2545],\n",
      "        [-0.2957],\n",
      "        [ 0.0003],\n",
      "        [ 0.0991]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2309]],\n",
      "\n",
      "        [[-0.2135]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[-0.1015]]], dtype=torch.float64)\n",
      "tensor([[ 0.1271],\n",
      "        [ 0.0055],\n",
      "        [-0.0788],\n",
      "        [-0.0997]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2140]],\n",
      "\n",
      "        [[ 0.0349]],\n",
      "\n",
      "        [[-0.0483]],\n",
      "\n",
      "        [[-0.1823]]], dtype=torch.float64)\n",
      "tensor([[-0.1661],\n",
      "        [-0.1987],\n",
      "        [-0.2970],\n",
      "        [-0.3787]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3198]],\n",
      "\n",
      "        [[-0.4527]],\n",
      "\n",
      "        [[-0.2170]],\n",
      "\n",
      "        [[-0.1188]]], dtype=torch.float64)\n",
      "tensor([[-0.4617],\n",
      "        [-0.5915],\n",
      "        [-0.6639],\n",
      "        [-0.8739]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2182]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-1.0997]],\n",
      "\n",
      "        [[-1.2476]]], dtype=torch.float64)\n",
      "tensor([[-0.8953],\n",
      "        [-0.3999],\n",
      "        [-0.7540],\n",
      "        [-0.9961]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5255]],\n",
      "\n",
      "        [[-0.2343]],\n",
      "\n",
      "        [[-0.8224]],\n",
      "\n",
      "        [[-1.1621]]], dtype=torch.float64)\n",
      "tensor([[-0.9301],\n",
      "        [-0.9744],\n",
      "        [-1.0707],\n",
      "        [-0.5855]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2811]],\n",
      "\n",
      "        [[-1.3493]],\n",
      "\n",
      "        [[-0.8952]],\n",
      "\n",
      "        [[-0.4423]]], dtype=torch.float64)\n",
      "tensor([[-0.8296],\n",
      "        [-0.9726],\n",
      "        [-0.9492],\n",
      "        [-1.0001]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0281]],\n",
      "\n",
      "        [[-1.2118]],\n",
      "\n",
      "        [[-1.2742]],\n",
      "\n",
      "        [[-1.4025]]], dtype=torch.float64)\n",
      "tensor([[-1.1055],\n",
      "        [-1.1038],\n",
      "        [-1.0354],\n",
      "        [-0.9187]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0766]],\n",
      "\n",
      "        [[-1.0293]],\n",
      "\n",
      "        [[-1.0073]],\n",
      "\n",
      "        [[-1.1148]]], dtype=torch.float64)\n",
      "tensor([[-0.8602],\n",
      "        [-0.8111],\n",
      "        [-0.8397],\n",
      "        [-0.9840]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0755]],\n",
      "\n",
      "        [[-1.0177]],\n",
      "\n",
      "        [[-0.7520]],\n",
      "\n",
      "        [[-0.8606]]], dtype=torch.float64)\n",
      "tensor([[-0.9072],\n",
      "        [-0.7712],\n",
      "        [-0.8463],\n",
      "        [-0.9391]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8213]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-1.2384]],\n",
      "\n",
      "        [[-1.3042]]], dtype=torch.float64)\n",
      "tensor([[-0.9016],\n",
      "        [-0.5940],\n",
      "        [-0.9716],\n",
      "        [-0.9138]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4862]],\n",
      "\n",
      "        [[-0.6098]],\n",
      "\n",
      "        [[-1.0466]],\n",
      "\n",
      "        [[-1.0882]]], dtype=torch.float64)\n",
      "tensor([[-0.7723],\n",
      "        [-0.5950],\n",
      "        [-0.5063],\n",
      "        [-0.3598]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8120]],\n",
      "\n",
      "        [[-0.6653]],\n",
      "\n",
      "        [[-0.3406]],\n",
      "\n",
      "        [[-0.1823]]], dtype=torch.float64)\n",
      "tensor([[-0.4385],\n",
      "        [-0.3883],\n",
      "        [-0.2640],\n",
      "        [-0.3098]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2286]],\n",
      "\n",
      "        [[-0.3360]],\n",
      "\n",
      "        [[-0.3903]],\n",
      "\n",
      "        [[-0.3822]]], dtype=torch.float64)\n",
      "tensor([[-0.3117],\n",
      "        [-0.3706],\n",
      "        [-0.4673],\n",
      "        [-0.5196]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2043]],\n",
      "\n",
      "        [[-0.1939]],\n",
      "\n",
      "        [[-0.4978]],\n",
      "\n",
      "        [[-0.7289]]], dtype=torch.float64)\n",
      "tensor([[-0.5577],\n",
      "        [-0.5586],\n",
      "        [-0.5557],\n",
      "        [-0.3738]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8294]],\n",
      "\n",
      "        [[-0.7959]],\n",
      "\n",
      "        [[-0.4781]],\n",
      "\n",
      "        [[-0.3522]]], dtype=torch.float64)\n",
      "tensor([[-0.5153],\n",
      "        [-0.3753],\n",
      "        [-0.2570],\n",
      "        [-0.3566]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3903]],\n",
      "\n",
      "        [[-0.4065]],\n",
      "\n",
      "        [[-0.4874]],\n",
      "\n",
      "        [[-0.5347]]], dtype=torch.float64)\n",
      "tensor([[-0.2907],\n",
      "        [-0.2907],\n",
      "        [-0.5999],\n",
      "        [-0.6047]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1858]],\n",
      "\n",
      "        [[-0.2794]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.5937]]], dtype=torch.float64)\n",
      "tensor([[-0.3919],\n",
      "        [-0.4278],\n",
      "        [-0.2391],\n",
      "        [-0.2861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5521]],\n",
      "\n",
      "        [[-0.4620]],\n",
      "\n",
      "        [[-0.0044]],\n",
      "\n",
      "        [[-0.0610]]], dtype=torch.float64)\n",
      "tensor([[-0.6284],\n",
      "        [-0.7796],\n",
      "        [-0.9721],\n",
      "        [-0.7021]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6595]],\n",
      "\n",
      "        [[-0.9599]],\n",
      "\n",
      "        [[-1.2938]],\n",
      "\n",
      "        [[-0.9518]]], dtype=torch.float64)\n",
      "tensor([[-0.6319],\n",
      "        [-0.4533],\n",
      "        [-0.5515],\n",
      "        [-0.4076]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3799]],\n",
      "\n",
      "        [[-0.2517]],\n",
      "\n",
      "        [[-0.3499]],\n",
      "\n",
      "        [[-0.2817]]], dtype=torch.float64)\n",
      "tensor([[-0.2096],\n",
      "        [-0.2450],\n",
      "        [-0.2985],\n",
      "        [-0.2210]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3060]],\n",
      "\n",
      "        [[-0.2505]],\n",
      "\n",
      "        [[-0.0518]],\n",
      "\n",
      "        [[ 0.0095]]], dtype=torch.float64)\n",
      "tensor([[-0.3669],\n",
      "        [-0.3077],\n",
      "        [-0.1653],\n",
      "        [ 0.0211]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1789]],\n",
      "\n",
      "        [[-0.3152]],\n",
      "\n",
      "        [[-0.3025]],\n",
      "\n",
      "        [[ 0.1007]]], dtype=torch.float64)\n",
      "tensor([[ 0.0497],\n",
      "        [-0.0692],\n",
      "        [-0.2589],\n",
      "        [-0.3018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5768]],\n",
      "\n",
      "        [[ 0.3584]],\n",
      "\n",
      "        [[-0.0368]],\n",
      "\n",
      "        [[-0.2505]]], dtype=torch.float64)\n",
      "tensor([[-0.4882],\n",
      "        [-0.5797],\n",
      "        [-0.5503],\n",
      "        [-0.2787]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5498]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.1662]],\n",
      "\n",
      "        [[-0.0680]]], dtype=torch.float64)\n",
      "tensor([[-0.2062],\n",
      "        [ 0.0690],\n",
      "        [ 0.1102],\n",
      "        [-0.0323]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0175]],\n",
      "\n",
      "        [[-0.0449]],\n",
      "\n",
      "        [[-0.1200]],\n",
      "\n",
      "        [[-0.1777]]], dtype=torch.float64)\n",
      "tensor([[-0.1989],\n",
      "        [-0.1930],\n",
      "        [-0.3007],\n",
      "        [-0.3200]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1188]],\n",
      "\n",
      "        [[-0.0483]],\n",
      "\n",
      "        [[-0.2343]],\n",
      "\n",
      "        [[-0.3129]]], dtype=torch.float64)\n",
      "tensor([[-0.2985],\n",
      "        [-0.3708],\n",
      "        [-0.5183],\n",
      "        [-0.7314]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3672]],\n",
      "\n",
      "        [[-0.4111]],\n",
      "\n",
      "        [[-0.4053]],\n",
      "\n",
      "        [[-0.4596]]], dtype=torch.float64)\n",
      "tensor([[-0.7500],\n",
      "        [-0.8782],\n",
      "        [-0.7040],\n",
      "        [-0.7079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5544]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-0.6376]],\n",
      "\n",
      "        [[-0.7439]]], dtype=torch.float64)\n",
      "tensor([[-0.6968],\n",
      "        [-1.0129],\n",
      "        [-0.9733],\n",
      "        [-0.8614]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9657]],\n",
      "\n",
      "        [[-0.9715]],\n",
      "\n",
      "        [[-0.9796]],\n",
      "\n",
      "        [[-0.9449]]], dtype=torch.float64)\n",
      "tensor([[-0.8051],\n",
      "        [-0.8523],\n",
      "        [-0.9624],\n",
      "        [-0.9839]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9530]],\n",
      "\n",
      "        [[-0.9911]],\n",
      "\n",
      "        [[-0.8848]],\n",
      "\n",
      "        [[-0.9322]]], dtype=torch.float64)\n",
      "tensor([[-1.1004],\n",
      "        [-1.1847],\n",
      "        [-1.1997],\n",
      "        [-1.2912]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9888]],\n",
      "\n",
      "        [[-1.3828]],\n",
      "\n",
      "        [[-1.5804]],\n",
      "\n",
      "        [[-1.5908]]], dtype=torch.float64)\n",
      "tensor([[-1.2032],\n",
      "        [-1.0200],\n",
      "        [-1.1339],\n",
      "        [-1.1141]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1367]],\n",
      "\n",
      "        [[-0.9923]],\n",
      "\n",
      "        [[-1.2511]],\n",
      "\n",
      "        [[-1.2465]]], dtype=torch.float64)\n",
      "tensor([[-1.0797],\n",
      "        [-1.0514],\n",
      "        [-1.0399],\n",
      "        [-1.0249]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2546]],\n",
      "\n",
      "        [[-1.2384]],\n",
      "\n",
      "        [[-1.0142]],\n",
      "\n",
      "        [[-1.0085]]], dtype=torch.float64)\n",
      "tensor([[-1.0483],\n",
      "        [-0.9416],\n",
      "        [-0.8717],\n",
      "        [-0.9437]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9160]],\n",
      "\n",
      "        [[-1.0154]],\n",
      "\n",
      "        [[-1.0293]],\n",
      "\n",
      "        [[-1.1321]]], dtype=torch.float64)\n",
      "tensor([[-1.0362],\n",
      "        [-0.9703],\n",
      "        [-1.0521],\n",
      "        [-0.9463]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8848]],\n",
      "\n",
      "        [[-0.9692]],\n",
      "\n",
      "        [[-1.0223]],\n",
      "\n",
      "        [[-1.0408]]], dtype=torch.float64)\n",
      "tensor([[-0.7766],\n",
      "        [-0.8609],\n",
      "        [-0.7813],\n",
      "        [-0.8044]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9218]],\n",
      "\n",
      "        [[-0.8744]],\n",
      "\n",
      "        [[-0.6618]],\n",
      "\n",
      "        [[-0.7046]]], dtype=torch.float64)\n",
      "tensor([[-0.7860],\n",
      "        [-0.8583],\n",
      "        [-0.8829],\n",
      "        [-0.9498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7543]],\n",
      "\n",
      "        [[-0.7473]],\n",
      "\n",
      "        [[-0.9923]],\n",
      "\n",
      "        [[-1.0258]]], dtype=torch.float64)\n",
      "tensor([[-0.9725],\n",
      "        [-1.0541],\n",
      "        [-1.2403],\n",
      "        [-1.2321]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9114]],\n",
      "\n",
      "        [[-1.0547]],\n",
      "\n",
      "        [[-1.3297]],\n",
      "\n",
      "        [[-1.3470]]], dtype=torch.float64)\n",
      "tensor([[-1.0813],\n",
      "        [-1.1854],\n",
      "        [-1.3584],\n",
      "        [-1.4646]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2338]],\n",
      "\n",
      "        [[-1.3181]],\n",
      "\n",
      "        [[-1.2869]],\n",
      "\n",
      "        [[-1.2811]]], dtype=torch.float64)\n",
      "tensor([[-1.4505],\n",
      "        [-1.3336],\n",
      "        [-1.4345],\n",
      "        [-1.5214]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2881]],\n",
      "\n",
      "        [[-1.5145]],\n",
      "\n",
      "        [[-1.7549]],\n",
      "\n",
      "        [[-1.8843]]], dtype=torch.float64)\n",
      "tensor([[-1.3489],\n",
      "        [-1.2895],\n",
      "        [-1.5608],\n",
      "        [-1.6300]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2361]],\n",
      "\n",
      "        [[-1.3597]],\n",
      "\n",
      "        [[-1.6220]],\n",
      "\n",
      "        [[-1.9143]]], dtype=torch.float64)\n",
      "tensor([[-1.7776],\n",
      "        [-1.9514],\n",
      "        [-1.8844],\n",
      "        [-1.7166]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2332]],\n",
      "\n",
      "        [[-2.4516]],\n",
      "\n",
      "        [[-1.7237]],\n",
      "\n",
      "        [[-1.5943]]], dtype=torch.float64)\n",
      "tensor([[-1.8155],\n",
      "        [-1.7421],\n",
      "        [-1.6810],\n",
      "        [-1.6468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8172]],\n",
      "\n",
      "        [[-1.9524]],\n",
      "\n",
      "        [[-1.9755]],\n",
      "\n",
      "        [[-1.7456]]], dtype=torch.float64)\n",
      "tensor([[-1.4462],\n",
      "        [-1.2196],\n",
      "        [-1.1535],\n",
      "        [-0.9066]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5076]],\n",
      "\n",
      "        [[-1.1783]],\n",
      "\n",
      "        [[-0.9738]],\n",
      "\n",
      "        [[-0.8594]]], dtype=torch.float64)\n",
      "tensor([[-0.7762],\n",
      "        [-0.8280],\n",
      "        [-0.9288],\n",
      "        [-1.1311]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9114]],\n",
      "\n",
      "        [[-0.8167]],\n",
      "\n",
      "        [[-0.8502]],\n",
      "\n",
      "        [[-1.0108]]], dtype=torch.float64)\n",
      "tensor([[-1.1752],\n",
      "        [-1.1659],\n",
      "        [-1.4057],\n",
      "        [-1.4055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0443]],\n",
      "\n",
      "        [[-1.1656]],\n",
      "\n",
      "        [[-1.4071]],\n",
      "\n",
      "        [[-1.4510]]], dtype=torch.float64)\n",
      "tensor([[-1.3860],\n",
      "        [-1.5425],\n",
      "        [-1.6963],\n",
      "        [-1.6882]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3204]],\n",
      "\n",
      "        [[-1.4452]],\n",
      "\n",
      "        [[-1.6289]],\n",
      "\n",
      "        [[-1.6809]]], dtype=torch.float64)\n",
      "tensor([[-1.5426],\n",
      "        [-1.4924],\n",
      "        [-1.4526],\n",
      "        [-1.5100]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6890]],\n",
      "\n",
      "        [[-1.6070]],\n",
      "\n",
      "        [[-1.3944]],\n",
      "\n",
      "        [[-1.3435]]], dtype=torch.float64)\n",
      "tensor([[-1.5381],\n",
      "        [-1.5900],\n",
      "        [-1.4551],\n",
      "        [-1.5091]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5007]],\n",
      "\n",
      "        [[-1.5931]],\n",
      "\n",
      "        [[-1.5365]],\n",
      "\n",
      "        [[-1.8172]]], dtype=torch.float64)\n",
      "tensor([[-1.5281],\n",
      "        [-1.4744],\n",
      "        [-1.5574],\n",
      "        [-1.4668]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3967]],\n",
      "\n",
      "        [[-1.3470]],\n",
      "\n",
      "        [[-1.4637]],\n",
      "\n",
      "        [[-1.3932]]], dtype=torch.float64)\n",
      "tensor([[-1.2743],\n",
      "        [-0.9770],\n",
      "        [-1.0545],\n",
      "        [-1.0533]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2211]],\n",
      "\n",
      "        [[-1.0489]],\n",
      "\n",
      "        [[-0.8109]],\n",
      "\n",
      "        [[-0.9276]]], dtype=torch.float64)\n",
      "tensor([[-1.1924],\n",
      "        [-1.0130],\n",
      "        [-0.7846],\n",
      "        [-0.5667]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9669]],\n",
      "\n",
      "        [[-0.8097]],\n",
      "\n",
      "        [[-0.6549]],\n",
      "\n",
      "        [[-0.5625]]], dtype=torch.float64)\n",
      "tensor([[-0.6253],\n",
      "        [-0.4807],\n",
      "        [-0.6454],\n",
      "        [-0.6825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3522]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[-0.4446]],\n",
      "\n",
      "        [[-0.5451]]], dtype=torch.float64)\n",
      "tensor([[-0.6639],\n",
      "        [-0.5658],\n",
      "        [-0.6742],\n",
      "        [-0.5484]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6156]],\n",
      "\n",
      "        [[-0.7161]],\n",
      "\n",
      "        [[-0.3741]],\n",
      "\n",
      "        [[-0.4377]]], dtype=torch.float64)\n",
      "tensor([[-0.6009],\n",
      "        [-0.6751],\n",
      "        [-0.7409],\n",
      "        [-0.7768]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5463]],\n",
      "\n",
      "        [[-0.7323]],\n",
      "\n",
      "        [[-0.8063]],\n",
      "\n",
      "        [[-0.7589]]], dtype=torch.float64)\n",
      "tensor([[-0.7338],\n",
      "        [-0.5901],\n",
      "        [-0.6767],\n",
      "        [-0.7316]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4920]],\n",
      "\n",
      "        [[-0.4539]],\n",
      "\n",
      "        [[-0.6260]],\n",
      "\n",
      "        [[-0.7127]]], dtype=torch.float64)\n",
      "tensor([[-0.6481],\n",
      "        [-0.7100],\n",
      "        [-0.7065],\n",
      "        [-0.6908]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6838]],\n",
      "\n",
      "        [[-0.6272]],\n",
      "\n",
      "        [[-0.5047]],\n",
      "\n",
      "        [[-0.4492]]], dtype=torch.float64)\n",
      "tensor([[-0.7136],\n",
      "        [-0.7501],\n",
      "        [-0.7245],\n",
      "        [-0.7825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5544]],\n",
      "\n",
      "        [[-0.6849]],\n",
      "\n",
      "        [[-0.8109]],\n",
      "\n",
      "        [[-0.8525]]], dtype=torch.float64)\n",
      "tensor([[-0.8609],\n",
      "        [-0.8146],\n",
      "        [-0.8464],\n",
      "        [-0.9032]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7046]],\n",
      "\n",
      "        [[-0.6029]],\n",
      "\n",
      "        [[-0.6919]],\n",
      "\n",
      "        [[-0.8929]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.18261:  72%|███████▏  | 2209/3067 [00:06<00:02, 325.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9213],\n",
      "        [-0.7942],\n",
      "        [-0.9307],\n",
      "        [-1.1260]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9241]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-0.8721]],\n",
      "\n",
      "        [[-0.8964]]], dtype=torch.float64)\n",
      "tensor([[-1.0986],\n",
      "        [-1.1364],\n",
      "        [-1.1624],\n",
      "        [-1.0527]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9530]],\n",
      "\n",
      "        [[-1.0004]],\n",
      "\n",
      "        [[-1.1286]],\n",
      "\n",
      "        [[-1.1691]]], dtype=torch.float64)\n",
      "tensor([[-1.2547],\n",
      "        [-1.2909],\n",
      "        [-1.2810],\n",
      "        [-1.2668]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1610]],\n",
      "\n",
      "        [[-1.1148]],\n",
      "\n",
      "        [[-1.1483]],\n",
      "\n",
      "        [[-1.1691]]], dtype=torch.float64)\n",
      "tensor([[-1.1394],\n",
      "        [-0.9117],\n",
      "        [-0.9540],\n",
      "        [-0.6888]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1922]],\n",
      "\n",
      "        [[-1.0593]],\n",
      "\n",
      "        [[-0.7970]],\n",
      "\n",
      "        [[-0.5602]]], dtype=torch.float64)\n",
      "tensor([[-0.7144],\n",
      "        [-0.6149],\n",
      "        [-0.5306],\n",
      "        [-0.5218]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6018]],\n",
      "\n",
      "        [[-0.6168]],\n",
      "\n",
      "        [[-0.7000]],\n",
      "\n",
      "        [[-0.6607]]], dtype=torch.float64)\n",
      "tensor([[-0.5174],\n",
      "        [ 0.0498],\n",
      "        [ 0.0103],\n",
      "        [ 0.2477]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3788]],\n",
      "\n",
      "        [[ 0.2140]],\n",
      "\n",
      "        [[ 0.2821]],\n",
      "\n",
      "        [[-0.1431]]], dtype=torch.float64)\n",
      "tensor([[-0.1130],\n",
      "        [-0.0414],\n",
      "        [-0.1018],\n",
      "        [ 0.0097]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2517]],\n",
      "\n",
      "        [[-0.2159]],\n",
      "\n",
      "        [[-0.0876]],\n",
      "\n",
      "        [[ 0.0198]]], dtype=torch.float64)\n",
      "tensor([[-0.0690],\n",
      "        [ 0.0877],\n",
      "        [ 0.1135],\n",
      "        [-0.0811]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2151]],\n",
      "\n",
      "        [[ 0.4058]],\n",
      "\n",
      "        [[ 0.0591]],\n",
      "\n",
      "        [[-0.1442]]], dtype=torch.float64)\n",
      "tensor([[-0.0238],\n",
      "        [-0.2297],\n",
      "        [-0.2035],\n",
      "        [-0.2484]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6253]],\n",
      "\n",
      "        [[-0.0957]],\n",
      "\n",
      "        [[-0.1789]],\n",
      "\n",
      "        [[-0.0148]]], dtype=torch.float64)\n",
      "tensor([[-0.2025],\n",
      "        [-0.1730],\n",
      "        [-0.2705],\n",
      "        [-0.3850]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1431]],\n",
      "\n",
      "        [[-0.1743]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[-0.3418]]], dtype=torch.float64)\n",
      "tensor([[-0.6017],\n",
      "        [-0.2829],\n",
      "        [-0.2951],\n",
      "        [-0.2645]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4296]],\n",
      "\n",
      "        [[-0.2286]],\n",
      "\n",
      "        [[-0.1685]],\n",
      "\n",
      "        [[-0.2401]]], dtype=torch.float64)\n",
      "tensor([[-0.3237],\n",
      "        [-0.3133],\n",
      "        [-0.2728],\n",
      "        [-0.3776]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0518]],\n",
      "\n",
      "        [[-0.1280]],\n",
      "\n",
      "        [[-0.2863]],\n",
      "\n",
      "        [[-0.4908]]], dtype=torch.float64)\n",
      "tensor([[-0.4096],\n",
      "        [-0.8875],\n",
      "        [-1.1241],\n",
      "        [-0.9563]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7670]],\n",
      "\n",
      "        [[-1.0697]],\n",
      "\n",
      "        [[-0.8860]],\n",
      "\n",
      "        [[-0.8791]]], dtype=torch.float64)\n",
      "tensor([[-0.9845],\n",
      "        [-0.7754],\n",
      "        [-0.2892],\n",
      "        [-0.2459]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0304]],\n",
      "\n",
      "        [[-0.6399]],\n",
      "\n",
      "        [[-0.4088]],\n",
      "\n",
      "        [[-0.4273]]], dtype=torch.float64)\n",
      "tensor([[-0.1574],\n",
      "        [-0.1574],\n",
      "        [-0.4415],\n",
      "        [-0.1948]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1893]],\n",
      "\n",
      "        [[-0.1927]],\n",
      "\n",
      "        [[-0.2898]],\n",
      "\n",
      "        [[-0.3106]]], dtype=torch.float64)\n",
      "tensor([[-0.2182],\n",
      "        [-0.1784],\n",
      "        [-0.2347],\n",
      "        [-0.4326]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2921]],\n",
      "\n",
      "        [[-0.1384]],\n",
      "\n",
      "        [[-0.4169]],\n",
      "\n",
      "        [[-0.3094]]], dtype=torch.float64)\n",
      "tensor([[-0.5011],\n",
      "        [-0.3538],\n",
      "        [-0.2089],\n",
      "        [-0.1626]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4192]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.3210]],\n",
      "\n",
      "        [[-0.2598]]], dtype=torch.float64)\n",
      "tensor([[-0.2697],\n",
      "        [-0.2772],\n",
      "        [-0.2999],\n",
      "        [-0.3062]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1200]],\n",
      "\n",
      "        [[-0.1442]],\n",
      "\n",
      "        [[-0.2205]],\n",
      "\n",
      "        [[-0.3938]]], dtype=torch.float64)\n",
      "tensor([[-0.3918],\n",
      "        [-0.3376],\n",
      "        [-0.3484],\n",
      "        [-0.3830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4296]],\n",
      "\n",
      "        [[-0.4354]],\n",
      "\n",
      "        [[-0.1304]],\n",
      "\n",
      "        [[-0.2367]]], dtype=torch.float64)\n",
      "tensor([[-0.3753],\n",
      "        [-0.4366],\n",
      "        [-0.5879],\n",
      "        [-0.5238]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2609]],\n",
      "\n",
      "        [[-0.6237]],\n",
      "\n",
      "        [[-0.7716]],\n",
      "\n",
      "        [[-0.6387]]], dtype=torch.float64)\n",
      "tensor([[-0.4403],\n",
      "        [-0.5393],\n",
      "        [-0.6143],\n",
      "        [-0.5371]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3892]],\n",
      "\n",
      "        [[-0.4596]],\n",
      "\n",
      "        [[-0.5139]],\n",
      "\n",
      "        [[-0.7057]]], dtype=torch.float64)\n",
      "tensor([[-0.5044],\n",
      "        [-0.3229],\n",
      "        [-0.2633],\n",
      "        [-0.2183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5555]],\n",
      "\n",
      "        [[-0.5012]],\n",
      "\n",
      "        [[-0.1881]],\n",
      "\n",
      "        [[-0.0680]]], dtype=torch.float64)\n",
      "tensor([[-0.2405],\n",
      "        [-0.0348],\n",
      "        [ 0.0409],\n",
      "        [-0.0690]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0749]],\n",
      "\n",
      "        [[ 0.0187]],\n",
      "\n",
      "        [[ 0.0025]],\n",
      "\n",
      "        [[-0.0345]]], dtype=torch.float64)\n",
      "tensor([[-0.2154],\n",
      "        [-0.2032],\n",
      "        [-0.1327],\n",
      "        [-0.0519]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0903]],\n",
      "\n",
      "        [[ 0.0880]],\n",
      "\n",
      "        [[ 0.0568]],\n",
      "\n",
      "        [[-0.0287]]], dtype=torch.float64)\n",
      "tensor([[-0.1617],\n",
      "        [-0.1715],\n",
      "        [-0.1967],\n",
      "        [-0.2482]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1823]],\n",
      "\n",
      "        [[-0.2170]],\n",
      "\n",
      "        [[-0.1766]],\n",
      "\n",
      "        [[-0.1893]]], dtype=torch.float64)\n",
      "tensor([[-0.2253],\n",
      "        [-0.2502],\n",
      "        [-0.2542],\n",
      "        [-0.2677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2367]],\n",
      "\n",
      "        [[-0.3002]],\n",
      "\n",
      "        [[-0.3603]],\n",
      "\n",
      "        [[-0.3926]]], dtype=torch.float64)\n",
      "tensor([[-0.3867],\n",
      "        [-0.3537],\n",
      "        [-0.2120],\n",
      "        [-0.2353]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3522]],\n",
      "\n",
      "        [[-0.2517]],\n",
      "\n",
      "        [[-0.2355]],\n",
      "\n",
      "        [[-0.2829]]], dtype=torch.float64)\n",
      "tensor([[-0.1701],\n",
      "        [-0.3559],\n",
      "        [-0.3693],\n",
      "        [-0.3897]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4516]],\n",
      "\n",
      "        [[-0.5047]],\n",
      "\n",
      "        [[-0.4354]],\n",
      "\n",
      "        [[-0.3603]]], dtype=torch.float64)\n",
      "tensor([[-0.4650],\n",
      "        [-0.4626],\n",
      "        [-0.3128],\n",
      "        [-0.3259]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5070]],\n",
      "\n",
      "        [[-0.5440]],\n",
      "\n",
      "        [[-0.5821]],\n",
      "\n",
      "        [[-0.5648]]], dtype=torch.float64)\n",
      "tensor([[-0.3767],\n",
      "        [-0.3894],\n",
      "        [-0.4255],\n",
      "        [-0.3069]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3603]],\n",
      "\n",
      "        [[-0.4585]],\n",
      "\n",
      "        [[-0.4365]],\n",
      "\n",
      "        [[-0.4134]]], dtype=torch.float64)\n",
      "tensor([[-0.2647],\n",
      "        [-0.2596],\n",
      "        [-0.2038],\n",
      "        [-0.3221]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4377]],\n",
      "\n",
      "        [[-0.4365]],\n",
      "\n",
      "        [[-0.3175]],\n",
      "\n",
      "        [[-0.3429]]], dtype=torch.float64)\n",
      "tensor([[-0.4092],\n",
      "        [-0.4892],\n",
      "        [-0.4530],\n",
      "        [-0.5294]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4885]],\n",
      "\n",
      "        [[-0.6133]],\n",
      "\n",
      "        [[-0.5925]],\n",
      "\n",
      "        [[-0.6965]]], dtype=torch.float64)\n",
      "tensor([[-0.5307],\n",
      "        [-0.6428],\n",
      "        [-0.6287],\n",
      "        [-1.0366]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.5867]],\n",
      "\n",
      "        [[-0.7023]],\n",
      "\n",
      "        [[-1.1598]]], dtype=torch.float64)\n",
      "tensor([[-1.0058],\n",
      "        [-0.9950],\n",
      "        [-1.0724],\n",
      "        [-1.1093]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2661]],\n",
      "\n",
      "        [[-1.2973]],\n",
      "\n",
      "        [[-1.1413]],\n",
      "\n",
      "        [[-1.2523]]], dtype=torch.float64)\n",
      "tensor([[-1.1472],\n",
      "        [-1.1515],\n",
      "        [-1.0407],\n",
      "        [-1.0253]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2996]],\n",
      "\n",
      "        [[-1.3609]],\n",
      "\n",
      "        [[-1.3331]],\n",
      "\n",
      "        [[-1.3343]]], dtype=torch.float64)\n",
      "tensor([[-1.1398],\n",
      "        [-1.2770],\n",
      "        [-1.3602],\n",
      "        [-1.4618]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1991]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.6740]],\n",
      "\n",
      "        [[-1.8461]]], dtype=torch.float64)\n",
      "tensor([[-1.3569],\n",
      "        [-1.2579],\n",
      "        [-1.2347],\n",
      "        [-1.3022]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7144]],\n",
      "\n",
      "        [[-1.6000]],\n",
      "\n",
      "        [[-1.3770]],\n",
      "\n",
      "        [[-1.3990]]], dtype=torch.float64)\n",
      "tensor([[-1.5307],\n",
      "        [-1.4954],\n",
      "        [-1.3574],\n",
      "        [-1.1937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5989]],\n",
      "\n",
      "        [[-1.6359]],\n",
      "\n",
      "        [[-1.5550]],\n",
      "\n",
      "        [[-1.5769]]], dtype=torch.float64)\n",
      "tensor([[-1.2698],\n",
      "        [-1.2936],\n",
      "        [-1.2667],\n",
      "        [-1.2266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4313]],\n",
      "\n",
      "        [[-1.3389]],\n",
      "\n",
      "        [[-1.3551]],\n",
      "\n",
      "        [[-1.5492]]], dtype=torch.float64)\n",
      "tensor([[-1.4305],\n",
      "        [-1.6979],\n",
      "        [-1.6627],\n",
      "        [-1.3991]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9547]],\n",
      "\n",
      "        [[-2.2193]],\n",
      "\n",
      "        [[-1.5700]],\n",
      "\n",
      "        [[-1.3701]]], dtype=torch.float64)\n",
      "tensor([[-1.4987],\n",
      "        [-1.3855],\n",
      "        [-1.3822],\n",
      "        [-1.3900]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4233]],\n",
      "\n",
      "        [[-1.5088]],\n",
      "\n",
      "        [[-1.6104]],\n",
      "\n",
      "        [[-1.5515]]], dtype=torch.float64)\n",
      "tensor([[-1.4888],\n",
      "        [-1.5528],\n",
      "        [-1.6424],\n",
      "        [-1.6285]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4117]],\n",
      "\n",
      "        [[-1.4695]],\n",
      "\n",
      "        [[-1.5319]],\n",
      "\n",
      "        [[-1.6081]]], dtype=torch.float64)\n",
      "tensor([[-1.6386],\n",
      "        [-1.5584],\n",
      "        [-1.4367],\n",
      "        [-1.5311]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6093]],\n",
      "\n",
      "        [[-1.5088]],\n",
      "\n",
      "        [[-1.3146]],\n",
      "\n",
      "        [[-1.3551]]], dtype=torch.float64)\n",
      "tensor([[-1.6412],\n",
      "        [-1.5694],\n",
      "        [-1.4887],\n",
      "        [-1.5491]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3978]],\n",
      "\n",
      "        [[-1.4071]],\n",
      "\n",
      "        [[-1.4429]],\n",
      "\n",
      "        [[-1.5353]]], dtype=torch.float64)\n",
      "tensor([[-1.6741],\n",
      "        [-1.8181],\n",
      "        [-1.8575],\n",
      "        [-1.8302]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6035]],\n",
      "\n",
      "        [[-1.6474]],\n",
      "\n",
      "        [[-1.7098]],\n",
      "\n",
      "        [[-1.8172]]], dtype=torch.float64)\n",
      "tensor([[-1.8444],\n",
      "        [-1.8624],\n",
      "        [-1.8911],\n",
      "        [-1.9204]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8357]],\n",
      "\n",
      "        [[-1.8970]],\n",
      "\n",
      "        [[-1.7895]],\n",
      "\n",
      "        [[-1.8184]]], dtype=torch.float64)\n",
      "tensor([[-2.0051],\n",
      "        [-1.9766],\n",
      "        [-1.9218],\n",
      "        [-1.8825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8935]],\n",
      "\n",
      "        [[-1.9212]],\n",
      "\n",
      "        [[-1.9259]],\n",
      "\n",
      "        [[-1.9120]]], dtype=torch.float64)\n",
      "tensor([[-1.9078],\n",
      "        [-1.7850],\n",
      "        [-1.7452],\n",
      "        [-1.8376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7040]],\n",
      "\n",
      "        [[-1.6335]],\n",
      "\n",
      "        [[-1.6959]],\n",
      "\n",
      "        [[-1.8045]]], dtype=torch.float64)\n",
      "tensor([[-1.7499],\n",
      "        [-1.7633],\n",
      "        [-1.8173],\n",
      "        [-1.8300]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8219]],\n",
      "\n",
      "        [[-1.8057]],\n",
      "\n",
      "        [[-1.7387]],\n",
      "\n",
      "        [[-1.7803]]], dtype=torch.float64)\n",
      "tensor([[-1.9041],\n",
      "        [-1.9002],\n",
      "        [-1.8495],\n",
      "        [-1.9165]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8692]],\n",
      "\n",
      "        [[-1.8796]],\n",
      "\n",
      "        [[-1.9120]],\n",
      "\n",
      "        [[-1.9859]]], dtype=torch.float64)\n",
      "tensor([[-1.9394],\n",
      "        [-1.9804],\n",
      "        [-2.0629],\n",
      "        [-1.9927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8427]],\n",
      "\n",
      "        [[-1.8889]],\n",
      "\n",
      "        [[-1.9443]],\n",
      "\n",
      "        [[-1.9166]]], dtype=torch.float64)\n",
      "tensor([[-1.8756],\n",
      "        [-1.9095],\n",
      "        [-1.8944],\n",
      "        [-1.9092]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9455]],\n",
      "\n",
      "        [[-1.9467]],\n",
      "\n",
      "        [[-1.7306]],\n",
      "\n",
      "        [[-1.7803]]], dtype=torch.float64)\n",
      "tensor([[-1.9771],\n",
      "        [-1.8915],\n",
      "        [-1.8008],\n",
      "        [-1.7843]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8820]],\n",
      "\n",
      "        [[-1.8739]],\n",
      "\n",
      "        [[-1.8808]],\n",
      "\n",
      "        [[-1.8542]]], dtype=torch.float64)\n",
      "tensor([[-1.7592],\n",
      "        [-1.8013],\n",
      "        [-1.7428],\n",
      "        [-1.7875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6624]],\n",
      "\n",
      "        [[-1.6335]],\n",
      "\n",
      "        [[-1.6948]],\n",
      "\n",
      "        [[-1.6982]]], dtype=torch.float64)\n",
      "tensor([[-1.7046],\n",
      "        [-1.7648],\n",
      "        [-1.9532],\n",
      "        [-2.0344]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7491]],\n",
      "\n",
      "        [[-1.8300]],\n",
      "\n",
      "        [[-1.8681]],\n",
      "\n",
      "        [[-1.9478]]], dtype=torch.float64)\n",
      "tensor([[-1.9285],\n",
      "        [-1.8540],\n",
      "        [-1.7144],\n",
      "        [-1.5538]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9698]],\n",
      "\n",
      "        [[-1.9363]],\n",
      "\n",
      "        [[-1.7907]],\n",
      "\n",
      "        [[-1.7479]]], dtype=torch.float64)\n",
      "tensor([[-1.5206],\n",
      "        [-1.4351],\n",
      "        [-1.7044],\n",
      "        [-1.4659]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3874]],\n",
      "\n",
      "        [[-1.5203]],\n",
      "\n",
      "        [[-1.6936]],\n",
      "\n",
      "        [[-1.4059]]], dtype=torch.float64)\n",
      "tensor([[-1.2450],\n",
      "        [-1.2963],\n",
      "        [-1.1051],\n",
      "        [-0.9032]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4267]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-0.9322]],\n",
      "\n",
      "        [[-0.8594]]], dtype=torch.float64)\n",
      "tensor([[-0.9196],\n",
      "        [-0.8316],\n",
      "        [-0.8294],\n",
      "        [-0.8927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8964]],\n",
      "\n",
      "        [[-0.7878]],\n",
      "\n",
      "        [[-0.8860]],\n",
      "\n",
      "        [[-1.0431]]], dtype=torch.float64)\n",
      "tensor([[-0.8365],\n",
      "        [-0.6671],\n",
      "        [-0.7975],\n",
      "        [-0.6629]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5139]],\n",
      "\n",
      "        [[-0.5775]],\n",
      "\n",
      "        [[-0.7762]],\n",
      "\n",
      "        [[-0.6445]]], dtype=torch.float64)\n",
      "tensor([[-0.5309],\n",
      "        [-0.5316],\n",
      "        [-0.5672],\n",
      "        [-0.4656]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5509]],\n",
      "\n",
      "        [[-0.4620]],\n",
      "\n",
      "        [[-0.2921]],\n",
      "\n",
      "        [[-0.2424]]], dtype=torch.float64)\n",
      "tensor([[-0.2915],\n",
      "        [-0.2527],\n",
      "        [-0.0182],\n",
      "        [ 0.0496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1766]],\n",
      "\n",
      "        [[-0.1246]],\n",
      "\n",
      "        [[ 0.0557]],\n",
      "\n",
      "        [[ 0.1550]]], dtype=torch.float64)\n",
      "tensor([[-0.0462],\n",
      "        [-0.0275],\n",
      "        [-0.0250],\n",
      "        [-0.2963]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3884]],\n",
      "\n",
      "        [[ 0.4762]],\n",
      "\n",
      "        [[-0.0876]],\n",
      "\n",
      "        [[-0.2401]]], dtype=torch.float64)\n",
      "tensor([[-0.5329],\n",
      "        [-0.6001],\n",
      "        [-0.5089],\n",
      "        [-0.5093]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3557]],\n",
      "\n",
      "        [[-0.3637]],\n",
      "\n",
      "        [[-0.1477]],\n",
      "\n",
      "        [[-0.2702]]], dtype=torch.float64)\n",
      "tensor([[-0.4884],\n",
      "        [-0.5817],\n",
      "        [-0.6363],\n",
      "        [-0.5762]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4712]],\n",
      "\n",
      "        [[-0.4804]],\n",
      "\n",
      "        [[-0.5267]],\n",
      "\n",
      "        [[-0.5105]]], dtype=torch.float64)\n",
      "tensor([[-0.4616],\n",
      "        [-0.4930],\n",
      "        [-0.6195],\n",
      "        [-0.6022]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3002]],\n",
      "\n",
      "        [[-0.5347]],\n",
      "\n",
      "        [[-0.6468]],\n",
      "\n",
      "        [[-0.6306]]], dtype=torch.float64)\n",
      "tensor([[-0.6176],\n",
      "        [-0.8336],\n",
      "        [-0.8756],\n",
      "        [-0.8148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7520]],\n",
      "\n",
      "        [[-0.8975]],\n",
      "\n",
      "        [[-0.6087]],\n",
      "\n",
      "        [[-0.8409]]], dtype=torch.float64)\n",
      "tensor([[-1.0988],\n",
      "        [-1.0020],\n",
      "        [-0.9668],\n",
      "        [-0.8997]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0593]],\n",
      "\n",
      "        [[-1.0778]],\n",
      "\n",
      "        [[-0.9911]],\n",
      "\n",
      "        [[-0.9900]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.17691:  74%|███████▍  | 2279/3067 [00:07<00:02, 330.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9486],\n",
      "        [-0.9662],\n",
      "        [-0.8400],\n",
      "        [-0.8649]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8340]],\n",
      "\n",
      "        [[-0.7912]],\n",
      "\n",
      "        [[-0.9680]],\n",
      "\n",
      "        [[-0.8120]]], dtype=torch.float64)\n",
      "tensor([[-0.7462],\n",
      "        [-0.7017],\n",
      "        [-0.5995],\n",
      "        [-0.5525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7566]],\n",
      "\n",
      "        [[-0.9183]],\n",
      "\n",
      "        [[-0.5636]],\n",
      "\n",
      "        [[-0.2482]]], dtype=torch.float64)\n",
      "tensor([[-0.5203],\n",
      "        [-0.4878],\n",
      "        [-0.4579],\n",
      "        [-0.5387]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4169]],\n",
      "\n",
      "        [[-0.5775]],\n",
      "\n",
      "        [[-0.6156]],\n",
      "\n",
      "        [[-0.6896]]], dtype=torch.float64)\n",
      "tensor([[-0.5039],\n",
      "        [-0.8841],\n",
      "        [-0.9621],\n",
      "        [-0.8978]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3476]],\n",
      "\n",
      "        [[-0.8895]],\n",
      "\n",
      "        [[-1.0581]],\n",
      "\n",
      "        [[-1.0050]]], dtype=torch.float64)\n",
      "tensor([[-0.8907],\n",
      "        [-1.0468],\n",
      "        [-0.9253],\n",
      "        [-0.8391]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2315]],\n",
      "\n",
      "        [[-1.3100]],\n",
      "\n",
      "        [[-0.9103]],\n",
      "\n",
      "        [[-0.8178]]], dtype=torch.float64)\n",
      "tensor([[-0.9070],\n",
      "        [-0.9466],\n",
      "        [-0.9962],\n",
      "        [-0.8861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9576]],\n",
      "\n",
      "        [[-1.1448]],\n",
      "\n",
      "        [[-1.1829]],\n",
      "\n",
      "        [[-1.0189]]], dtype=torch.float64)\n",
      "tensor([[-0.8796],\n",
      "        [-0.9565],\n",
      "        [-0.9924],\n",
      "        [-1.0795]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7670]],\n",
      "\n",
      "        [[-0.8305]],\n",
      "\n",
      "        [[-1.0951]],\n",
      "\n",
      "        [[-1.1344]]], dtype=torch.float64)\n",
      "tensor([[-1.0148],\n",
      "        [-1.0099],\n",
      "        [-1.0470],\n",
      "        [-1.1756]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1841]],\n",
      "\n",
      "        [[-1.2107]],\n",
      "\n",
      "        [[-1.1286]],\n",
      "\n",
      "        [[-1.2731]]], dtype=torch.float64)\n",
      "tensor([[-1.2241],\n",
      "        [-1.2081],\n",
      "        [-1.2381],\n",
      "        [-1.2934]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3389]],\n",
      "\n",
      "        [[-1.3805]],\n",
      "\n",
      "        [[-1.4545]],\n",
      "\n",
      "        [[-1.6902]]], dtype=torch.float64)\n",
      "tensor([[-1.3030],\n",
      "        [-1.1828],\n",
      "        [-1.2566],\n",
      "        [-1.2118]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3505]],\n",
      "\n",
      "        [[-1.1806]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.4337]]], dtype=torch.float64)\n",
      "tensor([[-1.2542],\n",
      "        [-1.2972],\n",
      "        [-1.2157],\n",
      "        [-1.0537]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5030]],\n",
      "\n",
      "        [[-1.5839]],\n",
      "\n",
      "        [[-1.0813]],\n",
      "\n",
      "        [[-1.1517]]], dtype=torch.float64)\n",
      "tensor([[-1.3449],\n",
      "        [-1.5126],\n",
      "        [-1.6555],\n",
      "        [-1.7552]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5330]],\n",
      "\n",
      "        [[-1.7918]],\n",
      "\n",
      "        [[-2.0264]],\n",
      "\n",
      "        [[-2.0102]]], dtype=torch.float64)\n",
      "tensor([[-1.5118],\n",
      "        [-1.3553],\n",
      "        [-1.3430],\n",
      "        [-1.3267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2985]],\n",
      "\n",
      "        [[-1.1714]],\n",
      "\n",
      "        [[-1.2985]],\n",
      "\n",
      "        [[-1.3354]]], dtype=torch.float64)\n",
      "tensor([[-1.3457],\n",
      "        [-1.4404],\n",
      "        [-1.4784],\n",
      "        [-1.4693]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3412]],\n",
      "\n",
      "        [[-1.4233]],\n",
      "\n",
      "        [[-1.3874]],\n",
      "\n",
      "        [[-1.2684]]], dtype=torch.float64)\n",
      "tensor([[-1.4236],\n",
      "        [-1.2830],\n",
      "        [-1.2515],\n",
      "        [-1.2213]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3158]],\n",
      "\n",
      "        [[-1.3204]],\n",
      "\n",
      "        [[-1.3851]],\n",
      "\n",
      "        [[-1.3805]]], dtype=torch.float64)\n",
      "tensor([[-1.3633],\n",
      "        [-1.4230],\n",
      "        [-1.4138],\n",
      "        [-1.6200]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2985]],\n",
      "\n",
      "        [[-1.2095]],\n",
      "\n",
      "        [[-1.3643]],\n",
      "\n",
      "        [[-1.6925]]], dtype=torch.float64)\n",
      "tensor([[-1.6567],\n",
      "        [-1.5402],\n",
      "        [-1.3798],\n",
      "        [-1.1494]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7872]],\n",
      "\n",
      "        [[-1.6670]],\n",
      "\n",
      "        [[-1.1240]],\n",
      "\n",
      "        [[-0.9750]]], dtype=torch.float64)\n",
      "tensor([[-1.1274],\n",
      "        [-1.1468],\n",
      "        [-1.0832],\n",
      "        [-1.3303]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0766]],\n",
      "\n",
      "        [[-1.0824]],\n",
      "\n",
      "        [[-1.2222]],\n",
      "\n",
      "        [[-1.4129]]], dtype=torch.float64)\n",
      "tensor([[-1.2095],\n",
      "        [-1.1052],\n",
      "        [-1.2166],\n",
      "        [-1.1546]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8074]],\n",
      "\n",
      "        [[-0.9981]],\n",
      "\n",
      "        [[-1.1182]],\n",
      "\n",
      "        [[-1.1425]]], dtype=torch.float64)\n",
      "tensor([[-1.0306],\n",
      "        [-0.9524],\n",
      "        [-0.9233],\n",
      "        [-0.8366]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0732]],\n",
      "\n",
      "        [[-1.0246]],\n",
      "\n",
      "        [[-0.8375]],\n",
      "\n",
      "        [[-0.6919]]], dtype=torch.float64)\n",
      "tensor([[-0.8880],\n",
      "        [-0.9093],\n",
      "        [-0.8320],\n",
      "        [-0.9319]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7832]],\n",
      "\n",
      "        [[-0.8409]],\n",
      "\n",
      "        [[-0.9403]],\n",
      "\n",
      "        [[-1.0443]]], dtype=torch.float64)\n",
      "tensor([[-1.1043],\n",
      "        [-1.0978],\n",
      "        [-1.1491],\n",
      "        [-1.0392]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9992]],\n",
      "\n",
      "        [[-0.8929]],\n",
      "\n",
      "        [[-0.9680]],\n",
      "\n",
      "        [[-1.0223]]], dtype=torch.float64)\n",
      "tensor([[-1.0251],\n",
      "        [-1.0774],\n",
      "        [-1.0891],\n",
      "        [-1.1582]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0720]],\n",
      "\n",
      "        [[-1.0743]],\n",
      "\n",
      "        [[-0.9992]],\n",
      "\n",
      "        [[-0.9680]]], dtype=torch.float64)\n",
      "tensor([[-1.1959],\n",
      "        [-1.0559],\n",
      "        [-0.9250],\n",
      "        [-0.9657]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0258]],\n",
      "\n",
      "        [[-1.0501]],\n",
      "\n",
      "        [[-1.0004]],\n",
      "\n",
      "        [[-1.0755]]], dtype=torch.float64)\n",
      "tensor([[-1.1055],\n",
      "        [-1.0383],\n",
      "        [-1.2019],\n",
      "        [-1.2277]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9923]],\n",
      "\n",
      "        [[-1.0304]],\n",
      "\n",
      "        [[-1.1286]],\n",
      "\n",
      "        [[-1.2222]]], dtype=torch.float64)\n",
      "tensor([[-1.1440],\n",
      "        [-1.2854],\n",
      "        [-1.4019],\n",
      "        [-1.4330]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2465]],\n",
      "\n",
      "        [[-1.2835]],\n",
      "\n",
      "        [[-1.2453]],\n",
      "\n",
      "        [[-1.2164]]], dtype=torch.float64)\n",
      "tensor([[-1.4375],\n",
      "        [-1.4644],\n",
      "        [-1.5219],\n",
      "        [-1.5313]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3828]],\n",
      "\n",
      "        [[-1.4822]],\n",
      "\n",
      "        [[-1.5619]],\n",
      "\n",
      "        [[-1.6162]]], dtype=torch.float64)\n",
      "tensor([[-1.6164],\n",
      "        [-1.6435],\n",
      "        [-1.6762],\n",
      "        [-1.6222]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4799]],\n",
      "\n",
      "        [[-1.4984]],\n",
      "\n",
      "        [[-1.6220]],\n",
      "\n",
      "        [[-1.6416]]], dtype=torch.float64)\n",
      "tensor([[-1.5878],\n",
      "        [-1.6093],\n",
      "        [-1.6414],\n",
      "        [-1.6984]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7098]],\n",
      "\n",
      "        [[-1.7017]],\n",
      "\n",
      "        [[-1.5977]],\n",
      "\n",
      "        [[-1.6451]]], dtype=torch.float64)\n",
      "tensor([[-1.7197],\n",
      "        [-1.6285],\n",
      "        [-1.5503],\n",
      "        [-1.5683]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6543]],\n",
      "\n",
      "        [[-1.6047]],\n",
      "\n",
      "        [[-1.6347]],\n",
      "\n",
      "        [[-1.6566]]], dtype=torch.float64)\n",
      "tensor([[-1.6569],\n",
      "        [-1.6027],\n",
      "        [-1.5274],\n",
      "        [-1.3614]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6162]],\n",
      "\n",
      "        [[-1.5688]],\n",
      "\n",
      "        [[-1.4706]],\n",
      "\n",
      "        [[-1.3897]]], dtype=torch.float64)\n",
      "tensor([[-1.1825],\n",
      "        [-1.1341],\n",
      "        [-1.0929],\n",
      "        [-1.0676]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3378]],\n",
      "\n",
      "        [[-1.2638]],\n",
      "\n",
      "        [[-1.0893]],\n",
      "\n",
      "        [[-1.0917]]], dtype=torch.float64)\n",
      "tensor([[-1.0533],\n",
      "        [-1.0392],\n",
      "        [-0.9800],\n",
      "        [-0.9561]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0674]],\n",
      "\n",
      "        [[-1.0685]],\n",
      "\n",
      "        [[-1.0535]],\n",
      "\n",
      "        [[-1.0605]]], dtype=torch.float64)\n",
      "tensor([[-1.0304],\n",
      "        [-1.0673],\n",
      "        [-1.0421],\n",
      "        [-0.9522]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0408]],\n",
      "\n",
      "        [[-1.0223]],\n",
      "\n",
      "        [[-0.9992]],\n",
      "\n",
      "        [[-0.9981]]], dtype=torch.float64)\n",
      "tensor([[-0.8969],\n",
      "        [-0.9044],\n",
      "        [-1.0720],\n",
      "        [-1.1330]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0062]],\n",
      "\n",
      "        [[-1.0293]],\n",
      "\n",
      "        [[-1.0605]],\n",
      "\n",
      "        [[-1.0605]]], dtype=torch.float64)\n",
      "tensor([[-1.1499],\n",
      "        [-1.1601],\n",
      "        [-1.0887],\n",
      "        [-1.0641]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0893]],\n",
      "\n",
      "        [[-1.1298]],\n",
      "\n",
      "        [[-1.1841]],\n",
      "\n",
      "        [[-1.1783]]], dtype=torch.float64)\n",
      "tensor([[-1.1401],\n",
      "        [-1.1808],\n",
      "        [-1.1616],\n",
      "        [-1.0600]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0824]],\n",
      "\n",
      "        [[-1.0732]],\n",
      "\n",
      "        [[-1.0836]],\n",
      "\n",
      "        [[-1.0766]]], dtype=torch.float64)\n",
      "tensor([[-0.9771],\n",
      "        [-0.9177],\n",
      "        [-0.9554],\n",
      "        [-0.9343]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0836]],\n",
      "\n",
      "        [[-1.0674]],\n",
      "\n",
      "        [[-0.9680]],\n",
      "\n",
      "        [[-0.9565]]], dtype=torch.float64)\n",
      "tensor([[-0.9751],\n",
      "        [-0.9461],\n",
      "        [-0.9133],\n",
      "        [-0.9462]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0062]],\n",
      "\n",
      "        [[-1.0050]],\n",
      "\n",
      "        [[-1.0813]],\n",
      "\n",
      "        [[-1.0570]]], dtype=torch.float64)\n",
      "tensor([[-0.8577],\n",
      "        [-0.9359],\n",
      "        [-0.9675],\n",
      "        [-0.9763]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7497]],\n",
      "\n",
      "        [[-0.8432]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-1.0096]]], dtype=torch.float64)\n",
      "tensor([[-0.9420],\n",
      "        [-1.0299],\n",
      "        [-0.8993],\n",
      "        [-0.7798]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2153]],\n",
      "\n",
      "        [[-1.1228]],\n",
      "\n",
      "        [[-0.6977]],\n",
      "\n",
      "        [[-0.5960]]], dtype=torch.float64)\n",
      "tensor([[-0.9621],\n",
      "        [-1.1233],\n",
      "        [-1.0257],\n",
      "        [-1.0560]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0801]],\n",
      "\n",
      "        [[-1.3528]],\n",
      "\n",
      "        [[-1.1540]],\n",
      "\n",
      "        [[-1.0293]]], dtype=torch.float64)\n",
      "tensor([[-0.9018],\n",
      "        [-0.8623],\n",
      "        [-0.9386],\n",
      "        [-0.8431]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7138]],\n",
      "\n",
      "        [[-0.7439]],\n",
      "\n",
      "        [[-0.8144]],\n",
      "\n",
      "        [[-0.9750]]], dtype=torch.float64)\n",
      "tensor([[-0.8490],\n",
      "        [-1.0460],\n",
      "        [-0.6285],\n",
      "        [-0.3931]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0928]],\n",
      "\n",
      "        [[-1.0870]],\n",
      "\n",
      "        [[-0.3637]],\n",
      "\n",
      "        [[-0.1512]]], dtype=torch.float64)\n",
      "tensor([[-0.6739],\n",
      "        [-0.8032],\n",
      "        [-1.0310],\n",
      "        [-0.9812]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7312]],\n",
      "\n",
      "        [[-1.0154]],\n",
      "\n",
      "        [[-0.9773]],\n",
      "\n",
      "        [[-0.8606]]], dtype=torch.float64)\n",
      "tensor([[-0.4776],\n",
      "        [-0.0792],\n",
      "        [-0.3705],\n",
      "        [-0.6661]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0106]],\n",
      "\n",
      "        [[ 0.3318]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[-0.8132]]], dtype=torch.float64)\n",
      "tensor([[-0.9885],\n",
      "        [-1.0425],\n",
      "        [-0.4957],\n",
      "        [ 0.1550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1887]],\n",
      "\n",
      "        [[-0.9576]],\n",
      "\n",
      "        [[ 0.2012]],\n",
      "\n",
      "        [[ 0.4635]]], dtype=torch.float64)\n",
      "tensor([[-0.0642],\n",
      "        [-0.5670],\n",
      "        [-0.8356],\n",
      "        [-0.7717]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2713]],\n",
      "\n",
      "        [[-0.8386]],\n",
      "\n",
      "        [[-0.9137]],\n",
      "\n",
      "        [[-0.8629]]], dtype=torch.float64)\n",
      "tensor([[-0.6424],\n",
      "        [-0.3482],\n",
      "        [-0.2973],\n",
      "        [-0.3449]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4019]],\n",
      "\n",
      "        [[-0.1719]],\n",
      "\n",
      "        [[-0.3337]],\n",
      "\n",
      "        [[-0.4677]]], dtype=torch.float64)\n",
      "tensor([[-0.2700],\n",
      "        [-0.3054],\n",
      "        [-0.4956],\n",
      "        [-0.6429]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5220]],\n",
      "\n",
      "        [[-0.5347]],\n",
      "\n",
      "        [[-0.6803]],\n",
      "\n",
      "        [[-0.7947]]], dtype=torch.float64)\n",
      "tensor([[-0.8003],\n",
      "        [-0.8743],\n",
      "        [-0.8528],\n",
      "        [-0.8560]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9726]],\n",
      "\n",
      "        [[-1.0743]],\n",
      "\n",
      "        [[-1.1067]],\n",
      "\n",
      "        [[-1.0859]]], dtype=torch.float64)\n",
      "tensor([[-0.8181],\n",
      "        [-0.7420],\n",
      "        [-0.6918],\n",
      "        [-0.7067]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9079]],\n",
      "\n",
      "        [[-0.7531]],\n",
      "\n",
      "        [[-0.7473]],\n",
      "\n",
      "        [[-0.8744]]], dtype=torch.float64)\n",
      "tensor([[-0.6257],\n",
      "        [-0.6881],\n",
      "        [-0.1627],\n",
      "        [-0.6095]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9311]],\n",
      "\n",
      "        [[-0.9992]],\n",
      "\n",
      "        [[-0.3880]],\n",
      "\n",
      "        [[-0.9472]]], dtype=torch.float64)\n",
      "tensor([[-1.0658],\n",
      "        [-1.3610],\n",
      "        [-1.4451],\n",
      "        [-1.4669]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3089]],\n",
      "\n",
      "        [[-1.5919]],\n",
      "\n",
      "        [[-1.7167]],\n",
      "\n",
      "        [[-1.7329]]], dtype=torch.float64)\n",
      "tensor([[-1.5096],\n",
      "        [-1.5152],\n",
      "        [-1.5375],\n",
      "        [-1.4550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6590]],\n",
      "\n",
      "        [[-1.6058]],\n",
      "\n",
      "        [[-1.6335]],\n",
      "\n",
      "        [[-1.6416]]], dtype=torch.float64)\n",
      "tensor([[-1.4736],\n",
      "        [-1.5086],\n",
      "        [-1.5361],\n",
      "        [-1.5475]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7156]],\n",
      "\n",
      "        [[-1.7294]],\n",
      "\n",
      "        [[-1.6104]],\n",
      "\n",
      "        [[-1.6393]]], dtype=torch.float64)\n",
      "tensor([[-1.5891],\n",
      "        [-1.5594],\n",
      "        [-1.5381],\n",
      "        [-1.5119]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6844]],\n",
      "\n",
      "        [[-1.7040]],\n",
      "\n",
      "        [[-1.7572]],\n",
      "\n",
      "        [[-1.7653]]], dtype=torch.float64)\n",
      "tensor([[-1.5676],\n",
      "        [-1.5486],\n",
      "        [-1.6431],\n",
      "        [-1.8247]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5088]],\n",
      "\n",
      "        [[-1.5284]],\n",
      "\n",
      "        [[-1.8877]],\n",
      "\n",
      "        [[-2.3649]]], dtype=torch.float64)\n",
      "tensor([[-2.1108],\n",
      "        [-2.0734],\n",
      "        [-1.6542],\n",
      "        [-1.2747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6110]],\n",
      "\n",
      "        [[-2.2032]],\n",
      "\n",
      "        [[-1.1737]],\n",
      "\n",
      "        [[-1.1032]]], dtype=torch.float64)\n",
      "tensor([[-1.3719],\n",
      "        [-1.4079],\n",
      "        [-1.3860],\n",
      "        [-1.5514]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3921]],\n",
      "\n",
      "        [[-1.5353]],\n",
      "\n",
      "        [[-1.5931]],\n",
      "\n",
      "        [[-1.5342]]], dtype=torch.float64)\n",
      "tensor([[-1.5905],\n",
      "        [-1.5564],\n",
      "        [-1.5970],\n",
      "        [-1.7709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2534]],\n",
      "\n",
      "        [[-1.1760]],\n",
      "\n",
      "        [[-1.6451]],\n",
      "\n",
      "        [[-2.0194]]], dtype=torch.float64)\n",
      "tensor([[-1.9491],\n",
      "        [-1.8183],\n",
      "        [-1.1676],\n",
      "        [-0.7895]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2424]],\n",
      "\n",
      "        [[-1.7421]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.4932]]], dtype=torch.float64)\n",
      "tensor([[-0.9784],\n",
      "        [-1.0816],\n",
      "        [-1.1378],\n",
      "        [-1.1648]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9160]],\n",
      "\n",
      "        [[-1.0512]],\n",
      "\n",
      "        [[-1.1298]],\n",
      "\n",
      "        [[-0.9345]]], dtype=torch.float64)\n",
      "tensor([[-0.9365],\n",
      "        [-0.8521],\n",
      "        [-0.9172],\n",
      "        [-0.8519]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6087]],\n",
      "\n",
      "        [[-0.4932]],\n",
      "\n",
      "        [[-0.6191]],\n",
      "\n",
      "        [[-0.7439]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.17691:  76%|███████▋  | 2346/3067 [00:07<00:02, 317.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8355],\n",
      "        [-0.8390],\n",
      "        [-0.8352],\n",
      "        [-0.9488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8733]],\n",
      "\n",
      "        [[-0.9149]],\n",
      "\n",
      "        [[-0.7751]],\n",
      "\n",
      "        [[-0.9854]]], dtype=torch.float64)\n",
      "tensor([[-1.2120],\n",
      "        [-1.0362],\n",
      "        [-1.1546],\n",
      "        [-1.1401]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0986]],\n",
      "\n",
      "        [[-1.1748]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.0859]]], dtype=torch.float64)\n",
      "tensor([[-1.0632],\n",
      "        [-1.0407],\n",
      "        [-0.9293],\n",
      "        [-0.9354]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8744]],\n",
      "\n",
      "        [[-0.9137]],\n",
      "\n",
      "        [[-0.9126]],\n",
      "\n",
      "        [[-0.9507]]], dtype=torch.float64)\n",
      "tensor([[-0.9634],\n",
      "        [-1.1527],\n",
      "        [-1.2093],\n",
      "        [-1.1148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0928]],\n",
      "\n",
      "        [[-1.1818]],\n",
      "\n",
      "        [[-0.8617]],\n",
      "\n",
      "        [[-0.9761]]], dtype=torch.float64)\n",
      "tensor([[-1.0547],\n",
      "        [-0.9688],\n",
      "        [-0.9930],\n",
      "        [-1.0933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0154]],\n",
      "\n",
      "        [[-0.9842]],\n",
      "\n",
      "        [[-1.2338]],\n",
      "\n",
      "        [[-1.2107]]], dtype=torch.float64)\n",
      "tensor([[-1.1710],\n",
      "        [-1.1681],\n",
      "        [-1.1919],\n",
      "        [-1.2200]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9311]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-1.1228]],\n",
      "\n",
      "        [[-1.2719]]], dtype=torch.float64)\n",
      "tensor([[-1.3254],\n",
      "        [-1.3005],\n",
      "        [-1.4949],\n",
      "        [-1.5728]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4752]],\n",
      "\n",
      "        [[-1.3701]],\n",
      "\n",
      "        [[-1.3863]],\n",
      "\n",
      "        [[-1.3424]]], dtype=torch.float64)\n",
      "tensor([[-1.5266],\n",
      "        [-1.5891],\n",
      "        [-1.5914],\n",
      "        [-1.6542]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3759]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.6255]],\n",
      "\n",
      "        [[-1.7537]]], dtype=torch.float64)\n",
      "tensor([[-1.8206],\n",
      "        [-1.8217],\n",
      "        [-1.9590],\n",
      "        [-1.9183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5827]],\n",
      "\n",
      "        [[-1.4464]],\n",
      "\n",
      "        [[-1.6763]],\n",
      "\n",
      "        [[-1.9848]]], dtype=torch.float64)\n",
      "tensor([[-2.0621],\n",
      "        [-2.0608],\n",
      "        [-1.9278],\n",
      "        [-1.7655]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1616]],\n",
      "\n",
      "        [[-2.0171]],\n",
      "\n",
      "        [[-1.4383]],\n",
      "\n",
      "        [[-1.2315]]], dtype=torch.float64)\n",
      "tensor([[-1.7666],\n",
      "        [-1.8030],\n",
      "        [-1.7958],\n",
      "        [-1.7900]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4521]],\n",
      "\n",
      "        [[-1.7006]],\n",
      "\n",
      "        [[-1.8219]],\n",
      "\n",
      "        [[-1.7456]]], dtype=torch.float64)\n",
      "tensor([[-1.6011],\n",
      "        [-1.5056],\n",
      "        [-1.6285],\n",
      "        [-1.6623]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3170]],\n",
      "\n",
      "        [[-1.1552]],\n",
      "\n",
      "        [[-1.3967]],\n",
      "\n",
      "        [[-1.5758]]], dtype=torch.float64)\n",
      "tensor([[-1.5222],\n",
      "        [-1.6149],\n",
      "        [-1.4766],\n",
      "        [-1.2835]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7167]],\n",
      "\n",
      "        [[-1.6878]],\n",
      "\n",
      "        [[-1.1980]],\n",
      "\n",
      "        [[-0.9911]]], dtype=torch.float64)\n",
      "tensor([[-1.3181],\n",
      "        [-1.4012],\n",
      "        [-1.3402],\n",
      "        [-1.3814]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1956]],\n",
      "\n",
      "        [[-1.4117]],\n",
      "\n",
      "        [[-1.5388]],\n",
      "\n",
      "        [[-1.5272]]], dtype=torch.float64)\n",
      "tensor([[-1.3031],\n",
      "        [-1.2527],\n",
      "        [-1.1828],\n",
      "        [-1.1960]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0882]],\n",
      "\n",
      "        [[-1.0605]],\n",
      "\n",
      "        [[-1.2523]],\n",
      "\n",
      "        [[-1.3401]]], dtype=torch.float64)\n",
      "tensor([[-1.0518],\n",
      "        [-1.0507],\n",
      "        [-0.8372],\n",
      "        [-0.8076]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3840]],\n",
      "\n",
      "        [[-1.2858]],\n",
      "\n",
      "        [[-0.8652]],\n",
      "\n",
      "        [[-0.6942]]], dtype=torch.float64)\n",
      "tensor([[-0.9263],\n",
      "        [-0.9482],\n",
      "        [-0.8871],\n",
      "        [-0.9105]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0073]],\n",
      "\n",
      "        [[-1.1621]],\n",
      "\n",
      "        [[-1.0951]],\n",
      "\n",
      "        [[-1.0581]]], dtype=torch.float64)\n",
      "tensor([[-0.9373],\n",
      "        [-0.8324],\n",
      "        [-0.8617],\n",
      "        [-0.9158]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7681]],\n",
      "\n",
      "        [[-0.7508]],\n",
      "\n",
      "        [[-1.1032]],\n",
      "\n",
      "        [[-1.1922]]], dtype=torch.float64)\n",
      "tensor([[-0.8328],\n",
      "        [-0.8597],\n",
      "        [-0.8121],\n",
      "        [-0.8815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2234]],\n",
      "\n",
      "        [[-1.1910]],\n",
      "\n",
      "        [[-0.8467]],\n",
      "\n",
      "        [[-0.8190]]], dtype=torch.float64)\n",
      "tensor([[-1.0020],\n",
      "        [-0.9464],\n",
      "        [-1.0001],\n",
      "        [-0.9160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1078]],\n",
      "\n",
      "        [[-1.3482]],\n",
      "\n",
      "        [[-1.3666]],\n",
      "\n",
      "        [[-1.2407]]], dtype=torch.float64)\n",
      "tensor([[-0.9263],\n",
      "        [-0.9973],\n",
      "        [-0.9977],\n",
      "        [-0.9870]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1379]],\n",
      "\n",
      "        [[-1.0027]],\n",
      "\n",
      "        [[-1.2049]],\n",
      "\n",
      "        [[-1.3019]]], dtype=torch.float64)\n",
      "tensor([[-0.9757],\n",
      "        [-0.9405],\n",
      "        [-0.9630],\n",
      "        [-1.0513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3343]],\n",
      "\n",
      "        [[-1.2731]],\n",
      "\n",
      "        [[-0.9854]],\n",
      "\n",
      "        [[-0.8155]]], dtype=torch.float64)\n",
      "tensor([[-0.9199],\n",
      "        [-0.9097],\n",
      "        [-1.0344],\n",
      "        [-0.8787]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0373]],\n",
      "\n",
      "        [[-1.1436]],\n",
      "\n",
      "        [[-1.2153]],\n",
      "\n",
      "        [[-1.1252]]], dtype=torch.float64)\n",
      "tensor([[-0.8964],\n",
      "        [-0.9955],\n",
      "        [-0.9802],\n",
      "        [-0.9405]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9796]],\n",
      "\n",
      "        [[-0.9068]],\n",
      "\n",
      "        [[-0.9911]],\n",
      "\n",
      "        [[-1.1044]]], dtype=torch.float64)\n",
      "tensor([[-0.9504],\n",
      "        [-0.9398],\n",
      "        [-0.8660],\n",
      "        [-0.9806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2141]],\n",
      "\n",
      "        [[-1.1564]],\n",
      "\n",
      "        [[-1.0963]],\n",
      "\n",
      "        [[-1.1182]]], dtype=torch.float64)\n",
      "tensor([[-1.0916],\n",
      "        [-0.9842],\n",
      "        [-0.9482],\n",
      "        [-0.9559]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1610]],\n",
      "\n",
      "        [[-1.1413]],\n",
      "\n",
      "        [[-1.1980]],\n",
      "\n",
      "        [[-1.1910]]], dtype=torch.float64)\n",
      "tensor([[-0.9434],\n",
      "        [-0.9348],\n",
      "        [-0.8989],\n",
      "        [-0.9233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0212]],\n",
      "\n",
      "        [[-0.9287]],\n",
      "\n",
      "        [[-0.9773]],\n",
      "\n",
      "        [[-1.0050]]], dtype=torch.float64)\n",
      "tensor([[-0.9162],\n",
      "        [-0.9151],\n",
      "        [-0.9101],\n",
      "        [-0.9934]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0685]],\n",
      "\n",
      "        [[-1.0917]],\n",
      "\n",
      "        [[-0.9449]],\n",
      "\n",
      "        [[-0.9241]]], dtype=torch.float64)\n",
      "tensor([[-0.9514],\n",
      "        [-0.8677],\n",
      "        [-0.7160],\n",
      "        [-0.7672]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9599]],\n",
      "\n",
      "        [[-0.9796]],\n",
      "\n",
      "        [[-0.9842]],\n",
      "\n",
      "        [[-1.0616]]], dtype=torch.float64)\n",
      "tensor([[-0.9077],\n",
      "        [-0.9816],\n",
      "        [-0.9016],\n",
      "        [-0.9007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9391]],\n",
      "\n",
      "        [[-0.9056]],\n",
      "\n",
      "        [[-0.9946]],\n",
      "\n",
      "        [[-1.1228]]], dtype=torch.float64)\n",
      "tensor([[-0.8250],\n",
      "        [-0.8339],\n",
      "        [-0.5593],\n",
      "        [-0.5732]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1332]],\n",
      "\n",
      "        [[-1.0870]],\n",
      "\n",
      "        [[-0.5486]],\n",
      "\n",
      "        [[-0.3210]]], dtype=torch.float64)\n",
      "tensor([[-0.8062],\n",
      "        [-0.9749],\n",
      "        [-1.1638],\n",
      "        [-1.1533]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6884]],\n",
      "\n",
      "        [[-1.3343]],\n",
      "\n",
      "        [[-1.4984]],\n",
      "\n",
      "        [[-1.1217]]], dtype=torch.float64)\n",
      "tensor([[-0.6009],\n",
      "        [-0.5377],\n",
      "        [-0.6211],\n",
      "        [-0.5545]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2517]],\n",
      "\n",
      "        [[-0.2020]],\n",
      "\n",
      "        [[-0.3580]],\n",
      "\n",
      "        [[-0.4851]]], dtype=torch.float64)\n",
      "tensor([[-0.6447],\n",
      "        [-0.6306],\n",
      "        [ 0.0184],\n",
      "        [-0.0544]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6746]],\n",
      "\n",
      "        [[-0.6399]],\n",
      "\n",
      "        [[-0.0703]],\n",
      "\n",
      "        [[ 0.1539]]], dtype=torch.float64)\n",
      "tensor([[-0.1679],\n",
      "        [-0.5735],\n",
      "        [-0.6523],\n",
      "        [-0.5838]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3776]],\n",
      "\n",
      "        [[-0.7023]],\n",
      "\n",
      "        [[-0.8895]],\n",
      "\n",
      "        [[-0.5047]]], dtype=torch.float64)\n",
      "tensor([[ 0.0247],\n",
      "        [ 0.0503],\n",
      "        [-0.1082],\n",
      "        [-0.1638]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0638]],\n",
      "\n",
      "        [[ 0.2244]],\n",
      "\n",
      "        [[-0.1500]],\n",
      "\n",
      "        [[-0.2609]]], dtype=torch.float64)\n",
      "tensor([[-0.2480],\n",
      "        [-0.2308],\n",
      "        [ 0.2559],\n",
      "        [ 0.3373]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4481]],\n",
      "\n",
      "        [[-0.2528]],\n",
      "\n",
      "        [[ 0.4497]],\n",
      "\n",
      "        [[ 0.7582]]], dtype=torch.float64)\n",
      "tensor([[0.3528],\n",
      "        [0.4590],\n",
      "        [0.4555],\n",
      "        [0.1563]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5317]],\n",
      "\n",
      "        [[ 0.3214]],\n",
      "\n",
      "        [[ 0.1030]],\n",
      "\n",
      "        [[-0.0321]]], dtype=torch.float64)\n",
      "tensor([[-0.1075],\n",
      "        [ 0.1468],\n",
      "        [ 0.1306],\n",
      "        [ 0.0573]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0118]],\n",
      "\n",
      "        [[ 0.4289]],\n",
      "\n",
      "        [[ 0.1735]],\n",
      "\n",
      "        [[-0.0275]]], dtype=torch.float64)\n",
      "tensor([[0.2256],\n",
      "        [0.1732],\n",
      "        [0.1589],\n",
      "        [0.1130]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1003]],\n",
      "\n",
      "        [[-0.0194]],\n",
      "\n",
      "        [[ 0.1181]],\n",
      "\n",
      "        [[ 0.5074]]], dtype=torch.float64)\n",
      "tensor([[ 0.1580],\n",
      "        [ 0.1790],\n",
      "        [-0.0164],\n",
      "        [ 0.1294]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1215]],\n",
      "\n",
      "        [[-0.2447]],\n",
      "\n",
      "        [[-0.4100]],\n",
      "\n",
      "        [[-0.1673]]], dtype=torch.float64)\n",
      "tensor([[0.4467],\n",
      "        [0.5495],\n",
      "        [0.6082],\n",
      "        [0.5806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7166]],\n",
      "\n",
      "        [[1.0170]],\n",
      "\n",
      "        [[0.6761]],\n",
      "\n",
      "        [[0.2613]]], dtype=torch.float64)\n",
      "tensor([[0.5484],\n",
      "        [0.5527],\n",
      "        [0.9814],\n",
      "        [1.1065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1654]],\n",
      "\n",
      "        [[0.6969]],\n",
      "\n",
      "        [[1.4907]],\n",
      "\n",
      "        [[1.7449]]], dtype=torch.float64)\n",
      "tensor([[0.9563],\n",
      "        [0.8118],\n",
      "        [0.7662],\n",
      "        [0.5573]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2573]],\n",
      "\n",
      "        [[0.5490]],\n",
      "\n",
      "        [[0.2729]],\n",
      "\n",
      "        [[0.3307]]], dtype=torch.float64)\n",
      "tensor([[0.7385],\n",
      "        [0.8057],\n",
      "        [0.7563],\n",
      "        [0.7037]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1464]],\n",
      "\n",
      "        [[1.3081]],\n",
      "\n",
      "        [[1.0158]],\n",
      "\n",
      "        [[0.4797]]], dtype=torch.float64)\n",
      "tensor([[0.7667],\n",
      "        [0.8154],\n",
      "        [0.9154],\n",
      "        [0.8652]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6311]],\n",
      "\n",
      "        [[0.6415]],\n",
      "\n",
      "        [[1.2850]],\n",
      "\n",
      "        [[1.3763]]], dtype=torch.float64)\n",
      "tensor([[0.8565],\n",
      "        [0.7201],\n",
      "        [0.7054],\n",
      "        [0.8952]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0886]],\n",
      "\n",
      "        [[0.4670]],\n",
      "\n",
      "        [[0.3179]],\n",
      "\n",
      "        [[1.1510]]], dtype=torch.float64)\n",
      "tensor([[1.1864],\n",
      "        [1.1238],\n",
      "        [0.7012],\n",
      "        [0.5823]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7437]],\n",
      "\n",
      "        [[1.4410]],\n",
      "\n",
      "        [[1.0470]],\n",
      "\n",
      "        [[0.4266]]], dtype=torch.float64)\n",
      "tensor([[0.5889],\n",
      "        [0.4670],\n",
      "        [0.4598],\n",
      "        [0.2178]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0973]],\n",
      "\n",
      "        [[0.4381]],\n",
      "\n",
      "        [[0.6311]],\n",
      "\n",
      "        [[0.5548]]], dtype=torch.float64)\n",
      "tensor([[ 0.1088],\n",
      "        [ 0.0749],\n",
      "        [-0.0924],\n",
      "        [-0.5245]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2163]],\n",
      "\n",
      "        [[-0.0333]],\n",
      "\n",
      "        [[-0.2817]],\n",
      "\n",
      "        [[-0.5082]]], dtype=torch.float64)\n",
      "tensor([[-0.2750],\n",
      "        [-0.2041],\n",
      "        [-0.3051],\n",
      "        [-0.3168]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0160]],\n",
      "\n",
      "        [[ 0.0996]],\n",
      "\n",
      "        [[-0.0333]],\n",
      "\n",
      "        [[-0.1223]]], dtype=torch.float64)\n",
      "tensor([[-0.1059],\n",
      "        [-0.2830],\n",
      "        [ 0.2541],\n",
      "        [ 0.3968]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3903]],\n",
      "\n",
      "        [[-0.2251]],\n",
      "\n",
      "        [[ 0.4832]],\n",
      "\n",
      "        [[ 0.7801]]], dtype=torch.float64)\n",
      "tensor([[0.4608],\n",
      "        [0.4422],\n",
      "        [0.3471],\n",
      "        [0.3456]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5952]],\n",
      "\n",
      "        [[-0.0229]],\n",
      "\n",
      "        [[-0.0911]],\n",
      "\n",
      "        [[ 0.1550]]], dtype=torch.float64)\n",
      "tensor([[0.4140],\n",
      "        [0.2235],\n",
      "        [0.1996],\n",
      "        [0.3495]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5236]],\n",
      "\n",
      "        [[ 0.3295]],\n",
      "\n",
      "        [[ 0.2290]],\n",
      "\n",
      "        [[-0.0171]]], dtype=torch.float64)\n",
      "tensor([[0.2962],\n",
      "        [0.3481],\n",
      "        [0.4286],\n",
      "        [0.5156]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1997]],\n",
      "\n",
      "        [[ 0.3988]],\n",
      "\n",
      "        [[ 0.8125]],\n",
      "\n",
      "        [[ 1.0389]]], dtype=torch.float64)\n",
      "tensor([[0.5079],\n",
      "        [0.5657],\n",
      "        [0.6965],\n",
      "        [0.6826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6923]],\n",
      "\n",
      "        [[0.2983]],\n",
      "\n",
      "        [[0.1654]],\n",
      "\n",
      "        [[0.5756]]], dtype=torch.float64)\n",
      "tensor([[0.7329],\n",
      "        [0.8381],\n",
      "        [0.9138],\n",
      "        [0.7836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0331]],\n",
      "\n",
      "        [[1.3902]],\n",
      "\n",
      "        [[0.9534]],\n",
      "\n",
      "        [[0.3572]]], dtype=torch.float64)\n",
      "tensor([[0.6677],\n",
      "        [0.5985],\n",
      "        [1.0038],\n",
      "        [1.0178]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0506]],\n",
      "\n",
      "        [[ 0.5248]],\n",
      "\n",
      "        [[ 1.4699]],\n",
      "\n",
      "        [[ 1.5508]]], dtype=torch.float64)\n",
      "tensor([[0.9896],\n",
      "        [0.8867],\n",
      "        [0.6605],\n",
      "        [0.6689]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2145]],\n",
      "\n",
      "        [[0.3942]],\n",
      "\n",
      "        [[0.0742]],\n",
      "\n",
      "        [[0.8541]]], dtype=torch.float64)\n",
      "tensor([[1.2594],\n",
      "        [0.9637],\n",
      "        [0.5126],\n",
      "        [0.5742]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6825]],\n",
      "\n",
      "        [[1.0770]],\n",
      "\n",
      "        [[0.5617]],\n",
      "\n",
      "        [[0.0326]]], dtype=torch.float64)\n",
      "tensor([[ 0.1810],\n",
      "        [-0.1837],\n",
      "        [-0.3797],\n",
      "        [-0.4816]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3094]],\n",
      "\n",
      "        [[-0.4030]],\n",
      "\n",
      "        [[-0.3903]],\n",
      "\n",
      "        [[-0.4666]]], dtype=torch.float64)\n",
      "tensor([[-0.5683],\n",
      "        [-0.5200],\n",
      "        [-0.4570],\n",
      "        [-0.4737]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4585]],\n",
      "\n",
      "        [[-0.5544]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-0.4920]]], dtype=torch.float64)\n",
      "tensor([[-0.1018],\n",
      "        [-0.0377],\n",
      "        [ 0.0406],\n",
      "        [ 0.1487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1777]],\n",
      "\n",
      "        [[ 0.0025]],\n",
      "\n",
      "        [[-0.0610]],\n",
      "\n",
      "        [[-0.1581]]], dtype=torch.float64)\n",
      "tensor([[0.2371],\n",
      "        [0.3275],\n",
      "        [0.2676],\n",
      "        [0.2375]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.17504:  79%|███████▊  | 2414/3067 [00:07<00:02, 325.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2078]],\n",
      "\n",
      "        [[ 0.0349]],\n",
      "\n",
      "        [[ 0.1989]],\n",
      "\n",
      "        [[ 0.5768]]], dtype=torch.float64)\n",
      "tensor([[0.3152],\n",
      "        [0.2975],\n",
      "        [0.1072],\n",
      "        [0.0729]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2521]],\n",
      "\n",
      "        [[-0.1338]],\n",
      "\n",
      "        [[-0.4284]],\n",
      "\n",
      "        [[-0.1038]]], dtype=torch.float64)\n",
      "tensor([[ 0.1590],\n",
      "        [-0.0653],\n",
      "        [-0.0368],\n",
      "        [ 0.0290]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0649]],\n",
      "\n",
      "        [[ 0.0892]],\n",
      "\n",
      "        [[-0.1442]],\n",
      "\n",
      "        [[-0.2101]]], dtype=torch.float64)\n",
      "tensor([[0.2960],\n",
      "        [0.2306],\n",
      "        [0.3095],\n",
      "        [0.1952]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2263]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[ 0.1828]],\n",
      "\n",
      "        [[ 0.3549]]], dtype=torch.float64)\n",
      "tensor([[0.1941],\n",
      "        [0.3422],\n",
      "        [0.5357],\n",
      "        [0.4924]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2532]],\n",
      "\n",
      "        [[0.1573]],\n",
      "\n",
      "        [[0.0487]],\n",
      "\n",
      "        [[0.0649]]], dtype=torch.float64)\n",
      "tensor([[0.3242],\n",
      "        [0.1676],\n",
      "        [0.0617],\n",
      "        [0.3851]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2752]],\n",
      "\n",
      "        [[0.1631]],\n",
      "\n",
      "        [[0.1469]],\n",
      "\n",
      "        [[0.1724]]], dtype=torch.float64)\n",
      "tensor([[0.4782],\n",
      "        [0.2479],\n",
      "        [0.3020],\n",
      "        [0.3596]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0996]],\n",
      "\n",
      "        [[0.0406]],\n",
      "\n",
      "        [[0.4462]],\n",
      "\n",
      "        [[0.6484]]], dtype=torch.float64)\n",
      "tensor([[0.3499],\n",
      "        [0.3342],\n",
      "        [0.1821],\n",
      "        [0.3302]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4289]],\n",
      "\n",
      "        [[-0.1200]],\n",
      "\n",
      "        [[-0.1604]],\n",
      "\n",
      "        [[ 0.0534]]], dtype=torch.float64)\n",
      "tensor([[0.3610],\n",
      "        [0.3359],\n",
      "        [0.3746],\n",
      "        [0.4915]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4924]],\n",
      "\n",
      "        [[0.6068]],\n",
      "\n",
      "        [[0.4242]],\n",
      "\n",
      "        [[0.1885]]], dtype=torch.float64)\n",
      "tensor([[0.4814],\n",
      "        [0.2431],\n",
      "        [0.7300],\n",
      "        [0.8051]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0726]],\n",
      "\n",
      "        [[ 0.2660]],\n",
      "\n",
      "        [[ 1.0666]],\n",
      "\n",
      "        [[ 1.3116]]], dtype=torch.float64)\n",
      "tensor([[0.7464],\n",
      "        [0.5844],\n",
      "        [0.4555],\n",
      "        [0.4495]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9130]],\n",
      "\n",
      "        [[ 0.1527]],\n",
      "\n",
      "        [[-0.2031]],\n",
      "\n",
      "        [[ 0.5733]]], dtype=torch.float64)\n",
      "tensor([[0.8906],\n",
      "        [0.8343],\n",
      "        [0.7566],\n",
      "        [0.7807]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2434]],\n",
      "\n",
      "        [[1.2608]],\n",
      "\n",
      "        [[0.9199]],\n",
      "\n",
      "        [[0.6195]]], dtype=torch.float64)\n",
      "tensor([[0.8365],\n",
      "        [0.7931],\n",
      "        [0.5262],\n",
      "        [0.5742]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5155]],\n",
      "\n",
      "        [[0.4577]],\n",
      "\n",
      "        [[0.6680]],\n",
      "\n",
      "        [[0.7466]]], dtype=torch.float64)\n",
      "tensor([[0.5460],\n",
      "        [0.6619],\n",
      "        [0.7746],\n",
      "        [0.6834]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7374]],\n",
      "\n",
      "        [[0.4993]],\n",
      "\n",
      "        [[0.3930]],\n",
      "\n",
      "        [[0.5640]]], dtype=torch.float64)\n",
      "tensor([[1.0630],\n",
      "        [0.9806],\n",
      "        [0.8701],\n",
      "        [0.7464]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3682]],\n",
      "\n",
      "        [[1.5519]],\n",
      "\n",
      "        [[1.1602]],\n",
      "\n",
      "        [[0.5837]]], dtype=torch.float64)\n",
      "tensor([[0.7264],\n",
      "        [0.7694],\n",
      "        [0.9109],\n",
      "        [0.8801]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4185]],\n",
      "\n",
      "        [[0.6114]],\n",
      "\n",
      "        [[1.2584]],\n",
      "\n",
      "        [[1.4133]]], dtype=torch.float64)\n",
      "tensor([[0.5214],\n",
      "        [0.6357],\n",
      "        [0.7366],\n",
      "        [0.7488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6761]],\n",
      "\n",
      "        [[0.5282]],\n",
      "\n",
      "        [[0.4185]],\n",
      "\n",
      "        [[0.6195]]], dtype=torch.float64)\n",
      "tensor([[0.5402],\n",
      "        [0.5088],\n",
      "        [0.4589],\n",
      "        [0.5275]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8309]],\n",
      "\n",
      "        [[0.9869]],\n",
      "\n",
      "        [[0.6750]],\n",
      "\n",
      "        [[0.4508]]], dtype=torch.float64)\n",
      "tensor([[0.6458],\n",
      "        [0.6159],\n",
      "        [0.4539],\n",
      "        [0.4080]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2798]],\n",
      "\n",
      "        [[0.3688]],\n",
      "\n",
      "        [[0.4809]],\n",
      "\n",
      "        [[0.3688]]], dtype=torch.float64)\n",
      "tensor([[0.2303],\n",
      "        [0.3230],\n",
      "        [0.2102],\n",
      "        [0.3619]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2059]],\n",
      "\n",
      "        [[ 0.0083]],\n",
      "\n",
      "        [[-0.2101]],\n",
      "\n",
      "        [[ 0.2787]]], dtype=torch.float64)\n",
      "tensor([[ 0.3491],\n",
      "        [ 0.0198],\n",
      "        [ 0.1057],\n",
      "        [-0.0832]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0349]],\n",
      "\n",
      "        [[ 0.2186]],\n",
      "\n",
      "        [[-0.0483]],\n",
      "\n",
      "        [[-0.3880]]], dtype=torch.float64)\n",
      "tensor([[-0.2759],\n",
      "        [ 0.0624],\n",
      "        [ 0.2813],\n",
      "        [ 0.1774]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7219]],\n",
      "\n",
      "        [[ 0.0499]],\n",
      "\n",
      "        [[ 0.1573]],\n",
      "\n",
      "        [[ 0.3480]]], dtype=torch.float64)\n",
      "tensor([[0.3066],\n",
      "        [0.3707],\n",
      "        [0.4458],\n",
      "        [0.5374]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2798]],\n",
      "\n",
      "        [[0.2140]],\n",
      "\n",
      "        [[0.0788]],\n",
      "\n",
      "        [[0.4716]]], dtype=torch.float64)\n",
      "tensor([[0.5548],\n",
      "        [0.4960],\n",
      "        [0.4882],\n",
      "        [0.3894]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8229]],\n",
      "\n",
      "        [[0.8818]],\n",
      "\n",
      "        [[0.5698]],\n",
      "\n",
      "        [[0.1446]]], dtype=torch.float64)\n",
      "tensor([[0.3140],\n",
      "        [0.5153],\n",
      "        [1.0707],\n",
      "        [1.1380]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0453]],\n",
      "\n",
      "        [[0.9326]],\n",
      "\n",
      "        [[1.7714]],\n",
      "\n",
      "        [[1.8142]]], dtype=torch.float64)\n",
      "tensor([[0.8770],\n",
      "        [0.6541],\n",
      "        [0.6467],\n",
      "        [0.5918]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0724]],\n",
      "\n",
      "        [[0.4289]],\n",
      "\n",
      "        [[0.3595]],\n",
      "\n",
      "        [[0.7501]]], dtype=torch.float64)\n",
      "tensor([[0.8861],\n",
      "        [1.0219],\n",
      "        [0.9001],\n",
      "        [0.8023]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2943]],\n",
      "\n",
      "        [[1.5947]],\n",
      "\n",
      "        [[1.2145]],\n",
      "\n",
      "        [[0.6923]]], dtype=torch.float64)\n",
      "tensor([[0.6269],\n",
      "        [0.6944],\n",
      "        [0.9844],\n",
      "        [0.9946]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1608]],\n",
      "\n",
      "        [[1.1140]],\n",
      "\n",
      "        [[1.4294]],\n",
      "\n",
      "        [[1.5381]]], dtype=torch.float64)\n",
      "tensor([[0.9973],\n",
      "        [0.6135],\n",
      "        [0.5947],\n",
      "        [0.5007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7755]],\n",
      "\n",
      "        [[0.5421]],\n",
      "\n",
      "        [[0.3272]],\n",
      "\n",
      "        [[0.2082]]], dtype=torch.float64)\n",
      "tensor([[0.3130],\n",
      "        [0.4395],\n",
      "        [0.5405],\n",
      "        [0.4362]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3769]],\n",
      "\n",
      "        [[0.8252]],\n",
      "\n",
      "        [[0.5421]],\n",
      "\n",
      "        [[0.1458]]], dtype=torch.float64)\n",
      "tensor([[0.4259],\n",
      "        [0.2577],\n",
      "        [0.4227],\n",
      "        [0.8139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0853]],\n",
      "\n",
      "        [[ 0.1458]],\n",
      "\n",
      "        [[ 0.8286]],\n",
      "\n",
      "        [[ 1.3509]]], dtype=torch.float64)\n",
      "tensor([[0.8866],\n",
      "        [0.5479],\n",
      "        [0.5297],\n",
      "        [0.5190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7524]],\n",
      "\n",
      "        [[0.1805]],\n",
      "\n",
      "        [[0.0950]],\n",
      "\n",
      "        [[0.3295]]], dtype=torch.float64)\n",
      "tensor([[0.4408],\n",
      "        [0.3521],\n",
      "        [0.4309],\n",
      "        [0.4109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5571]],\n",
      "\n",
      "        [[0.8471]],\n",
      "\n",
      "        [[0.4716]],\n",
      "\n",
      "        [[0.1412]]], dtype=torch.float64)\n",
      "tensor([[0.4658],\n",
      "        [0.5559],\n",
      "        [0.4540],\n",
      "        [0.3654]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0795]],\n",
      "\n",
      "        [[ 0.2752]],\n",
      "\n",
      "        [[ 0.5918]],\n",
      "\n",
      "        [[ 0.7489]]], dtype=torch.float64)\n",
      "tensor([[0.3932],\n",
      "        [0.4467],\n",
      "        [0.4924],\n",
      "        [0.4427]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4381]],\n",
      "\n",
      "        [[0.1654]],\n",
      "\n",
      "        [[0.1215]],\n",
      "\n",
      "        [[0.0118]]], dtype=torch.float64)\n",
      "tensor([[-0.0354],\n",
      "        [-0.1475],\n",
      "        [-0.0781],\n",
      "        [-0.1540]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[-0.0795]],\n",
      "\n",
      "        [[-0.1442]],\n",
      "\n",
      "        [[-0.2170]]], dtype=torch.float64)\n",
      "tensor([[-0.2785],\n",
      "        [ 0.1974],\n",
      "        [ 0.2312],\n",
      "        [ 0.1489]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5706]],\n",
      "\n",
      "        [[-0.0657]],\n",
      "\n",
      "        [[ 0.1828]],\n",
      "\n",
      "        [[ 0.3179]]], dtype=torch.float64)\n",
      "tensor([[ 0.1168],\n",
      "        [-0.2696],\n",
      "        [-0.3616],\n",
      "        [-0.3198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0726]],\n",
      "\n",
      "        [[-0.5197]],\n",
      "\n",
      "        [[-0.5174]],\n",
      "\n",
      "        [[-0.3672]]], dtype=torch.float64)\n",
      "tensor([[-0.0555],\n",
      "        [-0.1770],\n",
      "        [-0.0577],\n",
      "        [-0.0767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1269]],\n",
      "\n",
      "        [[ 0.0025]],\n",
      "\n",
      "        [[-0.0911]],\n",
      "\n",
      "        [[-0.2748]]], dtype=torch.float64)\n",
      "tensor([[-0.1353],\n",
      "        [ 0.1128],\n",
      "        [ 0.1276],\n",
      "        [ 0.0775]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.0310]],\n",
      "\n",
      "        [[ 0.3977]],\n",
      "\n",
      "        [[ 0.3387]]], dtype=torch.float64)\n",
      "tensor([[ 0.0917],\n",
      "        [-0.2891],\n",
      "        [-0.2309],\n",
      "        [-0.1496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1673]],\n",
      "\n",
      "        [[-0.4204]],\n",
      "\n",
      "        [[-0.4215]],\n",
      "\n",
      "        [[-0.2990]]], dtype=torch.float64)\n",
      "tensor([[-0.1078],\n",
      "        [-0.0971],\n",
      "        [-0.0314],\n",
      "        [ 0.0676]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0807]],\n",
      "\n",
      "        [[ 0.0603]],\n",
      "\n",
      "        [[ 0.0025]],\n",
      "\n",
      "        [[-0.0287]]], dtype=torch.float64)\n",
      "tensor([[ 0.0713],\n",
      "        [-0.0003],\n",
      "        [-0.0203],\n",
      "        [ 0.0219]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1384]],\n",
      "\n",
      "        [[-0.0980]],\n",
      "\n",
      "        [[ 0.0984]],\n",
      "\n",
      "        [[ 0.2405]]], dtype=torch.float64)\n",
      "tensor([[0.1040],\n",
      "        [0.1801],\n",
      "        [0.2417],\n",
      "        [0.3977]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0788]],\n",
      "\n",
      "        [[-0.1211]],\n",
      "\n",
      "        [[-0.1176]],\n",
      "\n",
      "        [[ 0.3930]]], dtype=torch.float64)\n",
      "tensor([[0.5634],\n",
      "        [0.5863],\n",
      "        [0.6429],\n",
      "        [0.4410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8182]],\n",
      "\n",
      "        [[1.1787]],\n",
      "\n",
      "        [[0.6727]],\n",
      "\n",
      "        [[0.0799]]], dtype=torch.float64)\n",
      "tensor([[0.2961],\n",
      "        [0.3987],\n",
      "        [0.3955],\n",
      "        [0.3474]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0807]],\n",
      "\n",
      "        [[ 0.1885]],\n",
      "\n",
      "        [[ 0.6241]],\n",
      "\n",
      "        [[ 0.6750]]], dtype=torch.float64)\n",
      "tensor([[0.2647],\n",
      "        [0.2515],\n",
      "        [0.2137],\n",
      "        [0.3311]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3052]],\n",
      "\n",
      "        [[ 0.1042]],\n",
      "\n",
      "        [[-0.1535]],\n",
      "\n",
      "        [[ 0.0279]]], dtype=torch.float64)\n",
      "tensor([[0.1311],\n",
      "        [0.0567],\n",
      "        [0.0232],\n",
      "        [0.2343]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2636]],\n",
      "\n",
      "        [[0.1100]],\n",
      "\n",
      "        [[0.2024]],\n",
      "\n",
      "        [[0.4058]]], dtype=torch.float64)\n",
      "tensor([[0.7121],\n",
      "        [0.6614],\n",
      "        [0.4293],\n",
      "        [0.2608]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3642]],\n",
      "\n",
      "        [[0.4427]],\n",
      "\n",
      "        [[0.5063]],\n",
      "\n",
      "        [[0.5964]]], dtype=torch.float64)\n",
      "tensor([[0.3539],\n",
      "        [0.5291],\n",
      "        [0.6461],\n",
      "        [0.5793]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4809]],\n",
      "\n",
      "        [[0.4589]],\n",
      "\n",
      "        [[0.1735]],\n",
      "\n",
      "        [[0.5571]]], dtype=torch.float64)\n",
      "tensor([[0.4067],\n",
      "        [0.2774],\n",
      "        [0.1787],\n",
      "        [0.2486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4497]],\n",
      "\n",
      "        [[0.5352]],\n",
      "\n",
      "        [[0.3341]],\n",
      "\n",
      "        [[0.2070]]], dtype=torch.float64)\n",
      "tensor([[0.2427],\n",
      "        [0.2523],\n",
      "        [0.2139],\n",
      "        [0.0120]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0194]],\n",
      "\n",
      "        [[-0.0911]],\n",
      "\n",
      "        [[ 0.0233]],\n",
      "\n",
      "        [[ 0.1955]]], dtype=torch.float64)\n",
      "tensor([[0.1206],\n",
      "        [0.1488],\n",
      "        [0.1254],\n",
      "        [0.2538]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0152]],\n",
      "\n",
      "        [[-0.2216]],\n",
      "\n",
      "        [[-0.2621]],\n",
      "\n",
      "        [[-0.0229]]], dtype=torch.float64)\n",
      "tensor([[0.2312],\n",
      "        [0.2685],\n",
      "        [0.3694],\n",
      "        [0.4822]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4913]],\n",
      "\n",
      "        [[0.5490]],\n",
      "\n",
      "        [[0.5872]],\n",
      "\n",
      "        [[0.2278]]], dtype=torch.float64)\n",
      "tensor([[0.5128],\n",
      "        [0.4067],\n",
      "        [0.4455],\n",
      "        [0.5518]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1662]],\n",
      "\n",
      "        [[ 0.3099]],\n",
      "\n",
      "        [[ 0.7108]],\n",
      "\n",
      "        [[ 0.8598]]], dtype=torch.float64)\n",
      "tensor([[0.5567],\n",
      "        [0.5893],\n",
      "        [0.6608],\n",
      "        [0.6097]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7154]],\n",
      "\n",
      "        [[0.5259]],\n",
      "\n",
      "        [[0.1493]],\n",
      "\n",
      "        [[0.6045]]], dtype=torch.float64)\n",
      "tensor([[0.5498],\n",
      "        [0.5327],\n",
      "        [0.5987],\n",
      "        [0.4493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9072]],\n",
      "\n",
      "        [[1.1406]],\n",
      "\n",
      "        [[0.8691]],\n",
      "\n",
      "        [[0.0846]]], dtype=torch.float64)\n",
      "tensor([[0.2780],\n",
      "        [0.5931],\n",
      "        [0.8672],\n",
      "        [0.7743]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2806]],\n",
      "\n",
      "        [[ 0.7258]],\n",
      "\n",
      "        [[ 1.1799]],\n",
      "\n",
      "        [[ 1.3405]]], dtype=torch.float64)\n",
      "tensor([[0.8290],\n",
      "        [0.7464],\n",
      "        [0.6445],\n",
      "        [0.7339]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1117]],\n",
      "\n",
      "        [[0.4993]],\n",
      "\n",
      "        [[0.2024]],\n",
      "\n",
      "        [[1.0921]]], dtype=torch.float64)\n",
      "tensor([[1.0613],\n",
      "        [0.9130],\n",
      "        [0.9865],\n",
      "        [0.9466]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4502]],\n",
      "\n",
      "        [[1.5253]],\n",
      "\n",
      "        [[1.2781]],\n",
      "\n",
      "        [[0.7131]]], dtype=torch.float64)\n",
      "tensor([[0.8753],\n",
      "        [0.9069],\n",
      "        [1.1002],\n",
      "        [0.9891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6461]],\n",
      "\n",
      "        [[0.9846]],\n",
      "\n",
      "        [[1.5589]],\n",
      "\n",
      "        [[1.5011]]], dtype=torch.float64)\n",
      "tensor([[0.9247],\n",
      "        [0.8453],\n",
      "        [0.8432],\n",
      "        [0.7937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0632]],\n",
      "\n",
      "        [[0.7847]],\n",
      "\n",
      "        [[0.5941]],\n",
      "\n",
      "        [[0.8645]]], dtype=torch.float64)\n",
      "tensor([[0.9405],\n",
      "        [0.3805],\n",
      "        [0.3798],\n",
      "        [0.5495]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9430]],\n",
      "\n",
      "        [[0.5976]],\n",
      "\n",
      "        [[0.5132]],\n",
      "\n",
      "        [[0.5305]]], dtype=torch.float64)\n",
      "tensor([[0.7917],\n",
      "        [0.6383],\n",
      "        [0.3973],\n",
      "        [0.3925]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5560]],\n",
      "\n",
      "        [[0.4346]],\n",
      "\n",
      "        [[0.4277]],\n",
      "\n",
      "        [[0.8575]]], dtype=torch.float64)\n",
      "tensor([[0.5962],\n",
      "        [0.4942],\n",
      "        [0.4677],\n",
      "        [0.4922]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6103]],\n",
      "\n",
      "        [[0.1943]],\n",
      "\n",
      "        [[0.0198]],\n",
      "\n",
      "        [[0.7732]]], dtype=torch.float64)\n",
      "tensor([[0.9028],\n",
      "        [0.8066],\n",
      "        [0.8083],\n",
      "        [0.6644]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1972]],\n",
      "\n",
      "        [[1.2134]],\n",
      "\n",
      "        [[1.0343]],\n",
      "\n",
      "        [[0.4566]]], dtype=torch.float64)\n",
      "tensor([[0.7583],\n",
      "        [0.8977],\n",
      "        [1.1275],\n",
      "        [1.0034]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4069]],\n",
      "\n",
      "        [[1.1348]],\n",
      "\n",
      "        [[1.5947]],\n",
      "\n",
      "        [[1.5993]]], dtype=torch.float64)\n",
      "tensor([[1.1068],\n",
      "        [0.9685],\n",
      "        [0.9059],\n",
      "        [1.0111]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.17413:  81%|████████  | 2482/3067 [00:07<00:01, 331.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.2446]],\n",
      "\n",
      "        [[0.7905]],\n",
      "\n",
      "        [[0.5548]],\n",
      "\n",
      "        [[1.3555]]], dtype=torch.float64)\n",
      "tensor([[1.3461],\n",
      "        [1.3856],\n",
      "        [1.3920],\n",
      "        [0.9790]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7530]],\n",
      "\n",
      "        [[2.0291]],\n",
      "\n",
      "        [[1.6259]],\n",
      "\n",
      "        [[0.4866]]], dtype=torch.float64)\n",
      "tensor([[0.6842],\n",
      "        [0.6698],\n",
      "        [0.6764],\n",
      "        [0.6975]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2174]],\n",
      "\n",
      "        [[0.6831]],\n",
      "\n",
      "        [[0.9072]],\n",
      "\n",
      "        [[1.0482]]], dtype=torch.float64)\n",
      "tensor([[0.6490],\n",
      "        [0.6733],\n",
      "        [0.5235],\n",
      "        [0.5311]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7616]],\n",
      "\n",
      "        [[ 0.2244]],\n",
      "\n",
      "        [[-0.0472]],\n",
      "\n",
      "        [[ 0.8552]]], dtype=torch.float64)\n",
      "tensor([[1.1449],\n",
      "        [1.0506],\n",
      "        [0.9654],\n",
      "        [0.8723]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3809]],\n",
      "\n",
      "        [[1.5311]],\n",
      "\n",
      "        [[1.1267]],\n",
      "\n",
      "        [[0.6796]]], dtype=torch.float64)\n",
      "tensor([[0.7753],\n",
      "        [0.8867],\n",
      "        [0.9248],\n",
      "        [0.9176]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3538]],\n",
      "\n",
      "        [[0.9003]],\n",
      "\n",
      "        [[1.1972]],\n",
      "\n",
      "        [[1.4156]]], dtype=torch.float64)\n",
      "tensor([[0.9983],\n",
      "        [0.9108],\n",
      "        [0.8530],\n",
      "        [0.9171]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0909]],\n",
      "\n",
      "        [[0.6391]],\n",
      "\n",
      "        [[0.3064]],\n",
      "\n",
      "        [[1.1198]]], dtype=torch.float64)\n",
      "tensor([[1.3233],\n",
      "        [1.4856],\n",
      "        [1.4927],\n",
      "        [1.3866]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7148]],\n",
      "\n",
      "        [[1.8003]],\n",
      "\n",
      "        [[1.6051]],\n",
      "\n",
      "        [[1.1129]]], dtype=torch.float64)\n",
      "tensor([[1.2492],\n",
      "        [1.4335],\n",
      "        [1.8861],\n",
      "        [2.0534]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8333]],\n",
      "\n",
      "        [[1.5750]],\n",
      "\n",
      "        [[2.0996]],\n",
      "\n",
      "        [[2.3099]]], dtype=torch.float64)\n",
      "tensor([[2.1087],\n",
      "        [1.9000],\n",
      "        [1.6747],\n",
      "        [1.7183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9644]],\n",
      "\n",
      "        [[1.4225]],\n",
      "\n",
      "        [[1.1556]],\n",
      "\n",
      "        [[1.9320]]], dtype=torch.float64)\n",
      "tensor([[2.3399],\n",
      "        [2.4931],\n",
      "        [2.4514],\n",
      "        [2.3189]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.6519]],\n",
      "\n",
      "        [[2.9003]],\n",
      "\n",
      "        [[2.4185]],\n",
      "\n",
      "        [[1.9817]]], dtype=torch.float64)\n",
      "tensor([[2.0778],\n",
      "        [1.8806],\n",
      "        [2.0706],\n",
      "        [2.2409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4549]],\n",
      "\n",
      "        [[1.7310]],\n",
      "\n",
      "        [[2.3503]],\n",
      "\n",
      "        [[2.0245]]], dtype=torch.float64)\n",
      "tensor([[1.1847],\n",
      "        [1.3062],\n",
      "        [1.2821],\n",
      "        [1.1128]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1706]],\n",
      "\n",
      "        [[1.0747]],\n",
      "\n",
      "        [[0.9049]],\n",
      "\n",
      "        [[1.0574]]], dtype=torch.float64)\n",
      "tensor([[1.1772],\n",
      "        [1.1669],\n",
      "        [1.2080],\n",
      "        [1.0135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4029]],\n",
      "\n",
      "        [[1.5831]],\n",
      "\n",
      "        [[1.2018]],\n",
      "\n",
      "        [[0.8044]]], dtype=torch.float64)\n",
      "tensor([[0.9518],\n",
      "        [1.1286],\n",
      "        [1.2257],\n",
      "        [1.1609]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4959]],\n",
      "\n",
      "        [[1.1591]],\n",
      "\n",
      "        [[1.4514]],\n",
      "\n",
      "        [[1.5554]]], dtype=torch.float64)\n",
      "tensor([[1.1649],\n",
      "        [1.0617],\n",
      "        [1.0404],\n",
      "        [1.1524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2238]],\n",
      "\n",
      "        [[0.7697]],\n",
      "\n",
      "        [[0.7039]],\n",
      "\n",
      "        [[1.0297]]], dtype=torch.float64)\n",
      "tensor([[1.0670],\n",
      "        [0.9816],\n",
      "        [0.8961],\n",
      "        [0.8365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1787]],\n",
      "\n",
      "        [[1.4133]],\n",
      "\n",
      "        [[0.9118]],\n",
      "\n",
      "        [[0.6565]]], dtype=torch.float64)\n",
      "tensor([[0.8020],\n",
      "        [0.8980],\n",
      "        [0.8034],\n",
      "        [0.7761]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3572]],\n",
      "\n",
      "        [[0.7870]],\n",
      "\n",
      "        [[1.0863]],\n",
      "\n",
      "        [[0.8309]]], dtype=torch.float64)\n",
      "tensor([[0.5702],\n",
      "        [0.7077],\n",
      "        [0.6824],\n",
      "        [0.6640]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6103]],\n",
      "\n",
      "        [[0.5352]],\n",
      "\n",
      "        [[0.3411]],\n",
      "\n",
      "        [[0.3769]]], dtype=torch.float64)\n",
      "tensor([[0.5894],\n",
      "        [0.4243],\n",
      "        [0.2441],\n",
      "        [0.3040]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4427]],\n",
      "\n",
      "        [[0.3491]],\n",
      "\n",
      "        [[0.2232]],\n",
      "\n",
      "        [[0.1493]]], dtype=torch.float64)\n",
      "tensor([[0.4602],\n",
      "        [0.3534],\n",
      "        [0.2815],\n",
      "        [0.3309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0487]],\n",
      "\n",
      "        [[0.2059]],\n",
      "\n",
      "        [[0.4254]],\n",
      "\n",
      "        [[0.5398]]], dtype=torch.float64)\n",
      "tensor([[0.3436],\n",
      "        [0.3999],\n",
      "        [0.6174],\n",
      "        [0.6499]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2971]],\n",
      "\n",
      "        [[0.2093]],\n",
      "\n",
      "        [[0.0568]],\n",
      "\n",
      "        [[0.4011]]], dtype=torch.float64)\n",
      "tensor([[0.5912],\n",
      "        [0.5090],\n",
      "        [0.5303],\n",
      "        [0.4178]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7142]],\n",
      "\n",
      "        [[0.7651]],\n",
      "\n",
      "        [[0.2313]],\n",
      "\n",
      "        [[0.0718]]], dtype=torch.float64)\n",
      "tensor([[0.4596],\n",
      "        [0.5261],\n",
      "        [0.7638],\n",
      "        [0.6527]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0691]],\n",
      "\n",
      "        [[ 0.5074]],\n",
      "\n",
      "        [[ 0.8633]],\n",
      "\n",
      "        [[ 0.9245]]], dtype=torch.float64)\n",
      "tensor([[0.6089],\n",
      "        [0.6434],\n",
      "        [0.8140],\n",
      "        [0.8020]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6727]],\n",
      "\n",
      "        [[0.4913]],\n",
      "\n",
      "        [[0.4462]],\n",
      "\n",
      "        [[0.4913]]], dtype=torch.float64)\n",
      "tensor([[0.5959],\n",
      "        [0.5215],\n",
      "        [0.3854],\n",
      "        [0.3762]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6946]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[0.4162]],\n",
      "\n",
      "        [[0.2186]]], dtype=torch.float64)\n",
      "tensor([[0.4097],\n",
      "        [0.5467],\n",
      "        [0.4057],\n",
      "        [0.5099]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1304]],\n",
      "\n",
      "        [[ 0.3191]],\n",
      "\n",
      "        [[ 0.7062]],\n",
      "\n",
      "        [[ 0.8991]]], dtype=torch.float64)\n",
      "tensor([[0.6026],\n",
      "        [0.6619],\n",
      "        [0.7943],\n",
      "        [0.8874]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7293]],\n",
      "\n",
      "        [[0.6322]],\n",
      "\n",
      "        [[0.3954]],\n",
      "\n",
      "        [[1.2400]]], dtype=torch.float64)\n",
      "tensor([[1.0662],\n",
      "        [1.1194],\n",
      "        [1.0915],\n",
      "        [0.9419]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5496]],\n",
      "\n",
      "        [[1.7391]],\n",
      "\n",
      "        [[1.2896]],\n",
      "\n",
      "        [[0.8806]]], dtype=torch.float64)\n",
      "tensor([[0.8843],\n",
      "        [0.8944],\n",
      "        [1.0406],\n",
      "        [1.0977]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5779]],\n",
      "\n",
      "        [[1.2319]],\n",
      "\n",
      "        [[1.6363]],\n",
      "\n",
      "        [[1.8835]]], dtype=torch.float64)\n",
      "tensor([[1.0732],\n",
      "        [0.9166],\n",
      "        [0.8371],\n",
      "        [0.9575]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3717]],\n",
      "\n",
      "        [[0.7639]],\n",
      "\n",
      "        [[0.5756]],\n",
      "\n",
      "        [[1.4110]]], dtype=torch.float64)\n",
      "tensor([[1.2498],\n",
      "        [1.0142],\n",
      "        [0.9484],\n",
      "        [0.9007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5635]],\n",
      "\n",
      "        [[1.3497]],\n",
      "\n",
      "        [[1.1383]],\n",
      "\n",
      "        [[0.8101]]], dtype=torch.float64)\n",
      "tensor([[1.0188],\n",
      "        [1.1147],\n",
      "        [1.0390],\n",
      "        [1.0834]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8852]],\n",
      "\n",
      "        [[1.1129]],\n",
      "\n",
      "        [[1.4606]],\n",
      "\n",
      "        [[1.4734]]], dtype=torch.float64)\n",
      "tensor([[1.0359],\n",
      "        [1.0406],\n",
      "        [1.0966],\n",
      "        [1.0702]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2885]],\n",
      "\n",
      "        [[0.8980]],\n",
      "\n",
      "        [[0.7859]],\n",
      "\n",
      "        [[1.1556]]], dtype=torch.float64)\n",
      "tensor([[1.1400],\n",
      "        [1.1861],\n",
      "        [1.1131],\n",
      "        [1.0916]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4826]],\n",
      "\n",
      "        [[1.6108]],\n",
      "\n",
      "        [[1.2550]],\n",
      "\n",
      "        [[0.7697]]], dtype=torch.float64)\n",
      "tensor([[1.0728],\n",
      "        [1.1218],\n",
      "        [1.1942],\n",
      "        [1.1872]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7131]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[1.5115]],\n",
      "\n",
      "        [[1.6686]]], dtype=torch.float64)\n",
      "tensor([[1.1547],\n",
      "        [1.0575],\n",
      "        [0.9029],\n",
      "        [1.0124]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3058]],\n",
      "\n",
      "        [[0.7281]],\n",
      "\n",
      "        [[0.3734]],\n",
      "\n",
      "        [[1.0574]]], dtype=torch.float64)\n",
      "tensor([[1.2545],\n",
      "        [1.1586],\n",
      "        [1.2339],\n",
      "        [1.0804]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5508]],\n",
      "\n",
      "        [[1.7079]],\n",
      "\n",
      "        [[1.3335]],\n",
      "\n",
      "        [[0.7246]]], dtype=torch.float64)\n",
      "tensor([[0.9206],\n",
      "        [1.0984],\n",
      "        [1.3230],\n",
      "        [1.3173]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3734]],\n",
      "\n",
      "        [[1.1533]],\n",
      "\n",
      "        [[1.6085]],\n",
      "\n",
      "        [[1.7818]]], dtype=torch.float64)\n",
      "tensor([[1.3243],\n",
      "        [1.1495],\n",
      "        [0.9469],\n",
      "        [1.0946]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4907]],\n",
      "\n",
      "        [[0.7651]],\n",
      "\n",
      "        [[0.4104]],\n",
      "\n",
      "        [[1.2388]]], dtype=torch.float64)\n",
      "tensor([[1.4605],\n",
      "        [1.4197],\n",
      "        [1.4380],\n",
      "        [1.3240]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7842]],\n",
      "\n",
      "        [[1.9159]],\n",
      "\n",
      "        [[1.5600]],\n",
      "\n",
      "        [[0.8876]]], dtype=torch.float64)\n",
      "tensor([[1.1380],\n",
      "        [1.1692],\n",
      "        [1.4214],\n",
      "        [1.3420]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5848]],\n",
      "\n",
      "        [[1.3416]],\n",
      "\n",
      "        [[1.7171]],\n",
      "\n",
      "        [[1.3416]]], dtype=torch.float64)\n",
      "tensor([[0.9056],\n",
      "        [0.8943],\n",
      "        [0.8227],\n",
      "        [0.8296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9488]],\n",
      "\n",
      "        [[0.5571]],\n",
      "\n",
      "        [[0.3942]],\n",
      "\n",
      "        [[0.7986]]], dtype=torch.float64)\n",
      "tensor([[0.8701],\n",
      "        [0.7991],\n",
      "        [0.8287],\n",
      "        [0.8396]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0043]],\n",
      "\n",
      "        [[1.0158]],\n",
      "\n",
      "        [[0.8367]],\n",
      "\n",
      "        [[0.6207]]], dtype=torch.float64)\n",
      "tensor([[0.9761],\n",
      "        [1.0170],\n",
      "        [1.0791],\n",
      "        [1.0079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5097]],\n",
      "\n",
      "        [[0.9996]],\n",
      "\n",
      "        [[1.2492]],\n",
      "\n",
      "        [[1.4745]]], dtype=torch.float64)\n",
      "tensor([[1.0276],\n",
      "        [0.9235],\n",
      "        [0.7281],\n",
      "        [0.8560]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0586]],\n",
      "\n",
      "        [[0.5063]],\n",
      "\n",
      "        [[0.1042]],\n",
      "\n",
      "        [[0.9604]]], dtype=torch.float64)\n",
      "tensor([[1.1777],\n",
      "        [1.1552],\n",
      "        [1.1980],\n",
      "        [1.0708]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4029]],\n",
      "\n",
      "        [[1.5947]],\n",
      "\n",
      "        [[1.1637]],\n",
      "\n",
      "        [[0.7686]]], dtype=torch.float64)\n",
      "tensor([[0.9337],\n",
      "        [0.9501],\n",
      "        [1.1905],\n",
      "        [1.2606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3873]],\n",
      "\n",
      "        [[1.0851]],\n",
      "\n",
      "        [[1.6039]],\n",
      "\n",
      "        [[1.7044]]], dtype=torch.float64)\n",
      "tensor([[1.0251],\n",
      "        [0.9250],\n",
      "        [0.9698],\n",
      "        [0.9015]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0123]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[0.4208]],\n",
      "\n",
      "        [[0.6380]]], dtype=torch.float64)\n",
      "tensor([[1.0659],\n",
      "        [1.0898],\n",
      "        [1.2892],\n",
      "        [1.0913]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2931]],\n",
      "\n",
      "        [[1.6062]],\n",
      "\n",
      "        [[1.2573]],\n",
      "\n",
      "        [[0.6472]]], dtype=torch.float64)\n",
      "tensor([[0.8628],\n",
      "        [0.9568],\n",
      "        [1.4809],\n",
      "        [1.4364]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2579]],\n",
      "\n",
      "        [[1.1833]],\n",
      "\n",
      "        [[1.7610]],\n",
      "\n",
      "        [[1.8789]]], dtype=torch.float64)\n",
      "tensor([[1.3640],\n",
      "        [1.1763],\n",
      "        [1.0067],\n",
      "        [1.0904]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5461]],\n",
      "\n",
      "        [[0.8078]],\n",
      "\n",
      "        [[0.4081]],\n",
      "\n",
      "        [[1.1302]]], dtype=torch.float64)\n",
      "tensor([[1.4912],\n",
      "        [1.4268],\n",
      "        [1.4170],\n",
      "        [1.2979]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7634]],\n",
      "\n",
      "        [[1.8731]],\n",
      "\n",
      "        [[1.6420]],\n",
      "\n",
      "        [[0.9557]]], dtype=torch.float64)\n",
      "tensor([[1.2950],\n",
      "        [1.3037],\n",
      "        [1.5657],\n",
      "        [1.5271]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6738]],\n",
      "\n",
      "        [[1.2365]],\n",
      "\n",
      "        [[1.7842]],\n",
      "\n",
      "        [[1.9771]]], dtype=torch.float64)\n",
      "tensor([[1.4528],\n",
      "        [1.3693],\n",
      "        [1.2271],\n",
      "        [1.3346]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5103]],\n",
      "\n",
      "        [[0.9430]],\n",
      "\n",
      "        [[0.7524]],\n",
      "\n",
      "        [[1.3416]]], dtype=torch.float64)\n",
      "tensor([[1.4482],\n",
      "        [1.5440],\n",
      "        [1.5198],\n",
      "        [1.3195]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8130]],\n",
      "\n",
      "        [[2.0545]],\n",
      "\n",
      "        [[1.5126]],\n",
      "\n",
      "        [[1.0170]]], dtype=torch.float64)\n",
      "tensor([[1.2089],\n",
      "        [1.0788],\n",
      "        [1.0093],\n",
      "        [1.2610]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6657]],\n",
      "\n",
      "        [[0.8275]],\n",
      "\n",
      "        [[1.3093]],\n",
      "\n",
      "        [[1.6455]]], dtype=torch.float64)\n",
      "tensor([[1.3545],\n",
      "        [1.1750],\n",
      "        [1.0025],\n",
      "        [1.1229]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4976]],\n",
      "\n",
      "        [[0.8113]],\n",
      "\n",
      "        [[0.4266]],\n",
      "\n",
      "        [[1.3289]]], dtype=torch.float64)\n",
      "tensor([[1.6033],\n",
      "        [1.5904],\n",
      "        [1.5676],\n",
      "        [1.3368]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0291]],\n",
      "\n",
      "        [[2.1712]],\n",
      "\n",
      "        [[1.7553]],\n",
      "\n",
      "        [[1.0054]]], dtype=torch.float64)\n",
      "tensor([[1.1253],\n",
      "        [1.1755],\n",
      "        [1.7150],\n",
      "        [1.8644]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5721]],\n",
      "\n",
      "        [[1.4375]],\n",
      "\n",
      "        [[2.2683]],\n",
      "\n",
      "        [[2.4739]]], dtype=torch.float64)\n",
      "tensor([[1.6998],\n",
      "        [1.3405],\n",
      "        [1.1094],\n",
      "        [1.1157]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0164]],\n",
      "\n",
      "        [[1.0747]],\n",
      "\n",
      "        [[0.5802]],\n",
      "\n",
      "        [[1.5184]]], dtype=torch.float64)\n",
      "tensor([[1.7755],\n",
      "        [1.7746],\n",
      "        [1.6863],\n",
      "        [1.4586]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3780]],\n",
      "\n",
      "        [[2.4913]],\n",
      "\n",
      "        [[1.9852]],\n",
      "\n",
      "        [[1.1683]]], dtype=torch.float64)\n",
      "tensor([[1.2839],\n",
      "        [1.2871],\n",
      "        [1.8670],\n",
      "        [1.8201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7582]],\n",
      "\n",
      "        [[1.5045]],\n",
      "\n",
      "        [[2.2983]],\n",
      "\n",
      "        [[1.5369]]], dtype=torch.float64)\n",
      "tensor([[0.9712],\n",
      "        [1.1564],\n",
      "        [1.3660],\n",
      "        [1.2201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0355]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[0.8506]],\n",
      "\n",
      "        [[0.9523]]], dtype=torch.float64)\n",
      "tensor([[1.4973],\n",
      "        [1.7637],\n",
      "        [1.6630],\n",
      "        [1.6200]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7657]],\n",
      "\n",
      "        [[2.1123]],\n",
      "\n",
      "        [[1.8188]],\n",
      "\n",
      "        [[1.2735]]], dtype=torch.float64)\n",
      "tensor([[1.5082],\n",
      "        [1.5283],\n",
      "        [2.0396],\n",
      "        [1.9480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9396]],\n",
      "\n",
      "        [[1.6940]],\n",
      "\n",
      "        [[2.4427]],\n",
      "\n",
      "        [[2.4185]]], dtype=torch.float64)\n",
      "tensor([[2.0149],\n",
      "        [1.5537],\n",
      "        [1.5632],\n",
      "        [1.5085]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7610]],\n",
      "\n",
      "        [[1.3532]],\n",
      "\n",
      "        [[0.9915]],\n",
      "\n",
      "        [[1.7044]]], dtype=torch.float64)\n",
      "tensor([[2.2408],\n",
      "        [2.5064],\n",
      "        [2.2839],\n",
      "        [1.8336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.7247]],\n",
      "\n",
      "        [[2.9765]],\n",
      "\n",
      "        [[1.9159]],\n",
      "\n",
      "        [[1.5230]]], dtype=torch.float64)\n",
      "tensor([[1.7190],\n",
      "        [2.0736],\n",
      "        [2.0285],\n",
      "        [2.0900]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7379]],\n",
      "\n",
      "        [[1.8165]],\n",
      "\n",
      "        [[2.2093]],\n",
      "\n",
      "        [[2.6149]]], dtype=torch.float64)\n",
      "tensor([[1.9840],\n",
      "        [1.5789],\n",
      "        [1.5999],\n",
      "        [1.5442]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.17413:  83%|████████▎ | 2550/3067 [00:08<00:01, 327.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.9598]],\n",
      "\n",
      "        [[1.2180]],\n",
      "\n",
      "        [[1.1568]],\n",
      "\n",
      "        [[1.1418]]], dtype=torch.float64)\n",
      "tensor([[1.4181],\n",
      "        [1.4424],\n",
      "        [1.0480],\n",
      "        [0.9732]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5138]],\n",
      "\n",
      "        [[1.3532]],\n",
      "\n",
      "        [[1.0447]],\n",
      "\n",
      "        [[0.8471]]], dtype=torch.float64)\n",
      "tensor([[1.1936],\n",
      "        [1.3199],\n",
      "        [1.3770],\n",
      "        [1.2783]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7709]],\n",
      "\n",
      "        [[1.1094]],\n",
      "\n",
      "        [[1.6397]],\n",
      "\n",
      "        [[1.8223]]], dtype=torch.float64)\n",
      "tensor([[1.2384],\n",
      "        [1.1838],\n",
      "        [1.4174],\n",
      "        [1.3878]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2954]],\n",
      "\n",
      "        [[1.0459]],\n",
      "\n",
      "        [[1.0874]],\n",
      "\n",
      "        [[1.2492]]], dtype=torch.float64)\n",
      "tensor([[1.3140],\n",
      "        [1.1845],\n",
      "        [1.2032],\n",
      "        [1.1561]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5727]],\n",
      "\n",
      "        [[1.5727]],\n",
      "\n",
      "        [[1.2989]],\n",
      "\n",
      "        [[0.7813]]], dtype=torch.float64)\n",
      "tensor([[1.0801],\n",
      "        [1.1405],\n",
      "        [1.6592],\n",
      "        [1.7929]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5340]],\n",
      "\n",
      "        [[1.2642]],\n",
      "\n",
      "        [[2.0903]],\n",
      "\n",
      "        [[2.4439]]], dtype=torch.float64)\n",
      "tensor([[1.8608],\n",
      "        [1.5333],\n",
      "        [1.4063],\n",
      "        [1.4061]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0037]],\n",
      "\n",
      "        [[1.1753]],\n",
      "\n",
      "        [[0.7836]],\n",
      "\n",
      "        [[1.6652]]], dtype=torch.float64)\n",
      "tensor([[2.1335],\n",
      "        [2.1691],\n",
      "        [2.0455],\n",
      "        [1.6810]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.7570]],\n",
      "\n",
      "        [[2.8887]],\n",
      "\n",
      "        [[2.3318]],\n",
      "\n",
      "        [[1.3671]]], dtype=torch.float64)\n",
      "tensor([[1.4758],\n",
      "        [1.3907],\n",
      "        [1.8879],\n",
      "        [1.8686]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9962]],\n",
      "\n",
      "        [[1.9505]],\n",
      "\n",
      "        [[2.4393]],\n",
      "\n",
      "        [[2.5675]]], dtype=torch.float64)\n",
      "tensor([[1.8298],\n",
      "        [1.7370],\n",
      "        [1.6397],\n",
      "        [1.4754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9390]],\n",
      "\n",
      "        [[1.4687]],\n",
      "\n",
      "        [[1.2261]],\n",
      "\n",
      "        [[1.2573]]], dtype=torch.float64)\n",
      "tensor([[1.6653],\n",
      "        [1.2316],\n",
      "        [1.2374],\n",
      "        [1.3242]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9840]],\n",
      "\n",
      "        [[1.4190]],\n",
      "\n",
      "        [[1.3532]],\n",
      "\n",
      "        [[1.0274]]], dtype=torch.float64)\n",
      "tensor([[1.4180],\n",
      "        [1.4928],\n",
      "        [1.6632],\n",
      "        [1.8120]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9268]],\n",
      "\n",
      "        [[1.2642]],\n",
      "\n",
      "        [[2.0349]],\n",
      "\n",
      "        [[2.2486]]], dtype=torch.float64)\n",
      "tensor([[1.7629],\n",
      "        [1.6476],\n",
      "        [1.5839],\n",
      "        [1.6703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9297]],\n",
      "\n",
      "        [[1.2862]],\n",
      "\n",
      "        [[1.1198]],\n",
      "\n",
      "        [[1.6802]]], dtype=torch.float64)\n",
      "tensor([[2.0933],\n",
      "        [1.6018],\n",
      "        [1.1366],\n",
      "        [1.0605]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.5444]],\n",
      "\n",
      "        [[1.9840]],\n",
      "\n",
      "        [[0.9557]],\n",
      "\n",
      "        [[0.8194]]], dtype=torch.float64)\n",
      "tensor([[1.2445],\n",
      "        [1.2723],\n",
      "        [1.4211],\n",
      "        [1.4789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8552]],\n",
      "\n",
      "        [[1.0355]],\n",
      "\n",
      "        [[1.5392]],\n",
      "\n",
      "        [[1.8535]]], dtype=torch.float64)\n",
      "tensor([[1.4021],\n",
      "        [1.4539],\n",
      "        [1.6883],\n",
      "        [1.5075]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5392]],\n",
      "\n",
      "        [[1.3983]],\n",
      "\n",
      "        [[1.2677]],\n",
      "\n",
      "        [[1.2804]]], dtype=torch.float64)\n",
      "tensor([[1.4106],\n",
      "        [1.2630],\n",
      "        [0.9879],\n",
      "        [1.0199]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6536]],\n",
      "\n",
      "        [[1.5531]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[0.8702]]], dtype=torch.float64)\n",
      "tensor([[1.2492],\n",
      "        [1.1644],\n",
      "        [1.0119],\n",
      "        [0.8376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8067]],\n",
      "\n",
      "        [[0.8240]],\n",
      "\n",
      "        [[1.0031]],\n",
      "\n",
      "        [[1.0505]]], dtype=torch.float64)\n",
      "tensor([[0.8487],\n",
      "        [0.9652],\n",
      "        [1.1208],\n",
      "        [0.9430]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9419]],\n",
      "\n",
      "        [[0.5918]],\n",
      "\n",
      "        [[0.5640]],\n",
      "\n",
      "        [[0.9731]]], dtype=torch.float64)\n",
      "tensor([[1.3462],\n",
      "        [1.0520],\n",
      "        [1.1225],\n",
      "        [1.0812]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6132]],\n",
      "\n",
      "        [[1.6189]],\n",
      "\n",
      "        [[1.2076]],\n",
      "\n",
      "        [[0.8564]]], dtype=torch.float64)\n",
      "tensor([[1.0433],\n",
      "        [0.8773],\n",
      "        [0.7772],\n",
      "        [0.8060]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6137]],\n",
      "\n",
      "        [[0.7628]],\n",
      "\n",
      "        [[1.0019]],\n",
      "\n",
      "        [[1.1903]]], dtype=torch.float64)\n",
      "tensor([[0.7706],\n",
      "        [0.7057],\n",
      "        [0.6476],\n",
      "        [0.6767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8113]],\n",
      "\n",
      "        [[0.2105]],\n",
      "\n",
      "        [[0.0164]],\n",
      "\n",
      "        [[0.9245]]], dtype=torch.float64)\n",
      "tensor([[1.1739],\n",
      "        [1.1154],\n",
      "        [0.8893],\n",
      "        [0.6423]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5912]],\n",
      "\n",
      "        [[1.6074]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[0.3503]]], dtype=torch.float64)\n",
      "tensor([[0.7100],\n",
      "        [0.7491],\n",
      "        [0.7826],\n",
      "        [0.7580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1423]],\n",
      "\n",
      "        [[0.7119]],\n",
      "\n",
      "        [[0.8933]],\n",
      "\n",
      "        [[0.8506]]], dtype=torch.float64)\n",
      "tensor([[0.6055],\n",
      "        [0.6151],\n",
      "        [0.6630],\n",
      "        [0.6717]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6403]],\n",
      "\n",
      "        [[0.3526]],\n",
      "\n",
      "        [[0.0360]],\n",
      "\n",
      "        [[0.5872]]], dtype=torch.float64)\n",
      "tensor([[0.7501],\n",
      "        [0.7061],\n",
      "        [0.7304],\n",
      "        [0.5849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9211]],\n",
      "\n",
      "        [[1.1753]],\n",
      "\n",
      "        [[0.7766]],\n",
      "\n",
      "        [[0.1215]]], dtype=torch.float64)\n",
      "tensor([[0.5223],\n",
      "        [0.5112],\n",
      "        [1.0450],\n",
      "        [1.0335]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1569]],\n",
      "\n",
      "        [[ 0.5213]],\n",
      "\n",
      "        [[ 1.4248]],\n",
      "\n",
      "        [[ 1.5069]]], dtype=torch.float64)\n",
      "tensor([[0.9225],\n",
      "        [0.8291],\n",
      "        [0.7429],\n",
      "        [0.6899]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0713]],\n",
      "\n",
      "        [[0.4381]],\n",
      "\n",
      "        [[0.0973]],\n",
      "\n",
      "        [[0.8136]]], dtype=torch.float64)\n",
      "tensor([[1.2037],\n",
      "        [1.2361],\n",
      "        [1.2224],\n",
      "        [1.0160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8177]],\n",
      "\n",
      "        [[2.0430]],\n",
      "\n",
      "        [[1.3983]],\n",
      "\n",
      "        [[0.8159]]], dtype=torch.float64)\n",
      "tensor([[0.9391],\n",
      "        [0.8555],\n",
      "        [1.3339],\n",
      "        [1.3324]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4843]],\n",
      "\n",
      "        [[1.1106]],\n",
      "\n",
      "        [[1.9771]],\n",
      "\n",
      "        [[2.0303]]], dtype=torch.float64)\n",
      "tensor([[1.2837],\n",
      "        [1.1496],\n",
      "        [1.0932],\n",
      "        [1.0191]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4745]],\n",
      "\n",
      "        [[0.8991]],\n",
      "\n",
      "        [[0.6992]],\n",
      "\n",
      "        [[1.1521]]], dtype=torch.float64)\n",
      "tensor([[1.3840],\n",
      "        [1.0451],\n",
      "        [0.8449],\n",
      "        [1.1104]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7460]],\n",
      "\n",
      "        [[1.1325]],\n",
      "\n",
      "        [[1.2307]],\n",
      "\n",
      "        [[1.0435]]], dtype=torch.float64)\n",
      "tensor([[1.2839],\n",
      "        [1.0921],\n",
      "        [1.0005],\n",
      "        [1.0017]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8922]],\n",
      "\n",
      "        [[1.0435]],\n",
      "\n",
      "        [[1.3093]],\n",
      "\n",
      "        [[1.3116]]], dtype=torch.float64)\n",
      "tensor([[0.8209],\n",
      "        [0.7070],\n",
      "        [0.6996],\n",
      "        [0.8005]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9292]],\n",
      "\n",
      "        [[0.6287]],\n",
      "\n",
      "        [[0.3341]],\n",
      "\n",
      "        [[0.8125]]], dtype=torch.float64)\n",
      "tensor([[0.7935],\n",
      "        [0.8649],\n",
      "        [0.8538],\n",
      "        [0.8755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0482]],\n",
      "\n",
      "        [[1.2145]],\n",
      "\n",
      "        [[0.9615]],\n",
      "\n",
      "        [[0.5976]]], dtype=torch.float64)\n",
      "tensor([[0.7991],\n",
      "        [0.6809],\n",
      "        [1.0333],\n",
      "        [0.9275]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1689]],\n",
      "\n",
      "        [[0.7385]],\n",
      "\n",
      "        [[1.3000]],\n",
      "\n",
      "        [[1.4006]]], dtype=torch.float64)\n",
      "tensor([[0.8830],\n",
      "        [0.8340],\n",
      "        [0.7747],\n",
      "        [0.7003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0135]],\n",
      "\n",
      "        [[0.4346]],\n",
      "\n",
      "        [[0.1874]],\n",
      "\n",
      "        [[0.7743]]], dtype=torch.float64)\n",
      "tensor([[1.0883],\n",
      "        [1.0867],\n",
      "        [0.9013],\n",
      "        [0.9236]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6293]],\n",
      "\n",
      "        [[1.6236]],\n",
      "\n",
      "        [[1.1695]],\n",
      "\n",
      "        [[0.5594]]], dtype=torch.float64)\n",
      "tensor([[0.8107],\n",
      "        [0.7326],\n",
      "        [0.7699],\n",
      "        [0.7865]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2763]],\n",
      "\n",
      "        [[0.6611]],\n",
      "\n",
      "        [[1.0990]],\n",
      "\n",
      "        [[1.1880]]], dtype=torch.float64)\n",
      "tensor([[0.7499],\n",
      "        [0.9252],\n",
      "        [0.9689],\n",
      "        [0.8080]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9858]],\n",
      "\n",
      "        [[0.8171]],\n",
      "\n",
      "        [[0.4000]],\n",
      "\n",
      "        [[0.9188]]], dtype=torch.float64)\n",
      "tensor([[1.2159],\n",
      "        [1.2617],\n",
      "        [1.0841],\n",
      "        [1.0602]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7010]],\n",
      "\n",
      "        [[1.7449]],\n",
      "\n",
      "        [[1.2873]],\n",
      "\n",
      "        [[0.9396]]], dtype=torch.float64)\n",
      "tensor([[1.0499],\n",
      "        [0.8447],\n",
      "        [0.9437],\n",
      "        [1.0677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6195]],\n",
      "\n",
      "        [[0.8506]],\n",
      "\n",
      "        [[1.3312]],\n",
      "\n",
      "        [[0.9430]]], dtype=torch.float64)\n",
      "tensor([[0.5091],\n",
      "        [0.7039],\n",
      "        [0.8811],\n",
      "        [0.7753]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7154]],\n",
      "\n",
      "        [[0.6426]],\n",
      "\n",
      "        [[0.6565]],\n",
      "\n",
      "        [[0.5952]]], dtype=torch.float64)\n",
      "tensor([[0.7339],\n",
      "        [0.9211],\n",
      "        [0.7594],\n",
      "        [0.7831]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0782]],\n",
      "\n",
      "        [[1.1753]],\n",
      "\n",
      "        [[0.9037]],\n",
      "\n",
      "        [[0.5918]]], dtype=torch.float64)\n",
      "tensor([[0.8251],\n",
      "        [0.5898],\n",
      "        [0.9084],\n",
      "        [0.8570]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3734]],\n",
      "\n",
      "        [[0.6495]],\n",
      "\n",
      "        [[1.2908]],\n",
      "\n",
      "        [[1.2723]]], dtype=torch.float64)\n",
      "tensor([[0.7170],\n",
      "        [0.7670],\n",
      "        [0.6778],\n",
      "        [0.6548]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9003]],\n",
      "\n",
      "        [[0.3595]],\n",
      "\n",
      "        [[0.2186]],\n",
      "\n",
      "        [[0.6646]]], dtype=torch.float64)\n",
      "tensor([[1.0612],\n",
      "        [0.9026],\n",
      "        [0.8834],\n",
      "        [0.8902]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2746]],\n",
      "\n",
      "        [[1.4514]],\n",
      "\n",
      "        [[1.0805]],\n",
      "\n",
      "        [[0.4728]]], dtype=torch.float64)\n",
      "tensor([[0.7715],\n",
      "        [0.6854],\n",
      "        [1.1894],\n",
      "        [1.1582]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0788]],\n",
      "\n",
      "        [[0.6588]],\n",
      "\n",
      "        [[1.5693]],\n",
      "\n",
      "        [[1.6721]]], dtype=torch.float64)\n",
      "tensor([[1.0324],\n",
      "        [0.9037],\n",
      "        [0.8271],\n",
      "        [0.7306]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0505]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.1654]],\n",
      "\n",
      "        [[0.7108]]], dtype=torch.float64)\n",
      "tensor([[1.2975],\n",
      "        [1.2977],\n",
      "        [1.1594],\n",
      "        [1.0818]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7021]],\n",
      "\n",
      "        [[1.7021]],\n",
      "\n",
      "        [[1.3116]],\n",
      "\n",
      "        [[0.7720]]], dtype=torch.float64)\n",
      "tensor([[1.0965],\n",
      "        [0.9368],\n",
      "        [1.1664],\n",
      "        [1.1922]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5583]],\n",
      "\n",
      "        [[0.9014]],\n",
      "\n",
      "        [[1.5981]],\n",
      "\n",
      "        [[1.4630]]], dtype=torch.float64)\n",
      "tensor([[0.9703],\n",
      "        [0.7672],\n",
      "        [0.7441],\n",
      "        [0.6446]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7651]],\n",
      "\n",
      "        [[0.4520]],\n",
      "\n",
      "        [[0.2856]],\n",
      "\n",
      "        [[0.5825]]], dtype=torch.float64)\n",
      "tensor([[0.6849],\n",
      "        [0.5847],\n",
      "        [0.5312],\n",
      "        [0.6748]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8021]],\n",
      "\n",
      "        [[0.8760]],\n",
      "\n",
      "        [[0.5132]],\n",
      "\n",
      "        [[0.5352]]], dtype=torch.float64)\n",
      "tensor([[0.8766],\n",
      "        [0.8393],\n",
      "        [0.6867],\n",
      "        [0.5622]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4624]],\n",
      "\n",
      "        [[0.6438]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[0.8286]]], dtype=torch.float64)\n",
      "tensor([[0.7858],\n",
      "        [1.1284],\n",
      "        [1.2094],\n",
      "        [1.0806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0216]],\n",
      "\n",
      "        [[0.9742]],\n",
      "\n",
      "        [[0.8321]],\n",
      "\n",
      "        [[0.9199]]], dtype=torch.float64)\n",
      "tensor([[1.0749],\n",
      "        [1.0898],\n",
      "        [1.0947],\n",
      "        [1.2206]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2769]],\n",
      "\n",
      "        [[1.4237]],\n",
      "\n",
      "        [[1.1753]],\n",
      "\n",
      "        [[0.9869]]], dtype=torch.float64)\n",
      "tensor([[1.2691],\n",
      "        [1.0530],\n",
      "        [1.4749],\n",
      "        [1.3488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6426]],\n",
      "\n",
      "        [[1.0285]],\n",
      "\n",
      "        [[1.6374]],\n",
      "\n",
      "        [[1.7252]]], dtype=torch.float64)\n",
      "tensor([[1.2382],\n",
      "        [1.1556],\n",
      "        [1.0966],\n",
      "        [0.9354]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2423]],\n",
      "\n",
      "        [[0.8067]],\n",
      "\n",
      "        [[0.5456]],\n",
      "\n",
      "        [[1.0158]]], dtype=torch.float64)\n",
      "tensor([[1.5181],\n",
      "        [1.6403],\n",
      "        [1.4239],\n",
      "        [1.2890]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8662]],\n",
      "\n",
      "        [[2.0210]],\n",
      "\n",
      "        [[1.5323]],\n",
      "\n",
      "        [[1.0609]]], dtype=torch.float64)\n",
      "tensor([[1.2281],\n",
      "        [1.0510],\n",
      "        [1.5091],\n",
      "        [1.5998]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6703]],\n",
      "\n",
      "        [[1.2238]],\n",
      "\n",
      "        [[1.8997]],\n",
      "\n",
      "        [[2.1227]]], dtype=torch.float64)\n",
      "tensor([[1.3735],\n",
      "        [1.3509],\n",
      "        [1.2808],\n",
      "        [1.0403]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5138]],\n",
      "\n",
      "        [[1.1429]],\n",
      "\n",
      "        [[0.6068]],\n",
      "\n",
      "        [[1.1914]]], dtype=torch.float64)\n",
      "tensor([[1.6230],\n",
      "        [1.7237],\n",
      "        [1.3959],\n",
      "        [1.3078]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1966]],\n",
      "\n",
      "        [[2.2221]],\n",
      "\n",
      "        [[1.5935]],\n",
      "\n",
      "        [[1.1533]]], dtype=torch.float64)\n",
      "tensor([[1.2012],\n",
      "        [1.1289],\n",
      "        [1.0613],\n",
      "        [1.1522]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7917]],\n",
      "\n",
      "        [[1.0724]],\n",
      "\n",
      "        [[1.3347]],\n",
      "\n",
      "        [[1.4433]]], dtype=torch.float64)\n",
      "tensor([[0.9057],\n",
      "        [0.6699],\n",
      "        [0.6822],\n",
      "        [0.6334]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8864]],\n",
      "\n",
      "        [[0.4832]],\n",
      "\n",
      "        [[0.3260]],\n",
      "\n",
      "        [[0.3630]]], dtype=torch.float64)\n",
      "tensor([[0.4423],\n",
      "        [0.4088],\n",
      "        [0.4282],\n",
      "        [0.3025]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5190]],\n",
      "\n",
      "        [[0.7616]],\n",
      "\n",
      "        [[0.2891]],\n",
      "\n",
      "        [[0.1042]]], dtype=torch.float64)\n",
      "tensor([[0.6295],\n",
      "        [0.7709],\n",
      "        [0.5280],\n",
      "        [0.3604]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3099]],\n",
      "\n",
      "        [[0.5502]],\n",
      "\n",
      "        [[0.7027]],\n",
      "\n",
      "        [[0.5664]]], dtype=torch.float64)\n",
      "tensor([[0.3225],\n",
      "        [0.4153],\n",
      "        [0.6135],\n",
      "        [0.5262]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2163]],\n",
      "\n",
      "        [[0.1088]],\n",
      "\n",
      "        [[0.2463]],\n",
      "\n",
      "        [[0.1654]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.17384:  85%|████████▌ | 2620/3067 [00:08<00:01, 335.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3599],\n",
      "        [0.3032],\n",
      "        [0.2058],\n",
      "        [0.2804]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4624]],\n",
      "\n",
      "        [[0.4058]],\n",
      "\n",
      "        [[0.2301]],\n",
      "\n",
      "        [[0.1677]]], dtype=torch.float64)\n",
      "tensor([[0.5053],\n",
      "        [0.3922],\n",
      "        [0.4335],\n",
      "        [0.2023]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1065]],\n",
      "\n",
      "        [[0.2244]],\n",
      "\n",
      "        [[0.4416]],\n",
      "\n",
      "        [[0.4439]]], dtype=torch.float64)\n",
      "tensor([[0.1471],\n",
      "        [0.3743],\n",
      "        [0.5999],\n",
      "        [0.5843]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2833]],\n",
      "\n",
      "        [[0.2660]],\n",
      "\n",
      "        [[0.1758]],\n",
      "\n",
      "        [[0.6056]]], dtype=torch.float64)\n",
      "tensor([[0.6118],\n",
      "        [0.4933],\n",
      "        [0.3661],\n",
      "        [0.5468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8240]],\n",
      "\n",
      "        [[0.7466]],\n",
      "\n",
      "        [[0.5421]],\n",
      "\n",
      "        [[0.4358]]], dtype=torch.float64)\n",
      "tensor([[0.6144],\n",
      "        [0.3570],\n",
      "        [0.7038],\n",
      "        [0.6312]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0233]],\n",
      "\n",
      "        [[0.0915]],\n",
      "\n",
      "        [[0.9326]],\n",
      "\n",
      "        [[0.8529]]], dtype=torch.float64)\n",
      "tensor([[0.6088],\n",
      "        [0.7136],\n",
      "        [0.8371],\n",
      "        [0.6986]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7108]],\n",
      "\n",
      "        [[0.5860]],\n",
      "\n",
      "        [[0.4993]],\n",
      "\n",
      "        [[0.5594]]], dtype=torch.float64)\n",
      "tensor([[0.5624],\n",
      "        [0.3883],\n",
      "        [0.3174],\n",
      "        [0.4161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6519]],\n",
      "\n",
      "        [[0.7582]],\n",
      "\n",
      "        [[0.3884]],\n",
      "\n",
      "        [[0.3110]]], dtype=torch.float64)\n",
      "tensor([[0.6229],\n",
      "        [0.6053],\n",
      "        [0.4267],\n",
      "        [0.4245]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4554]],\n",
      "\n",
      "        [[0.5040]],\n",
      "\n",
      "        [[0.6715]],\n",
      "\n",
      "        [[0.6126]]], dtype=torch.float64)\n",
      "tensor([[ 0.0971],\n",
      "        [ 0.0890],\n",
      "        [ 0.0552],\n",
      "        [-0.1663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1007]],\n",
      "\n",
      "        [[ 0.0048]],\n",
      "\n",
      "        [[-0.2806]],\n",
      "\n",
      "        [[ 0.0915]]], dtype=torch.float64)\n",
      "tensor([[ 0.1584],\n",
      "        [ 0.1374],\n",
      "        [ 0.0872],\n",
      "        [-0.0379]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3642]],\n",
      "\n",
      "        [[ 0.3445]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[-0.0841]]], dtype=torch.float64)\n",
      "tensor([[0.2186],\n",
      "        [0.2798],\n",
      "        [0.2947],\n",
      "        [0.1584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0506]],\n",
      "\n",
      "        [[ 0.0950]],\n",
      "\n",
      "        [[ 0.4427]],\n",
      "\n",
      "        [[ 0.3387]]], dtype=torch.float64)\n",
      "tensor([[ 0.0305],\n",
      "        [-0.0212],\n",
      "        [ 0.2410],\n",
      "        [ 0.2067]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0638]],\n",
      "\n",
      "        [[-0.0853]],\n",
      "\n",
      "        [[ 0.0742]],\n",
      "\n",
      "        [[ 0.1527]]], dtype=torch.float64)\n",
      "tensor([[0.1804],\n",
      "        [0.1538],\n",
      "        [0.0892],\n",
      "        [0.3005]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4266]],\n",
      "\n",
      "        [[0.3850]],\n",
      "\n",
      "        [[0.2059]],\n",
      "\n",
      "        [[0.2290]]], dtype=torch.float64)\n",
      "tensor([[0.5383],\n",
      "        [0.3933],\n",
      "        [0.4258],\n",
      "        [0.2445]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0996]],\n",
      "\n",
      "        [[0.3226]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[0.5733]]], dtype=torch.float64)\n",
      "tensor([[0.2524],\n",
      "        [0.3529],\n",
      "        [0.5048],\n",
      "        [0.4605]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4034]],\n",
      "\n",
      "        [[0.3491]],\n",
      "\n",
      "        [[0.3341]],\n",
      "\n",
      "        [[0.3803]]], dtype=torch.float64)\n",
      "tensor([[0.4465],\n",
      "        [0.4281],\n",
      "        [0.3031],\n",
      "        [0.2266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6553]],\n",
      "\n",
      "        [[0.7813]],\n",
      "\n",
      "        [[0.2163]],\n",
      "\n",
      "        [[0.0256]]], dtype=torch.float64)\n",
      "tensor([[0.3542],\n",
      "        [0.2153],\n",
      "        [0.5970],\n",
      "        [0.4875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1246]],\n",
      "\n",
      "        [[ 0.0557]],\n",
      "\n",
      "        [[ 0.8702]],\n",
      "\n",
      "        [[ 0.8229]]], dtype=torch.float64)\n",
      "tensor([[0.4658],\n",
      "        [0.5955],\n",
      "        [0.8417],\n",
      "        [0.7664]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6877]],\n",
      "\n",
      "        [[0.6287]],\n",
      "\n",
      "        [[0.5895]],\n",
      "\n",
      "        [[0.6599]]], dtype=torch.float64)\n",
      "tensor([[0.5996],\n",
      "        [0.4967],\n",
      "        [0.4208],\n",
      "        [0.5789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9419]],\n",
      "\n",
      "        [[0.9084]],\n",
      "\n",
      "        [[0.6576]],\n",
      "\n",
      "        [[0.6495]]], dtype=torch.float64)\n",
      "tensor([[0.7653],\n",
      "        [0.6655],\n",
      "        [0.5732],\n",
      "        [0.4994]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5340]],\n",
      "\n",
      "        [[0.6276]],\n",
      "\n",
      "        [[0.8852]],\n",
      "\n",
      "        [[0.9627]]], dtype=torch.float64)\n",
      "tensor([[0.4461],\n",
      "        [0.5619],\n",
      "        [0.6281],\n",
      "        [0.5227]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6877]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.3803]],\n",
      "\n",
      "        [[0.4601]]], dtype=torch.float64)\n",
      "tensor([[0.7274],\n",
      "        [0.5584],\n",
      "        [0.4027],\n",
      "        [0.4186]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9742]],\n",
      "\n",
      "        [[0.9835]],\n",
      "\n",
      "        [[0.6230]],\n",
      "\n",
      "        [[0.4185]]], dtype=torch.float64)\n",
      "tensor([[0.6298],\n",
      "        [0.7180],\n",
      "        [0.6101],\n",
      "        [0.1235]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6553]],\n",
      "\n",
      "        [[0.6160]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[0.2579]]], dtype=torch.float64)\n",
      "tensor([[-0.1968],\n",
      "        [-0.2340],\n",
      "        [-0.3585],\n",
      "        [-0.4531]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0430]],\n",
      "\n",
      "        [[-0.2956]],\n",
      "\n",
      "        [[-0.4793]],\n",
      "\n",
      "        [[-0.4989]]], dtype=torch.float64)\n",
      "tensor([[-0.1548],\n",
      "        [ 0.1517],\n",
      "        [-0.1075],\n",
      "        [-0.5066]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2787]],\n",
      "\n",
      "        [[ 0.4474]],\n",
      "\n",
      "        [[-0.1997]],\n",
      "\n",
      "        [[-0.5879]]], dtype=torch.float64)\n",
      "tensor([[-0.7071],\n",
      "        [-0.8197],\n",
      "        [-0.0102],\n",
      "        [ 0.2847]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8675]],\n",
      "\n",
      "        [[-0.8317]],\n",
      "\n",
      "        [[ 0.5248]],\n",
      "\n",
      "        [[ 0.6576]]], dtype=torch.float64)\n",
      "tensor([[ 0.0322],\n",
      "        [-0.1025],\n",
      "        [-0.3066],\n",
      "        [-0.5010]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1874]],\n",
      "\n",
      "        [[-0.0021]],\n",
      "\n",
      "        [[-0.4308]],\n",
      "\n",
      "        [[ 0.0071]]], dtype=torch.float64)\n",
      "tensor([[ 0.2797],\n",
      "        [ 0.3241],\n",
      "        [-0.0334],\n",
      "        [-0.2999]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5363]],\n",
      "\n",
      "        [[ 0.6195]],\n",
      "\n",
      "        [[ 0.0672]],\n",
      "\n",
      "        [[-0.2678]]], dtype=torch.float64)\n",
      "tensor([[-0.4456],\n",
      "        [-0.6000],\n",
      "        [-0.0106],\n",
      "        [ 0.1000]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4516]],\n",
      "\n",
      "        [[-0.2667]],\n",
      "\n",
      "        [[ 0.3896]],\n",
      "\n",
      "        [[ 0.4312]]], dtype=torch.float64)\n",
      "tensor([[-0.1010],\n",
      "        [-0.1367],\n",
      "        [-0.5475],\n",
      "        [-0.7764]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0730]],\n",
      "\n",
      "        [[-0.1627]],\n",
      "\n",
      "        [[-0.6052]],\n",
      "\n",
      "        [[-0.6514]]], dtype=torch.float64)\n",
      "tensor([[-0.3475],\n",
      "        [ 0.0301],\n",
      "        [-0.1831],\n",
      "        [-0.4571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1261]],\n",
      "\n",
      "        [[ 0.3272]],\n",
      "\n",
      "        [[-0.0691]],\n",
      "\n",
      "        [[-0.3730]]], dtype=torch.float64)\n",
      "tensor([[-0.6771],\n",
      "        [-0.7917],\n",
      "        [ 0.1965],\n",
      "        [ 0.1312]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8744]],\n",
      "\n",
      "        [[-0.4504]],\n",
      "\n",
      "        [[ 0.2971]],\n",
      "\n",
      "        [[ 0.4138]]], dtype=torch.float64)\n",
      "tensor([[-0.2214],\n",
      "        [-0.5537],\n",
      "        [-0.6815],\n",
      "        [-0.8886]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1627]],\n",
      "\n",
      "        [[-0.5821]],\n",
      "\n",
      "        [[-0.8975]],\n",
      "\n",
      "        [[-0.4169]]], dtype=torch.float64)\n",
      "tensor([[ 0.1458],\n",
      "        [ 0.2404],\n",
      "        [-0.1156],\n",
      "        [-0.3612]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3676]],\n",
      "\n",
      "        [[ 0.6588]],\n",
      "\n",
      "        [[-0.0853]],\n",
      "\n",
      "        [[-0.3614]]], dtype=torch.float64)\n",
      "tensor([[-0.3695],\n",
      "        [-0.3925],\n",
      "        [ 0.1480],\n",
      "        [ 0.2720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5798]],\n",
      "\n",
      "        [[-0.5209]],\n",
      "\n",
      "        [[ 0.6022]],\n",
      "\n",
      "        [[ 0.5675]]], dtype=torch.float64)\n",
      "tensor([[0.2061],\n",
      "        [0.4350],\n",
      "        [0.3324],\n",
      "        [0.3153]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4185]],\n",
      "\n",
      "        [[0.1689]],\n",
      "\n",
      "        [[0.0372]],\n",
      "\n",
      "        [[0.2452]]], dtype=torch.float64)\n",
      "tensor([[0.3693],\n",
      "        [0.2407],\n",
      "        [0.0915],\n",
      "        [0.2565]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5918]],\n",
      "\n",
      "        [[0.4231]],\n",
      "\n",
      "        [[0.2498]],\n",
      "\n",
      "        [[0.2220]]], dtype=torch.float64)\n",
      "tensor([[0.4597],\n",
      "        [0.4280],\n",
      "        [0.3267],\n",
      "        [0.1174]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1862]],\n",
      "\n",
      "        [[0.2151]],\n",
      "\n",
      "        [[0.3769]],\n",
      "\n",
      "        [[0.3722]]], dtype=torch.float64)\n",
      "tensor([[0.1481],\n",
      "        [0.4537],\n",
      "        [0.6089],\n",
      "        [0.5042]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3815]],\n",
      "\n",
      "        [[0.3411]],\n",
      "\n",
      "        [[0.3260]],\n",
      "\n",
      "        [[0.3376]]], dtype=torch.float64)\n",
      "tensor([[0.5576],\n",
      "        [0.4864],\n",
      "        [0.3290],\n",
      "        [0.6088]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7004]],\n",
      "\n",
      "        [[0.7281]],\n",
      "\n",
      "        [[0.5987]],\n",
      "\n",
      "        [[0.4577]]], dtype=torch.float64)\n",
      "tensor([[0.6994],\n",
      "        [0.5291],\n",
      "        [0.5061],\n",
      "        [0.3640]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3399]],\n",
      "\n",
      "        [[0.4023]],\n",
      "\n",
      "        [[0.7350]],\n",
      "\n",
      "        [[0.6033]]], dtype=torch.float64)\n",
      "tensor([[0.2172],\n",
      "        [0.4744],\n",
      "        [0.5973],\n",
      "        [0.4828]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4069]],\n",
      "\n",
      "        [[0.3341]],\n",
      "\n",
      "        [[0.2660]],\n",
      "\n",
      "        [[0.5687]]], dtype=torch.float64)\n",
      "tensor([[0.6140],\n",
      "        [0.4036],\n",
      "        [0.3440],\n",
      "        [0.4444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8159]],\n",
      "\n",
      "        [[0.7223]],\n",
      "\n",
      "        [[0.4566]],\n",
      "\n",
      "        [[0.3711]]], dtype=torch.float64)\n",
      "tensor([[ 0.4457],\n",
      "        [ 0.4204],\n",
      "        [-0.1256],\n",
      "        [-0.2519]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2359]],\n",
      "\n",
      "        [[-0.1188]],\n",
      "\n",
      "        [[-0.2008]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[-0.2871],\n",
      "        [-0.2885],\n",
      "        [-0.1816],\n",
      "        [-0.0828]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3349]],\n",
      "\n",
      "        [[-0.3834]],\n",
      "\n",
      "        [[-0.3672]],\n",
      "\n",
      "        [[-0.3014]]], dtype=torch.float64)\n",
      "tensor([[-0.2056],\n",
      "        [-0.1354],\n",
      "        [-0.1396],\n",
      "        [-0.2630]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1985]],\n",
      "\n",
      "        [[-0.1165]],\n",
      "\n",
      "        [[-0.2447]],\n",
      "\n",
      "        [[-0.5116]]], dtype=torch.float64)\n",
      "tensor([[-0.4267],\n",
      "        [-0.5251],\n",
      "        [-0.3800],\n",
      "        [-0.1496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7277]],\n",
      "\n",
      "        [[-0.6988]],\n",
      "\n",
      "        [[-0.3707]],\n",
      "\n",
      "        [[-0.0714]]], dtype=torch.float64)\n",
      "tensor([[-0.1629],\n",
      "        [-0.1695],\n",
      "        [-0.1465],\n",
      "        [-0.2120]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2886]],\n",
      "\n",
      "        [[-0.3245]],\n",
      "\n",
      "        [[-0.4573]],\n",
      "\n",
      "        [[-0.4157]]], dtype=torch.float64)\n",
      "tensor([[ 0.0689],\n",
      "        [-0.0228],\n",
      "        [-0.3658],\n",
      "        [-0.5230]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0869]],\n",
      "\n",
      "        [[ 0.0349]],\n",
      "\n",
      "        [[-0.5382]],\n",
      "\n",
      "        [[-0.8328]]], dtype=torch.float64)\n",
      "tensor([[-0.5270],\n",
      "        [-0.4995],\n",
      "        [ 0.0275],\n",
      "        [ 0.2560]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8432]],\n",
      "\n",
      "        [[-0.3141]],\n",
      "\n",
      "        [[ 0.3584]],\n",
      "\n",
      "        [[ 0.4416]]], dtype=torch.float64)\n",
      "tensor([[0.1305],\n",
      "        [0.1660],\n",
      "        [0.3080],\n",
      "        [0.3254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1458]],\n",
      "\n",
      "        [[0.0730]],\n",
      "\n",
      "        [[0.2556]],\n",
      "\n",
      "        [[0.1227]]], dtype=torch.float64)\n",
      "tensor([[ 0.2401],\n",
      "        [ 0.1641],\n",
      "        [-0.0527],\n",
      "        [-0.0284]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1978]],\n",
      "\n",
      "        [[ 0.3110]],\n",
      "\n",
      "        [[-0.0414]],\n",
      "\n",
      "        [[-0.0876]]], dtype=torch.float64)\n",
      "tensor([[ 2.7568e-02],\n",
      "        [-6.6899e-02],\n",
      "        [-9.8633e-05],\n",
      "        [-3.2287e-02]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1119]],\n",
      "\n",
      "        [[-0.0922]],\n",
      "\n",
      "        [[ 0.1608]],\n",
      "\n",
      "        [[ 0.1608]]], dtype=torch.float64)\n",
      "tensor([[-0.0617],\n",
      "        [-0.1283],\n",
      "        [-0.0843],\n",
      "        [ 0.1826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0807]],\n",
      "\n",
      "        [[-0.3372]],\n",
      "\n",
      "        [[-0.2066]],\n",
      "\n",
      "        [[ 0.0926]]], dtype=torch.float64)\n",
      "tensor([[0.2629],\n",
      "        [0.2516],\n",
      "        [0.2194],\n",
      "        [0.2237]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5698]],\n",
      "\n",
      "        [[0.5352]],\n",
      "\n",
      "        [[0.2636]],\n",
      "\n",
      "        [[0.1758]]], dtype=torch.float64)\n",
      "tensor([[0.3287],\n",
      "        [0.1804],\n",
      "        [0.1076],\n",
      "        [0.0378]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0661]],\n",
      "\n",
      "        [[0.1620]],\n",
      "\n",
      "        [[0.3191]],\n",
      "\n",
      "        [[0.2532]]], dtype=torch.float64)\n",
      "tensor([[-0.0210],\n",
      "        [-0.0469],\n",
      "        [-0.3184],\n",
      "        [-0.4498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0014]],\n",
      "\n",
      "        [[-0.3187]],\n",
      "\n",
      "        [[-0.7196]],\n",
      "\n",
      "        [[-0.4388]]], dtype=torch.float64)\n",
      "tensor([[0.1817],\n",
      "        [0.3795],\n",
      "        [0.2516],\n",
      "        [0.4384]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6449]],\n",
      "\n",
      "        [[0.7790]],\n",
      "\n",
      "        [[0.4670]],\n",
      "\n",
      "        [[0.6230]]], dtype=torch.float64)\n",
      "tensor([[0.6905],\n",
      "        [0.7153],\n",
      "        [0.6955],\n",
      "        [0.4955]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7847]],\n",
      "\n",
      "        [[0.5409]],\n",
      "\n",
      "        [[0.8956]],\n",
      "\n",
      "        [[0.8182]]], dtype=torch.float64)\n",
      "tensor([[0.3881],\n",
      "        [0.4599],\n",
      "        [0.6970],\n",
      "        [0.6927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5837]],\n",
      "\n",
      "        [[0.6045]],\n",
      "\n",
      "        [[0.6449]],\n",
      "\n",
      "        [[0.6576]]], dtype=torch.float64)\n",
      "tensor([[0.5643],\n",
      "        [0.6276],\n",
      "        [0.4442],\n",
      "        [0.4380]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9511]],\n",
      "\n",
      "        [[0.9858]],\n",
      "\n",
      "        [[0.6253]],\n",
      "\n",
      "        [[0.2532]]], dtype=torch.float64)\n",
      "tensor([[0.3471],\n",
      "        [0.2691],\n",
      "        [0.6136],\n",
      "        [1.0319]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1331]],\n",
      "\n",
      "        [[0.3029]],\n",
      "\n",
      "        [[1.3775]],\n",
      "\n",
      "        [[1.3705]]], dtype=torch.float64)\n",
      "tensor([[0.7248],\n",
      "        [0.7490],\n",
      "        [0.8701],\n",
      "        [0.6530]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8980]],\n",
      "\n",
      "        [[0.8783]],\n",
      "\n",
      "        [[0.6114]],\n",
      "\n",
      "        [[0.5271]]], dtype=torch.float64)\n",
      "tensor([[0.6583],\n",
      "        [0.6439],\n",
      "        [0.5620],\n",
      "        [0.6850]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0886]],\n",
      "\n",
      "        [[0.9846]],\n",
      "\n",
      "        [[0.8356]],\n",
      "\n",
      "        [[0.6992]]], dtype=torch.float64)\n",
      "tensor([[0.7437],\n",
      "        [0.4925],\n",
      "        [0.6077],\n",
      "        [0.5423]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4439]],\n",
      "\n",
      "        [[0.5051]],\n",
      "\n",
      "        [[0.9892]],\n",
      "\n",
      "        [[0.6646]]], dtype=torch.float64)\n",
      "tensor([[ 0.2298],\n",
      "        [ 0.2355],\n",
      "        [ 0.0652],\n",
      "        [-0.0298]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3526]],\n",
      "\n",
      "        [[-0.0922]],\n",
      "\n",
      "        [[-0.2424]],\n",
      "\n",
      "        [[-0.2505]]], dtype=torch.float64)\n",
      "tensor([[0.1904],\n",
      "        [0.5345],\n",
      "        [0.4688],\n",
      "        [0.6053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6184]],\n",
      "\n",
      "        [[0.7974]],\n",
      "\n",
      "        [[0.5906]],\n",
      "\n",
      "        [[0.6415]]], dtype=torch.float64)\n",
      "tensor([[0.9092],\n",
      "        [0.8376],\n",
      "        [0.8763],\n",
      "        [0.8958]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7870]],\n",
      "\n",
      "        [[0.8021]],\n",
      "\n",
      "        [[1.2619]],\n",
      "\n",
      "        [[1.2273]]], dtype=torch.float64)\n",
      "tensor([[0.8180],\n",
      "        [0.9885],\n",
      "        [0.9615],\n",
      "        [0.7483]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0482]],\n",
      "\n",
      "        [[0.8379]],\n",
      "\n",
      "        [[0.6495]],\n",
      "\n",
      "        [[0.7420]]], dtype=torch.float64)\n",
      "tensor([[0.5803],\n",
      "        [0.5468],\n",
      "        [0.2527],\n",
      "        [0.3995]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0181]],\n",
      "\n",
      "        [[0.8113]],\n",
      "\n",
      "        [[0.2798]],\n",
      "\n",
      "        [[0.3988]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.17047:  88%|████████▊ | 2692/3067 [00:08<00:01, 345.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6387],\n",
      "        [0.6258],\n",
      "        [0.6957],\n",
      "        [0.5813]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4601]],\n",
      "\n",
      "        [[0.7431]],\n",
      "\n",
      "        [[1.2839]],\n",
      "\n",
      "        [[0.9696]]], dtype=torch.float64)\n",
      "tensor([[0.6118],\n",
      "        [0.6555],\n",
      "        [0.5719],\n",
      "        [0.3418]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7073]],\n",
      "\n",
      "        [[0.5664]],\n",
      "\n",
      "        [[0.3203]],\n",
      "\n",
      "        [[0.3214]]], dtype=torch.float64)\n",
      "tensor([[0.2774],\n",
      "        [0.2437],\n",
      "        [0.0127],\n",
      "        [0.0154]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5652]],\n",
      "\n",
      "        [[ 0.3930]],\n",
      "\n",
      "        [[ 0.0672]],\n",
      "\n",
      "        [[-0.1107]]], dtype=torch.float64)\n",
      "tensor([[ 0.0046],\n",
      "        [-0.0379],\n",
      "        [ 0.1116],\n",
      "        [-0.0222]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2216]],\n",
      "\n",
      "        [[-0.1581]],\n",
      "\n",
      "        [[ 0.2833]],\n",
      "\n",
      "        [[ 0.1862]]], dtype=torch.float64)\n",
      "tensor([[-0.3090],\n",
      "        [-0.5526],\n",
      "        [-0.6448],\n",
      "        [-0.7880]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4712]],\n",
      "\n",
      "        [[-0.8860]],\n",
      "\n",
      "        [[-1.1044]],\n",
      "\n",
      "        [[-1.1448]]], dtype=torch.float64)\n",
      "tensor([[-0.4375],\n",
      "        [ 0.0854],\n",
      "        [-0.3209],\n",
      "        [-0.5802]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2232]],\n",
      "\n",
      "        [[ 0.2220]],\n",
      "\n",
      "        [[-0.3973]],\n",
      "\n",
      "        [[-0.8594]]], dtype=torch.float64)\n",
      "tensor([[-0.5673],\n",
      "        [-0.3310],\n",
      "        [-0.0360],\n",
      "        [-0.0891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6133]],\n",
      "\n",
      "        [[-0.3568]],\n",
      "\n",
      "        [[-0.0460]],\n",
      "\n",
      "        [[-0.0148]]], dtype=torch.float64)\n",
      "tensor([[-0.1292],\n",
      "        [ 0.0664],\n",
      "        [ 0.0127],\n",
      "        [ 0.1357]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0876]],\n",
      "\n",
      "        [[-0.1731]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[ 0.0661]]], dtype=torch.float64)\n",
      "tensor([[0.4440],\n",
      "        [0.4403],\n",
      "        [0.4321],\n",
      "        [0.5822]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6750]],\n",
      "\n",
      "        [[0.6588]],\n",
      "\n",
      "        [[0.5629]],\n",
      "\n",
      "        [[0.3295]]], dtype=torch.float64)\n",
      "tensor([[ 0.5928],\n",
      "        [ 0.4292],\n",
      "        [ 0.1034],\n",
      "        [-0.0747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3376]],\n",
      "\n",
      "        [[ 0.0661]],\n",
      "\n",
      "        [[ 0.1412]],\n",
      "\n",
      "        [[-0.1153]]], dtype=torch.float64)\n",
      "tensor([[-0.2781],\n",
      "        [-0.1419],\n",
      "        [-0.0677],\n",
      "        [-0.0121]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2274]],\n",
      "\n",
      "        [[-0.2413]],\n",
      "\n",
      "        [[-0.3083]],\n",
      "\n",
      "        [[-0.1673]]], dtype=torch.float64)\n",
      "tensor([[ 0.1006],\n",
      "        [ 0.2068],\n",
      "        [ 0.2611],\n",
      "        [-0.2676]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1481]],\n",
      "\n",
      "        [[ 0.3029]],\n",
      "\n",
      "        [[ 0.3457]],\n",
      "\n",
      "        [[-0.2806]]], dtype=torch.float64)\n",
      "tensor([[-0.2693],\n",
      "        [-0.2528],\n",
      "        [-0.2523],\n",
      "        [-0.2554]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4169]],\n",
      "\n",
      "        [[-0.2829]],\n",
      "\n",
      "        [[-0.1026]],\n",
      "\n",
      "        [[-0.2424]]], dtype=torch.float64)\n",
      "tensor([[-0.5099],\n",
      "        [-0.3683],\n",
      "        [-0.3215],\n",
      "        [-0.1605]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3568]],\n",
      "\n",
      "        [[-0.5139]],\n",
      "\n",
      "        [[-0.1974]],\n",
      "\n",
      "        [[-0.4620]]], dtype=torch.float64)\n",
      "tensor([[-0.2668],\n",
      "        [-0.1026],\n",
      "        [-0.1348],\n",
      "        [-0.0013]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0206]],\n",
      "\n",
      "        [[ 0.0106]],\n",
      "\n",
      "        [[-0.1246]],\n",
      "\n",
      "        [[-0.1442]]], dtype=torch.float64)\n",
      "tensor([[0.3146],\n",
      "        [0.5760],\n",
      "        [0.5076],\n",
      "        [0.5019]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4254]],\n",
      "\n",
      "        [[0.5594]],\n",
      "\n",
      "        [[0.7062]],\n",
      "\n",
      "        [[0.6599]]], dtype=torch.float64)\n",
      "tensor([[0.4934],\n",
      "        [0.6793],\n",
      "        [0.7728],\n",
      "        [0.5279]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6045]],\n",
      "\n",
      "        [[ 0.5097]],\n",
      "\n",
      "        [[ 0.6368]],\n",
      "\n",
      "        [[-0.0876]]], dtype=torch.float64)\n",
      "tensor([[0.1260],\n",
      "        [0.0372],\n",
      "        [0.1149],\n",
      "        [0.1869]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1285]],\n",
      "\n",
      "        [[0.1377]],\n",
      "\n",
      "        [[0.0279]],\n",
      "\n",
      "        [[0.0707]]], dtype=torch.float64)\n",
      "tensor([[ 0.5555],\n",
      "        [ 0.2704],\n",
      "        [-0.0056],\n",
      "        [-0.0419]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3145]],\n",
      "\n",
      "        [[ 0.0430]],\n",
      "\n",
      "        [[ 0.1943]],\n",
      "\n",
      "        [[-0.0229]]], dtype=torch.float64)\n",
      "tensor([[-0.4124],\n",
      "        [-0.4155],\n",
      "        [-0.1516],\n",
      "        [-0.1751]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4573]],\n",
      "\n",
      "        [[-0.5220]],\n",
      "\n",
      "        [[-0.3279]],\n",
      "\n",
      "        [[-0.3083]]], dtype=torch.float64)\n",
      "tensor([[-0.3667],\n",
      "        [-0.4938],\n",
      "        [-0.5214],\n",
      "        [-0.5144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3141]],\n",
      "\n",
      "        [[-0.3476]],\n",
      "\n",
      "        [[-0.4874]],\n",
      "\n",
      "        [[-0.5994]]], dtype=torch.float64)\n",
      "tensor([[-0.3852],\n",
      "        [-0.3978],\n",
      "        [-0.3109],\n",
      "        [-0.3522]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4562]],\n",
      "\n",
      "        [[-0.4365]],\n",
      "\n",
      "        [[-0.2228]],\n",
      "\n",
      "        [[-0.2528]]], dtype=torch.float64)\n",
      "tensor([[-0.5488],\n",
      "        [-0.7182],\n",
      "        [-0.7975],\n",
      "        [-0.8135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7462]],\n",
      "\n",
      "        [[-1.0697]],\n",
      "\n",
      "        [[-1.1610]],\n",
      "\n",
      "        [[-1.2684]]], dtype=torch.float64)\n",
      "tensor([[-0.7565],\n",
      "        [-0.3377],\n",
      "        [-0.5362],\n",
      "        [-0.5102]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4100]],\n",
      "\n",
      "        [[-0.2471]],\n",
      "\n",
      "        [[-0.5694]],\n",
      "\n",
      "        [[-0.6722]]], dtype=torch.float64)\n",
      "tensor([[-0.4223],\n",
      "        [-0.2989],\n",
      "        [-0.2298],\n",
      "        [-0.3109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6295]],\n",
      "\n",
      "        [[-0.3776]],\n",
      "\n",
      "        [[ 0.0210]],\n",
      "\n",
      "        [[-0.1962]]], dtype=torch.float64)\n",
      "tensor([[-0.5989],\n",
      "        [-0.7764],\n",
      "        [-0.8101],\n",
      "        [-0.9109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7866]],\n",
      "\n",
      "        [[-1.1032]],\n",
      "\n",
      "        [[-1.1968]],\n",
      "\n",
      "        [[-1.2684]]], dtype=torch.float64)\n",
      "tensor([[-0.8826],\n",
      "        [-0.6332],\n",
      "        [-0.7318],\n",
      "        [-0.7363]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7993]],\n",
      "\n",
      "        [[-0.6237]],\n",
      "\n",
      "        [[-0.7681]],\n",
      "\n",
      "        [[-0.9033]]], dtype=torch.float64)\n",
      "tensor([[-0.7872],\n",
      "        [-0.7783],\n",
      "        [-0.8200],\n",
      "        [-0.8097]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9611]],\n",
      "\n",
      "        [[-0.9357]],\n",
      "\n",
      "        [[-0.8328]],\n",
      "\n",
      "        [[-0.8028]]], dtype=torch.float64)\n",
      "tensor([[-0.8365],\n",
      "        [-0.7623],\n",
      "        [-0.6538],\n",
      "        [-0.6870]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8074]],\n",
      "\n",
      "        [[-0.7947]],\n",
      "\n",
      "        [[-0.8224]],\n",
      "\n",
      "        [[-0.7843]]], dtype=torch.float64)\n",
      "tensor([[-0.6875],\n",
      "        [-0.5470],\n",
      "        [-0.7829],\n",
      "        [-0.8856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3765]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.8825]],\n",
      "\n",
      "        [[-1.1598]]], dtype=torch.float64)\n",
      "tensor([[-0.8935],\n",
      "        [-1.0055],\n",
      "        [-0.9100],\n",
      "        [-0.9027]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2222]],\n",
      "\n",
      "        [[-1.2083]],\n",
      "\n",
      "        [[-1.0096]],\n",
      "\n",
      "        [[-0.8178]]], dtype=torch.float64)\n",
      "tensor([[-0.8243],\n",
      "        [-0.6985],\n",
      "        [-0.5695],\n",
      "        [-0.5387]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7485]],\n",
      "\n",
      "        [[-0.7138]],\n",
      "\n",
      "        [[-0.7057]],\n",
      "\n",
      "        [[-0.6306]]], dtype=torch.float64)\n",
      "tensor([[-0.5696],\n",
      "        [-0.4948],\n",
      "        [-0.5153],\n",
      "        [-0.4532]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4666]],\n",
      "\n",
      "        [[-0.3903]],\n",
      "\n",
      "        [[-0.4273]],\n",
      "\n",
      "        [[-0.3869]]], dtype=torch.float64)\n",
      "tensor([[-0.2625],\n",
      "        [-0.3059],\n",
      "        [-0.5132],\n",
      "        [-0.6054]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4134]],\n",
      "\n",
      "        [[-0.3857]],\n",
      "\n",
      "        [[-0.4851]],\n",
      "\n",
      "        [[-0.4215]]], dtype=torch.float64)\n",
      "tensor([[-0.5291],\n",
      "        [-0.5539],\n",
      "        [-0.5001],\n",
      "        [-0.6989]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4365]],\n",
      "\n",
      "        [[-0.5278]],\n",
      "\n",
      "        [[-0.5867]],\n",
      "\n",
      "        [[-0.9368]]], dtype=torch.float64)\n",
      "tensor([[-0.9137],\n",
      "        [-0.8112],\n",
      "        [-0.8259],\n",
      "        [-0.7666]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8409]],\n",
      "\n",
      "        [[-0.7601]],\n",
      "\n",
      "        [[-0.8063]],\n",
      "\n",
      "        [[-0.8999]]], dtype=torch.float64)\n",
      "tensor([[-0.8281],\n",
      "        [-0.8072],\n",
      "        [-0.8704],\n",
      "        [-0.9713]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9518]],\n",
      "\n",
      "        [[-0.8201]],\n",
      "\n",
      "        [[-0.7820]],\n",
      "\n",
      "        [[-0.8375]]], dtype=torch.float64)\n",
      "tensor([[-0.9303],\n",
      "        [-0.8362],\n",
      "        [-0.7636],\n",
      "        [-0.8434]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8120]],\n",
      "\n",
      "        [[-0.7751]],\n",
      "\n",
      "        [[-0.8155]],\n",
      "\n",
      "        [[-0.8606]]], dtype=torch.float64)\n",
      "tensor([[-0.9006],\n",
      "        [-0.8414],\n",
      "        [-0.7942],\n",
      "        [-0.7234]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7774]],\n",
      "\n",
      "        [[-0.7231]],\n",
      "\n",
      "        [[-0.6942]],\n",
      "\n",
      "        [[-0.6676]]], dtype=torch.float64)\n",
      "tensor([[-0.6237],\n",
      "        [-0.6228],\n",
      "        [-0.6751],\n",
      "        [-0.6822]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6364]],\n",
      "\n",
      "        [[-0.6364]],\n",
      "\n",
      "        [[-0.5891]],\n",
      "\n",
      "        [[-0.5209]]], dtype=torch.float64)\n",
      "tensor([[-0.6237],\n",
      "        [-0.6657],\n",
      "        [-0.6300],\n",
      "        [-0.6896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4435]],\n",
      "\n",
      "        [[-0.5324]],\n",
      "\n",
      "        [[-0.7023]],\n",
      "\n",
      "        [[-0.8201]]], dtype=torch.float64)\n",
      "tensor([[-0.7502],\n",
      "        [-0.7454],\n",
      "        [-0.9398],\n",
      "        [-1.1580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6041]],\n",
      "\n",
      "        [[-0.6630]],\n",
      "\n",
      "        [[-0.9449]],\n",
      "\n",
      "        [[-1.1448]]], dtype=torch.float64)\n",
      "tensor([[-1.0205],\n",
      "        [-1.1695],\n",
      "        [-1.1649],\n",
      "        [-1.1005]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2546]],\n",
      "\n",
      "        [[-1.2014]],\n",
      "\n",
      "        [[-0.7508]],\n",
      "\n",
      "        [[-0.9438]]], dtype=torch.float64)\n",
      "tensor([[-1.1493],\n",
      "        [-1.0789],\n",
      "        [-1.0323],\n",
      "        [-1.1034]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0489]],\n",
      "\n",
      "        [[-1.1968]],\n",
      "\n",
      "        [[-1.2303]],\n",
      "\n",
      "        [[-1.1344]]], dtype=torch.float64)\n",
      "tensor([[-1.0683],\n",
      "        [-1.1293],\n",
      "        [-1.2059],\n",
      "        [-1.3270]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8687]],\n",
      "\n",
      "        [[-1.0720]],\n",
      "\n",
      "        [[-1.2523]],\n",
      "\n",
      "        [[-1.5527]]], dtype=torch.float64)\n",
      "tensor([[-1.3512],\n",
      "        [-1.4171],\n",
      "        [-1.3461],\n",
      "        [-1.0278]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6925]],\n",
      "\n",
      "        [[-1.7583]],\n",
      "\n",
      "        [[-1.2592]],\n",
      "\n",
      "        [[-0.8317]]], dtype=torch.float64)\n",
      "tensor([[-1.0156],\n",
      "        [-0.9602],\n",
      "        [-0.8311],\n",
      "        [-0.7659]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9438]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-0.9518]],\n",
      "\n",
      "        [[-0.8259]]], dtype=torch.float64)\n",
      "tensor([[-0.6886],\n",
      "        [-0.6081],\n",
      "        [-0.6551],\n",
      "        [-0.6174]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.4966]],\n",
      "\n",
      "        [[-0.5047]],\n",
      "\n",
      "        [[-0.5163]]], dtype=torch.float64)\n",
      "tensor([[-0.5195],\n",
      "        [-0.5780],\n",
      "        [-0.4882],\n",
      "        [-0.6389]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5139]],\n",
      "\n",
      "        [[-0.6075]],\n",
      "\n",
      "        [[-0.4331]],\n",
      "\n",
      "        [[-0.5671]]], dtype=torch.float64)\n",
      "tensor([[-0.6793],\n",
      "        [-0.6979],\n",
      "        [-0.7626],\n",
      "        [-0.5815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6110]],\n",
      "\n",
      "        [[-0.7057]],\n",
      "\n",
      "        [[-0.6480]],\n",
      "\n",
      "        [[-0.6514]]], dtype=torch.float64)\n",
      "tensor([[-0.6598],\n",
      "        [-0.6692],\n",
      "        [-0.7555],\n",
      "        [-0.7136]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4908]],\n",
      "\n",
      "        [[-0.4955]],\n",
      "\n",
      "        [[-0.6387]],\n",
      "\n",
      "        [[-0.6618]]], dtype=torch.float64)\n",
      "tensor([[-0.6471],\n",
      "        [-0.6480],\n",
      "        [-0.5839],\n",
      "        [-0.5851]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6965]],\n",
      "\n",
      "        [[-0.6491]],\n",
      "\n",
      "        [[-0.3614]],\n",
      "\n",
      "        [[-0.4146]]], dtype=torch.float64)\n",
      "tensor([[-0.5814],\n",
      "        [-0.4658],\n",
      "        [-0.3888],\n",
      "        [-0.5835]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4181]],\n",
      "\n",
      "        [[-0.3834]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-0.5752]]], dtype=torch.float64)\n",
      "tensor([[-0.6111],\n",
      "        [-0.5922],\n",
      "        [-0.8972],\n",
      "        [-1.0175]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3014]],\n",
      "\n",
      "        [[-0.5290]],\n",
      "\n",
      "        [[-0.9264]],\n",
      "\n",
      "        [[-1.2349]]], dtype=torch.float64)\n",
      "tensor([[-1.0618],\n",
      "        [-1.1711],\n",
      "        [-1.1073],\n",
      "        [-0.8727]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2973]],\n",
      "\n",
      "        [[-1.4475]],\n",
      "\n",
      "        [[-0.8952]],\n",
      "\n",
      "        [[-0.7762]]], dtype=torch.float64)\n",
      "tensor([[-1.0932],\n",
      "        [-1.1747],\n",
      "        [-1.1871],\n",
      "        [-1.2726]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1922]],\n",
      "\n",
      "        [[-1.3378]],\n",
      "\n",
      "        [[-1.4371]],\n",
      "\n",
      "        [[-1.4891]]], dtype=torch.float64)\n",
      "tensor([[-1.0837],\n",
      "        [-0.9958],\n",
      "        [-0.8467],\n",
      "        [-0.6962]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0085]],\n",
      "\n",
      "        [[-0.7832]],\n",
      "\n",
      "        [[-0.7265]],\n",
      "\n",
      "        [[-0.6734]]], dtype=torch.float64)\n",
      "tensor([[-0.7226],\n",
      "        [-0.7727],\n",
      "        [-0.6530],\n",
      "        [-0.7577]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8271]],\n",
      "\n",
      "        [[-0.9750]],\n",
      "\n",
      "        [[-0.7138]],\n",
      "\n",
      "        [[-0.6202]]], dtype=torch.float64)\n",
      "tensor([[-0.6651],\n",
      "        [-0.8977],\n",
      "        [-0.9803],\n",
      "        [-1.0139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5821]],\n",
      "\n",
      "        [[-0.9230]],\n",
      "\n",
      "        [[-0.8837]],\n",
      "\n",
      "        [[-0.9357]]], dtype=torch.float64)\n",
      "tensor([[-1.0129],\n",
      "        [-1.1602],\n",
      "        [-1.0631],\n",
      "        [-1.0269]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8421]],\n",
      "\n",
      "        [[-0.8871]],\n",
      "\n",
      "        [[-0.9218]],\n",
      "\n",
      "        [[-1.0373]]], dtype=torch.float64)\n",
      "tensor([[-0.9779],\n",
      "        [-0.9735],\n",
      "        [-0.9116],\n",
      "        [-0.9637]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9773]],\n",
      "\n",
      "        [[-0.9299]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[-0.8213]]], dtype=torch.float64)\n",
      "tensor([[-0.9174],\n",
      "        [-0.6509],\n",
      "        [-0.5683],\n",
      "        [-0.5544]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7231]],\n",
      "\n",
      "        [[-0.6168]],\n",
      "\n",
      "        [[-0.5752]],\n",
      "\n",
      "        [[-0.5498]]], dtype=torch.float64)\n",
      "tensor([[-0.4222],\n",
      "        [-0.4409],\n",
      "        [-0.4372],\n",
      "        [-0.3452]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3291]],\n",
      "\n",
      "        [[-0.4111]],\n",
      "\n",
      "        [[-0.3279]],\n",
      "\n",
      "        [[-0.2216]]], dtype=torch.float64)\n",
      "tensor([[-0.2228],\n",
      "        [-0.2547],\n",
      "        [-0.3328],\n",
      "        [-0.3186]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2043]],\n",
      "\n",
      "        [[-0.1072]],\n",
      "\n",
      "        [[-0.0830]],\n",
      "\n",
      "        [[-0.1408]]], dtype=torch.float64)\n",
      "tensor([[-0.2418],\n",
      "        [-0.1849],\n",
      "        [-0.1623],\n",
      "        [-0.1654]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1153]],\n",
      "\n",
      "        [[-0.2332]],\n",
      "\n",
      "        [[-0.2678]],\n",
      "\n",
      "        [[-0.2574]]], dtype=torch.float64)\n",
      "tensor([[-0.1603],\n",
      "        [-0.1820],\n",
      "        [-0.2143],\n",
      "        [-0.3136]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1165]],\n",
      "\n",
      "        [[-0.0760]],\n",
      "\n",
      "        [[-0.2147]],\n",
      "\n",
      "        [[-0.4804]]], dtype=torch.float64)\n",
      "tensor([[-0.3326],\n",
      "        [-0.5584],\n",
      "        [-0.6628],\n",
      "        [-0.5987]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5602]],\n",
      "\n",
      "        [[-0.9553]],\n",
      "\n",
      "        [[-0.6526]],\n",
      "\n",
      "        [[-0.4828]]], dtype=torch.float64)\n",
      "tensor([[-0.6287],\n",
      "        [-0.6800],\n",
      "        [-0.7320],\n",
      "        [-0.8579]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6445]],\n",
      "\n",
      "        [[-0.8375]],\n",
      "\n",
      "        [[-1.0466]],\n",
      "\n",
      "        [[-1.1702]]], dtype=torch.float64)\n",
      "tensor([[-0.9593],\n",
      "        [-0.6414],\n",
      "        [-0.8929],\n",
      "        [-0.9679]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.17047:  90%|█████████ | 2761/3067 [00:08<00:00, 335.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8606]],\n",
      "\n",
      "        [[-0.7312]],\n",
      "\n",
      "        [[-1.0397]],\n",
      "\n",
      "        [[-1.1113]]], dtype=torch.float64)\n",
      "tensor([[-0.9253],\n",
      "        [-1.0544],\n",
      "        [-0.9304],\n",
      "        [-0.6829]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2534]],\n",
      "\n",
      "        [[-1.3701]],\n",
      "\n",
      "        [[-0.6826]],\n",
      "\n",
      "        [[-0.7543]]], dtype=torch.float64)\n",
      "tensor([[-0.9632],\n",
      "        [-1.1112],\n",
      "        [-1.1231],\n",
      "        [-1.1091]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1286]],\n",
      "\n",
      "        [[-1.3042]],\n",
      "\n",
      "        [[-1.3782]],\n",
      "\n",
      "        [[-1.4059]]], dtype=torch.float64)\n",
      "tensor([[-0.9476],\n",
      "        [-0.8134],\n",
      "        [-0.8384],\n",
      "        [-0.7772]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8074]],\n",
      "\n",
      "        [[-0.7670]],\n",
      "\n",
      "        [[-0.8536]],\n",
      "\n",
      "        [[-0.8040]]], dtype=torch.float64)\n",
      "tensor([[-0.7338],\n",
      "        [-0.7234],\n",
      "        [-0.5126],\n",
      "        [-0.5849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9334]],\n",
      "\n",
      "        [[-0.7762]],\n",
      "\n",
      "        [[-0.4169]],\n",
      "\n",
      "        [[-0.4273]]], dtype=torch.float64)\n",
      "tensor([[-0.6599],\n",
      "        [-0.8553],\n",
      "        [-0.8453],\n",
      "        [-0.8082]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7369]],\n",
      "\n",
      "        [[-0.9299]],\n",
      "\n",
      "        [[-0.9207]],\n",
      "\n",
      "        [[-0.8987]]], dtype=torch.float64)\n",
      "tensor([[-0.7321],\n",
      "        [-0.1672],\n",
      "        [-0.3902],\n",
      "        [-0.3849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0129]],\n",
      "\n",
      "        [[ 0.1955]],\n",
      "\n",
      "        [[-0.1315]],\n",
      "\n",
      "        [[-0.4077]]], dtype=torch.float64)\n",
      "tensor([[-0.5371],\n",
      "        [-0.7123],\n",
      "        [-0.6840],\n",
      "        [-0.4221]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6110]],\n",
      "\n",
      "        [[-0.7242]],\n",
      "\n",
      "        [[-0.2863]],\n",
      "\n",
      "        [[-0.1985]]], dtype=torch.float64)\n",
      "tensor([[-0.7135],\n",
      "        [-0.9385],\n",
      "        [-1.0017],\n",
      "        [-0.9909]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7866]],\n",
      "\n",
      "        [[-1.0836]],\n",
      "\n",
      "        [[-1.2060]],\n",
      "\n",
      "        [[-1.0789]]], dtype=torch.float64)\n",
      "tensor([[-0.8802],\n",
      "        [-0.6457],\n",
      "        [-0.6505],\n",
      "        [-0.7022]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6364]],\n",
      "\n",
      "        [[-0.3984]],\n",
      "\n",
      "        [[-0.5116]],\n",
      "\n",
      "        [[-0.7554]]], dtype=torch.float64)\n",
      "tensor([[-0.6858],\n",
      "        [-0.5752],\n",
      "        [-0.4159],\n",
      "        [-0.3799]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7242]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[-0.3314]],\n",
      "\n",
      "        [[-0.2459]]], dtype=torch.float64)\n",
      "tensor([[-0.4066],\n",
      "        [-0.2810],\n",
      "        [-0.3650],\n",
      "        [-0.5085]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2563]],\n",
      "\n",
      "        [[-0.3776]],\n",
      "\n",
      "        [[-0.5394]],\n",
      "\n",
      "        [[-0.7277]]], dtype=torch.float64)\n",
      "tensor([[-0.5977],\n",
      "        [-0.4042],\n",
      "        [-0.7066],\n",
      "        [-0.7298]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2794]],\n",
      "\n",
      "        [[-0.2609]],\n",
      "\n",
      "        [[-0.6722]],\n",
      "\n",
      "        [[-0.9114]]], dtype=torch.float64)\n",
      "tensor([[-0.6182],\n",
      "        [-0.6066],\n",
      "        [-0.5906],\n",
      "        [-0.5387]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9588]],\n",
      "\n",
      "        [[-0.6977]],\n",
      "\n",
      "        [[-0.4562]],\n",
      "\n",
      "        [[-0.6526]]], dtype=torch.float64)\n",
      "tensor([[-0.7581],\n",
      "        [-0.6322],\n",
      "        [-0.2653],\n",
      "        [-0.0680]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6029]],\n",
      "\n",
      "        [[-0.5359]],\n",
      "\n",
      "        [[-0.0298]],\n",
      "\n",
      "        [[-0.0414]]], dtype=torch.float64)\n",
      "tensor([[-0.0793],\n",
      "        [ 0.0223],\n",
      "        [-0.0155],\n",
      "        [-0.0101]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0591]],\n",
      "\n",
      "        [[0.0915]],\n",
      "\n",
      "        [[0.1192]],\n",
      "\n",
      "        [[0.0349]]], dtype=torch.float64)\n",
      "tensor([[-0.1210],\n",
      "        [-0.3025],\n",
      "        [-0.3252],\n",
      "        [-0.2622]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2829]],\n",
      "\n",
      "        [[-0.3580]],\n",
      "\n",
      "        [[-0.0506]],\n",
      "\n",
      "        [[-0.2078]]], dtype=torch.float64)\n",
      "tensor([[-0.3032],\n",
      "        [-0.0965],\n",
      "        [-0.0345],\n",
      "        [-0.0183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2886]],\n",
      "\n",
      "        [[-0.0587]],\n",
      "\n",
      "        [[-0.0784]],\n",
      "\n",
      "        [[-0.1107]]], dtype=torch.float64)\n",
      "tensor([[-0.0444],\n",
      "        [-0.0092],\n",
      "        [-0.2101],\n",
      "        [-0.2467]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1816]],\n",
      "\n",
      "        [[ 0.2925]],\n",
      "\n",
      "        [[ 0.0984]],\n",
      "\n",
      "        [[-0.0622]]], dtype=torch.float64)\n",
      "tensor([[-0.3186],\n",
      "        [-0.2711],\n",
      "        [-0.2910],\n",
      "        [-0.2493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1800]],\n",
      "\n",
      "        [[-0.2494]],\n",
      "\n",
      "        [[ 0.0256]],\n",
      "\n",
      "        [[-0.1569]]], dtype=torch.float64)\n",
      "tensor([[-0.2629],\n",
      "        [-0.3459],\n",
      "        [-0.4246],\n",
      "        [-0.4569]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3337]],\n",
      "\n",
      "        [[-0.4284]],\n",
      "\n",
      "        [[-0.5059]],\n",
      "\n",
      "        [[-0.4585]]], dtype=torch.float64)\n",
      "tensor([[-0.4805],\n",
      "        [-0.4150],\n",
      "        [-0.4149],\n",
      "        [-0.3487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4677]],\n",
      "\n",
      "        [[-0.4261]],\n",
      "\n",
      "        [[-0.3741]],\n",
      "\n",
      "        [[-0.3892]]], dtype=torch.float64)\n",
      "tensor([[-0.3551],\n",
      "        [-0.3689],\n",
      "        [-0.4060],\n",
      "        [-0.3814]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4296]],\n",
      "\n",
      "        [[-0.4851]],\n",
      "\n",
      "        [[-0.3048]],\n",
      "\n",
      "        [[-0.3302]]], dtype=torch.float64)\n",
      "tensor([[-0.4690],\n",
      "        [-0.3377],\n",
      "        [-0.1072],\n",
      "        [-0.1641]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3591]],\n",
      "\n",
      "        [[-0.2898]],\n",
      "\n",
      "        [[-0.2447]],\n",
      "\n",
      "        [[-0.0818]]], dtype=torch.float64)\n",
      "tensor([[-0.0415],\n",
      "        [-0.1501],\n",
      "        [-0.2423],\n",
      "        [-0.2308]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1030]],\n",
      "\n",
      "        [[-0.0449]],\n",
      "\n",
      "        [[-0.1823]],\n",
      "\n",
      "        [[-0.2020]]], dtype=torch.float64)\n",
      "tensor([[-0.1604],\n",
      "        [-0.4778],\n",
      "        [-0.3841],\n",
      "        [-0.3274]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1939]],\n",
      "\n",
      "        [[-0.6133]],\n",
      "\n",
      "        [[-0.2910]],\n",
      "\n",
      "        [[-0.4735]]], dtype=torch.float64)\n",
      "tensor([[-0.5871],\n",
      "        [-0.7395],\n",
      "        [-0.7935],\n",
      "        [-1.0151]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7242]],\n",
      "\n",
      "        [[-0.8999]],\n",
      "\n",
      "        [[-1.1552]],\n",
      "\n",
      "        [[-1.2083]]], dtype=torch.float64)\n",
      "tensor([[-0.8492],\n",
      "        [-0.5465],\n",
      "        [-0.8819],\n",
      "        [-0.9238]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4700]],\n",
      "\n",
      "        [[-0.6607]],\n",
      "\n",
      "        [[-1.0189]],\n",
      "\n",
      "        [[-1.0697]]], dtype=torch.float64)\n",
      "tensor([[-0.8130],\n",
      "        [-0.7318],\n",
      "        [-0.6681],\n",
      "        [-0.4992]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9426]],\n",
      "\n",
      "        [[-0.9264]],\n",
      "\n",
      "        [[-0.4204]],\n",
      "\n",
      "        [[-0.4620]]], dtype=torch.float64)\n",
      "tensor([[-0.7806],\n",
      "        [-0.8927],\n",
      "        [-0.7708],\n",
      "        [-0.6858]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9264]],\n",
      "\n",
      "        [[-1.0605]],\n",
      "\n",
      "        [[-0.7127]],\n",
      "\n",
      "        [[-0.8201]]], dtype=torch.float64)\n",
      "tensor([[-0.7797],\n",
      "        [-0.6608],\n",
      "        [-0.8228],\n",
      "        [-0.7179]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7473]],\n",
      "\n",
      "        [[-0.7265]],\n",
      "\n",
      "        [[-0.8987]],\n",
      "\n",
      "        [[-0.8409]]], dtype=torch.float64)\n",
      "tensor([[-0.5832],\n",
      "        [-0.5543],\n",
      "        [-0.5713],\n",
      "        [-0.3212]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6041]],\n",
      "\n",
      "        [[-0.5613]],\n",
      "\n",
      "        [[-0.3187]],\n",
      "\n",
      "        [[-0.2713]]], dtype=torch.float64)\n",
      "tensor([[-0.4018],\n",
      "        [-0.3829],\n",
      "        [-0.4439],\n",
      "        [-0.4290]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2471]],\n",
      "\n",
      "        [[-0.4839]],\n",
      "\n",
      "        [[-0.4596]],\n",
      "\n",
      "        [[-0.4724]]], dtype=torch.float64)\n",
      "tensor([[-0.4315],\n",
      "        [-0.2273],\n",
      "        [-0.2204],\n",
      "        [-0.0463]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2748]],\n",
      "\n",
      "        [[-0.0576]],\n",
      "\n",
      "        [[-0.0888]],\n",
      "\n",
      "        [[ 0.0869]]], dtype=torch.float64)\n",
      "tensor([[-0.0801],\n",
      "        [-0.2260],\n",
      "        [-0.3658],\n",
      "        [-0.3695]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1719]],\n",
      "\n",
      "        [[-0.3614]],\n",
      "\n",
      "        [[-0.2678]],\n",
      "\n",
      "        [[-0.1847]]], dtype=torch.float64)\n",
      "tensor([[-0.4879],\n",
      "        [-0.2772],\n",
      "        [-0.2115],\n",
      "        [-0.3636]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3996]],\n",
      "\n",
      "        [[-0.3129]],\n",
      "\n",
      "        [[-0.2898]],\n",
      "\n",
      "        [[-0.3014]]], dtype=torch.float64)\n",
      "tensor([[-0.3552],\n",
      "        [-0.3682],\n",
      "        [-0.5857],\n",
      "        [-0.7260]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1847]],\n",
      "\n",
      "        [[-0.3106]],\n",
      "\n",
      "        [[-0.7057]],\n",
      "\n",
      "        [[-0.9010]]], dtype=torch.float64)\n",
      "tensor([[-0.7471],\n",
      "        [-0.5068],\n",
      "        [-0.2912],\n",
      "        [-0.3019]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8837]],\n",
      "\n",
      "        [[-0.5059]],\n",
      "\n",
      "        [[-0.1904]],\n",
      "\n",
      "        [[-0.1627]]], dtype=torch.float64)\n",
      "tensor([[-0.1700],\n",
      "        [-0.0242],\n",
      "        [-0.1181],\n",
      "        [-0.1861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0137]],\n",
      "\n",
      "        [[-0.0599]],\n",
      "\n",
      "        [[-0.2459]],\n",
      "\n",
      "        [[-0.2494]]], dtype=torch.float64)\n",
      "tensor([[ 0.0082],\n",
      "        [ 0.0611],\n",
      "        [-0.0672],\n",
      "        [ 0.0440]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3364]],\n",
      "\n",
      "        [[0.3607]],\n",
      "\n",
      "        [[0.1712]],\n",
      "\n",
      "        [[0.1042]]], dtype=torch.float64)\n",
      "tensor([[ 0.0402],\n",
      "        [-0.0259],\n",
      "        [ 0.1041],\n",
      "        [ 0.0015]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0737]],\n",
      "\n",
      "        [[ 0.2128]],\n",
      "\n",
      "        [[ 0.3838]],\n",
      "\n",
      "        [[ 0.2163]]], dtype=torch.float64)\n",
      "tensor([[-0.1287],\n",
      "        [-0.3921],\n",
      "        [-0.4646],\n",
      "        [-0.2023]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1951]],\n",
      "\n",
      "        [[-0.5694]],\n",
      "\n",
      "        [[-0.4712]],\n",
      "\n",
      "        [[-0.0333]]], dtype=torch.float64)\n",
      "tensor([[ 0.0702],\n",
      "        [ 0.0424],\n",
      "        [ 0.0593],\n",
      "        [-0.1985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4219]],\n",
      "\n",
      "        [[ 0.3260]],\n",
      "\n",
      "        [[-0.0691]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[-0.4109],\n",
      "        [-0.4899],\n",
      "        [-0.4775],\n",
      "        [-0.4326]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4585]],\n",
      "\n",
      "        [[-0.4781]],\n",
      "\n",
      "        [[-0.2759]],\n",
      "\n",
      "        [[-0.3464]]], dtype=torch.float64)\n",
      "tensor([[-0.4784],\n",
      "        [-0.6602],\n",
      "        [-0.6515],\n",
      "        [-0.7833]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5359]],\n",
      "\n",
      "        [[-0.7092]],\n",
      "\n",
      "        [[-0.8744]],\n",
      "\n",
      "        [[-1.0373]]], dtype=torch.float64)\n",
      "tensor([[-0.7301],\n",
      "        [-0.3613],\n",
      "        [-0.4395],\n",
      "        [-0.6023]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5174]],\n",
      "\n",
      "        [[-0.3268]],\n",
      "\n",
      "        [[-0.4354]],\n",
      "\n",
      "        [[-0.6642]]], dtype=torch.float64)\n",
      "tensor([[-0.6001],\n",
      "        [-0.7017],\n",
      "        [-0.6343],\n",
      "        [-0.6549]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7497]],\n",
      "\n",
      "        [[-0.7936]],\n",
      "\n",
      "        [[-0.4955]],\n",
      "\n",
      "        [[-0.6133]]], dtype=torch.float64)\n",
      "tensor([[-0.8977],\n",
      "        [-1.0621],\n",
      "        [-1.0484],\n",
      "        [-1.1299]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1494]],\n",
      "\n",
      "        [[-1.3620]],\n",
      "\n",
      "        [[-1.3378]],\n",
      "\n",
      "        [[-1.3828]]], dtype=torch.float64)\n",
      "tensor([[-0.8114],\n",
      "        [-0.5337],\n",
      "        [-0.6094],\n",
      "        [-0.6583]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5891]],\n",
      "\n",
      "        [[-0.4388]],\n",
      "\n",
      "        [[-0.6618]],\n",
      "\n",
      "        [[-0.7612]]], dtype=torch.float64)\n",
      "tensor([[-0.5848],\n",
      "        [-0.6561],\n",
      "        [-0.6762],\n",
      "        [-0.7127]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7728]],\n",
      "\n",
      "        [[-0.8525]],\n",
      "\n",
      "        [[-0.6965]],\n",
      "\n",
      "        [[-0.7589]]], dtype=torch.float64)\n",
      "tensor([[-0.7469],\n",
      "        [-0.6418],\n",
      "        [-0.5980],\n",
      "        [-0.6197]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7982]],\n",
      "\n",
      "        [[-0.7300]],\n",
      "\n",
      "        [[-0.7566]],\n",
      "\n",
      "        [[-0.8109]]], dtype=torch.float64)\n",
      "tensor([[-0.5939],\n",
      "        [-0.5314],\n",
      "        [-0.7923],\n",
      "        [-0.8065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.5971]],\n",
      "\n",
      "        [[-0.9599]],\n",
      "\n",
      "        [[-0.8710]]], dtype=torch.float64)\n",
      "tensor([[-0.6447],\n",
      "        [-0.5034],\n",
      "        [-0.5135],\n",
      "        [-0.4363]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8063]],\n",
      "\n",
      "        [[-0.6665]],\n",
      "\n",
      "        [[-0.4400]],\n",
      "\n",
      "        [[-0.3741]]], dtype=torch.float64)\n",
      "tensor([[-0.4956],\n",
      "        [-0.4184],\n",
      "        [-0.3213],\n",
      "        [-0.2165]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4596]],\n",
      "\n",
      "        [[-0.3684]],\n",
      "\n",
      "        [[-0.3984]],\n",
      "\n",
      "        [[-0.3152]]], dtype=torch.float64)\n",
      "tensor([[-0.2231],\n",
      "        [-0.2761],\n",
      "        [-0.4447],\n",
      "        [-0.6863]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2078]],\n",
      "\n",
      "        [[-0.2586]],\n",
      "\n",
      "        [[-0.5821]],\n",
      "\n",
      "        [[-0.7150]]], dtype=torch.float64)\n",
      "tensor([[-0.5659],\n",
      "        [-0.6233],\n",
      "        [-0.5811],\n",
      "        [-0.3268]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8432]],\n",
      "\n",
      "        [[-0.8571]],\n",
      "\n",
      "        [[-0.3788]],\n",
      "\n",
      "        [[-0.3002]]], dtype=torch.float64)\n",
      "tensor([[-0.5656],\n",
      "        [-0.8284],\n",
      "        [-0.9178],\n",
      "        [-0.8195]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8248]],\n",
      "\n",
      "        [[-1.1159]],\n",
      "\n",
      "        [[-1.0558]],\n",
      "\n",
      "        [[-0.8051]]], dtype=torch.float64)\n",
      "tensor([[-0.7174],\n",
      "        [-0.6776],\n",
      "        [-0.7708],\n",
      "        [-0.7934]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7219]],\n",
      "\n",
      "        [[-0.6561]],\n",
      "\n",
      "        [[-0.7624]],\n",
      "\n",
      "        [[-0.9311]]], dtype=torch.float64)\n",
      "tensor([[-0.9444],\n",
      "        [-0.9857],\n",
      "        [-1.0876],\n",
      "        [-1.1805]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0524]],\n",
      "\n",
      "        [[-1.1136]],\n",
      "\n",
      "        [[-1.1841]],\n",
      "\n",
      "        [[-1.2037]]], dtype=torch.float64)\n",
      "tensor([[-1.1838],\n",
      "        [-1.1098],\n",
      "        [-1.0350],\n",
      "        [-1.0523]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2141]],\n",
      "\n",
      "        [[-1.1991]],\n",
      "\n",
      "        [[-1.2222]],\n",
      "\n",
      "        [[-1.2280]]], dtype=torch.float64)\n",
      "tensor([[-1.0956],\n",
      "        [-1.1525],\n",
      "        [-1.1615],\n",
      "        [-1.0868]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2060]],\n",
      "\n",
      "        [[-1.1714]],\n",
      "\n",
      "        [[-1.1691]],\n",
      "\n",
      "        [[-1.1737]]], dtype=torch.float64)\n",
      "tensor([[-1.0565],\n",
      "        [-1.0666],\n",
      "        [-1.1357],\n",
      "        [-1.2207]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1945]],\n",
      "\n",
      "        [[-1.2488]],\n",
      "\n",
      "        [[-1.1679]],\n",
      "\n",
      "        [[-1.1991]]], dtype=torch.float64)\n",
      "tensor([[-1.3216],\n",
      "        [-1.3681],\n",
      "        [-1.3605],\n",
      "        [-1.3435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3308]],\n",
      "\n",
      "        [[-1.4360]],\n",
      "\n",
      "        [[-1.5307]],\n",
      "\n",
      "        [[-1.5122]]], dtype=torch.float64)\n",
      "tensor([[-1.3706],\n",
      "        [-1.3299],\n",
      "        [-1.3106],\n",
      "        [-1.1200]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3678]],\n",
      "\n",
      "        [[-1.2707]],\n",
      "\n",
      "        [[-1.2569]],\n",
      "\n",
      "        [[-1.2534]]], dtype=torch.float64)\n",
      "tensor([[-1.1021],\n",
      "        [-1.1854],\n",
      "        [-1.3135],\n",
      "        [-1.4653]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2800]],\n",
      "\n",
      "        [[-1.3077]],\n",
      "\n",
      "        [[-1.3562]],\n",
      "\n",
      "        [[-1.5226]]], dtype=torch.float64)\n",
      "tensor([[-1.6284],\n",
      "        [-1.6246],\n",
      "        [-1.6383],\n",
      "        [-1.6645]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6497]],\n",
      "\n",
      "        [[-1.7248]],\n",
      "\n",
      "        [[-1.8508]],\n",
      "\n",
      "        [[-1.9582]]], dtype=torch.float64)\n",
      "tensor([[-1.8432],\n",
      "        [-1.9141],\n",
      "        [-1.8275],\n",
      "        [-1.7187]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9559]],\n",
      "\n",
      "        [[-2.0229]],\n",
      "\n",
      "        [[-2.0206]],\n",
      "\n",
      "        [[-1.9351]]], dtype=torch.float64)\n",
      "tensor([[-1.5987],\n",
      "        [-1.8214],\n",
      "        [-2.0090],\n",
      "        [-1.9337]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.16623:  92%|█████████▏| 2828/3067 [00:08<00:00, 328.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.7664]],\n",
      "\n",
      "        [[-2.1431]],\n",
      "\n",
      "        [[-2.1361]],\n",
      "\n",
      "        [[-1.9339]]], dtype=torch.float64)\n",
      "tensor([[-1.7109],\n",
      "        [-1.5516],\n",
      "        [-1.0418],\n",
      "        [-0.9010]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7872]],\n",
      "\n",
      "        [[-1.4441]],\n",
      "\n",
      "        [[-1.0293]],\n",
      "\n",
      "        [[-0.9784]]], dtype=torch.float64)\n",
      "tensor([[-0.8696],\n",
      "        [-0.8321],\n",
      "        [-0.9055],\n",
      "        [-1.0548]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6676]],\n",
      "\n",
      "        [[-0.7081]],\n",
      "\n",
      "        [[-1.0154]],\n",
      "\n",
      "        [[-0.9981]]], dtype=torch.float64)\n",
      "tensor([[-1.1084],\n",
      "        [-1.2369],\n",
      "        [-1.0766],\n",
      "        [-0.9586]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2904]],\n",
      "\n",
      "        [[-1.2442]],\n",
      "\n",
      "        [[-0.8028]],\n",
      "\n",
      "        [[-0.7901]]], dtype=torch.float64)\n",
      "tensor([[-1.1735],\n",
      "        [-1.3946],\n",
      "        [-1.4036],\n",
      "        [-1.5628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1113]],\n",
      "\n",
      "        [[-1.2615]],\n",
      "\n",
      "        [[-1.4244]],\n",
      "\n",
      "        [[-1.5434]]], dtype=torch.float64)\n",
      "tensor([[-1.7296],\n",
      "        [-1.7212],\n",
      "        [-1.6744],\n",
      "        [-1.6153]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5457]],\n",
      "\n",
      "        [[-1.4845]],\n",
      "\n",
      "        [[-1.4464]],\n",
      "\n",
      "        [[-1.4071]]], dtype=torch.float64)\n",
      "tensor([[-1.4102],\n",
      "        [-1.1521],\n",
      "        [-1.1715],\n",
      "        [-1.0431]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2754]],\n",
      "\n",
      "        [[-1.2453]],\n",
      "\n",
      "        [[-0.8779]],\n",
      "\n",
      "        [[-0.9507]]], dtype=torch.float64)\n",
      "tensor([[-1.3645],\n",
      "        [-1.5534],\n",
      "        [-1.4715],\n",
      "        [-1.4722]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3100]],\n",
      "\n",
      "        [[-1.4695]],\n",
      "\n",
      "        [[-1.4371]],\n",
      "\n",
      "        [[-1.4625]]], dtype=torch.float64)\n",
      "tensor([[-1.2845],\n",
      "        [-1.0104],\n",
      "        [-1.1806],\n",
      "        [-1.1108]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7601]],\n",
      "\n",
      "        [[-0.8571]],\n",
      "\n",
      "        [[-1.0709]],\n",
      "\n",
      "        [[-1.0108]]], dtype=torch.float64)\n",
      "tensor([[-0.9852],\n",
      "        [-0.8982],\n",
      "        [-0.7410],\n",
      "        [-0.3479]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0350]],\n",
      "\n",
      "        [[-0.9507]],\n",
      "\n",
      "        [[-0.2517]],\n",
      "\n",
      "        [[-0.1731]]], dtype=torch.float64)\n",
      "tensor([[-0.6103],\n",
      "        [-0.7939],\n",
      "        [-0.7575],\n",
      "        [-0.8207]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5324]],\n",
      "\n",
      "        [[-0.7208]],\n",
      "\n",
      "        [[-0.7751]],\n",
      "\n",
      "        [[-0.8444]]], dtype=torch.float64)\n",
      "tensor([[-0.8529],\n",
      "        [-0.7339],\n",
      "        [-0.8152],\n",
      "        [-0.9966]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7069]],\n",
      "\n",
      "        [[-0.5994]],\n",
      "\n",
      "        [[-0.7577]],\n",
      "\n",
      "        [[-1.0223]]], dtype=torch.float64)\n",
      "tensor([[-1.0345],\n",
      "        [-1.1083],\n",
      "        [-1.0365],\n",
      "        [-0.8626]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1021]],\n",
      "\n",
      "        [[-1.0951]],\n",
      "\n",
      "        [[-0.7173]],\n",
      "\n",
      "        [[-0.8097]]], dtype=torch.float64)\n",
      "tensor([[-1.0270],\n",
      "        [-1.0967],\n",
      "        [-1.0171],\n",
      "        [-0.9561]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0558]],\n",
      "\n",
      "        [[-1.1055]],\n",
      "\n",
      "        [[-1.1240]],\n",
      "\n",
      "        [[-0.9507]]], dtype=torch.float64)\n",
      "tensor([[-0.7758],\n",
      "        [-0.6587],\n",
      "        [-0.7754],\n",
      "        [-1.0401]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5347]],\n",
      "\n",
      "        [[-0.4874]],\n",
      "\n",
      "        [[-0.9056]],\n",
      "\n",
      "        [[-1.1240]]], dtype=torch.float64)\n",
      "tensor([[-1.0872],\n",
      "        [-1.0596],\n",
      "        [-0.8362],\n",
      "        [-0.7327]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2546]],\n",
      "\n",
      "        [[-1.1841]],\n",
      "\n",
      "        [[-0.4781]],\n",
      "\n",
      "        [[-0.5428]]], dtype=torch.float64)\n",
      "tensor([[-0.8123],\n",
      "        [-0.8776],\n",
      "        [-0.6338],\n",
      "        [-0.4267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6595]],\n",
      "\n",
      "        [[-0.8248]],\n",
      "\n",
      "        [[-0.4504]],\n",
      "\n",
      "        [[-0.5290]]], dtype=torch.float64)\n",
      "tensor([[-0.4261],\n",
      "        [-0.1835],\n",
      "        [-0.5127],\n",
      "        [-0.4997]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1696]],\n",
      "\n",
      "        [[-0.1246]],\n",
      "\n",
      "        [[-0.5024]],\n",
      "\n",
      "        [[-0.4215]]], dtype=torch.float64)\n",
      "tensor([[-0.3022],\n",
      "        [-0.2048],\n",
      "        [ 0.0132],\n",
      "        [ 0.2566]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2355]],\n",
      "\n",
      "        [[-0.1026]],\n",
      "\n",
      "        [[ 0.3295]],\n",
      "\n",
      "        [[ 0.1481]]], dtype=torch.float64)\n",
      "tensor([[-0.2763],\n",
      "        [-0.3610],\n",
      "        [-0.4863],\n",
      "        [-0.7116]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1026]],\n",
      "\n",
      "        [[-0.3718]],\n",
      "\n",
      "        [[-0.5856]],\n",
      "\n",
      "        [[-0.5983]]], dtype=torch.float64)\n",
      "tensor([[-0.3072],\n",
      "        [-0.4331],\n",
      "        [-0.3077],\n",
      "        [-0.4720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1951]],\n",
      "\n",
      "        [[-0.1072]],\n",
      "\n",
      "        [[-0.3048]],\n",
      "\n",
      "        [[-0.4943]]], dtype=torch.float64)\n",
      "tensor([[-0.4097],\n",
      "        [-0.3494],\n",
      "        [-0.4516],\n",
      "        [-0.3123]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3938]],\n",
      "\n",
      "        [[-0.4169]],\n",
      "\n",
      "        [[-0.2239]],\n",
      "\n",
      "        [[-0.2343]]], dtype=torch.float64)\n",
      "tensor([[-0.5912],\n",
      "        [-0.6891],\n",
      "        [-0.7680],\n",
      "        [-0.9322]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6353]],\n",
      "\n",
      "        [[-0.8028]],\n",
      "\n",
      "        [[-1.0200]],\n",
      "\n",
      "        [[-0.9854]]], dtype=torch.float64)\n",
      "tensor([[-0.7276],\n",
      "        [-0.4781],\n",
      "        [-0.5494],\n",
      "        [-0.5541]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2424]],\n",
      "\n",
      "        [[-0.2274]],\n",
      "\n",
      "        [[-0.4077]],\n",
      "\n",
      "        [[-0.5243]]], dtype=torch.float64)\n",
      "tensor([[-0.4640],\n",
      "        [-0.5105],\n",
      "        [-0.4797],\n",
      "        [-0.4052]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5209]],\n",
      "\n",
      "        [[-0.5359]],\n",
      "\n",
      "        [[-0.3360]],\n",
      "\n",
      "        [[-0.3349]]], dtype=torch.float64)\n",
      "tensor([[-0.5518],\n",
      "        [-0.6705],\n",
      "        [-0.6912],\n",
      "        [-0.7448]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5891]],\n",
      "\n",
      "        [[-0.8560]],\n",
      "\n",
      "        [[-0.9391]],\n",
      "\n",
      "        [[-0.7959]]], dtype=torch.float64)\n",
      "tensor([[-0.5166],\n",
      "        [-0.3086],\n",
      "        [-0.6136],\n",
      "        [-0.6479]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2667]],\n",
      "\n",
      "        [[-0.3071]],\n",
      "\n",
      "        [[-0.7808]],\n",
      "\n",
      "        [[-0.6410]]], dtype=torch.float64)\n",
      "tensor([[-0.3498],\n",
      "        [-0.3666],\n",
      "        [-0.2339],\n",
      "        [-0.3576]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6156]],\n",
      "\n",
      "        [[-0.4308]],\n",
      "\n",
      "        [[-0.1743]],\n",
      "\n",
      "        [[-0.2875]]], dtype=torch.float64)\n",
      "tensor([[-0.5463],\n",
      "        [-0.5506],\n",
      "        [-0.5479],\n",
      "        [-0.5691]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4943]],\n",
      "\n",
      "        [[-0.4897]],\n",
      "\n",
      "        [[-0.6826]],\n",
      "\n",
      "        [[-0.6422]]], dtype=torch.float64)\n",
      "tensor([[-0.4300],\n",
      "        [-0.2569],\n",
      "        [-0.5038],\n",
      "        [-0.3952]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3094]],\n",
      "\n",
      "        [[-0.2436]],\n",
      "\n",
      "        [[-0.4354]],\n",
      "\n",
      "        [[-0.1835]]], dtype=torch.float64)\n",
      "tensor([[-0.1174],\n",
      "        [-0.0726],\n",
      "        [ 0.0839],\n",
      "        [-0.0825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1038]],\n",
      "\n",
      "        [[ 0.0487]],\n",
      "\n",
      "        [[ 0.2625]],\n",
      "\n",
      "        [[-0.0714]]], dtype=torch.float64)\n",
      "tensor([[-0.1123],\n",
      "        [-0.1660],\n",
      "        [-0.1862],\n",
      "        [-0.1709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0610]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.2216]],\n",
      "\n",
      "        [[-0.3083]]], dtype=torch.float64)\n",
      "tensor([[-0.1635],\n",
      "        [-0.1525],\n",
      "        [-0.4612],\n",
      "        [-0.5225]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1431]],\n",
      "\n",
      "        [[-0.5059]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[-0.7069]]], dtype=torch.float64)\n",
      "tensor([[-0.5054],\n",
      "        [-0.6541],\n",
      "        [-0.3604],\n",
      "        [-0.0423]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9010]],\n",
      "\n",
      "        [[-0.8883]],\n",
      "\n",
      "        [[-0.1338]],\n",
      "\n",
      "        [[-0.0067]]], dtype=torch.float64)\n",
      "tensor([[-0.3473],\n",
      "        [-0.7332],\n",
      "        [-0.8521],\n",
      "        [-0.8721]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5902]],\n",
      "\n",
      "        [[-1.0073]],\n",
      "\n",
      "        [[-1.0997]],\n",
      "\n",
      "        [[-1.1737]]], dtype=torch.float64)\n",
      "tensor([[-0.8026],\n",
      "        [-0.2249],\n",
      "        [-0.3801],\n",
      "        [-0.4082]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5948]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[-0.3915]],\n",
      "\n",
      "        [[-0.5694]]], dtype=torch.float64)\n",
      "tensor([[-0.4593],\n",
      "        [-0.3760],\n",
      "        [-0.1819],\n",
      "        [-0.0643]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6029]],\n",
      "\n",
      "        [[-0.3522]],\n",
      "\n",
      "        [[ 0.0037]],\n",
      "\n",
      "        [[-0.0668]]], dtype=torch.float64)\n",
      "tensor([[-0.3116],\n",
      "        [-0.3587],\n",
      "        [-0.4107],\n",
      "        [-0.4710]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3522]],\n",
      "\n",
      "        [[-0.4966]],\n",
      "\n",
      "        [[-0.6399]],\n",
      "\n",
      "        [[-0.5706]]], dtype=torch.float64)\n",
      "tensor([[-0.2011],\n",
      "        [-0.0711],\n",
      "        [-0.3104],\n",
      "        [-0.5127]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0118]],\n",
      "\n",
      "        [[-0.0044]],\n",
      "\n",
      "        [[-0.4284]],\n",
      "\n",
      "        [[-0.6041]]], dtype=torch.float64)\n",
      "tensor([[-0.4774],\n",
      "        [-0.2693],\n",
      "        [-0.0585],\n",
      "        [-0.1018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5036]],\n",
      "\n",
      "        [[-0.4481]],\n",
      "\n",
      "        [[ 0.0718]],\n",
      "\n",
      "        [[-0.0576]]], dtype=torch.float64)\n",
      "tensor([[-0.3918],\n",
      "        [-0.5134],\n",
      "        [-0.6351],\n",
      "        [-0.7994]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4458]],\n",
      "\n",
      "        [[-0.6607]],\n",
      "\n",
      "        [[-1.0720]],\n",
      "\n",
      "        [[-0.8767]]], dtype=torch.float64)\n",
      "tensor([[-0.2170],\n",
      "        [-0.1705],\n",
      "        [-0.4280],\n",
      "        [-0.4468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1604]],\n",
      "\n",
      "        [[-0.1685]],\n",
      "\n",
      "        [[-0.4920]],\n",
      "\n",
      "        [[-0.5659]]], dtype=torch.float64)\n",
      "tensor([[-0.4931],\n",
      "        [-0.7615],\n",
      "        [-0.4277],\n",
      "        [-0.1270]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9103]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-0.0830]],\n",
      "\n",
      "        [[-0.0356]]], dtype=torch.float64)\n",
      "tensor([[-0.4519],\n",
      "        [-0.6406],\n",
      "        [-0.8798],\n",
      "        [-0.7686]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5428]],\n",
      "\n",
      "        [[-0.8051]],\n",
      "\n",
      "        [[-1.2707]],\n",
      "\n",
      "        [[-0.7970]]], dtype=torch.float64)\n",
      "tensor([[-0.2030],\n",
      "        [ 0.0490],\n",
      "        [-0.1368],\n",
      "        [-0.4239]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1250]],\n",
      "\n",
      "        [[ 0.4520]],\n",
      "\n",
      "        [[-0.1604]],\n",
      "\n",
      "        [[-0.4562]]], dtype=torch.float64)\n",
      "tensor([[-0.5920],\n",
      "        [-0.7209],\n",
      "        [-0.2600],\n",
      "        [ 0.1741]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7901]],\n",
      "\n",
      "        [[-0.7762]],\n",
      "\n",
      "        [[ 0.3930]],\n",
      "\n",
      "        [[ 0.4832]]], dtype=torch.float64)\n",
      "tensor([[-0.1616],\n",
      "        [-0.4676],\n",
      "        [-0.5020],\n",
      "        [-0.5217]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1615]],\n",
      "\n",
      "        [[-0.5417]],\n",
      "\n",
      "        [[-0.6480]],\n",
      "\n",
      "        [[-0.6457]]], dtype=torch.float64)\n",
      "tensor([[-0.2725],\n",
      "        [ 0.0798],\n",
      "        [-0.0813],\n",
      "        [-0.1736]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2278]],\n",
      "\n",
      "        [[ 0.2694]],\n",
      "\n",
      "        [[-0.0160]],\n",
      "\n",
      "        [[-0.3048]]], dtype=torch.float64)\n",
      "tensor([[-0.1620],\n",
      "        [-0.2592],\n",
      "        [-0.1187],\n",
      "        [-0.1229]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4354]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[ 0.0441]]], dtype=torch.float64)\n",
      "tensor([[-0.2718],\n",
      "        [-0.4154],\n",
      "        [-0.4657],\n",
      "        [-0.4647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3291]],\n",
      "\n",
      "        [[-0.5012]],\n",
      "\n",
      "        [[-0.6410]],\n",
      "\n",
      "        [[-0.6387]]], dtype=torch.float64)\n",
      "tensor([[-0.4690],\n",
      "        [-0.4016],\n",
      "        [-0.4863],\n",
      "        [-0.7017]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3129]],\n",
      "\n",
      "        [[-0.2228]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[-0.9599]]], dtype=torch.float64)\n",
      "tensor([[-0.7958],\n",
      "        [-0.7797],\n",
      "        [-0.3849],\n",
      "        [-0.0160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9830]],\n",
      "\n",
      "        [[-0.9518]],\n",
      "\n",
      "        [[ 0.0788]],\n",
      "\n",
      "        [[ 0.1654]]], dtype=torch.float64)\n",
      "tensor([[-0.3922],\n",
      "        [-0.5976],\n",
      "        [-0.6808],\n",
      "        [-0.7089]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4053]],\n",
      "\n",
      "        [[-0.8352]],\n",
      "\n",
      "        [[-0.9207]],\n",
      "\n",
      "        [[-0.9449]]], dtype=torch.float64)\n",
      "tensor([[-0.5216],\n",
      "        [-0.2290],\n",
      "        [-0.4056],\n",
      "        [-0.5931]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1269]],\n",
      "\n",
      "        [[-0.1673]],\n",
      "\n",
      "        [[-0.5116]],\n",
      "\n",
      "        [[-0.9622]]], dtype=torch.float64)\n",
      "tensor([[-0.8356],\n",
      "        [-0.9816],\n",
      "        [-0.4356],\n",
      "        [-0.0850]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2638]],\n",
      "\n",
      "        [[-1.2523]],\n",
      "\n",
      "        [[ 0.2694]],\n",
      "\n",
      "        [[ 0.1573]]], dtype=torch.float64)\n",
      "tensor([[-0.3337],\n",
      "        [-0.5225],\n",
      "        [-0.5760],\n",
      "        [-0.5508]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3106]],\n",
      "\n",
      "        [[-0.6722]],\n",
      "\n",
      "        [[-0.6607]],\n",
      "\n",
      "        [[-0.5047]]], dtype=torch.float64)\n",
      "tensor([[-0.3803],\n",
      "        [-0.2905],\n",
      "        [-0.3488],\n",
      "        [-0.4551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2829]],\n",
      "\n",
      "        [[-0.1812]],\n",
      "\n",
      "        [[-0.3326]],\n",
      "\n",
      "        [[-0.7023]]], dtype=torch.float64)\n",
      "tensor([[-0.6378],\n",
      "        [-0.8523],\n",
      "        [-0.3731],\n",
      "        [-0.2109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0697]],\n",
      "\n",
      "        [[-1.1021]],\n",
      "\n",
      "        [[ 0.0834]],\n",
      "\n",
      "        [[-0.2378]]], dtype=torch.float64)\n",
      "tensor([[-0.4971],\n",
      "        [-0.5488],\n",
      "        [-0.4914],\n",
      "        [-0.4973]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6306]],\n",
      "\n",
      "        [[-0.7393]],\n",
      "\n",
      "        [[-0.7554]],\n",
      "\n",
      "        [[-0.6306]]], dtype=torch.float64)\n",
      "tensor([[-0.3278],\n",
      "        [-0.1844],\n",
      "        [-0.3562],\n",
      "        [-0.6271]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1026]],\n",
      "\n",
      "        [[-0.0056]],\n",
      "\n",
      "        [[-0.4828]],\n",
      "\n",
      "        [[-0.8675]]], dtype=torch.float64)\n",
      "tensor([[-0.6301],\n",
      "        [-0.7411],\n",
      "        [-0.6887],\n",
      "        [-0.1825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0605]],\n",
      "\n",
      "        [[-1.1702]],\n",
      "\n",
      "        [[-0.1269]],\n",
      "\n",
      "        [[ 0.1181]]], dtype=torch.float64)\n",
      "tensor([[-0.2785],\n",
      "        [-0.4079],\n",
      "        [-0.5216],\n",
      "        [-0.6138]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4100]],\n",
      "\n",
      "        [[-0.6306]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[-0.7393]]], dtype=torch.float64)\n",
      "tensor([[-0.3303],\n",
      "        [-0.0608],\n",
      "        [-0.2248],\n",
      "        [-0.4359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0137]],\n",
      "\n",
      "        [[ 0.1481]],\n",
      "\n",
      "        [[-0.2182]],\n",
      "\n",
      "        [[-0.8352]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #1 - Loss = 0.16623:  93%|█████████▎| 2861/3067 [00:08<00:00, 320.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6966],\n",
      "        [-0.8068],\n",
      "        [-0.3251],\n",
      "        [ 0.5655]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0628]],\n",
      "\n",
      "        [[-1.1610]],\n",
      "\n",
      "        [[ 0.5317]],\n",
      "\n",
      "        [[ 1.1810]]], dtype=torch.float64)\n",
      "tensor([[ 0.3970],\n",
      "        [-0.2231],\n",
      "        [-0.5360],\n",
      "        [-0.7429]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1539]],\n",
      "\n",
      "        [[-0.5509]],\n",
      "\n",
      "        [[-1.0212]],\n",
      "\n",
      "        [[-0.6769]]], dtype=torch.float64)\n",
      "tensor([[ 0.0361],\n",
      "        [ 0.3449],\n",
      "        [ 0.1047],\n",
      "        [-0.3142]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7339]],\n",
      "\n",
      "        [[ 0.8113]],\n",
      "\n",
      "        [[ 0.0233]],\n",
      "\n",
      "        [[-0.5613]]], dtype=torch.float64)\n",
      "tensor([[-0.4875],\n",
      "        [-0.6985],\n",
      "        [-0.3392],\n",
      "        [-0.0266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9634]],\n",
      "\n",
      "        [[-0.8051]],\n",
      "\n",
      "        [[ 0.2036]],\n",
      "\n",
      "        [[ 0.2579]]], dtype=torch.float64)\n",
      "tensor([[-0.2344],\n",
      "        [-0.3304],\n",
      "        [-0.5605],\n",
      "        [-0.6766]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1096]],\n",
      "\n",
      "        [[-0.6838]],\n",
      "\n",
      "        [[-0.9415]],\n",
      "\n",
      "        [[-1.0062]]], dtype=torch.float64)\n",
      "tensor([[-0.4959],\n",
      "        [-0.0552],\n",
      "        [-0.1867],\n",
      "        [-0.5082]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1269]],\n",
      "\n",
      "        [[ 0.5109]],\n",
      "\n",
      "        [[-0.1107]],\n",
      "\n",
      "        [[-0.7808]]], dtype=torch.float64)\n",
      "tensor([[-0.6332],\n",
      "        [-0.7325],\n",
      "        [-0.0983],\n",
      "        [ 0.4572]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1101]],\n",
      "\n",
      "        [[-0.8294]],\n",
      "\n",
      "        [[ 0.6935]],\n",
      "\n",
      "        [[ 0.9557]]], dtype=torch.float64)\n",
      "tensor([[ 0.2381],\n",
      "        [-0.2391],\n",
      "        [-0.4488],\n",
      "        [-0.6399]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1908]],\n",
      "\n",
      "        [[-0.4978]],\n",
      "\n",
      "        [[-0.9484]],\n",
      "\n",
      "        [[-0.7589]]], dtype=torch.float64)\n",
      "tensor([[-0.0560],\n",
      "        [ 0.2307],\n",
      "        [ 0.1437],\n",
      "        [-0.3106]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4855]],\n",
      "\n",
      "        [[ 0.8645]],\n",
      "\n",
      "        [[ 0.1053]],\n",
      "\n",
      "        [[-0.2736]]], dtype=torch.float64)\n",
      "tensor([[ 0.0857],\n",
      "        [ 0.0780],\n",
      "        [-0.3623],\n",
      "        [-0.2998]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1573]],\n",
      "\n",
      "        [[-0.1269]],\n",
      "\n",
      "        [[-0.2598]],\n",
      "\n",
      "        [[-0.0599]]], dtype=torch.float64)\n",
      "tensor([[-0.2890],\n",
      "        [-0.3250],\n",
      "        [-0.0992],\n",
      "        [-0.0225]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2159]],\n",
      "\n",
      "        [[-0.2055]],\n",
      "\n",
      "        [[-0.0449]],\n",
      "\n",
      "        [[ 0.0892]]], dtype=torch.float64)\n",
      "tensor([[0.0062],\n",
      "        [0.0437],\n",
      "        [0.0041],\n",
      "        [0.2183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2278]],\n",
      "\n",
      "        [[0.0822]],\n",
      "\n",
      "        [[0.1400]],\n",
      "\n",
      "        [[0.0672]]], dtype=torch.float64)\n",
      "tensor([[ 0.1542],\n",
      "        [ 0.1609],\n",
      "        [ 0.0224],\n",
      "        [-0.0149]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0060]],\n",
      "\n",
      "        [[0.1469]],\n",
      "\n",
      "        [[0.2382]],\n",
      "\n",
      "        [[0.2579]]], dtype=torch.float64)\n",
      "tensor([[-0.0055],\n",
      "        [ 0.0314],\n",
      "        [ 0.1019],\n",
      "        [ 0.0321]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0499]],\n",
      "\n",
      "        [[-0.0056]],\n",
      "\n",
      "        [[-0.1038]],\n",
      "\n",
      "        [[-0.0391]]], dtype=torch.float64)\n",
      "tensor([[0.0134],\n",
      "        [0.0815],\n",
      "        [0.0602],\n",
      "        [0.0471]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3272]],\n",
      "\n",
      "        [[0.2336]],\n",
      "\n",
      "        [[0.0684]],\n",
      "\n",
      "        [[0.0337]]], dtype=torch.float64)\n",
      "tensor([[-0.0395],\n",
      "        [-0.0711],\n",
      "        [-0.0108],\n",
      "        [ 0.0162]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1523]],\n",
      "\n",
      "        [[-0.0737]],\n",
      "\n",
      "        [[ 0.1539]],\n",
      "\n",
      "        [[ 0.4693]]], dtype=torch.float64)\n",
      "tensor([[ 0.1003],\n",
      "        [ 0.2217],\n",
      "        [ 0.3076],\n",
      "        [-0.0817]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2047]],\n",
      "\n",
      "        [[ 0.1423]],\n",
      "\n",
      "        [[-0.2517]],\n",
      "\n",
      "        [[-0.1200]]], dtype=torch.float64)\n",
      "tensor([[0.4218],\n",
      "        [0.5860],\n",
      "        [0.5675],\n",
      "        [0.6480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0840]],\n",
      "\n",
      "        [[1.3081]],\n",
      "\n",
      "        [[0.8055]],\n",
      "\n",
      "        [[0.6195]]], dtype=torch.float64)\n",
      "tensor([[0.6159],\n",
      "        [0.4694],\n",
      "        [0.6614],\n",
      "        [0.6308]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4520]],\n",
      "\n",
      "        [[0.8691]],\n",
      "\n",
      "        [[1.1521]],\n",
      "\n",
      "        [[1.1302]]], dtype=torch.float64)\n",
      "tensor([[0.5551],\n",
      "        [0.6482],\n",
      "        [0.5401],\n",
      "        [0.7346]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1937]],\n",
      "\n",
      "        [[1.0713]],\n",
      "\n",
      "        [[0.8009]],\n",
      "\n",
      "        [[0.6357]]], dtype=torch.float64)\n",
      "tensor([[0.5975],\n",
      "        [0.6320],\n",
      "        [0.6972],\n",
      "        [0.6548]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3630]],\n",
      "\n",
      "        [[0.9800]],\n",
      "\n",
      "        [[1.2273]],\n",
      "\n",
      "        [[0.8887]]], dtype=torch.float64)\n",
      "tensor([[ 0.3725],\n",
      "        [ 0.0073],\n",
      "        [-0.0263],\n",
      "        [ 0.1033]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0302]],\n",
      "\n",
      "        [[-0.1269]],\n",
      "\n",
      "        [[-0.1800]],\n",
      "\n",
      "        [[ 0.1608]]], dtype=torch.float64)\n",
      "tensor([[ 0.1263],\n",
      "        [ 0.0369],\n",
      "        [-0.0405],\n",
      "        [-0.2039]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1631]],\n",
      "\n",
      "        [[ 0.0834]],\n",
      "\n",
      "        [[-0.0760]],\n",
      "\n",
      "        [[-0.3372]]], dtype=torch.float64)\n",
      "tensor([[-0.2491],\n",
      "        [-0.2656],\n",
      "        [-0.2136],\n",
      "        [-0.2881]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5544]],\n",
      "\n",
      "        [[-0.3730]],\n",
      "\n",
      "        [[-0.1188]],\n",
      "\n",
      "        [[-0.1350]]], dtype=torch.float64)\n",
      "tensor([[-0.3630],\n",
      "        [-0.4643],\n",
      "        [-0.3414],\n",
      "        [-0.3901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6376]],\n",
      "\n",
      "        [[-0.5983]],\n",
      "\n",
      "        [[-0.6618]],\n",
      "\n",
      "        [[-0.5579]]], dtype=torch.float64)\n",
      "tensor([[-0.3463],\n",
      "        [-0.3365],\n",
      "        [-0.4694],\n",
      "        [-0.5022]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1847]],\n",
      "\n",
      "        [[-0.4550]],\n",
      "\n",
      "        [[-0.6376]],\n",
      "\n",
      "        [[-1.0339]]], dtype=torch.float64)\n",
      "tensor([[-0.5234],\n",
      "        [-0.4894],\n",
      "        [-0.3786],\n",
      "        [-0.3968]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1517]],\n",
      "\n",
      "        [[-0.6179]],\n",
      "\n",
      "        [[-0.3453]],\n",
      "\n",
      "        [[-0.3568]]], dtype=torch.float64)\n",
      "tensor([[-0.4915],\n",
      "        [-0.5655],\n",
      "        [-0.6337],\n",
      "        [-0.6677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8663]],\n",
      "\n",
      "        [[-1.1933]],\n",
      "\n",
      "        [[-1.3227]],\n",
      "\n",
      "        [[-0.8871]]], dtype=torch.float64)\n",
      "tensor([[-0.1580],\n",
      "        [-0.2122],\n",
      "        [-0.3230],\n",
      "        [-0.1627]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0314]],\n",
      "\n",
      "        [[ 0.0649]],\n",
      "\n",
      "        [[-0.2482]],\n",
      "\n",
      "        [[-0.4284]]], dtype=torch.float64)\n",
      "tensor([[-0.3062],\n",
      "        [-0.3295],\n",
      "        [-0.0179],\n",
      "        [-0.0241]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5625]],\n",
      "\n",
      "        [[-0.4100]],\n",
      "\n",
      "        [[ 0.3561]],\n",
      "\n",
      "        [[ 0.2428]]], dtype=torch.float64)\n",
      "tensor([[-0.1124],\n",
      "        [-0.1604],\n",
      "        [-0.3158],\n",
      "        [-0.4199]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0599]],\n",
      "\n",
      "        [[-0.3580]],\n",
      "\n",
      "        [[-0.7878]],\n",
      "\n",
      "        [[-0.4146]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.16632:  94%|█████████▍| 2894/3067 [00:09<00:00, 210.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1980],\n",
      "        [-0.3163],\n",
      "        [-0.2670],\n",
      "        [-0.1415]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2066]],\n",
      "\n",
      "        [[-0.2667]],\n",
      "\n",
      "        [[-0.3164]],\n",
      "\n",
      "        [[-0.4596]]], dtype=torch.float64)\n",
      "tensor([[-0.1361],\n",
      "        [-0.3109],\n",
      "        [ 0.1977],\n",
      "        [ 0.3600]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6572]],\n",
      "\n",
      "        [[-0.3961]],\n",
      "\n",
      "        [[ 0.6207]],\n",
      "\n",
      "        [[ 0.6449]]], dtype=torch.float64)\n",
      "tensor([[ 0.3004],\n",
      "        [ 0.0449],\n",
      "        [-0.2304],\n",
      "        [-0.1917]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2036]],\n",
      "\n",
      "        [[-0.4539]],\n",
      "\n",
      "        [[-0.7208]],\n",
      "\n",
      "        [[-0.4065]]], dtype=torch.float64)\n",
      "tensor([[0.5946],\n",
      "        [0.6725],\n",
      "        [0.4104],\n",
      "        [0.0756]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.1579]],\n",
      "\n",
      "        [[ 0.9095]],\n",
      "\n",
      "        [[ 0.2093]],\n",
      "\n",
      "        [[-0.2170]]], dtype=torch.float64)\n",
      "tensor([[-0.0952],\n",
      "        [-0.1083],\n",
      "        [ 0.4442],\n",
      "        [ 0.5955]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5197]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[ 0.7997]],\n",
      "\n",
      "        [[ 0.8055]]], dtype=torch.float64)\n",
      "tensor([[ 0.3608],\n",
      "        [ 0.0630],\n",
      "        [-0.1342],\n",
      "        [ 0.0131]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1100]],\n",
      "\n",
      "        [[-0.3418]],\n",
      "\n",
      "        [[-0.5636]],\n",
      "\n",
      "        [[ 0.2047]]], dtype=torch.float64)\n",
      "tensor([[0.5803],\n",
      "        [0.6379],\n",
      "        [0.5554],\n",
      "        [0.3168]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9869]],\n",
      "\n",
      "        [[ 0.8610]],\n",
      "\n",
      "        [[ 0.4543]],\n",
      "\n",
      "        [[-0.0206]]], dtype=torch.float64)\n",
      "tensor([[0.0118],\n",
      "        [0.2428],\n",
      "        [1.0235],\n",
      "        [1.0488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2886]],\n",
      "\n",
      "        [[ 0.6080]],\n",
      "\n",
      "        [[ 1.3543]],\n",
      "\n",
      "        [[ 1.2538]]], dtype=torch.float64)\n",
      "tensor([[0.6880],\n",
      "        [0.3609],\n",
      "        [0.0459],\n",
      "        [0.2530]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3803]],\n",
      "\n",
      "        [[-0.1026]],\n",
      "\n",
      "        [[-0.3210]],\n",
      "\n",
      "        [[ 0.5721]]], dtype=torch.float64)\n",
      "tensor([[1.0300],\n",
      "        [1.0636],\n",
      "        [0.7431],\n",
      "        [0.6066]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4895]],\n",
      "\n",
      "        [[1.2099]],\n",
      "\n",
      "        [[0.6923]],\n",
      "\n",
      "        [[0.2752]]], dtype=torch.float64)\n",
      "tensor([[0.4115],\n",
      "        [0.4460],\n",
      "        [0.5324],\n",
      "        [0.3167]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0695]],\n",
      "\n",
      "        [[0.6056]],\n",
      "\n",
      "        [[0.7674]],\n",
      "\n",
      "        [[0.5051]]], dtype=torch.float64)\n",
      "tensor([[0.1977],\n",
      "        [0.3198],\n",
      "        [0.2367],\n",
      "        [0.1604]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2821]],\n",
      "\n",
      "        [[ 0.0580]],\n",
      "\n",
      "        [[-0.0529]],\n",
      "\n",
      "        [[ 0.1377]]], dtype=torch.float64)\n",
      "tensor([[0.3870],\n",
      "        [0.2132],\n",
      "        [0.2538],\n",
      "        [0.2779]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7616]],\n",
      "\n",
      "        [[0.4889]],\n",
      "\n",
      "        [[0.2128]],\n",
      "\n",
      "        [[0.0025]]], dtype=torch.float64)\n",
      "tensor([[0.3285],\n",
      "        [0.4128],\n",
      "        [0.7535],\n",
      "        [0.6851]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0749]],\n",
      "\n",
      "        [[ 0.5987]],\n",
      "\n",
      "        [[ 1.0158]],\n",
      "\n",
      "        [[ 1.0285]]], dtype=torch.float64)\n",
      "tensor([[0.5588],\n",
      "        [0.3678],\n",
      "        [0.3616],\n",
      "        [0.4077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2914]],\n",
      "\n",
      "        [[ 0.0568]],\n",
      "\n",
      "        [[-0.1800]],\n",
      "\n",
      "        [[ 0.8749]]], dtype=torch.float64)\n",
      "tensor([[0.9080],\n",
      "        [1.1084],\n",
      "        [0.9015],\n",
      "        [0.8190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2839]],\n",
      "\n",
      "        [[1.2827]],\n",
      "\n",
      "        [[0.7778]],\n",
      "\n",
      "        [[0.5999]]], dtype=torch.float64)\n",
      "tensor([[1.0231],\n",
      "        [1.1120],\n",
      "        [0.5140],\n",
      "        [0.1684]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6715]],\n",
      "\n",
      "        [[0.3226]],\n",
      "\n",
      "        [[0.6946]],\n",
      "\n",
      "        [[0.1377]]], dtype=torch.float64)\n",
      "tensor([[-0.1935],\n",
      "        [-0.2589],\n",
      "        [-0.1885],\n",
      "        [-0.0368]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2413]],\n",
      "\n",
      "        [[-0.4423]],\n",
      "\n",
      "        [[-0.3626]],\n",
      "\n",
      "        [[-0.0252]]], dtype=torch.float64)\n",
      "tensor([[0.0603],\n",
      "        [0.0036],\n",
      "        [0.0266],\n",
      "        [0.0871]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1377]],\n",
      "\n",
      "        [[ 0.1238]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[-0.1731]]], dtype=torch.float64)\n",
      "tensor([[0.2049],\n",
      "        [0.1976],\n",
      "        [0.1832],\n",
      "        [0.0326]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1465]],\n",
      "\n",
      "        [[ 0.1539]],\n",
      "\n",
      "        [[ 0.2348]],\n",
      "\n",
      "        [[-0.0645]]], dtype=torch.float64)\n",
      "tensor([[0.0036],\n",
      "        [0.1531],\n",
      "        [0.2207],\n",
      "        [0.2065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0841]],\n",
      "\n",
      "        [[-0.1592]],\n",
      "\n",
      "        [[-0.2031]],\n",
      "\n",
      "        [[-0.0356]]], dtype=torch.float64)\n",
      "tensor([[0.2623],\n",
      "        [0.3132],\n",
      "        [0.1771],\n",
      "        [0.2588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3769]],\n",
      "\n",
      "        [[0.5017]],\n",
      "\n",
      "        [[0.2070]],\n",
      "\n",
      "        [[0.0060]]], dtype=torch.float64)\n",
      "tensor([[0.2424],\n",
      "        [0.1775],\n",
      "        [0.3592],\n",
      "        [0.4076]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0599]],\n",
      "\n",
      "        [[ 0.2174]],\n",
      "\n",
      "        [[ 0.5606]],\n",
      "\n",
      "        [[ 0.6565]]], dtype=torch.float64)\n",
      "tensor([[0.3674],\n",
      "        [0.3499],\n",
      "        [0.3922],\n",
      "        [0.3901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3387]],\n",
      "\n",
      "        [[0.1677]],\n",
      "\n",
      "        [[0.0360]],\n",
      "\n",
      "        [[0.4855]]], dtype=torch.float64)\n",
      "tensor([[0.3477],\n",
      "        [0.2714],\n",
      "        [0.2005],\n",
      "        [0.2579]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5837]],\n",
      "\n",
      "        [[ 0.4658]],\n",
      "\n",
      "        [[ 0.1100]],\n",
      "\n",
      "        [[-0.0576]]], dtype=torch.float64)\n",
      "tensor([[ 0.0203],\n",
      "        [-0.0779],\n",
      "        [-0.1405],\n",
      "        [-0.4284]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0980]],\n",
      "\n",
      "        [[-0.0402]],\n",
      "\n",
      "        [[ 0.2244]],\n",
      "\n",
      "        [[-0.4227]]], dtype=torch.float64)\n",
      "tensor([[-0.5319],\n",
      "        [-0.4773],\n",
      "        [-0.3956],\n",
      "        [-0.2723]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7115]],\n",
      "\n",
      "        [[-0.7231]],\n",
      "\n",
      "        [[-0.6480]],\n",
      "\n",
      "        [[-0.3487]]], dtype=torch.float64)\n",
      "tensor([[-0.1785],\n",
      "        [-0.3408],\n",
      "        [-0.4086],\n",
      "        [-0.2845]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3106]],\n",
      "\n",
      "        [[-0.2713]],\n",
      "\n",
      "        [[-0.6075]],\n",
      "\n",
      "        [[-0.6018]]], dtype=torch.float64)\n",
      "tensor([[-0.2269],\n",
      "        [-0.2469],\n",
      "        [-0.2400],\n",
      "        [-0.2549]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6584]],\n",
      "\n",
      "        [[-0.4539]],\n",
      "\n",
      "        [[ 0.0510]],\n",
      "\n",
      "        [[ 0.0903]]], dtype=torch.float64)\n",
      "tensor([[-0.4133],\n",
      "        [-0.5565],\n",
      "        [-0.6272],\n",
      "        [-0.3325]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5405]],\n",
      "\n",
      "        [[-1.0709]],\n",
      "\n",
      "        [[-1.2407]],\n",
      "\n",
      "        [[ 0.0730]]], dtype=torch.float64)\n",
      "tensor([[ 0.2904],\n",
      "        [ 0.2874],\n",
      "        [ 0.0190],\n",
      "        [-0.2126]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4624]],\n",
      "\n",
      "        [[ 0.5051]],\n",
      "\n",
      "        [[ 0.0141]],\n",
      "\n",
      "        [[-0.2979]]], dtype=torch.float64)\n",
      "tensor([[ 0.2000],\n",
      "        [-0.2002],\n",
      "        [-0.2130],\n",
      "        [-0.3537]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3603]],\n",
      "\n",
      "        [[-0.3973]],\n",
      "\n",
      "        [[-0.1003]],\n",
      "\n",
      "        [[-0.2644]]], dtype=torch.float64)\n",
      "tensor([[-0.4297],\n",
      "        [-0.3952],\n",
      "        [-0.3857],\n",
      "        [-0.3017]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6306]],\n",
      "\n",
      "        [[-0.7589]],\n",
      "\n",
      "        [[-0.7785]],\n",
      "\n",
      "        [[-0.5163]]], dtype=torch.float64)\n",
      "tensor([[-0.1071],\n",
      "        [ 0.1603],\n",
      "        [ 0.2971],\n",
      "        [ 0.2597]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0788]],\n",
      "\n",
      "        [[0.7697]],\n",
      "\n",
      "        [[0.0788]],\n",
      "\n",
      "        [[0.1966]]], dtype=torch.float64)\n",
      "tensor([[0.4110],\n",
      "        [0.5356],\n",
      "        [0.5565],\n",
      "        [0.3700]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2763]],\n",
      "\n",
      "        [[0.7142]],\n",
      "\n",
      "        [[1.0008]],\n",
      "\n",
      "        [[0.4647]]], dtype=torch.float64)\n",
      "tensor([[ 0.1925],\n",
      "        [ 0.2138],\n",
      "        [-0.0508],\n",
      "        [-0.0240]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1204]],\n",
      "\n",
      "        [[-0.1812]],\n",
      "\n",
      "        [[-0.4007]],\n",
      "\n",
      "        [[ 0.3249]]], dtype=torch.float64)\n",
      "tensor([[0.5078],\n",
      "        [0.3469],\n",
      "        [0.3001],\n",
      "        [0.2638]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6472]],\n",
      "\n",
      "        [[ 0.7431]],\n",
      "\n",
      "        [[ 0.2960]],\n",
      "\n",
      "        [[-0.0079]]], dtype=torch.float64)\n",
      "tensor([[0.2534],\n",
      "        [0.4685],\n",
      "        [0.7627],\n",
      "        [0.6332]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1107]],\n",
      "\n",
      "        [[ 0.8240]],\n",
      "\n",
      "        [[ 1.0586]],\n",
      "\n",
      "        [[ 0.8460]]], dtype=torch.float64)\n",
      "tensor([[0.4863],\n",
      "        [0.3862],\n",
      "        [0.1154],\n",
      "        [0.4473]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5040]],\n",
      "\n",
      "        [[-0.0691]],\n",
      "\n",
      "        [[-0.2771]],\n",
      "\n",
      "        [[ 0.9500]]], dtype=torch.float64)\n",
      "tensor([[0.7341],\n",
      "        [0.6951],\n",
      "        [0.5472],\n",
      "        [0.4108]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1233]],\n",
      "\n",
      "        [[1.1926]],\n",
      "\n",
      "        [[0.4924]],\n",
      "\n",
      "        [[0.0672]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.16632:  97%|█████████▋| 2961/3067 [00:09<00:00, 259.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2115],\n",
      "        [0.4363],\n",
      "        [0.4962],\n",
      "        [0.4981]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1974]],\n",
      "\n",
      "        [[ 0.6241]],\n",
      "\n",
      "        [[ 0.7882]],\n",
      "\n",
      "        [[ 0.9419]]], dtype=torch.float64)\n",
      "tensor([[0.4709],\n",
      "        [0.4807],\n",
      "        [0.3921],\n",
      "        [0.3751]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5017]],\n",
      "\n",
      "        [[0.2024]],\n",
      "\n",
      "        [[0.1469]],\n",
      "\n",
      "        [[0.4728]]], dtype=torch.float64)\n",
      "tensor([[0.6382],\n",
      "        [0.8355],\n",
      "        [0.7263],\n",
      "        [0.6775]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2538]],\n",
      "\n",
      "        [[1.2792]],\n",
      "\n",
      "        [[0.8148]],\n",
      "\n",
      "        [[0.2452]]], dtype=torch.float64)\n",
      "tensor([[0.3646],\n",
      "        [0.5516],\n",
      "        [0.9329],\n",
      "        [0.7901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0268]],\n",
      "\n",
      "        [[0.9696]],\n",
      "\n",
      "        [[1.2862]],\n",
      "\n",
      "        [[1.1545]]], dtype=torch.float64)\n",
      "tensor([[0.6682],\n",
      "        [0.5178],\n",
      "        [0.3160],\n",
      "        [0.4435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5259]],\n",
      "\n",
      "        [[ 0.1285]],\n",
      "\n",
      "        [[-0.0657]],\n",
      "\n",
      "        [[ 1.0828]]], dtype=torch.float64)\n",
      "tensor([[0.7319],\n",
      "        [0.2935],\n",
      "        [0.3652],\n",
      "        [0.4854]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7397]],\n",
      "\n",
      "        [[0.4658]],\n",
      "\n",
      "        [[0.3411]],\n",
      "\n",
      "        [[0.3422]]], dtype=torch.float64)\n",
      "tensor([[0.5694],\n",
      "        [0.4544],\n",
      "        [0.3334],\n",
      "        [0.4122]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3064]],\n",
      "\n",
      "        [[0.2590]],\n",
      "\n",
      "        [[0.5132]],\n",
      "\n",
      "        [[0.7697]]], dtype=torch.float64)\n",
      "tensor([[0.5344],\n",
      "        [0.6106],\n",
      "        [0.3055],\n",
      "        [0.3624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5883]],\n",
      "\n",
      "        [[ 0.2278]],\n",
      "\n",
      "        [[-0.1107]],\n",
      "\n",
      "        [[ 0.6149]]], dtype=torch.float64)\n",
      "tensor([[0.7152],\n",
      "        [0.7478],\n",
      "        [0.5811],\n",
      "        [0.3525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9835]],\n",
      "\n",
      "        [[ 1.0840]],\n",
      "\n",
      "        [[ 0.3584]],\n",
      "\n",
      "        [[-0.0368]]], dtype=torch.float64)\n",
      "tensor([[0.1859],\n",
      "        [0.4153],\n",
      "        [0.7810],\n",
      "        [0.7176]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1639]],\n",
      "\n",
      "        [[ 0.8991]],\n",
      "\n",
      "        [[ 1.2469]],\n",
      "\n",
      "        [[ 1.2261]]], dtype=torch.float64)\n",
      "tensor([[0.6212],\n",
      "        [0.4913],\n",
      "        [0.5486],\n",
      "        [0.5335]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4693]],\n",
      "\n",
      "        [[0.2163]],\n",
      "\n",
      "        [[0.2163]],\n",
      "\n",
      "        [[0.5802]]], dtype=torch.float64)\n",
      "tensor([[0.6320],\n",
      "        [0.2572],\n",
      "        [0.2162],\n",
      "        [0.3883]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4566]],\n",
      "\n",
      "        [[0.3803]],\n",
      "\n",
      "        [[0.2544]],\n",
      "\n",
      "        [[0.1539]]], dtype=torch.float64)\n",
      "tensor([[ 0.4786],\n",
      "        [ 0.0254],\n",
      "        [-0.2814],\n",
      "        [-0.4535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1862]],\n",
      "\n",
      "        [[-0.1997]],\n",
      "\n",
      "        [[-0.4134]],\n",
      "\n",
      "        [[-0.4781]]], dtype=torch.float64)\n",
      "tensor([[-0.6259],\n",
      "        [-0.5315],\n",
      "        [-0.3905],\n",
      "        [-0.2377]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5948]],\n",
      "\n",
      "        [[-0.5821]],\n",
      "\n",
      "        [[-0.5451]],\n",
      "\n",
      "        [[-0.1512]]], dtype=torch.float64)\n",
      "tensor([[-0.1846],\n",
      "        [-0.2383],\n",
      "        [-0.2726],\n",
      "        [-0.4307]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0360]],\n",
      "\n",
      "        [[ 0.1192]],\n",
      "\n",
      "        [[-0.4677]],\n",
      "\n",
      "        [[-0.8733]]], dtype=torch.float64)\n",
      "tensor([[-0.5190],\n",
      "        [ 0.0300],\n",
      "        [-0.0328],\n",
      "        [-0.1190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8756]],\n",
      "\n",
      "        [[ 0.0210]],\n",
      "\n",
      "        [[ 0.2740]],\n",
      "\n",
      "        [[ 0.0742]]], dtype=torch.float64)\n",
      "tensor([[-0.3405],\n",
      "        [-0.3386],\n",
      "        [-0.3330],\n",
      "        [ 0.0359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3938]],\n",
      "\n",
      "        [[-0.6826]],\n",
      "\n",
      "        [[-0.6942]],\n",
      "\n",
      "        [[ 0.1469]]], dtype=torch.float64)\n",
      "tensor([[0.3284],\n",
      "        [0.2550],\n",
      "        [0.1432],\n",
      "        [0.1458]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6080]],\n",
      "\n",
      "        [[ 0.6692]],\n",
      "\n",
      "        [[ 0.1389]],\n",
      "\n",
      "        [[-0.3510]]], dtype=torch.float64)\n",
      "tensor([[-0.0517],\n",
      "        [ 0.5112],\n",
      "        [ 1.0213],\n",
      "        [ 0.9726]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3222]],\n",
      "\n",
      "        [[ 0.9615]],\n",
      "\n",
      "        [[ 1.3902]],\n",
      "\n",
      "        [[ 1.1776]]], dtype=torch.float64)\n",
      "tensor([[0.6559],\n",
      "        [0.8875],\n",
      "        [0.9007],\n",
      "        [0.6889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8240]],\n",
      "\n",
      "        [[0.6958]],\n",
      "\n",
      "        [[0.6276]],\n",
      "\n",
      "        [[0.6911]]], dtype=torch.float64)\n",
      "tensor([[0.5577],\n",
      "        [0.5001],\n",
      "        [0.4167],\n",
      "        [0.4225]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8956]],\n",
      "\n",
      "        [[0.8795]],\n",
      "\n",
      "        [[0.3075]],\n",
      "\n",
      "        [[0.1285]]], dtype=torch.float64)\n",
      "tensor([[0.4616],\n",
      "        [0.6541],\n",
      "        [0.6397],\n",
      "        [0.6081]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1296]],\n",
      "\n",
      "        [[0.6195]],\n",
      "\n",
      "        [[0.8517]],\n",
      "\n",
      "        [[0.7212]]], dtype=torch.float64)\n",
      "tensor([[0.3176],\n",
      "        [0.6023],\n",
      "        [0.7408],\n",
      "        [0.8636]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2671]],\n",
      "\n",
      "        [[0.3480]],\n",
      "\n",
      "        [[0.4624]],\n",
      "\n",
      "        [[0.9268]]], dtype=torch.float64)\n",
      "tensor([[0.7729],\n",
      "        [0.7557],\n",
      "        [0.4341],\n",
      "        [0.0731]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7189]],\n",
      "\n",
      "        [[ 0.8598]],\n",
      "\n",
      "        [[ 0.0314]],\n",
      "\n",
      "        [[-0.1997]]], dtype=torch.float64)\n",
      "tensor([[0.1789],\n",
      "        [0.5496],\n",
      "        [0.6272],\n",
      "        [0.4785]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1327]],\n",
      "\n",
      "        [[ 0.4739]],\n",
      "\n",
      "        [[ 0.7304]],\n",
      "\n",
      "        [[ 0.3688]]], dtype=torch.float64)\n",
      "tensor([[0.3460],\n",
      "        [0.4198],\n",
      "        [0.2278],\n",
      "        [0.3839]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2440]],\n",
      "\n",
      "        [[ 0.0522]],\n",
      "\n",
      "        [[-0.0287]],\n",
      "\n",
      "        [[ 0.4427]]], dtype=torch.float64)\n",
      "tensor([[0.3293],\n",
      "        [0.3382],\n",
      "        [0.0501],\n",
      "        [0.1195]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5017]],\n",
      "\n",
      "        [[ 0.3203]],\n",
      "\n",
      "        [[-0.0564]],\n",
      "\n",
      "        [[-0.1188]]], dtype=torch.float64)\n",
      "tensor([[0.2599],\n",
      "        [0.3656],\n",
      "        [0.3389],\n",
      "        [0.4116]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0095]],\n",
      "\n",
      "        [[0.3584]],\n",
      "\n",
      "        [[0.4913]],\n",
      "\n",
      "        [[0.5513]]], dtype=torch.float64)\n",
      "tensor([[0.1382],\n",
      "        [0.0423],\n",
      "        [0.1884],\n",
      "        [0.2164]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0638]],\n",
      "\n",
      "        [[-0.1592]],\n",
      "\n",
      "        [[-0.1835]],\n",
      "\n",
      "        [[ 0.1735]]], dtype=torch.float64)\n",
      "tensor([[0.1817],\n",
      "        [0.0724],\n",
      "        [0.0930],\n",
      "        [0.1057]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4716]],\n",
      "\n",
      "        [[ 0.1285]],\n",
      "\n",
      "        [[-0.0599]],\n",
      "\n",
      "        [[-0.2759]]], dtype=torch.float64)\n",
      "tensor([[-0.0265],\n",
      "        [ 0.1600],\n",
      "        [ 0.1919],\n",
      "        [ 0.1026]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3684]],\n",
      "\n",
      "        [[ 0.1654]],\n",
      "\n",
      "        [[ 0.2798]],\n",
      "\n",
      "        [[-0.0714]]], dtype=torch.float64)\n",
      "tensor([[-0.0791],\n",
      "        [ 0.0780],\n",
      "        [ 0.1102],\n",
      "        [ 0.1544]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1939]],\n",
      "\n",
      "        [[-0.3510]],\n",
      "\n",
      "        [[-0.4019]],\n",
      "\n",
      "        [[ 0.0903]]], dtype=torch.float64)\n",
      "tensor([[0.1003],\n",
      "        [0.0752],\n",
      "        [0.1900],\n",
      "        [0.3424]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1874]],\n",
      "\n",
      "        [[ 0.4358]],\n",
      "\n",
      "        [[ 0.1643]],\n",
      "\n",
      "        [[-0.1338]]], dtype=torch.float64)\n",
      "tensor([[0.2749],\n",
      "        [0.2010],\n",
      "        [0.2666],\n",
      "        [0.2044]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1777]],\n",
      "\n",
      "        [[ 0.4081]],\n",
      "\n",
      "        [[ 0.7062]],\n",
      "\n",
      "        [[ 0.8078]]], dtype=torch.float64)\n",
      "tensor([[0.4500],\n",
      "        [0.3716],\n",
      "        [0.3376],\n",
      "        [0.2822]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4797]],\n",
      "\n",
      "        [[ 0.0857]],\n",
      "\n",
      "        [[-0.0310]],\n",
      "\n",
      "        [[ 0.3411]]], dtype=torch.float64)\n",
      "tensor([[0.3459],\n",
      "        [0.3849],\n",
      "        [0.4992],\n",
      "        [0.5087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7974]],\n",
      "\n",
      "        [[0.8379]],\n",
      "\n",
      "        [[0.5560]],\n",
      "\n",
      "        [[0.1100]]], dtype=torch.float64)\n",
      "tensor([[0.5048],\n",
      "        [0.2557],\n",
      "        [0.2047],\n",
      "        [0.1565]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2255]],\n",
      "\n",
      "        [[0.2255]],\n",
      "\n",
      "        [[0.3341]],\n",
      "\n",
      "        [[0.2948]]], dtype=torch.float64)\n",
      "tensor([[0.2025],\n",
      "        [0.3098],\n",
      "        [0.3768],\n",
      "        [0.5352]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1539]],\n",
      "\n",
      "        [[0.0973]],\n",
      "\n",
      "        [[0.0603]],\n",
      "\n",
      "        [[0.6276]]], dtype=torch.float64)\n",
      "tensor([[0.7340],\n",
      "        [0.9809],\n",
      "        [0.8124],\n",
      "        [0.6352]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1926]],\n",
      "\n",
      "        [[1.5635]],\n",
      "\n",
      "        [[0.7697]],\n",
      "\n",
      "        [[0.2775]]], dtype=torch.float64)\n",
      "tensor([[0.5014],\n",
      "        [0.9221],\n",
      "        [1.1956],\n",
      "        [1.1414]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3722]],\n",
      "\n",
      "        [[1.6709]],\n",
      "\n",
      "        [[1.9193]],\n",
      "\n",
      "        [[1.6721]]], dtype=torch.float64)\n",
      "tensor([[0.9554],\n",
      "        [0.7965],\n",
      "        [0.6215],\n",
      "        [1.1173]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0574]],\n",
      "\n",
      "        [[0.4635]],\n",
      "\n",
      "        [[0.5421]],\n",
      "\n",
      "        [[1.8223]]], dtype=torch.float64)\n",
      "tensor([[1.4863],\n",
      "        [1.4420],\n",
      "        [1.1672],\n",
      "        [1.1127]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0672]],\n",
      "\n",
      "        [[1.9783]],\n",
      "\n",
      "        [[1.4271]],\n",
      "\n",
      "        [[0.8899]]], dtype=torch.float64)\n",
      "tensor([[0.9380],\n",
      "        [1.3630],\n",
      "        [1.4948],\n",
      "        [1.4206]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0193]],\n",
      "\n",
      "        [[1.9690]],\n",
      "\n",
      "        [[2.0892]],\n",
      "\n",
      "        [[2.0880]]], dtype=torch.float64)\n",
      "tensor([[1.4649],\n",
      "        [1.0567],\n",
      "        [0.7476],\n",
      "        [0.9215]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4271]],\n",
      "\n",
      "        [[0.6576]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[1.1764]]], dtype=torch.float64)\n",
      "tensor([[0.8390],\n",
      "        [0.7591],\n",
      "        [0.7723],\n",
      "        [0.6877]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0944]],\n",
      "\n",
      "        [[1.0840]],\n",
      "\n",
      "        [[0.6669]],\n",
      "\n",
      "        [[0.2717]]], dtype=torch.float64)\n",
      "tensor([[0.5125],\n",
      "        [0.8747],\n",
      "        [0.9379],\n",
      "        [0.6099]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3203]],\n",
      "\n",
      "        [[1.0355]],\n",
      "\n",
      "        [[1.1903]],\n",
      "\n",
      "        [[1.0389]]], dtype=torch.float64)\n",
      "tensor([[0.7335],\n",
      "        [0.6914],\n",
      "        [0.4452],\n",
      "        [0.6655]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5848]],\n",
      "\n",
      "        [[ 0.2290]],\n",
      "\n",
      "        [[-0.1165]],\n",
      "\n",
      "        [[ 1.0204]]], dtype=torch.float64)\n",
      "tensor([[0.9186],\n",
      "        [0.9546],\n",
      "        [0.8667],\n",
      "        [0.7319]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2573]],\n",
      "\n",
      "        [[1.4098]],\n",
      "\n",
      "        [[0.7582]],\n",
      "\n",
      "        [[0.2879]]], dtype=torch.float64)\n",
      "tensor([[0.5764],\n",
      "        [1.0590],\n",
      "        [1.2919],\n",
      "        [1.2501]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4173]],\n",
      "\n",
      "        [[1.4664]],\n",
      "\n",
      "        [[1.6028]],\n",
      "\n",
      "        [[1.6085]]], dtype=torch.float64)\n",
      "tensor([[1.1034],\n",
      "        [1.2164],\n",
      "        [1.0584],\n",
      "        [0.9469]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1857]],\n",
      "\n",
      "        [[0.9014]],\n",
      "\n",
      "        [[0.6033]],\n",
      "\n",
      "        [[0.8148]]], dtype=torch.float64)\n",
      "tensor([[0.8398],\n",
      "        [0.6860],\n",
      "        [0.7534],\n",
      "        [0.8252]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6807]],\n",
      "\n",
      "        [[0.9095]],\n",
      "\n",
      "        [[0.7108]],\n",
      "\n",
      "        [[0.3122]]], dtype=torch.float64)\n",
      "tensor([[0.6458],\n",
      "        [0.4096],\n",
      "        [0.2929],\n",
      "        [0.2316]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1412]],\n",
      "\n",
      "        [[0.1608]],\n",
      "\n",
      "        [[0.3376]],\n",
      "\n",
      "        [[0.3376]]], dtype=torch.float64)\n",
      "tensor([[0.2956],\n",
      "        [0.3801],\n",
      "        [0.3660],\n",
      "        [0.1496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0718]],\n",
      "\n",
      "        [[ 0.0534]],\n",
      "\n",
      "        [[-0.0668]],\n",
      "\n",
      "        [[-0.1916]]], dtype=torch.float64)\n",
      "tensor([[-0.0776],\n",
      "        [-0.1339],\n",
      "        [-0.1156],\n",
      "        [ 0.1244]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0934]],\n",
      "\n",
      "        [[-0.0529]],\n",
      "\n",
      "        [[-0.1280]],\n",
      "\n",
      "        [[-0.1604]]], dtype=torch.float64)\n",
      "tensor([[0.3247],\n",
      "        [0.4461],\n",
      "        [0.4658],\n",
      "        [0.5252]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1315]],\n",
      "\n",
      "        [[ 0.3722]],\n",
      "\n",
      "        [[ 0.6299]],\n",
      "\n",
      "        [[ 0.7709]]], dtype=torch.float64)\n",
      "tensor([[0.5124],\n",
      "        [0.3051],\n",
      "        [0.1233],\n",
      "        [0.7207]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1689]],\n",
      "\n",
      "        [[-0.2713]],\n",
      "\n",
      "        [[-0.1823]],\n",
      "\n",
      "        [[ 0.8171]]], dtype=torch.float64)\n",
      "tensor([[0.7966],\n",
      "        [0.8267],\n",
      "        [0.6889],\n",
      "        [0.4243]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.1556]],\n",
      "\n",
      "        [[ 1.2296]],\n",
      "\n",
      "        [[ 0.5363]],\n",
      "\n",
      "        [[-0.1153]]], dtype=torch.float64)\n",
      "tensor([[0.2273],\n",
      "        [0.7082],\n",
      "        [0.6902],\n",
      "        [0.7101]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0287]],\n",
      "\n",
      "        [[ 0.7108]],\n",
      "\n",
      "        [[ 1.0551]],\n",
      "\n",
      "        [[ 0.8298]]], dtype=torch.float64)\n",
      "tensor([[0.5883],\n",
      "        [0.5393],\n",
      "        [0.4618],\n",
      "        [0.7062]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3873]],\n",
      "\n",
      "        [[0.0684]],\n",
      "\n",
      "        [[0.1423]],\n",
      "\n",
      "        [[0.7801]]], dtype=torch.float64)\n",
      "tensor([[0.7357],\n",
      "        [0.6972],\n",
      "        [0.6920],\n",
      "        [0.6086]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9580]],\n",
      "\n",
      "        [[1.0355]],\n",
      "\n",
      "        [[0.4924]],\n",
      "\n",
      "        [[0.1712]]], dtype=torch.float64)\n",
      "tensor([[0.4499],\n",
      "        [0.7802],\n",
      "        [0.8935],\n",
      "        [0.8993]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1026]],\n",
      "\n",
      "        [[ 0.9442]],\n",
      "\n",
      "        [[ 1.2446]],\n",
      "\n",
      "        [[ 1.2977]]], dtype=torch.float64)\n",
      "tensor([[0.7841],\n",
      "        [0.6686],\n",
      "        [0.5310],\n",
      "        [1.0365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6495]],\n",
      "\n",
      "        [[0.2371]],\n",
      "\n",
      "        [[0.1238]],\n",
      "\n",
      "        [[1.3428]]], dtype=torch.float64)\n",
      "tensor([[1.1366],\n",
      "        [0.9765],\n",
      "        [1.0461],\n",
      "        [0.8243]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2365]],\n",
      "\n",
      "        [[1.3382]],\n",
      "\n",
      "        [[0.6264]],\n",
      "\n",
      "        [[0.4832]]], dtype=torch.float64)\n",
      "tensor([[0.8756],\n",
      "        [0.8047],\n",
      "        [0.6743],\n",
      "        [0.7258]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4474]],\n",
      "\n",
      "        [[0.6623]],\n",
      "\n",
      "        [[0.8991]],\n",
      "\n",
      "        [[1.0008]]], dtype=torch.float64)\n",
      "tensor([[0.6486],\n",
      "        [0.5428],\n",
      "        [0.3520],\n",
      "        [0.8930]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5467]],\n",
      "\n",
      "        [[0.0118]],\n",
      "\n",
      "        [[0.0349]],\n",
      "\n",
      "        [[1.3035]]], dtype=torch.float64)\n",
      "tensor([[1.3359],\n",
      "        [1.4083],\n",
      "        [1.1532],\n",
      "        [0.8635]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6963]],\n",
      "\n",
      "        [[1.8338]],\n",
      "\n",
      "        [[1.0493]],\n",
      "\n",
      "        [[0.3757]]], dtype=torch.float64)\n",
      "tensor([[0.6916],\n",
      "        [1.2824],\n",
      "        [1.7062],\n",
      "        [1.6771]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4705]],\n",
      "\n",
      "        [[1.8269]],\n",
      "\n",
      "        [[2.3965]],\n",
      "\n",
      "        [[2.2174]]], dtype=torch.float64)\n",
      "tensor([[1.5920],\n",
      "        [1.4024],\n",
      "        [1.1200],\n",
      "        [1.6358]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5658]],\n",
      "\n",
      "        [[0.9292]],\n",
      "\n",
      "        [[0.9754]],\n",
      "\n",
      "        [[2.3422]]], dtype=torch.float64)\n",
      "tensor([[2.2103],\n",
      "        [2.2086],\n",
      "        [1.8011],\n",
      "        [1.5075]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.7339]],\n",
      "\n",
      "        [[2.8136]],\n",
      "\n",
      "        [[1.7275]],\n",
      "\n",
      "        [[1.2885]]], dtype=torch.float64)\n",
      "tensor([[1.3813],\n",
      "        [1.5649],\n",
      "        [1.7278],\n",
      "        [2.0655]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1498]],\n",
      "\n",
      "        [[1.6097]],\n",
      "\n",
      "        [[2.2660]],\n",
      "\n",
      "        [[2.4982]]], dtype=torch.float64)\n",
      "tensor([[1.9407],\n",
      "        [1.8515],\n",
      "        [1.5857],\n",
      "        [1.9085]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9193]],\n",
      "\n",
      "        [[1.5646]],\n",
      "\n",
      "        [[1.3439]],\n",
      "\n",
      "        [[2.1296]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.16698:  99%|█████████▊| 3028/3067 [00:09<00:00, 288.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0163],\n",
      "        [1.9109],\n",
      "        [1.9143],\n",
      "        [1.7531]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2151]],\n",
      "\n",
      "        [[2.0175]],\n",
      "\n",
      "        [[1.7206]],\n",
      "\n",
      "        [[1.4803]]], dtype=torch.float64)\n",
      "tensor([[1.6822],\n",
      "        [1.7380],\n",
      "        [1.4043],\n",
      "        [1.2686]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4202]],\n",
      "\n",
      "        [[1.5149]],\n",
      "\n",
      "        [[1.3809]],\n",
      "\n",
      "        [[1.5600]]], dtype=torch.float64)\n",
      "tensor([[1.3060],\n",
      "        [1.3391],\n",
      "        [1.2643],\n",
      "        [1.0682]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2169]],\n",
      "\n",
      "        [[1.0077]],\n",
      "\n",
      "        [[0.8321]],\n",
      "\n",
      "        [[1.1025]]], dtype=torch.float64)\n",
      "tensor([[1.1027],\n",
      "        [1.0793],\n",
      "        [0.8276],\n",
      "        [0.8863]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4086]],\n",
      "\n",
      "        [[1.4387]],\n",
      "\n",
      "        [[0.8656]],\n",
      "\n",
      "        [[0.3907]]], dtype=torch.float64)\n",
      "tensor([[0.7345],\n",
      "        [1.0531],\n",
      "        [0.9580],\n",
      "        [0.8004]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5363]],\n",
      "\n",
      "        [[1.2041]],\n",
      "\n",
      "        [[1.3555]],\n",
      "\n",
      "        [[1.0424]]], dtype=torch.float64)\n",
      "tensor([[0.7513],\n",
      "        [0.8199],\n",
      "        [0.6207],\n",
      "        [0.6458]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6611]],\n",
      "\n",
      "        [[0.4543]],\n",
      "\n",
      "        [[0.3099]],\n",
      "\n",
      "        [[0.7119]]], dtype=torch.float64)\n",
      "tensor([[0.5946],\n",
      "        [0.5601],\n",
      "        [0.5100],\n",
      "        [0.5254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8910]],\n",
      "\n",
      "        [[0.7027]],\n",
      "\n",
      "        [[0.3018]],\n",
      "\n",
      "        [[0.0014]]], dtype=torch.float64)\n",
      "tensor([[0.5108],\n",
      "        [0.7719],\n",
      "        [0.6747],\n",
      "        [0.6263]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0372]],\n",
      "\n",
      "        [[0.8021]],\n",
      "\n",
      "        [[1.0678]],\n",
      "\n",
      "        [[1.1880]]], dtype=torch.float64)\n",
      "tensor([[0.6716],\n",
      "        [0.5747],\n",
      "        [0.5375],\n",
      "        [0.7232]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5791]],\n",
      "\n",
      "        [[0.0383]],\n",
      "\n",
      "        [[0.0095]],\n",
      "\n",
      "        [[0.9130]]], dtype=torch.float64)\n",
      "tensor([[0.9207],\n",
      "        [0.7696],\n",
      "        [0.6125],\n",
      "        [0.6870]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2365]],\n",
      "\n",
      "        [[0.9326]],\n",
      "\n",
      "        [[0.4959]],\n",
      "\n",
      "        [[0.3214]]], dtype=torch.float64)\n",
      "tensor([[0.6967],\n",
      "        [0.7518],\n",
      "        [0.7410],\n",
      "        [0.7808]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3087]],\n",
      "\n",
      "        [[0.7362]],\n",
      "\n",
      "        [[1.0331]],\n",
      "\n",
      "        [[1.4029]]], dtype=torch.float64)\n",
      "tensor([[0.7839],\n",
      "        [0.6786],\n",
      "        [0.5482],\n",
      "        [0.9618]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6935]],\n",
      "\n",
      "        [[0.1608]],\n",
      "\n",
      "        [[0.2509]],\n",
      "\n",
      "        [[1.2099]]], dtype=torch.float64)\n",
      "tensor([[1.0144],\n",
      "        [0.9769],\n",
      "        [0.8951],\n",
      "        [0.8045]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5900]],\n",
      "\n",
      "        [[1.6028]],\n",
      "\n",
      "        [[0.8413]],\n",
      "\n",
      "        [[0.3584]]], dtype=torch.float64)\n",
      "tensor([[0.6602],\n",
      "        [0.7081],\n",
      "        [0.6054],\n",
      "        [0.6718]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4554]],\n",
      "\n",
      "        [[0.5883]],\n",
      "\n",
      "        [[1.0089]],\n",
      "\n",
      "        [[0.6103]]], dtype=torch.float64)\n",
      "tensor([[0.4613],\n",
      "        [0.5904],\n",
      "        [0.6683],\n",
      "        [0.5652]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4635]],\n",
      "\n",
      "        [[0.2995]],\n",
      "\n",
      "        [[0.3052]],\n",
      "\n",
      "        [[0.4416]]], dtype=torch.float64)\n",
      "tensor([[0.5978],\n",
      "        [0.4928],\n",
      "        [0.5320],\n",
      "        [0.5623]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6646]],\n",
      "\n",
      "        [[0.7582]],\n",
      "\n",
      "        [[0.4554]],\n",
      "\n",
      "        [[0.3179]]], dtype=torch.float64)\n",
      "tensor([[0.5904],\n",
      "        [0.6358],\n",
      "        [0.5909],\n",
      "        [0.5598]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3122]],\n",
      "\n",
      "        [[0.7743]],\n",
      "\n",
      "        [[0.9049]],\n",
      "\n",
      "        [[0.9026]]], dtype=torch.float64)\n",
      "tensor([[0.5339],\n",
      "        [0.6838],\n",
      "        [0.7123],\n",
      "        [0.7325]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4589]],\n",
      "\n",
      "        [[0.3584]],\n",
      "\n",
      "        [[0.3549]],\n",
      "\n",
      "        [[0.8333]]], dtype=torch.float64)\n",
      "tensor([[0.7739],\n",
      "        [0.6705],\n",
      "        [0.6663],\n",
      "        [0.6710]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1660]],\n",
      "\n",
      "        [[1.0043]],\n",
      "\n",
      "        [[0.5768]],\n",
      "\n",
      "        [[0.1989]]], dtype=torch.float64)\n",
      "tensor([[0.6467],\n",
      "        [0.6551],\n",
      "        [0.5418],\n",
      "        [0.6473]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4393]],\n",
      "\n",
      "        [[0.5941]],\n",
      "\n",
      "        [[0.9904]],\n",
      "\n",
      "        [[1.1175]]], dtype=torch.float64)\n",
      "tensor([[0.7315],\n",
      "        [0.7372],\n",
      "        [0.5661],\n",
      "        [0.9279]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6657]],\n",
      "\n",
      "        [[0.2694]],\n",
      "\n",
      "        [[0.2844]],\n",
      "\n",
      "        [[0.9338]]], dtype=torch.float64)\n",
      "tensor([[0.8849],\n",
      "        [0.8498],\n",
      "        [0.5927],\n",
      "        [0.5952]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2850]],\n",
      "\n",
      "        [[0.7963]],\n",
      "\n",
      "        [[0.4543]],\n",
      "\n",
      "        [[0.2290]]], dtype=torch.float64)\n",
      "tensor([[0.6130],\n",
      "        [0.4322],\n",
      "        [0.3935],\n",
      "        [0.3204]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2879]],\n",
      "\n",
      "        [[0.3503]],\n",
      "\n",
      "        [[0.8598]],\n",
      "\n",
      "        [[0.5097]]], dtype=torch.float64)\n",
      "tensor([[0.3579],\n",
      "        [0.4730],\n",
      "        [0.4900],\n",
      "        [0.6887]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1261]],\n",
      "\n",
      "        [[0.1839]],\n",
      "\n",
      "        [[0.1042]],\n",
      "\n",
      "        [[0.7281]]], dtype=torch.float64)\n",
      "tensor([[0.8021],\n",
      "        [0.4591],\n",
      "        [0.4740],\n",
      "        [0.5079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8125]],\n",
      "\n",
      "        [[0.8980]],\n",
      "\n",
      "        [[0.3549]],\n",
      "\n",
      "        [[0.0071]]], dtype=torch.float64)\n",
      "tensor([[0.4197],\n",
      "        [0.8102],\n",
      "        [1.0518],\n",
      "        [1.1031]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0333]],\n",
      "\n",
      "        [[ 1.1914]],\n",
      "\n",
      "        [[ 1.5635]],\n",
      "\n",
      "        [[ 1.6455]]], dtype=torch.float64)\n",
      "tensor([[1.1348],\n",
      "        [0.9893],\n",
      "        [0.9503],\n",
      "        [1.1477]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0851]],\n",
      "\n",
      "        [[0.6056]],\n",
      "\n",
      "        [[0.6588]],\n",
      "\n",
      "        [[1.3959]]], dtype=torch.float64)\n",
      "tensor([[1.2553],\n",
      "        [0.9447],\n",
      "        [0.8833],\n",
      "        [1.0631]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6062]],\n",
      "\n",
      "        [[1.1267]],\n",
      "\n",
      "        [[0.9095]],\n",
      "\n",
      "        [[0.8078]]], dtype=torch.float64)\n",
      "tensor([[1.0947],\n",
      "        [1.2170],\n",
      "        [0.6240],\n",
      "        [0.4942]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7813]],\n",
      "\n",
      "        [[1.1394]],\n",
      "\n",
      "        [[0.6241]],\n",
      "\n",
      "        [[0.7974]]], dtype=torch.float64)\n",
      "tensor([[0.6250],\n",
      "        [0.6565],\n",
      "        [0.7324],\n",
      "        [0.7286]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5017]],\n",
      "\n",
      "        [[0.3214]],\n",
      "\n",
      "        [[0.4554]],\n",
      "\n",
      "        [[0.7524]]], dtype=torch.float64)\n",
      "tensor([[0.7924],\n",
      "        [0.6970],\n",
      "        [0.4826],\n",
      "        [0.4773]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9742]],\n",
      "\n",
      "        [[0.9742]],\n",
      "\n",
      "        [[0.4046]],\n",
      "\n",
      "        [[0.1342]]], dtype=torch.float64)\n",
      "tensor([[0.5028],\n",
      "        [0.6486],\n",
      "        [0.6791],\n",
      "        [0.7526]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1030]],\n",
      "\n",
      "        [[0.7235]],\n",
      "\n",
      "        [[1.1649]],\n",
      "\n",
      "        [[1.2400]]], dtype=torch.float64)\n",
      "tensor([[0.7200],\n",
      "        [0.6534],\n",
      "        [0.4766],\n",
      "        [0.7463]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7790]],\n",
      "\n",
      "        [[0.1851]],\n",
      "\n",
      "        [[0.2278]],\n",
      "\n",
      "        [[0.9661]]], dtype=torch.float64)\n",
      "tensor([[0.8058],\n",
      "        [0.8539],\n",
      "        [0.8022],\n",
      "        [0.6114]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3694]],\n",
      "\n",
      "        [[1.4757]],\n",
      "\n",
      "        [[0.7951]],\n",
      "\n",
      "        [[0.1920]]], dtype=torch.float64)\n",
      "tensor([[0.5137],\n",
      "        [0.8834],\n",
      "        [1.2383],\n",
      "        [1.2928]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1319]],\n",
      "\n",
      "        [[1.3359]],\n",
      "\n",
      "        [[1.9783]],\n",
      "\n",
      "        [[2.0984]]], dtype=torch.float64)\n",
      "tensor([[1.3094],\n",
      "        [1.0218],\n",
      "        [0.8611],\n",
      "        [1.3691]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2065]],\n",
      "\n",
      "        [[0.6484]],\n",
      "\n",
      "        [[0.7720]],\n",
      "\n",
      "        [[1.9875]]], dtype=torch.float64)\n",
      "tensor([[1.6712],\n",
      "        [1.7019],\n",
      "        [1.5011],\n",
      "        [1.3474]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3538]],\n",
      "\n",
      "        [[2.5051]],\n",
      "\n",
      "        [[1.8442]],\n",
      "\n",
      "        [[1.1614]]], dtype=torch.float64)\n",
      "tensor([[1.2710],\n",
      "        [1.4665],\n",
      "        [1.6133],\n",
      "        [1.3980]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1510]],\n",
      "\n",
      "        [[1.9055]],\n",
      "\n",
      "        [[1.9494]],\n",
      "\n",
      "        [[1.7622]]], dtype=torch.float64)\n",
      "tensor([[1.2844],\n",
      "        [1.3572],\n",
      "        [1.2905],\n",
      "        [1.6434]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2654]],\n",
      "\n",
      "        [[1.0239]],\n",
      "\n",
      "        [[1.1175]],\n",
      "\n",
      "        [[1.8731]]], dtype=torch.float64)\n",
      "tensor([[1.7594],\n",
      "        [1.9066],\n",
      "        [1.8091],\n",
      "        [1.6625]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2498]],\n",
      "\n",
      "        [[2.4497]],\n",
      "\n",
      "        [[1.7772]],\n",
      "\n",
      "        [[1.4237]]], dtype=torch.float64)\n",
      "tensor([[1.5266],\n",
      "        [1.2981],\n",
      "        [1.3384],\n",
      "        [1.2767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2723]],\n",
      "\n",
      "        [[1.2330]],\n",
      "\n",
      "        [[1.6628]],\n",
      "\n",
      "        [[1.5993]]], dtype=torch.float64)\n",
      "tensor([[1.1657],\n",
      "        [1.1680],\n",
      "        [1.1691],\n",
      "        [1.1645]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2873]],\n",
      "\n",
      "        [[0.9326]],\n",
      "\n",
      "        [[0.9107]],\n",
      "\n",
      "        [[1.0505]]], dtype=torch.float64)\n",
      "tensor([[1.0956],\n",
      "        [1.0067],\n",
      "        [1.0208],\n",
      "        [1.0142]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1972]],\n",
      "\n",
      "        [[1.0447]],\n",
      "\n",
      "        [[0.9060]],\n",
      "\n",
      "        [[0.7189]]], dtype=torch.float64)\n",
      "tensor([[0.8752],\n",
      "        [0.7488],\n",
      "        [0.6446],\n",
      "        [0.7159]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4115]],\n",
      "\n",
      "        [[0.4497]],\n",
      "\n",
      "        [[0.7096]],\n",
      "\n",
      "        [[0.8483]]], dtype=torch.float64)\n",
      "tensor([[0.7933],\n",
      "        [0.9479],\n",
      "        [0.9711],\n",
      "        [0.8829]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6403]],\n",
      "\n",
      "        [[0.5282]],\n",
      "\n",
      "        [[0.5040]],\n",
      "\n",
      "        [[0.5733]]], dtype=torch.float64)\n",
      "tensor([[0.9114],\n",
      "        [1.0508],\n",
      "        [0.9421],\n",
      "        [1.0573]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5554]],\n",
      "\n",
      "        [[0.9823]],\n",
      "\n",
      "        [[0.8679]],\n",
      "\n",
      "        [[0.5606]]], dtype=torch.float64)\n",
      "tensor([[0.9051],\n",
      "        [1.2429],\n",
      "        [1.5233],\n",
      "        [1.3038]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4450]],\n",
      "\n",
      "        [[1.4884]],\n",
      "\n",
      "        [[1.2920]],\n",
      "\n",
      "        [[0.8899]]], dtype=torch.float64)\n",
      "tensor([[0.8661],\n",
      "        [0.9592],\n",
      "        [0.8125],\n",
      "        [0.9087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7801]],\n",
      "\n",
      "        [[0.5363]],\n",
      "\n",
      "        [[0.4589]],\n",
      "\n",
      "        [[0.8309]]], dtype=torch.float64)\n",
      "tensor([[0.9311],\n",
      "        [1.0965],\n",
      "        [0.8814],\n",
      "        [0.9012]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2388]],\n",
      "\n",
      "        [[1.5681]],\n",
      "\n",
      "        [[0.8552]],\n",
      "\n",
      "        [[0.3930]]], dtype=torch.float64)\n",
      "tensor([[0.7334],\n",
      "        [0.9310],\n",
      "        [1.3284],\n",
      "        [0.9028]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2891]],\n",
      "\n",
      "        [[1.1059]],\n",
      "\n",
      "        [[1.1937]],\n",
      "\n",
      "        [[0.8471]]], dtype=torch.float64)\n",
      "tensor([[0.8759],\n",
      "        [1.1124],\n",
      "        [1.1927],\n",
      "        [1.3981]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8078]],\n",
      "\n",
      "        [[0.7986]],\n",
      "\n",
      "        [[0.8506]],\n",
      "\n",
      "        [[1.3555]]], dtype=torch.float64)\n",
      "tensor([[1.4384],\n",
      "        [1.4820],\n",
      "        [1.3477],\n",
      "        [1.2339]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8084]],\n",
      "\n",
      "        [[1.9205]],\n",
      "\n",
      "        [[1.1741]],\n",
      "\n",
      "        [[0.8541]]], dtype=torch.float64)\n",
      "tensor([[1.0952],\n",
      "        [1.4124],\n",
      "        [1.5108],\n",
      "        [1.5615]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8055]],\n",
      "\n",
      "        [[1.4953]],\n",
      "\n",
      "        [[1.8338]],\n",
      "\n",
      "        [[1.9448]]], dtype=torch.float64)\n",
      "tensor([[1.4624],\n",
      "        [1.3653],\n",
      "        [1.1561],\n",
      "        [1.4323]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3821]],\n",
      "\n",
      "        [[0.9257]],\n",
      "\n",
      "        [[0.9003]],\n",
      "\n",
      "        [[1.5669]]], dtype=torch.float64)\n",
      "tensor([[1.3902],\n",
      "        [1.4604],\n",
      "        [1.3824],\n",
      "        [1.2884]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7922]],\n",
      "\n",
      "        [[1.7229]],\n",
      "\n",
      "        [[1.2584]],\n",
      "\n",
      "        [[0.9488]]], dtype=torch.float64)\n",
      "tensor([[1.2366],\n",
      "        [1.5816],\n",
      "        [1.7099],\n",
      "        [1.6620]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9731]],\n",
      "\n",
      "        [[1.7911]],\n",
      "\n",
      "        [[2.1054]],\n",
      "\n",
      "        [[2.1285]]], dtype=torch.float64)\n",
      "tensor([[1.5129],\n",
      "        [1.2712],\n",
      "        [1.0351],\n",
      "        [1.4123]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4029]],\n",
      "\n",
      "        [[0.8448]],\n",
      "\n",
      "        [[0.7674]],\n",
      "\n",
      "        [[1.9378]]], dtype=torch.float64)\n",
      "tensor([[1.8021],\n",
      "        [1.8345],\n",
      "        [1.6343],\n",
      "        [1.5167]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2787]],\n",
      "\n",
      "        [[2.3434]],\n",
      "\n",
      "        [[1.6039]],\n",
      "\n",
      "        [[1.1568]]], dtype=torch.float64)\n",
      "tensor([[1.2680],\n",
      "        [1.6431],\n",
      "        [2.0489],\n",
      "        [2.1636]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9927]],\n",
      "\n",
      "        [[2.2209]],\n",
      "\n",
      "        [[2.5664]],\n",
      "\n",
      "        [[2.7073]]], dtype=torch.float64)\n",
      "tensor([[1.8653],\n",
      "        [1.6033],\n",
      "        [1.3331],\n",
      "        [1.5907]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9644]],\n",
      "\n",
      "        [[1.1614]],\n",
      "\n",
      "        [[1.1741]],\n",
      "\n",
      "        [[2.2163]]], dtype=torch.float64)\n",
      "tensor([[2.1931],\n",
      "        [2.2065],\n",
      "        [1.9012],\n",
      "        [1.7974]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.6773]],\n",
      "\n",
      "        [[2.6033]],\n",
      "\n",
      "        [[1.8708]],\n",
      "\n",
      "        [[1.5877]]], dtype=torch.float64)\n",
      "tensor([[1.6476],\n",
      "        [1.4321],\n",
      "        [1.2186],\n",
      "        [1.1377]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1695]],\n",
      "\n",
      "        [[1.3717]],\n",
      "\n",
      "        [[1.3024]],\n",
      "\n",
      "        [[1.5115]]], dtype=torch.float64)\n",
      "tensor([[1.3455],\n",
      "        [1.5380],\n",
      "        [1.4037],\n",
      "        [1.3720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3474]],\n",
      "\n",
      "        [[1.2816]],\n",
      "\n",
      "        [[1.0493]],\n",
      "\n",
      "        [[1.5080]]], dtype=torch.float64)\n",
      "tensor([[1.5191],\n",
      "        [1.5577],\n",
      "        [1.5011],\n",
      "        [1.4228]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9748]],\n",
      "\n",
      "        [[2.1065]],\n",
      "\n",
      "        [[1.6444]],\n",
      "\n",
      "        [[1.2457]]], dtype=torch.float64)\n",
      "tensor([[1.4433],\n",
      "        [1.4883],\n",
      "        [1.5911],\n",
      "        [1.5819]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1510]],\n",
      "\n",
      "        [[1.5450]],\n",
      "\n",
      "        [[2.0129]],\n",
      "\n",
      "        [[2.0118]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.16698: 100%|██████████| 3067/3067 [00:09<00:00, 313.99it/s]\n",
      "Epoch #2 - Loss = 0.16361:   1%|          | 31/3067 [00:00<00:09, 305.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4575],\n",
      "        [1.4288],\n",
      "        [1.1827],\n",
      "        [1.2811]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4826]],\n",
      "\n",
      "        [[1.0251]],\n",
      "\n",
      "        [[0.8217]],\n",
      "\n",
      "        [[1.3382]]], dtype=torch.float64)\n",
      "tensor([[1.3470],\n",
      "        [1.0051],\n",
      "        [0.9880],\n",
      "        [1.0617]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3936]],\n",
      "\n",
      "        [[1.3278]],\n",
      "\n",
      "        [[0.8413]],\n",
      "\n",
      "        [[0.7524]]], dtype=torch.float64)\n",
      "tensor([[1.1341],\n",
      "        [1.1147],\n",
      "        [1.0422],\n",
      "        [1.2834]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7281]],\n",
      "\n",
      "        [[0.8956]],\n",
      "\n",
      "        [[1.3312]],\n",
      "\n",
      "        [[1.5797]]], dtype=torch.float64)\n",
      "tensor([[1.2968],\n",
      "        [1.2393],\n",
      "        [1.1290],\n",
      "        [1.1867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0482]],\n",
      "\n",
      "        [[0.7270]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[1.4110]]], dtype=torch.float64)\n",
      "tensor([[1.7594],\n",
      "        [1.4252],\n",
      "        [1.3093],\n",
      "        [1.2583]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0407]],\n",
      "\n",
      "        [[1.3959]],\n",
      "\n",
      "        [[1.0574]],\n",
      "\n",
      "        [[0.7870]]], dtype=torch.float64)\n",
      "tensor([[1.1519],\n",
      "        [1.4741],\n",
      "        [1.9129],\n",
      "        [1.6031]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7374]],\n",
      "\n",
      "        [[1.5404]],\n",
      "\n",
      "        [[2.1019]],\n",
      "\n",
      "        [[1.1314]]], dtype=torch.float64)\n",
      "tensor([[1.0380],\n",
      "        [1.2094],\n",
      "        [1.1689],\n",
      "        [1.3137]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9881]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.7223]],\n",
      "\n",
      "        [[1.4814]]], dtype=torch.float64)\n",
      "tensor([[1.6694],\n",
      "        [1.7285],\n",
      "        [1.6543],\n",
      "        [1.6148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9482]],\n",
      "\n",
      "        [[1.8593]],\n",
      "\n",
      "        [[1.5577]],\n",
      "\n",
      "        [[1.2654]]], dtype=torch.float64)\n",
      "tensor([[1.4500],\n",
      "        [1.4475],\n",
      "        [1.5700],\n",
      "        [1.2829]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1418]],\n",
      "\n",
      "        [[1.5785]],\n",
      "\n",
      "        [[1.5877]],\n",
      "\n",
      "        [[1.3104]]], dtype=torch.float64)\n",
      "tensor([[1.1025],\n",
      "        [1.3369],\n",
      "        [1.3840],\n",
      "        [1.4113]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1787]],\n",
      "\n",
      "        [[1.0563]],\n",
      "\n",
      "        [[1.1106]],\n",
      "\n",
      "        [[1.2862]]], dtype=torch.float64)\n",
      "tensor([[1.1570],\n",
      "        [1.0178],\n",
      "        [1.0245],\n",
      "        [1.2356]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1949]],\n",
      "\n",
      "        [[1.1429]],\n",
      "\n",
      "        [[1.0713]],\n",
      "\n",
      "        [[1.0112]]], dtype=torch.float64)\n",
      "tensor([[1.2014],\n",
      "        [1.2511],\n",
      "        [1.1790],\n",
      "        [1.3814]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8760]],\n",
      "\n",
      "        [[1.3335]],\n",
      "\n",
      "        [[1.6571]],\n",
      "\n",
      "        [[1.7310]]], dtype=torch.float64)\n",
      "tensor([[1.1997],\n",
      "        [0.9956],\n",
      "        [0.8329],\n",
      "        [1.2445]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0216]],\n",
      "\n",
      "        [[0.5467]],\n",
      "\n",
      "        [[0.5513]],\n",
      "\n",
      "        [[1.6571]]], dtype=torch.float64)\n",
      "tensor([[1.3890],\n",
      "        [1.4189],\n",
      "        [1.2380],\n",
      "        [1.2656]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9101]],\n",
      "\n",
      "        [[1.7587]],\n",
      "\n",
      "        [[1.3740]],\n",
      "\n",
      "        [[0.8552]]], dtype=torch.float64)\n",
      "tensor([[0.9885],\n",
      "        [1.3873],\n",
      "        [1.8781],\n",
      "        [1.8351]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8344]],\n",
      "\n",
      "        [[1.8569]],\n",
      "\n",
      "        [[2.2694]],\n",
      "\n",
      "        [[2.1262]]], dtype=torch.float64)\n",
      "tensor([[1.5924],\n",
      "        [1.2158],\n",
      "        [1.2006],\n",
      "        [1.4055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1452]],\n",
      "\n",
      "        [[1.0609]],\n",
      "\n",
      "        [[0.9430]],\n",
      "\n",
      "        [[1.6236]]], dtype=torch.float64)\n",
      "tensor([[0.8765],\n",
      "        [0.9912],\n",
      "        [1.0297],\n",
      "        [1.1849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1810]],\n",
      "\n",
      "        [[1.4861]],\n",
      "\n",
      "        [[1.1452]],\n",
      "\n",
      "        [[1.0551]]], dtype=torch.float64)\n",
      "tensor([[1.2575],\n",
      "        [1.0858],\n",
      "        [0.9486],\n",
      "        [1.2776]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0193]],\n",
      "\n",
      "        [[1.3451]],\n",
      "\n",
      "        [[1.3786]],\n",
      "\n",
      "        [[1.0551]]], dtype=torch.float64)\n",
      "tensor([[0.7794]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8795]]], dtype=torch.float64)\n",
      "tensor([[-1.5154],\n",
      "        [-1.5820],\n",
      "        [-1.5637],\n",
      "        [-1.4687]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0980]],\n",
      "\n",
      "        [[-1.9883]],\n",
      "\n",
      "        [[-1.8461]],\n",
      "\n",
      "        [[-1.6763]]], dtype=torch.float64)\n",
      "tensor([[-1.5123],\n",
      "        [-1.3653],\n",
      "        [-1.2314],\n",
      "        [-1.2174]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6185]],\n",
      "\n",
      "        [[-1.5769]],\n",
      "\n",
      "        [[-1.5815]],\n",
      "\n",
      "        [[-1.5527]]], dtype=torch.float64)\n",
      "tensor([[-1.2293],\n",
      "        [-1.3258],\n",
      "        [-1.4700],\n",
      "        [-1.4444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4129]],\n",
      "\n",
      "        [[-1.3713]],\n",
      "\n",
      "        [[-1.4337]],\n",
      "\n",
      "        [[-1.5966]]], dtype=torch.float64)\n",
      "tensor([[-1.4283],\n",
      "        [-1.5226],\n",
      "        [-1.6472],\n",
      "        [-1.3820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7699]],\n",
      "\n",
      "        [[-2.1246]],\n",
      "\n",
      "        [[-1.7410]],\n",
      "\n",
      "        [[-1.3759]]], dtype=torch.float64)\n",
      "tensor([[-1.6244],\n",
      "        [-1.3481],\n",
      "        [-1.0130],\n",
      "        [-0.9860]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4960]],\n",
      "\n",
      "        [[-1.2719]],\n",
      "\n",
      "        [[-1.2696]],\n",
      "\n",
      "        [[-1.1552]]], dtype=torch.float64)\n",
      "tensor([[-1.0925],\n",
      "        [-1.2112],\n",
      "        [-1.2573],\n",
      "        [-1.0820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1922]],\n",
      "\n",
      "        [[-1.1737]],\n",
      "\n",
      "        [[-1.2326]],\n",
      "\n",
      "        [[-1.2222]]], dtype=torch.float64)\n",
      "tensor([[-1.1537],\n",
      "        [-1.1638],\n",
      "        [-1.4789],\n",
      "        [-1.7727]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2557]],\n",
      "\n",
      "        [[-1.3666]],\n",
      "\n",
      "        [[-1.4741]],\n",
      "\n",
      "        [[-1.7156]]], dtype=torch.float64)\n",
      "tensor([[-2.0708],\n",
      "        [-2.1703],\n",
      "        [-2.2335],\n",
      "        [-2.2573]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1073]],\n",
      "\n",
      "        [[-2.5117]],\n",
      "\n",
      "        [[-2.7034]],\n",
      "\n",
      "        [[-3.0073]]], dtype=torch.float64)\n",
      "tensor([[-2.4546],\n",
      "        [-2.3342],\n",
      "        [-2.6128],\n",
      "        [-2.7445]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.7300]],\n",
      "\n",
      "        [[-2.6145]],\n",
      "\n",
      "        [[-3.1725]],\n",
      "\n",
      "        [[-3.4891]]], dtype=torch.float64)\n",
      "tensor([[-2.8855],\n",
      "        [-2.8843],\n",
      "        [-2.8398],\n",
      "        [-2.3634]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-3.6393]],\n",
      "\n",
      "        [[-3.6520]],\n",
      "\n",
      "        [[-2.9588]],\n",
      "\n",
      "        [[-2.1593]]], dtype=torch.float64)\n",
      "tensor([[-2.1753],\n",
      "        [-2.2200],\n",
      "        [-2.3418],\n",
      "        [-2.2641]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9594]],\n",
      "\n",
      "        [[-2.2979]],\n",
      "\n",
      "        [[-2.4747]],\n",
      "\n",
      "        [[-2.2089]]], dtype=torch.float64)\n",
      "tensor([[-2.1911],\n",
      "        [-1.8932],\n",
      "        [-2.4043],\n",
      "        [-2.6015]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8427]],\n",
      "\n",
      "        [[-1.6266]],\n",
      "\n",
      "        [[-2.2852]],\n",
      "\n",
      "        [[-2.6595]]], dtype=torch.float64)\n",
      "tensor([[-2.8559],\n",
      "        [-2.9523],\n",
      "        [-2.8779],\n",
      "        [-2.1992]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.9345]],\n",
      "\n",
      "        [[-3.0189]],\n",
      "\n",
      "        [[-2.2621]],\n",
      "\n",
      "        [[-1.6012]]], dtype=torch.float64)\n",
      "tensor([[-2.5917],\n",
      "        [-2.7865],\n",
      "        [-2.8277],\n",
      "        [-2.8924]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4308]],\n",
      "\n",
      "        [[-2.5821]],\n",
      "\n",
      "        [[-2.7381]],\n",
      "\n",
      "        [[-2.8386]]], dtype=torch.float64)\n",
      "tensor([[-2.8060],\n",
      "        [-2.1322],\n",
      "        [-2.5115],\n",
      "        [-2.6591]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9166]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-2.1431]],\n",
      "\n",
      "        [[-2.2944]]], dtype=torch.float64)\n",
      "tensor([[-2.6274],\n",
      "        [-2.5792],\n",
      "        [-2.5133],\n",
      "        [-1.9288]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.5752]],\n",
      "\n",
      "        [[-2.6006]],\n",
      "\n",
      "        [[-1.8750]],\n",
      "\n",
      "        [[-1.0905]]], dtype=torch.float64)\n",
      "tensor([[-2.1490],\n",
      "        [-2.2822],\n",
      "        [-2.1169],\n",
      "        [-2.2540]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0079]],\n",
      "\n",
      "        [[-2.0876]],\n",
      "\n",
      "        [[-2.1616]],\n",
      "\n",
      "        [[-2.1315]]], dtype=torch.float64)\n",
      "tensor([[-2.0414],\n",
      "        [-1.5460],\n",
      "        [-1.8041],\n",
      "        [-1.8179]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4729]],\n",
      "\n",
      "        [[-0.8779]],\n",
      "\n",
      "        [[-1.4602]],\n",
      "\n",
      "        [[-1.6520]]], dtype=torch.float64)\n",
      "tensor([[-1.6183],\n",
      "        [-1.6032],\n",
      "        [-1.4760],\n",
      "        [-1.1351]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6185]],\n",
      "\n",
      "        [[-1.4868]],\n",
      "\n",
      "        [[-0.7543]],\n",
      "\n",
      "        [[-0.6769]]], dtype=torch.float64)\n",
      "tensor([[-1.4889],\n",
      "        [-1.5676],\n",
      "        [-1.7396],\n",
      "        [-1.9923]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2338]],\n",
      "\n",
      "        [[-1.5619]],\n",
      "\n",
      "        [[-2.0218]],\n",
      "\n",
      "        [[-2.2320]]], dtype=torch.float64)\n",
      "tensor([[-1.8938],\n",
      "        [-1.5212],\n",
      "        [-1.4508],\n",
      "        [-1.1878]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5931]],\n",
      "\n",
      "        [[-1.1829]],\n",
      "\n",
      "        [[-1.2476]],\n",
      "\n",
      "        [[-1.0015]]], dtype=torch.float64)\n",
      "tensor([[-0.9472],\n",
      "        [-0.9881],\n",
      "        [-1.0189],\n",
      "        [-0.9713]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0928]],\n",
      "\n",
      "        [[-1.0535]],\n",
      "\n",
      "        [[-0.8224]],\n",
      "\n",
      "        [[-0.7543]]], dtype=torch.float64)\n",
      "tensor([[-1.2826],\n",
      "        [-1.3944],\n",
      "        [-1.3400],\n",
      "        [-1.3184]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3863]],\n",
      "\n",
      "        [[-1.5180]],\n",
      "\n",
      "        [[-1.6428]],\n",
      "\n",
      "        [[-1.5457]]], dtype=torch.float64)\n",
      "tensor([[-1.3150],\n",
      "        [-1.1391],\n",
      "        [-1.2013],\n",
      "        [-1.1504]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3817]],\n",
      "\n",
      "        [[-1.0085]],\n",
      "\n",
      "        [[-1.2580]],\n",
      "\n",
      "        [[-1.3181]]], dtype=torch.float64)\n",
      "tensor([[-1.0481],\n",
      "        [-0.9358],\n",
      "        [-0.8854],\n",
      "        [-0.9140]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2881]],\n",
      "\n",
      "        [[-1.1956]],\n",
      "\n",
      "        [[-0.9715]],\n",
      "\n",
      "        [[-0.8132]]], dtype=torch.float64)\n",
      "tensor([[-0.9106],\n",
      "        [-0.7965],\n",
      "        [-0.7246],\n",
      "        [-0.7980]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9264]],\n",
      "\n",
      "        [[-0.8282]],\n",
      "\n",
      "        [[-0.9391]],\n",
      "\n",
      "        [[-0.8721]]], dtype=torch.float64)\n",
      "tensor([[-0.6926],\n",
      "        [-0.6334],\n",
      "        [-0.7863],\n",
      "        [-0.7021]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4689]],\n",
      "\n",
      "        [[-0.7115]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.7185]]], dtype=torch.float64)\n",
      "tensor([[-0.7682],\n",
      "        [-0.7467],\n",
      "        [-0.7717],\n",
      "        [-0.6773]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9056]],\n",
      "\n",
      "        [[-0.9553]],\n",
      "\n",
      "        [[-0.6919]],\n",
      "\n",
      "        [[-0.6584]]], dtype=torch.float64)\n",
      "tensor([[-0.7302],\n",
      "        [-0.6309],\n",
      "        [-0.4374],\n",
      "        [-0.5665]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6249]],\n",
      "\n",
      "        [[-0.5810]],\n",
      "\n",
      "        [[-0.3314]],\n",
      "\n",
      "        [[-0.5163]]], dtype=torch.float64)\n",
      "tensor([[-0.6477],\n",
      "        [-0.7218],\n",
      "        [-0.8943],\n",
      "        [-1.0449]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5613]],\n",
      "\n",
      "        [[-0.6399]],\n",
      "\n",
      "        [[-1.1044]],\n",
      "\n",
      "        [[-1.3944]]], dtype=torch.float64)\n",
      "tensor([[-1.0217],\n",
      "        [-1.0360],\n",
      "        [-1.0114],\n",
      "        [-0.9402]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3331]],\n",
      "\n",
      "        [[-1.3874]],\n",
      "\n",
      "        [[-1.0813]],\n",
      "\n",
      "        [[-0.9611]]], dtype=torch.float64)\n",
      "tensor([[-0.9713],\n",
      "        [-1.0461],\n",
      "        [-1.0210],\n",
      "        [-0.9699]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2650]],\n",
      "\n",
      "        [[-1.4706]],\n",
      "\n",
      "        [[-1.4417]],\n",
      "\n",
      "        [[-1.4221]]], dtype=torch.float64)\n",
      "tensor([[-0.9490],\n",
      "        [-0.7220],\n",
      "        [-0.9318],\n",
      "        [-0.9256]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8213]],\n",
      "\n",
      "        [[-0.7728]],\n",
      "\n",
      "        [[-1.1644]],\n",
      "\n",
      "        [[-1.1390]]], dtype=torch.float64)\n",
      "tensor([[-0.9397],\n",
      "        [-0.9190],\n",
      "        [-0.8216],\n",
      "        [-0.8242]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2095]],\n",
      "\n",
      "        [[-1.2268]],\n",
      "\n",
      "        [[-0.7034]],\n",
      "\n",
      "        [[-0.8213]]], dtype=torch.float64)\n",
      "tensor([[-0.7555],\n",
      "        [-0.6334],\n",
      "        [-0.7573],\n",
      "        [-0.8051]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4631]],\n",
      "\n",
      "        [[-0.5983]],\n",
      "\n",
      "        [[-0.7705]],\n",
      "\n",
      "        [[-0.8132]]], dtype=torch.float64)\n",
      "tensor([[-0.7734],\n",
      "        [-0.8373],\n",
      "        [-0.9186],\n",
      "        [-0.8836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6110]],\n",
      "\n",
      "        [[-0.6133]],\n",
      "\n",
      "        [[-0.7808]],\n",
      "\n",
      "        [[-1.0189]]], dtype=torch.float64)\n",
      "tensor([[-0.8402],\n",
      "        [-0.8486],\n",
      "        [-0.8632],\n",
      "        [-0.6905]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9923]],\n",
      "\n",
      "        [[-1.1413]],\n",
      "\n",
      "        [[-0.6838]],\n",
      "\n",
      "        [[-0.4030]]], dtype=torch.float64)\n",
      "tensor([[-0.9108],\n",
      "        [-1.0855],\n",
      "        [-1.1108],\n",
      "        [-1.1714]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1517]],\n",
      "\n",
      "        [[-1.4313]],\n",
      "\n",
      "        [[-1.5388]],\n",
      "\n",
      "        [[-1.7190]]], dtype=torch.float64)\n",
      "tensor([[-1.3683],\n",
      "        [-1.2742],\n",
      "        [-1.2240],\n",
      "        [-1.0716]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4082]],\n",
      "\n",
      "        [[-1.3528]],\n",
      "\n",
      "        [[-1.2361]],\n",
      "\n",
      "        [[-1.1841]]], dtype=torch.float64)\n",
      "tensor([[-1.0008],\n",
      "        [-0.9312],\n",
      "        [-1.0893],\n",
      "        [-1.1789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1876]],\n",
      "\n",
      "        [[-1.1795]],\n",
      "\n",
      "        [[-1.2014]],\n",
      "\n",
      "        [[-1.2176]]], dtype=torch.float64)\n",
      "tensor([[-1.2517],\n",
      "        [-1.1715],\n",
      "        [-0.9617],\n",
      "        [-1.0031]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2488]],\n",
      "\n",
      "        [[-1.2465]],\n",
      "\n",
      "        [[-1.2754]],\n",
      "\n",
      "        [[-1.3724]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.09897:   3%|▎         | 96/3067 [00:00<00:09, 315.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1329],\n",
      "        [-1.2301],\n",
      "        [-1.2663],\n",
      "        [-1.2102]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3574]],\n",
      "\n",
      "        [[-1.3354]],\n",
      "\n",
      "        [[-1.3539]],\n",
      "\n",
      "        [[-1.3690]]], dtype=torch.float64)\n",
      "tensor([[-1.0949],\n",
      "        [-1.1222],\n",
      "        [-1.2154],\n",
      "        [-1.2550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3678]],\n",
      "\n",
      "        [[-1.4256]],\n",
      "\n",
      "        [[-1.2719]],\n",
      "\n",
      "        [[-1.2534]]], dtype=torch.float64)\n",
      "tensor([[-1.2744],\n",
      "        [-1.2095],\n",
      "        [-1.1124],\n",
      "        [-1.0543]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2765]],\n",
      "\n",
      "        [[-1.2788]],\n",
      "\n",
      "        [[-1.3054]],\n",
      "\n",
      "        [[-1.3666]]], dtype=torch.float64)\n",
      "tensor([[-1.2106],\n",
      "        [-1.4044],\n",
      "        [-1.3400],\n",
      "        [-1.3456]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3747]],\n",
      "\n",
      "        [[-1.3250]],\n",
      "\n",
      "        [[-1.3031]],\n",
      "\n",
      "        [[-1.3389]]], dtype=torch.float64)\n",
      "tensor([[-1.1937],\n",
      "        [-1.1306],\n",
      "        [-1.2100],\n",
      "        [-1.3062]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3227]],\n",
      "\n",
      "        [[-1.2892]],\n",
      "\n",
      "        [[-1.2222]],\n",
      "\n",
      "        [[-1.2361]]], dtype=torch.float64)\n",
      "tensor([[-1.4575],\n",
      "        [-1.4355],\n",
      "        [-1.4389],\n",
      "        [-1.3714]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3239]],\n",
      "\n",
      "        [[-1.3955]],\n",
      "\n",
      "        [[-1.4776]],\n",
      "\n",
      "        [[-1.5319]]], dtype=torch.float64)\n",
      "tensor([[-1.4783],\n",
      "        [-1.5561],\n",
      "        [-1.6107],\n",
      "        [-1.4628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4094]],\n",
      "\n",
      "        [[-1.3678]],\n",
      "\n",
      "        [[-1.4325]],\n",
      "\n",
      "        [[-1.3458]]], dtype=torch.float64)\n",
      "tensor([[-1.3532],\n",
      "        [-1.3331],\n",
      "        [-1.2506],\n",
      "        [-0.9757]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3817]],\n",
      "\n",
      "        [[-1.6312]],\n",
      "\n",
      "        [[-1.0027]],\n",
      "\n",
      "        [[-0.7208]]], dtype=torch.float64)\n",
      "tensor([[-1.1358],\n",
      "        [-1.1332],\n",
      "        [-1.2312],\n",
      "        [-1.2237]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0085]],\n",
      "\n",
      "        [[-1.1564]],\n",
      "\n",
      "        [[-1.3678]],\n",
      "\n",
      "        [[-1.4313]]], dtype=torch.float64)\n",
      "tensor([[-1.1816],\n",
      "        [-0.8275],\n",
      "        [-0.9828],\n",
      "        [-1.2485]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9149]],\n",
      "\n",
      "        [[-0.4088]],\n",
      "\n",
      "        [[-1.0477]],\n",
      "\n",
      "        [[-1.3574]]], dtype=torch.float64)\n",
      "tensor([[-1.3153],\n",
      "        [-1.3816],\n",
      "        [-1.3292],\n",
      "        [-0.9531]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5342]],\n",
      "\n",
      "        [[-1.6104]],\n",
      "\n",
      "        [[-1.0119]],\n",
      "\n",
      "        [[-0.6283]]], dtype=torch.float64)\n",
      "tensor([[-1.1509],\n",
      "        [-1.1014],\n",
      "        [-1.0047],\n",
      "        [-1.1064]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0443]],\n",
      "\n",
      "        [[-0.9622]],\n",
      "\n",
      "        [[-1.0940]],\n",
      "\n",
      "        [[-1.1945]]], dtype=torch.float64)\n",
      "tensor([[-0.9325],\n",
      "        [-0.6860],\n",
      "        [-0.8556],\n",
      "        [-0.9943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5891]],\n",
      "\n",
      "        [[-0.4342]],\n",
      "\n",
      "        [[-0.7150]],\n",
      "\n",
      "        [[-0.9622]]], dtype=torch.float64)\n",
      "tensor([[-1.0102],\n",
      "        [-1.0183],\n",
      "        [-1.0504],\n",
      "        [-0.6294]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1436]],\n",
      "\n",
      "        [[-1.0477]],\n",
      "\n",
      "        [[-0.7300]],\n",
      "\n",
      "        [[-0.1719]]], dtype=torch.float64)\n",
      "tensor([[-0.6972],\n",
      "        [-0.9731],\n",
      "        [-1.0948],\n",
      "        [-1.2132]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6133]],\n",
      "\n",
      "        [[-0.9576]],\n",
      "\n",
      "        [[-1.2095]],\n",
      "\n",
      "        [[-1.2684]]], dtype=torch.float64)\n",
      "tensor([[-1.1627],\n",
      "        [-0.8418],\n",
      "        [-0.9543],\n",
      "        [-0.9942]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7485]],\n",
      "\n",
      "        [[-0.6029]],\n",
      "\n",
      "        [[-0.6907]],\n",
      "\n",
      "        [[-0.7970]]], dtype=torch.float64)\n",
      "tensor([[-0.9733],\n",
      "        [-1.0006],\n",
      "        [-1.1870],\n",
      "        [-1.2220]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8952]],\n",
      "\n",
      "        [[-1.0408]],\n",
      "\n",
      "        [[-0.8016]],\n",
      "\n",
      "        [[-0.7023]]], dtype=torch.float64)\n",
      "tensor([[-1.1498],\n",
      "        [-1.1648],\n",
      "        [-1.1917],\n",
      "        [-1.0805]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0281]],\n",
      "\n",
      "        [[-1.3227]],\n",
      "\n",
      "        [[-1.3643]],\n",
      "\n",
      "        [[-1.1471]]], dtype=torch.float64)\n",
      "tensor([[-0.9620],\n",
      "        [-0.8874],\n",
      "        [-1.0409],\n",
      "        [-1.1040]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7993]],\n",
      "\n",
      "        [[-0.8248]],\n",
      "\n",
      "        [[-1.0917]],\n",
      "\n",
      "        [[-1.0674]]], dtype=torch.float64)\n",
      "tensor([[-0.8765],\n",
      "        [-0.8033],\n",
      "        [-0.5739],\n",
      "        [-0.6849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1506]],\n",
      "\n",
      "        [[-0.7635]],\n",
      "\n",
      "        [[-0.2967]],\n",
      "\n",
      "        [[-0.5833]]], dtype=torch.float64)\n",
      "tensor([[-0.9466],\n",
      "        [-1.1228],\n",
      "        [-1.1047],\n",
      "        [-1.1498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8363]],\n",
      "\n",
      "        [[-0.9750]],\n",
      "\n",
      "        [[-1.1009]],\n",
      "\n",
      "        [[-1.0720]]], dtype=torch.float64)\n",
      "tensor([[-1.1081],\n",
      "        [-1.1916],\n",
      "        [-1.1647],\n",
      "        [-1.0475]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8929]],\n",
      "\n",
      "        [[-0.8132]],\n",
      "\n",
      "        [[-1.0327]],\n",
      "\n",
      "        [[-1.0836]]], dtype=torch.float64)\n",
      "tensor([[-1.0552],\n",
      "        [-1.1762],\n",
      "        [-1.1844],\n",
      "        [-1.2186]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2187]],\n",
      "\n",
      "        [[-1.4036]],\n",
      "\n",
      "        [[-1.0639]],\n",
      "\n",
      "        [[-1.0685]]], dtype=torch.float64)\n",
      "tensor([[-1.2995],\n",
      "        [-1.2286],\n",
      "        [-1.1202],\n",
      "        [-1.1441]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2973]],\n",
      "\n",
      "        [[-1.2985]],\n",
      "\n",
      "        [[-1.4429]],\n",
      "\n",
      "        [[-1.5977]]], dtype=torch.float64)\n",
      "tensor([[-1.1734],\n",
      "        [-1.1271],\n",
      "        [-1.0715],\n",
      "        [-1.0274]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9726]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.1148]],\n",
      "\n",
      "        [[-1.1321]]], dtype=torch.float64)\n",
      "tensor([[-0.9439],\n",
      "        [-1.2146],\n",
      "        [-1.4248],\n",
      "        [-1.3910]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1991]],\n",
      "\n",
      "        [[-1.7110]],\n",
      "\n",
      "        [[-1.6035]],\n",
      "\n",
      "        [[-1.3493]]], dtype=torch.float64)\n",
      "tensor([[-1.4461],\n",
      "        [-1.3582],\n",
      "        [-1.3829],\n",
      "        [-1.4151]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5607]],\n",
      "\n",
      "        [[-1.6613]],\n",
      "\n",
      "        [[-1.9432]],\n",
      "\n",
      "        [[-1.8958]]], dtype=torch.float64)\n",
      "tensor([[-1.2326],\n",
      "        [-1.2185],\n",
      "        [-1.2195],\n",
      "        [-1.1111]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2765]],\n",
      "\n",
      "        [[-1.1910]],\n",
      "\n",
      "        [[-1.4267]],\n",
      "\n",
      "        [[-1.3921]]], dtype=torch.float64)\n",
      "tensor([[-0.8929],\n",
      "        [-0.9501],\n",
      "        [-0.9488],\n",
      "        [-0.9493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2938]],\n",
      "\n",
      "        [[-1.0859]],\n",
      "\n",
      "        [[-0.8479]],\n",
      "\n",
      "        [[-0.8409]]], dtype=torch.float64)\n",
      "tensor([[-0.9831],\n",
      "        [-0.9235],\n",
      "        [-0.9181],\n",
      "        [-0.9754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8952]],\n",
      "\n",
      "        [[-1.0789]],\n",
      "\n",
      "        [[-1.0339]],\n",
      "\n",
      "        [[-1.2534]]], dtype=torch.float64)\n",
      "tensor([[-1.3519],\n",
      "        [-1.5076],\n",
      "        [-1.5949],\n",
      "        [-1.5453]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4117]],\n",
      "\n",
      "        [[-1.3354]],\n",
      "\n",
      "        [[-1.5792]],\n",
      "\n",
      "        [[-1.6266]]], dtype=torch.float64)\n",
      "tensor([[-1.3290],\n",
      "        [-1.3003],\n",
      "        [-1.3745],\n",
      "        [-1.4518]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6278]],\n",
      "\n",
      "        [[-1.6578]],\n",
      "\n",
      "        [[-1.3932]],\n",
      "\n",
      "        [[-1.1922]]], dtype=torch.float64)\n",
      "tensor([[-1.5850],\n",
      "        [-1.5865],\n",
      "        [-1.6852],\n",
      "        [-1.6912]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5769]],\n",
      "\n",
      "        [[-1.9651]],\n",
      "\n",
      "        [[-2.3372]],\n",
      "\n",
      "        [[-2.1812]]], dtype=torch.float64)\n",
      "tensor([[-1.4667],\n",
      "        [-1.1670],\n",
      "        [-1.2894],\n",
      "        [-1.2976]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0928]],\n",
      "\n",
      "        [[-1.0177]],\n",
      "\n",
      "        [[-1.2338]],\n",
      "\n",
      "        [[-1.3343]]], dtype=torch.float64)\n",
      "tensor([[-1.1130],\n",
      "        [-0.9947],\n",
      "        [-0.9541],\n",
      "        [-0.9756]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3435]],\n",
      "\n",
      "        [[-1.0304]],\n",
      "\n",
      "        [[-0.7947]],\n",
      "\n",
      "        [[-0.8952]]], dtype=torch.float64)\n",
      "tensor([[-1.0910],\n",
      "        [-0.9455],\n",
      "        [-0.8511],\n",
      "        [-0.9222]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8791]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.9253]],\n",
      "\n",
      "        [[-1.0293]]], dtype=torch.float64)\n",
      "tensor([[-1.0296],\n",
      "        [-1.0807],\n",
      "        [-1.1271],\n",
      "        [-1.0357]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9230]],\n",
      "\n",
      "        [[-0.8271]],\n",
      "\n",
      "        [[-0.9380]],\n",
      "\n",
      "        [[-1.0720]]], dtype=torch.float64)\n",
      "tensor([[-1.0244],\n",
      "        [-0.9079],\n",
      "        [-0.8457],\n",
      "        [-0.7828]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1425]],\n",
      "\n",
      "        [[-1.0223]],\n",
      "\n",
      "        [[-0.6826]],\n",
      "\n",
      "        [[-0.5833]]], dtype=torch.float64)\n",
      "tensor([[-0.8399],\n",
      "        [-0.8919],\n",
      "        [-0.8923],\n",
      "        [-0.9452]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6330]],\n",
      "\n",
      "        [[-0.7277]],\n",
      "\n",
      "        [[-0.8178]],\n",
      "\n",
      "        [[-0.8201]]], dtype=torch.float64)\n",
      "tensor([[-1.0456],\n",
      "        [-0.9681],\n",
      "        [-0.9804],\n",
      "        [-1.0674]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7289]],\n",
      "\n",
      "        [[-0.6029]],\n",
      "\n",
      "        [[-0.8224]],\n",
      "\n",
      "        [[-1.0870]]], dtype=torch.float64)\n",
      "tensor([[-1.0913],\n",
      "        [-1.1782],\n",
      "        [-1.1707],\n",
      "        [-1.3054]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1032]],\n",
      "\n",
      "        [[-1.1679]],\n",
      "\n",
      "        [[-1.1101]],\n",
      "\n",
      "        [[-1.0177]]], dtype=torch.float64)\n",
      "tensor([[-1.2555],\n",
      "        [-1.1773],\n",
      "        [-1.1463],\n",
      "        [-1.2577]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0466]],\n",
      "\n",
      "        [[-1.1725]],\n",
      "\n",
      "        [[-1.3100]],\n",
      "\n",
      "        [[-1.3239]]], dtype=torch.float64)\n",
      "tensor([[-0.8891],\n",
      "        [-0.7136],\n",
      "        [-0.8641],\n",
      "        [-0.8010]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6514]],\n",
      "\n",
      "        [[-0.4839]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.6491]]], dtype=torch.float64)\n",
      "tensor([[-0.6706],\n",
      "        [-0.6567],\n",
      "        [-0.7774],\n",
      "        [-0.7190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7173]],\n",
      "\n",
      "        [[-0.8386]],\n",
      "\n",
      "        [[-0.5255]],\n",
      "\n",
      "        [[-0.4053]]], dtype=torch.float64)\n",
      "tensor([[-0.7532],\n",
      "        [-0.7713],\n",
      "        [-0.7008],\n",
      "        [-0.6344]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4862]],\n",
      "\n",
      "        [[-0.5636]],\n",
      "\n",
      "        [[-0.6480]],\n",
      "\n",
      "        [[-0.6341]]], dtype=torch.float64)\n",
      "tensor([[-0.6080],\n",
      "        [-0.6267],\n",
      "        [-0.6513],\n",
      "        [-0.5513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4527]],\n",
      "\n",
      "        [[-0.3799]],\n",
      "\n",
      "        [[-0.4284]],\n",
      "\n",
      "        [[-0.3603]]], dtype=torch.float64)\n",
      "tensor([[-0.3453],\n",
      "        [-0.3631],\n",
      "        [-0.3190],\n",
      "        [-0.2401]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3533]],\n",
      "\n",
      "        [[-0.3869]],\n",
      "\n",
      "        [[-0.1731]],\n",
      "\n",
      "        [[-0.1639]]], dtype=torch.float64)\n",
      "tensor([[-0.3494],\n",
      "        [-0.4585],\n",
      "        [-0.3814],\n",
      "        [-0.5003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2852]],\n",
      "\n",
      "        [[-0.4204]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[-0.5891]]], dtype=torch.float64)\n",
      "tensor([[-0.5091],\n",
      "        [-0.1142],\n",
      "        [-0.5408],\n",
      "        [-0.7361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3741]],\n",
      "\n",
      "        [[ 0.2382]],\n",
      "\n",
      "        [[-0.6353]],\n",
      "\n",
      "        [[-0.6457]]], dtype=torch.float64)\n",
      "tensor([[-0.3968],\n",
      "        [-0.3929],\n",
      "        [-0.3370],\n",
      "        [-0.3779]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5128]],\n",
      "\n",
      "        [[-0.5267]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.2147]]], dtype=torch.float64)\n",
      "tensor([[-0.5259],\n",
      "        [-0.5650],\n",
      "        [-0.6292],\n",
      "        [-0.6559]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4354]],\n",
      "\n",
      "        [[-0.5787]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.8791]]], dtype=torch.float64)\n",
      "tensor([[-0.5603],\n",
      "        [-0.4701],\n",
      "        [-0.7164],\n",
      "        [-0.9972]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2563]],\n",
      "\n",
      "        [[-0.2205]],\n",
      "\n",
      "        [[-0.7462]],\n",
      "\n",
      "        [[-1.0917]]], dtype=torch.float64)\n",
      "tensor([[-0.8978],\n",
      "        [-0.7378],\n",
      "        [-0.3606],\n",
      "        [-0.3047]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9599]],\n",
      "\n",
      "        [[-0.7312]],\n",
      "\n",
      "        [[-0.0610]],\n",
      "\n",
      "        [[-0.0021]]], dtype=torch.float64)\n",
      "tensor([[-0.5487],\n",
      "        [-0.7639],\n",
      "        [-0.9640],\n",
      "        [-1.0875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[-1.1668]],\n",
      "\n",
      "        [[-1.2303]]], dtype=torch.float64)\n",
      "tensor([[-1.0363],\n",
      "        [-0.7946],\n",
      "        [-0.6060],\n",
      "        [-0.4835]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8005]],\n",
      "\n",
      "        [[-0.4631]],\n",
      "\n",
      "        [[-0.3857]],\n",
      "\n",
      "        [[-0.4585]]], dtype=torch.float64)\n",
      "tensor([[-0.3629],\n",
      "        [-0.4502],\n",
      "        [-0.7041],\n",
      "        [-0.7165]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4435]],\n",
      "\n",
      "        [[-0.5994]],\n",
      "\n",
      "        [[-0.6722]],\n",
      "\n",
      "        [[-0.6018]]], dtype=torch.float64)\n",
      "tensor([[-0.7425],\n",
      "        [-0.7107],\n",
      "        [-0.7090],\n",
      "        [-0.8232]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6780]],\n",
      "\n",
      "        [[-0.7277]],\n",
      "\n",
      "        [[-0.8536]],\n",
      "\n",
      "        [[-0.9022]]], dtype=torch.float64)\n",
      "tensor([[-0.7750],\n",
      "        [-0.8141],\n",
      "        [-0.8666],\n",
      "        [-0.8990]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7485]],\n",
      "\n",
      "        [[-0.8409]],\n",
      "\n",
      "        [[-0.8640]],\n",
      "\n",
      "        [[-1.2627]]], dtype=torch.float64)\n",
      "tensor([[-0.9586],\n",
      "        [-0.8403],\n",
      "        [-0.5867],\n",
      "        [-0.4410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2950]],\n",
      "\n",
      "        [[-0.8190]],\n",
      "\n",
      "        [[-0.3834]],\n",
      "\n",
      "        [[-0.3707]]], dtype=torch.float64)\n",
      "tensor([[-0.4724],\n",
      "        [-0.5138],\n",
      "        [-0.5111],\n",
      "        [-0.7556]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4250]],\n",
      "\n",
      "        [[-0.5671]],\n",
      "\n",
      "        [[-0.7335]],\n",
      "\n",
      "        [[-0.7866]]], dtype=torch.float64)\n",
      "tensor([[-0.6867],\n",
      "        [-0.6086],\n",
      "        [-0.6922],\n",
      "        [-0.6335]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5498]],\n",
      "\n",
      "        [[-0.4331]],\n",
      "\n",
      "        [[-0.6179]],\n",
      "\n",
      "        [[-0.6861]]], dtype=torch.float64)\n",
      "tensor([[-0.6513],\n",
      "        [-0.5321],\n",
      "        [-0.5323],\n",
      "        [-0.5542]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7866]],\n",
      "\n",
      "        [[-0.7416]],\n",
      "\n",
      "        [[-0.4643]],\n",
      "\n",
      "        [[-0.4469]]], dtype=torch.float64)\n",
      "tensor([[-0.6071],\n",
      "        [-0.7391],\n",
      "        [-0.7201],\n",
      "        [-0.7727]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6815]],\n",
      "\n",
      "        [[-0.8074]],\n",
      "\n",
      "        [[-0.9357]],\n",
      "\n",
      "        [[-0.9657]]], dtype=torch.float64)\n",
      "tensor([[-0.6827],\n",
      "        [-0.7502],\n",
      "        [-0.7231],\n",
      "        [-0.6744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.5971]],\n",
      "\n",
      "        [[-0.6572]],\n",
      "\n",
      "        [[-0.6919]]], dtype=torch.float64)\n",
      "tensor([[-0.5849],\n",
      "        [-0.6641],\n",
      "        [-0.6022],\n",
      "        [-0.5744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7716]],\n",
      "\n",
      "        [[-0.8663]],\n",
      "\n",
      "        [[-0.5151]],\n",
      "\n",
      "        [[-0.7543]]], dtype=torch.float64)\n",
      "tensor([[-0.6843],\n",
      "        [-0.4538],\n",
      "        [-0.3754],\n",
      "        [-0.4914]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6757]],\n",
      "\n",
      "        [[-0.3753]],\n",
      "\n",
      "        [[-0.5267]],\n",
      "\n",
      "        [[-0.4550]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.09897:   5%|▌         | 165/3067 [00:00<00:08, 327.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3946],\n",
      "        [-0.2476],\n",
      "        [-0.3550],\n",
      "        [-0.5796]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0090]],\n",
      "\n",
      "        [[ 0.0661]],\n",
      "\n",
      "        [[-0.2644]],\n",
      "\n",
      "        [[-0.7300]]], dtype=torch.float64)\n",
      "tensor([[-0.6892],\n",
      "        [-0.7317],\n",
      "        [-0.4172],\n",
      "        [-0.1354]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0489]],\n",
      "\n",
      "        [[-1.0073]],\n",
      "\n",
      "        [[ 0.0464]],\n",
      "\n",
      "        [[ 0.0892]]], dtype=torch.float64)\n",
      "tensor([[-0.2112],\n",
      "        [-0.3017],\n",
      "        [-0.2107],\n",
      "        [-0.3241]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2008]],\n",
      "\n",
      "        [[-0.2655]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.3845]]], dtype=torch.float64)\n",
      "tensor([[-0.3630],\n",
      "        [-0.4488],\n",
      "        [-0.4241],\n",
      "        [-0.4275]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3372]],\n",
      "\n",
      "        [[-0.2944]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.3961]]], dtype=torch.float64)\n",
      "tensor([[-0.3022],\n",
      "        [-0.2660],\n",
      "        [-0.2961],\n",
      "        [-0.3525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4839]],\n",
      "\n",
      "        [[-0.4585]],\n",
      "\n",
      "        [[-0.1384]],\n",
      "\n",
      "        [[-0.2367]]], dtype=torch.float64)\n",
      "tensor([[-0.4350],\n",
      "        [-0.4014],\n",
      "        [-0.3322],\n",
      "        [-0.3553]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3175]],\n",
      "\n",
      "        [[-0.4157]],\n",
      "\n",
      "        [[-0.5451]],\n",
      "\n",
      "        [[-0.4215]]], dtype=torch.float64)\n",
      "tensor([[-0.3285],\n",
      "        [-0.2515],\n",
      "        [-0.3465],\n",
      "        [-0.6869]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1789]],\n",
      "\n",
      "        [[ 0.0915]],\n",
      "\n",
      "        [[-0.3326]],\n",
      "\n",
      "        [[-0.7462]]], dtype=torch.float64)\n",
      "tensor([[-0.7114],\n",
      "        [-0.7929],\n",
      "        [-0.6962],\n",
      "        [-0.4072]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0466]],\n",
      "\n",
      "        [[-0.8363]],\n",
      "\n",
      "        [[-0.3938]],\n",
      "\n",
      "        [[-0.0922]]], dtype=torch.float64)\n",
      "tensor([[-0.5810],\n",
      "        [-0.6391],\n",
      "        [-0.5485],\n",
      "        [-0.5713]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5093]],\n",
      "\n",
      "        [[-0.6341]],\n",
      "\n",
      "        [[-0.7254]],\n",
      "\n",
      "        [[-0.6202]]], dtype=torch.float64)\n",
      "tensor([[-0.7559],\n",
      "        [-1.0325],\n",
      "        [-0.9314],\n",
      "        [-1.1360]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6676]],\n",
      "\n",
      "        [[-0.7323]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-1.0940]]], dtype=torch.float64)\n",
      "tensor([[-0.9821],\n",
      "        [-1.0378],\n",
      "        [-1.1168],\n",
      "        [-1.0604]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1321]],\n",
      "\n",
      "        [[-1.1610]],\n",
      "\n",
      "        [[-0.9495]],\n",
      "\n",
      "        [[-0.8005]]], dtype=torch.float64)\n",
      "tensor([[-1.0474],\n",
      "        [-0.9934],\n",
      "        [-1.0228],\n",
      "        [-1.0612]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9588]],\n",
      "\n",
      "        [[-1.2904]],\n",
      "\n",
      "        [[-1.4637]],\n",
      "\n",
      "        [[-1.0893]]], dtype=torch.float64)\n",
      "tensor([[-0.7212],\n",
      "        [-0.6382],\n",
      "        [-0.7369],\n",
      "        [-0.7350]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5775]],\n",
      "\n",
      "        [[-0.2505]],\n",
      "\n",
      "        [[-0.5937]],\n",
      "\n",
      "        [[-1.0316]]], dtype=torch.float64)\n",
      "tensor([[-0.8251],\n",
      "        [-0.6719],\n",
      "        [-0.6335],\n",
      "        [-0.3578]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2303]],\n",
      "\n",
      "        [[-0.6653]],\n",
      "\n",
      "        [[-0.5555]],\n",
      "\n",
      "        [[-0.1546]]], dtype=torch.float64)\n",
      "tensor([[-0.4513],\n",
      "        [-0.4355],\n",
      "        [-0.2984],\n",
      "        [-0.2996]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[-0.3395]],\n",
      "\n",
      "        [[-0.3776]],\n",
      "\n",
      "        [[-0.2979]]], dtype=torch.float64)\n",
      "tensor([[-0.3089],\n",
      "        [-0.3835],\n",
      "        [-0.4193],\n",
      "        [-0.8260]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2471]],\n",
      "\n",
      "        [[-0.1696]],\n",
      "\n",
      "        [[-0.5891]],\n",
      "\n",
      "        [[-0.9276]]], dtype=torch.float64)\n",
      "tensor([[-0.7153],\n",
      "        [-0.7496],\n",
      "        [-0.7483],\n",
      "        [-0.7687]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8802]],\n",
      "\n",
      "        [[-0.8848]],\n",
      "\n",
      "        [[-0.5729]],\n",
      "\n",
      "        [[-1.0674]]], dtype=torch.float64)\n",
      "tensor([[-0.9650],\n",
      "        [-1.0443],\n",
      "        [-0.9716],\n",
      "        [-0.8427]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1171]],\n",
      "\n",
      "        [[-1.2546]],\n",
      "\n",
      "        [[-1.4325]],\n",
      "\n",
      "        [[-1.2499]]], dtype=torch.float64)\n",
      "tensor([[-0.7539],\n",
      "        [-0.7950],\n",
      "        [-0.8038],\n",
      "        [-0.8095]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8941]],\n",
      "\n",
      "        [[-0.7751]],\n",
      "\n",
      "        [[-0.9403]],\n",
      "\n",
      "        [[-1.0327]]], dtype=torch.float64)\n",
      "tensor([[-0.6794],\n",
      "        [-0.6496],\n",
      "        [-0.4171],\n",
      "        [-0.3595]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8328]],\n",
      "\n",
      "        [[-0.7138]],\n",
      "\n",
      "        [[-0.2517]],\n",
      "\n",
      "        [[-0.1870]]], dtype=torch.float64)\n",
      "tensor([[-0.4621],\n",
      "        [-0.4935],\n",
      "        [-0.2690],\n",
      "        [-0.2630]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4735]],\n",
      "\n",
      "        [[-0.4654]],\n",
      "\n",
      "        [[-0.3360]],\n",
      "\n",
      "        [[-0.1269]]], dtype=torch.float64)\n",
      "tensor([[-0.1884],\n",
      "        [-0.4491],\n",
      "        [-0.5137],\n",
      "        [-0.5645]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5232]],\n",
      "\n",
      "        [[-0.1350]],\n",
      "\n",
      "        [[-0.6538]],\n",
      "\n",
      "        [[-0.5994]]], dtype=torch.float64)\n",
      "tensor([[-0.4294],\n",
      "        [-0.6077],\n",
      "        [-0.1736],\n",
      "        [-0.3330]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6665]],\n",
      "\n",
      "        [[-0.7104]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[-0.0668]]], dtype=torch.float64)\n",
      "tensor([[-0.5498],\n",
      "        [-0.5041],\n",
      "        [-0.4784],\n",
      "        [-0.4603]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5128]],\n",
      "\n",
      "        [[-0.5544]],\n",
      "\n",
      "        [[-0.6122]],\n",
      "\n",
      "        [[-0.5763]]], dtype=torch.float64)\n",
      "tensor([[-0.2030],\n",
      "        [-0.4213],\n",
      "        [-0.5161],\n",
      "        [-0.5862]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1639]],\n",
      "\n",
      "        [[-0.1280]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[-0.5174]]], dtype=torch.float64)\n",
      "tensor([[-0.4866],\n",
      "        [-0.4618],\n",
      "        [-0.4163],\n",
      "        [-0.4700]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7277]],\n",
      "\n",
      "        [[-0.6549]],\n",
      "\n",
      "        [[-0.2424]],\n",
      "\n",
      "        [[-0.1304]]], dtype=torch.float64)\n",
      "tensor([[-0.4876],\n",
      "        [-0.7292],\n",
      "        [-0.8176],\n",
      "        [-0.8754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4550]],\n",
      "\n",
      "        [[-1.0108]],\n",
      "\n",
      "        [[-1.2811]],\n",
      "\n",
      "        [[-1.2869]]], dtype=torch.float64)\n",
      "tensor([[-0.3718],\n",
      "        [-0.1112],\n",
      "        [-0.3209],\n",
      "        [-0.4990]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0788]],\n",
      "\n",
      "        [[ 0.2833]],\n",
      "\n",
      "        [[-0.1361]],\n",
      "\n",
      "        [[-0.6503]]], dtype=torch.float64)\n",
      "tensor([[-0.6985],\n",
      "        [-0.7766],\n",
      "        [-0.0931],\n",
      "        [-0.0512]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1621]],\n",
      "\n",
      "        [[-0.4308]],\n",
      "\n",
      "        [[ 0.1747]],\n",
      "\n",
      "        [[ 0.4520]]], dtype=torch.float64)\n",
      "tensor([[-0.1280],\n",
      "        [-0.2234],\n",
      "        [-0.3169],\n",
      "        [-0.5077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2625]],\n",
      "\n",
      "        [[-0.1084]],\n",
      "\n",
      "        [[-0.4319]],\n",
      "\n",
      "        [[-0.2609]]], dtype=torch.float64)\n",
      "tensor([[0.0914],\n",
      "        [0.2904],\n",
      "        [0.1939],\n",
      "        [0.1522]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5340]],\n",
      "\n",
      "        [[0.8148]],\n",
      "\n",
      "        [[0.3838]],\n",
      "\n",
      "        [[0.0464]]], dtype=torch.float64)\n",
      "tensor([[-0.1558],\n",
      "        [-0.3631],\n",
      "        [ 0.3201],\n",
      "        [ 0.8575]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5567]],\n",
      "\n",
      "        [[-0.2124]],\n",
      "\n",
      "        [[ 1.0066]],\n",
      "\n",
      "        [[ 1.5323]]], dtype=torch.float64)\n",
      "tensor([[ 0.7263],\n",
      "        [ 0.3509],\n",
      "        [ 0.1586],\n",
      "        [-0.0803]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9188]],\n",
      "\n",
      "        [[ 0.0950]],\n",
      "\n",
      "        [[-0.2898]],\n",
      "\n",
      "        [[ 0.0268]]], dtype=torch.float64)\n",
      "tensor([[0.5474],\n",
      "        [0.6090],\n",
      "        [0.5311],\n",
      "        [0.4300]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0805]],\n",
      "\n",
      "        [[1.1695]],\n",
      "\n",
      "        [[0.7270]],\n",
      "\n",
      "        [[0.2683]]], dtype=torch.float64)\n",
      "tensor([[0.4643],\n",
      "        [0.1024],\n",
      "        [0.1530],\n",
      "        [0.1821]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1597]],\n",
      "\n",
      "        [[0.0337]],\n",
      "\n",
      "        [[0.3746]],\n",
      "\n",
      "        [[0.5594]]], dtype=torch.float64)\n",
      "tensor([[-0.0442],\n",
      "        [-0.0681],\n",
      "        [-0.0135],\n",
      "        [-0.0753]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1666]],\n",
      "\n",
      "        [[-0.1858]],\n",
      "\n",
      "        [[-0.3025]],\n",
      "\n",
      "        [[-0.2667]]], dtype=torch.float64)\n",
      "tensor([[0.2538],\n",
      "        [0.5904],\n",
      "        [0.4881],\n",
      "        [0.2801]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7905]],\n",
      "\n",
      "        [[1.1002]],\n",
      "\n",
      "        [[0.7293]],\n",
      "\n",
      "        [[0.0510]]], dtype=torch.float64)\n",
      "tensor([[ 0.0542],\n",
      "        [-0.1638],\n",
      "        [ 0.4647],\n",
      "        [ 0.6231]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2898]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[ 1.2873]],\n",
      "\n",
      "        [[ 1.4953]]], dtype=torch.float64)\n",
      "tensor([[0.5886],\n",
      "        [0.2822],\n",
      "        [0.2950],\n",
      "        [0.1336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6160]],\n",
      "\n",
      "        [[ 0.1389]],\n",
      "\n",
      "        [[-0.0021]],\n",
      "\n",
      "        [[ 0.1123]]], dtype=torch.float64)\n",
      "tensor([[0.4526],\n",
      "        [0.4996],\n",
      "        [0.3745],\n",
      "        [0.3715]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8598]],\n",
      "\n",
      "        [[0.9442]],\n",
      "\n",
      "        [[0.4681]],\n",
      "\n",
      "        [[0.2232]]], dtype=torch.float64)\n",
      "tensor([[0.2645],\n",
      "        [0.1728],\n",
      "        [0.4416],\n",
      "        [0.3966]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[ 0.0603]],\n",
      "\n",
      "        [[ 0.8621]],\n",
      "\n",
      "        [[ 0.8541]]], dtype=torch.float64)\n",
      "tensor([[ 0.3933],\n",
      "        [ 0.2577],\n",
      "        [ 0.0802],\n",
      "        [-0.1670]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5513]],\n",
      "\n",
      "        [[ 0.0095]],\n",
      "\n",
      "        [[-0.3880]],\n",
      "\n",
      "        [[-0.3187]]], dtype=torch.float64)\n",
      "tensor([[0.5009],\n",
      "        [0.9315],\n",
      "        [0.9164],\n",
      "        [0.6060]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1845]],\n",
      "\n",
      "        [[1.5461]],\n",
      "\n",
      "        [[1.0193]],\n",
      "\n",
      "        [[0.5918]]], dtype=torch.float64)\n",
      "tensor([[0.4468],\n",
      "        [0.0703],\n",
      "        [0.5676],\n",
      "        [0.8798]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0703]],\n",
      "\n",
      "        [[ 0.3757]],\n",
      "\n",
      "        [[ 1.1129]],\n",
      "\n",
      "        [[ 1.3913]]], dtype=torch.float64)\n",
      "tensor([[0.7527],\n",
      "        [0.5895],\n",
      "        [0.3141],\n",
      "        [0.0558]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9754]],\n",
      "\n",
      "        [[ 0.4150]],\n",
      "\n",
      "        [[-0.1315]],\n",
      "\n",
      "        [[ 0.4878]]], dtype=torch.float64)\n",
      "tensor([[0.5523],\n",
      "        [0.7541],\n",
      "        [0.6453],\n",
      "        [0.4281]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0112]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[0.8078]],\n",
      "\n",
      "        [[0.1874]]], dtype=torch.float64)\n",
      "tensor([[ 0.1278],\n",
      "        [-0.1328],\n",
      "        [ 0.4577],\n",
      "        [ 0.7593]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4215]],\n",
      "\n",
      "        [[ 0.0037]],\n",
      "\n",
      "        [[ 0.9858]],\n",
      "\n",
      "        [[ 1.1695]]], dtype=torch.float64)\n",
      "tensor([[ 0.6180],\n",
      "        [ 0.3797],\n",
      "        [ 0.0478],\n",
      "        [-0.0433]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7512]],\n",
      "\n",
      "        [[ 0.0788]],\n",
      "\n",
      "        [[-0.3545]],\n",
      "\n",
      "        [[ 0.2244]]], dtype=torch.float64)\n",
      "tensor([[0.6480],\n",
      "        [0.7686],\n",
      "        [0.7698],\n",
      "        [0.4629]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0886]],\n",
      "\n",
      "        [[1.2781]],\n",
      "\n",
      "        [[0.8471]],\n",
      "\n",
      "        [[0.1227]]], dtype=torch.float64)\n",
      "tensor([[0.1769],\n",
      "        [0.0441],\n",
      "        [0.8340],\n",
      "        [0.9487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2667]],\n",
      "\n",
      "        [[ 0.1573]],\n",
      "\n",
      "        [[ 1.3821]],\n",
      "\n",
      "        [[ 1.4086]]], dtype=torch.float64)\n",
      "tensor([[0.7748],\n",
      "        [0.6573],\n",
      "        [0.3452],\n",
      "        [0.0786]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.0204]],\n",
      "\n",
      "        [[ 0.4947]],\n",
      "\n",
      "        [[-0.3118]],\n",
      "\n",
      "        [[ 0.5144]]], dtype=torch.float64)\n",
      "tensor([[0.8168],\n",
      "        [0.9988],\n",
      "        [0.7157],\n",
      "        [0.4511]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1625]],\n",
      "\n",
      "        [[1.4606]],\n",
      "\n",
      "        [[0.8252]],\n",
      "\n",
      "        [[0.3826]]], dtype=torch.float64)\n",
      "tensor([[ 0.4774],\n",
      "        [ 0.2138],\n",
      "        [-0.0156],\n",
      "        [-0.1257]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0869]],\n",
      "\n",
      "        [[-0.2239]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.2586]]], dtype=torch.float64)\n",
      "tensor([[-0.1599],\n",
      "        [-0.0802],\n",
      "        [ 0.0230],\n",
      "        [-0.1147]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2078]],\n",
      "\n",
      "        [[-0.1026]],\n",
      "\n",
      "        [[-0.3314]],\n",
      "\n",
      "        [[-0.4481]]], dtype=torch.float64)\n",
      "tensor([[-0.1878],\n",
      "        [-0.0665],\n",
      "        [-0.1898],\n",
      "        [-0.0138]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1951]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[-0.1153]],\n",
      "\n",
      "        [[-0.1465]]], dtype=torch.float64)\n",
      "tensor([[0.1981],\n",
      "        [0.2196],\n",
      "        [0.2074],\n",
      "        [0.2141]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1165]],\n",
      "\n",
      "        [[-0.0807]],\n",
      "\n",
      "        [[ 0.3006]],\n",
      "\n",
      "        [[ 0.5952]]], dtype=torch.float64)\n",
      "tensor([[ 0.1486],\n",
      "        [ 0.1392],\n",
      "        [ 0.0836],\n",
      "        [-0.0052]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2960]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[-0.6098]],\n",
      "\n",
      "        [[-0.1615]]], dtype=torch.float64)\n",
      "tensor([[0.3655],\n",
      "        [0.3568],\n",
      "        [0.3281],\n",
      "        [0.3116]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6334]],\n",
      "\n",
      "        [[ 0.8263]],\n",
      "\n",
      "        [[ 0.4878]],\n",
      "\n",
      "        [[-0.1130]]], dtype=torch.float64)\n",
      "tensor([[0.1543],\n",
      "        [0.0187],\n",
      "        [0.4589],\n",
      "        [0.4665]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6029]],\n",
      "\n",
      "        [[ 0.0129]],\n",
      "\n",
      "        [[ 0.6611]],\n",
      "\n",
      "        [[ 0.9107]]], dtype=torch.float64)\n",
      "tensor([[ 0.3825],\n",
      "        [ 0.1380],\n",
      "        [-0.1642],\n",
      "        [-0.1081]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5201]],\n",
      "\n",
      "        [[-0.3210]],\n",
      "\n",
      "        [[-0.7023]],\n",
      "\n",
      "        [[-0.0922]]], dtype=torch.float64)\n",
      "tensor([[ 0.4624],\n",
      "        [ 0.2095],\n",
      "        [-0.1142],\n",
      "        [-0.2519]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6888]],\n",
      "\n",
      "        [[ 0.0534]],\n",
      "\n",
      "        [[-0.3302]],\n",
      "\n",
      "        [[-0.4215]]], dtype=torch.float64)\n",
      "tensor([[-0.1980],\n",
      "        [-0.0351],\n",
      "        [-0.1248],\n",
      "        [-0.1869]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5475]],\n",
      "\n",
      "        [[-0.4111]],\n",
      "\n",
      "        [[-0.1200]],\n",
      "\n",
      "        [[-0.1072]]], dtype=torch.float64)\n",
      "tensor([[-0.2301],\n",
      "        [-0.1624],\n",
      "        [-0.2335],\n",
      "        [-0.1336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2078]],\n",
      "\n",
      "        [[-0.5775]],\n",
      "\n",
      "        [[-0.6953]],\n",
      "\n",
      "        [[-0.5267]]], dtype=torch.float64)\n",
      "tensor([[0.0822],\n",
      "        [0.4639],\n",
      "        [0.4524],\n",
      "        [0.4880]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4450]],\n",
      "\n",
      "        [[0.9892]],\n",
      "\n",
      "        [[0.6230]],\n",
      "\n",
      "        [[0.1735]]], dtype=torch.float64)\n",
      "tensor([[0.4066],\n",
      "        [0.2175],\n",
      "        [0.8217],\n",
      "        [0.8948]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2008]],\n",
      "\n",
      "        [[ 0.2440]],\n",
      "\n",
      "        [[ 1.1117]],\n",
      "\n",
      "        [[ 1.4398]]], dtype=torch.float64)\n",
      "tensor([[0.8210],\n",
      "        [0.4734],\n",
      "        [0.1953],\n",
      "        [0.0830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8645]],\n",
      "\n",
      "        [[ 0.0256]],\n",
      "\n",
      "        [[-0.4204]],\n",
      "\n",
      "        [[ 0.1389]]], dtype=torch.float64)\n",
      "tensor([[0.7893],\n",
      "        [0.8818],\n",
      "        [0.7463],\n",
      "        [0.5866]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1452]],\n",
      "\n",
      "        [[1.3128]],\n",
      "\n",
      "        [[0.9523]],\n",
      "\n",
      "        [[0.4185]]], dtype=torch.float64)\n",
      "tensor([[0.5735],\n",
      "        [0.5795],\n",
      "        [0.8539],\n",
      "        [0.9651]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3769]],\n",
      "\n",
      "        [[0.8090]],\n",
      "\n",
      "        [[1.0955]],\n",
      "\n",
      "        [[1.3543]]], dtype=torch.float64)\n",
      "tensor([[0.6890],\n",
      "        [0.5666],\n",
      "        [0.4699],\n",
      "        [0.4182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7073]],\n",
      "\n",
      "        [[0.3711]],\n",
      "\n",
      "        [[0.1539]],\n",
      "\n",
      "        [[0.5629]]], dtype=torch.float64)\n",
      "tensor([[0.9356],\n",
      "        [0.6055],\n",
      "        [0.1259],\n",
      "        [0.1619]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13786:   8%|▊         | 233/3067 [00:00<00:08, 330.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3035]],\n",
      "\n",
      "        [[ 0.3896]],\n",
      "\n",
      "        [[ 0.0464]],\n",
      "\n",
      "        [[-0.0553]]], dtype=torch.float64)\n",
      "tensor([[0.2431],\n",
      "        [0.2137],\n",
      "        [0.0939],\n",
      "        [0.0919]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1142]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[ 0.0638]],\n",
      "\n",
      "        [[ 0.1908]]], dtype=torch.float64)\n",
      "tensor([[0.1213],\n",
      "        [0.2050],\n",
      "        [0.3910],\n",
      "        [0.3474]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0603]],\n",
      "\n",
      "        [[-0.0160]],\n",
      "\n",
      "        [[-0.0021]],\n",
      "\n",
      "        [[ 0.1747]]], dtype=torch.float64)\n",
      "tensor([[0.3822],\n",
      "        [0.3715],\n",
      "        [0.5086],\n",
      "        [0.3546]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6472]],\n",
      "\n",
      "        [[0.9176]],\n",
      "\n",
      "        [[0.4785]],\n",
      "\n",
      "        [[0.0672]]], dtype=torch.float64)\n",
      "tensor([[0.3943],\n",
      "        [0.3060],\n",
      "        [0.4727],\n",
      "        [0.5272]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0587]],\n",
      "\n",
      "        [[ 0.0926]],\n",
      "\n",
      "        [[ 0.7894]],\n",
      "\n",
      "        [[ 0.9130]]], dtype=torch.float64)\n",
      "tensor([[0.4900],\n",
      "        [0.4645],\n",
      "        [0.4246],\n",
      "        [0.2477]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6103]],\n",
      "\n",
      "        [[ 0.1423]],\n",
      "\n",
      "        [[-0.2505]],\n",
      "\n",
      "        [[-0.1442]]], dtype=torch.float64)\n",
      "tensor([[0.5687],\n",
      "        [0.5718],\n",
      "        [0.5793],\n",
      "        [0.4307]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9569]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[0.7039]],\n",
      "\n",
      "        [[0.1134]]], dtype=torch.float64)\n",
      "tensor([[0.3729],\n",
      "        [0.2182],\n",
      "        [0.8215],\n",
      "        [0.7869]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2644]],\n",
      "\n",
      "        [[-0.0148]],\n",
      "\n",
      "        [[ 1.1822]],\n",
      "\n",
      "        [[ 1.2885]]], dtype=torch.float64)\n",
      "tensor([[0.5698],\n",
      "        [0.2796],\n",
      "        [0.2862],\n",
      "        [0.1861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4751]],\n",
      "\n",
      "        [[ 0.0753]],\n",
      "\n",
      "        [[-0.2274]],\n",
      "\n",
      "        [[-0.2078]]], dtype=torch.float64)\n",
      "tensor([[ 0.0405],\n",
      "        [-0.0954],\n",
      "        [ 0.0299],\n",
      "        [-0.2335]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2609]],\n",
      "\n",
      "        [[ 0.3087]],\n",
      "\n",
      "        [[-0.0137]],\n",
      "\n",
      "        [[-0.6746]]], dtype=torch.float64)\n",
      "tensor([[-0.3450],\n",
      "        [-0.3003],\n",
      "        [ 0.2054],\n",
      "        [ 0.0580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9726]],\n",
      "\n",
      "        [[-0.5798]],\n",
      "\n",
      "        [[ 0.2174]],\n",
      "\n",
      "        [[ 0.0880]]], dtype=torch.float64)\n",
      "tensor([[0.1027],\n",
      "        [0.1705],\n",
      "        [0.3001],\n",
      "        [0.3954]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0349]],\n",
      "\n",
      "        [[-0.0749]],\n",
      "\n",
      "        [[-0.0321]],\n",
      "\n",
      "        [[ 0.2024]]], dtype=torch.float64)\n",
      "tensor([[0.2716],\n",
      "        [0.1065],\n",
      "        [0.1312],\n",
      "        [0.2755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3861]],\n",
      "\n",
      "        [[0.2625]],\n",
      "\n",
      "        [[0.2278]],\n",
      "\n",
      "        [[0.0961]]], dtype=torch.float64)\n",
      "tensor([[0.4094],\n",
      "        [0.5115],\n",
      "        [0.6244],\n",
      "        [0.6842]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0857]],\n",
      "\n",
      "        [[0.5271]],\n",
      "\n",
      "        [[0.9372]],\n",
      "\n",
      "        [[1.1152]]], dtype=torch.float64)\n",
      "tensor([[0.5928],\n",
      "        [0.4590],\n",
      "        [0.3030],\n",
      "        [0.3165]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8136]],\n",
      "\n",
      "        [[ 0.1631]],\n",
      "\n",
      "        [[-0.2759]],\n",
      "\n",
      "        [[ 0.1389]]], dtype=torch.float64)\n",
      "tensor([[0.4891],\n",
      "        [0.7899],\n",
      "        [0.5787],\n",
      "        [0.4524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8922]],\n",
      "\n",
      "        [[1.2284]],\n",
      "\n",
      "        [[0.5814]],\n",
      "\n",
      "        [[0.3075]]], dtype=torch.float64)\n",
      "tensor([[0.2940],\n",
      "        [0.1992],\n",
      "        [0.4840],\n",
      "        [0.6568]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4088]],\n",
      "\n",
      "        [[ 0.0672]],\n",
      "\n",
      "        [[ 0.8425]],\n",
      "\n",
      "        [[ 1.0770]]], dtype=torch.float64)\n",
      "tensor([[0.5443],\n",
      "        [0.6144],\n",
      "        [0.6530],\n",
      "        [0.4638]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8598]],\n",
      "\n",
      "        [[0.5352]],\n",
      "\n",
      "        [[0.3884]],\n",
      "\n",
      "        [[0.3249]]], dtype=torch.float64)\n",
      "tensor([[0.4543],\n",
      "        [0.5327],\n",
      "        [0.4334],\n",
      "        [0.4361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6680]],\n",
      "\n",
      "        [[0.9384]],\n",
      "\n",
      "        [[0.5883]],\n",
      "\n",
      "        [[0.1862]]], dtype=torch.float64)\n",
      "tensor([[0.4897],\n",
      "        [0.4881],\n",
      "        [0.3853],\n",
      "        [0.0947]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1273]],\n",
      "\n",
      "        [[0.0984]],\n",
      "\n",
      "        [[0.3422]],\n",
      "\n",
      "        [[0.2636]]], dtype=torch.float64)\n",
      "tensor([[-0.2213],\n",
      "        [ 0.0197],\n",
      "        [ 0.3330],\n",
      "        [ 0.0716]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0141]],\n",
      "\n",
      "        [[-0.0160]],\n",
      "\n",
      "        [[-0.0587]],\n",
      "\n",
      "        [[-0.0460]]], dtype=torch.float64)\n",
      "tensor([[0.2544],\n",
      "        [0.1134],\n",
      "        [0.1294],\n",
      "        [0.2445]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3156]],\n",
      "\n",
      "        [[ 0.6172]],\n",
      "\n",
      "        [[ 0.3584]],\n",
      "\n",
      "        [[-0.0183]]], dtype=torch.float64)\n",
      "tensor([[0.2697],\n",
      "        [0.1662],\n",
      "        [0.3744],\n",
      "        [0.3616]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2124]],\n",
      "\n",
      "        [[-0.0356]],\n",
      "\n",
      "        [[ 0.6426]],\n",
      "\n",
      "        [[ 0.7628]]], dtype=torch.float64)\n",
      "tensor([[0.3270],\n",
      "        [0.3778],\n",
      "        [0.3722],\n",
      "        [0.2910]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5906]],\n",
      "\n",
      "        [[ 0.1458]],\n",
      "\n",
      "        [[-0.1200]],\n",
      "\n",
      "        [[-0.0171]]], dtype=torch.float64)\n",
      "tensor([[0.3114],\n",
      "        [0.4804],\n",
      "        [0.3990],\n",
      "        [0.3571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6345]],\n",
      "\n",
      "        [[0.9650]],\n",
      "\n",
      "        [[0.5213]],\n",
      "\n",
      "        [[0.2047]]], dtype=torch.float64)\n",
      "tensor([[0.4326],\n",
      "        [0.4867],\n",
      "        [0.6344],\n",
      "        [0.5871]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0730]],\n",
      "\n",
      "        [[0.3549]],\n",
      "\n",
      "        [[0.9580]],\n",
      "\n",
      "        [[1.1961]]], dtype=torch.float64)\n",
      "tensor([[0.6078],\n",
      "        [0.5884],\n",
      "        [0.3834],\n",
      "        [0.3693]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9130]],\n",
      "\n",
      "        [[0.3226]],\n",
      "\n",
      "        [[0.1146]],\n",
      "\n",
      "        [[0.3780]]], dtype=torch.float64)\n",
      "tensor([[0.3851],\n",
      "        [0.4034],\n",
      "        [0.4000],\n",
      "        [0.4480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7466]],\n",
      "\n",
      "        [[0.7836]],\n",
      "\n",
      "        [[0.5271]],\n",
      "\n",
      "        [[0.0926]]], dtype=torch.float64)\n",
      "tensor([[0.2379],\n",
      "        [0.2777],\n",
      "        [0.8986],\n",
      "        [1.0703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3164]],\n",
      "\n",
      "        [[ 0.4404]],\n",
      "\n",
      "        [[ 1.3266]],\n",
      "\n",
      "        [[ 1.8673]]], dtype=torch.float64)\n",
      "tensor([[1.0280],\n",
      "        [0.6594],\n",
      "        [0.6610],\n",
      "        [0.6628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8182]],\n",
      "\n",
      "        [[0.4970]],\n",
      "\n",
      "        [[0.4427]],\n",
      "\n",
      "        [[0.6195]]], dtype=torch.float64)\n",
      "tensor([[0.6138],\n",
      "        [0.6837],\n",
      "        [0.6397],\n",
      "        [0.4820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0643]],\n",
      "\n",
      "        [[1.1441]],\n",
      "\n",
      "        [[0.6981]],\n",
      "\n",
      "        [[0.3006]]], dtype=torch.float64)\n",
      "tensor([[0.4683],\n",
      "        [0.5142],\n",
      "        [0.8801],\n",
      "        [0.7386]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0287]],\n",
      "\n",
      "        [[ 0.6137]],\n",
      "\n",
      "        [[ 1.2215]],\n",
      "\n",
      "        [[ 1.3047]]], dtype=torch.float64)\n",
      "tensor([[0.7183],\n",
      "        [0.6581],\n",
      "        [0.5633],\n",
      "        [0.6385]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0331]],\n",
      "\n",
      "        [[0.2763]],\n",
      "\n",
      "        [[0.3526]],\n",
      "\n",
      "        [[0.8194]]], dtype=torch.float64)\n",
      "tensor([[0.9372],\n",
      "        [0.8981],\n",
      "        [0.8924],\n",
      "        [0.6960]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3393]],\n",
      "\n",
      "        [[1.4849]],\n",
      "\n",
      "        [[1.2538]],\n",
      "\n",
      "        [[0.5744]]], dtype=torch.float64)\n",
      "tensor([[0.6394],\n",
      "        [0.6936],\n",
      "        [0.9177],\n",
      "        [0.9919]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4450]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[1.3393]],\n",
      "\n",
      "        [[1.3867]]], dtype=torch.float64)\n",
      "tensor([[0.6110],\n",
      "        [0.7206],\n",
      "        [0.7390],\n",
      "        [0.6174]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9315]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[0.4936]],\n",
      "\n",
      "        [[0.2036]]], dtype=torch.float64)\n",
      "tensor([[0.2766],\n",
      "        [0.5162],\n",
      "        [0.3441],\n",
      "        [0.3393]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5432]],\n",
      "\n",
      "        [[0.9777]],\n",
      "\n",
      "        [[0.4370]],\n",
      "\n",
      "        [[0.1793]]], dtype=torch.float64)\n",
      "tensor([[0.2926],\n",
      "        [0.4584],\n",
      "        [0.5482],\n",
      "        [0.4932]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2598]],\n",
      "\n",
      "        [[ 0.4289]],\n",
      "\n",
      "        [[ 0.8078]],\n",
      "\n",
      "        [[ 1.0470]]], dtype=torch.float64)\n",
      "tensor([[0.5850],\n",
      "        [0.5051],\n",
      "        [0.6731],\n",
      "        [0.7250]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7501]],\n",
      "\n",
      "        [[0.4127]],\n",
      "\n",
      "        [[0.2660]],\n",
      "\n",
      "        [[0.8621]]], dtype=torch.float64)\n",
      "tensor([[1.1309],\n",
      "        [1.0524],\n",
      "        [1.1384],\n",
      "        [0.9922]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6120]],\n",
      "\n",
      "        [[1.8315]],\n",
      "\n",
      "        [[1.3717]],\n",
      "\n",
      "        [[0.7570]]], dtype=torch.float64)\n",
      "tensor([[0.8418],\n",
      "        [0.7645],\n",
      "        [1.0768],\n",
      "        [1.0917]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3387]],\n",
      "\n",
      "        [[0.8344]],\n",
      "\n",
      "        [[1.5277]],\n",
      "\n",
      "        [[1.7114]]], dtype=torch.float64)\n",
      "tensor([[1.0909],\n",
      "        [0.9638],\n",
      "        [0.9144],\n",
      "        [1.1247]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3959]],\n",
      "\n",
      "        [[0.7062]],\n",
      "\n",
      "        [[0.7558]],\n",
      "\n",
      "        [[1.3359]]], dtype=torch.float64)\n",
      "tensor([[1.4758],\n",
      "        [1.3521],\n",
      "        [1.0156],\n",
      "        [0.7520]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6952]],\n",
      "\n",
      "        [[1.6929]],\n",
      "\n",
      "        [[1.2873]],\n",
      "\n",
      "        [[0.4474]]], dtype=torch.float64)\n",
      "tensor([[0.5257],\n",
      "        [0.4280],\n",
      "        [0.5219],\n",
      "        [0.4524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0395]],\n",
      "\n",
      "        [[0.3445]],\n",
      "\n",
      "        [[0.6207]],\n",
      "\n",
      "        [[0.8194]]], dtype=torch.float64)\n",
      "tensor([[0.5810],\n",
      "        [0.5336],\n",
      "        [0.6153],\n",
      "        [0.6364]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5144]],\n",
      "\n",
      "        [[0.2740]],\n",
      "\n",
      "        [[0.0545]],\n",
      "\n",
      "        [[0.3122]]], dtype=torch.float64)\n",
      "tensor([[0.5437],\n",
      "        [0.5025],\n",
      "        [0.3104],\n",
      "        [0.2588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7177]],\n",
      "\n",
      "        [[ 0.2613]],\n",
      "\n",
      "        [[ 0.3688]],\n",
      "\n",
      "        [[-0.1488]]], dtype=torch.float64)\n",
      "tensor([[0.1742],\n",
      "        [0.3086],\n",
      "        [0.5253],\n",
      "        [0.2986]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[ 0.1527]],\n",
      "\n",
      "        [[ 0.3434]],\n",
      "\n",
      "        [[ 0.7350]]], dtype=torch.float64)\n",
      "tensor([[0.2874],\n",
      "        [0.3092],\n",
      "        [0.3226],\n",
      "        [0.3486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5271]],\n",
      "\n",
      "        [[ 0.1053]],\n",
      "\n",
      "        [[-0.2147]],\n",
      "\n",
      "        [[-0.0414]]], dtype=torch.float64)\n",
      "tensor([[0.4717],\n",
      "        [0.1974],\n",
      "        [0.2385],\n",
      "        [0.4444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5109]],\n",
      "\n",
      "        [[0.2729]],\n",
      "\n",
      "        [[0.3295]],\n",
      "\n",
      "        [[0.3064]]], dtype=torch.float64)\n",
      "tensor([[0.7289],\n",
      "        [0.5842],\n",
      "        [0.5866],\n",
      "        [0.5174]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1701]],\n",
      "\n",
      "        [[0.2324]],\n",
      "\n",
      "        [[0.6368]],\n",
      "\n",
      "        [[0.9153]]], dtype=torch.float64)\n",
      "tensor([[0.8042],\n",
      "        [0.6458],\n",
      "        [0.7504],\n",
      "        [0.7704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8055]],\n",
      "\n",
      "        [[0.3780]],\n",
      "\n",
      "        [[0.2867]],\n",
      "\n",
      "        [[0.4277]]], dtype=torch.float64)\n",
      "tensor([[0.8390],\n",
      "        [0.6978],\n",
      "        [0.8147],\n",
      "        [0.7780]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9407]],\n",
      "\n",
      "        [[1.2330]],\n",
      "\n",
      "        [[0.9037]],\n",
      "\n",
      "        [[0.4266]]], dtype=torch.float64)\n",
      "tensor([[0.7360],\n",
      "        [0.9144],\n",
      "        [1.0223],\n",
      "        [0.9643]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2706]],\n",
      "\n",
      "        [[0.9708]],\n",
      "\n",
      "        [[1.3948]],\n",
      "\n",
      "        [[1.6201]]], dtype=torch.float64)\n",
      "tensor([[0.9670],\n",
      "        [0.6842],\n",
      "        [0.5050],\n",
      "        [0.3321]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.0574]],\n",
      "\n",
      "        [[ 0.4543]],\n",
      "\n",
      "        [[-0.0079]],\n",
      "\n",
      "        [[ 0.2348]]], dtype=torch.float64)\n",
      "tensor([[0.2116],\n",
      "        [0.1830],\n",
      "        [0.1962],\n",
      "        [0.1949]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3295]],\n",
      "\n",
      "        [[ 0.4381]],\n",
      "\n",
      "        [[ 0.1238]],\n",
      "\n",
      "        [[-0.0206]]], dtype=torch.float64)\n",
      "tensor([[0.1685],\n",
      "        [0.1095],\n",
      "        [0.1806],\n",
      "        [0.0244]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2205]],\n",
      "\n",
      "        [[-0.0968]],\n",
      "\n",
      "        [[ 0.0580]],\n",
      "\n",
      "        [[ 0.3561]]], dtype=torch.float64)\n",
      "tensor([[0.1531],\n",
      "        [0.1669],\n",
      "        [0.1938],\n",
      "        [0.2235]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1227]],\n",
      "\n",
      "        [[-0.0102]],\n",
      "\n",
      "        [[-0.2736]],\n",
      "\n",
      "        [[ 0.1019]]], dtype=torch.float64)\n",
      "tensor([[ 0.1845],\n",
      "        [-0.0143],\n",
      "        [ 0.0786],\n",
      "        [-0.0695]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1053]],\n",
      "\n",
      "        [[ 0.2995]],\n",
      "\n",
      "        [[ 0.1643]],\n",
      "\n",
      "        [[-0.4250]]], dtype=torch.float64)\n",
      "tensor([[-0.2094],\n",
      "        [ 0.1009],\n",
      "        [ 0.2582],\n",
      "        [-0.0317]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5405]],\n",
      "\n",
      "        [[-0.0529]],\n",
      "\n",
      "        [[ 0.1446]],\n",
      "\n",
      "        [[-0.0310]]], dtype=torch.float64)\n",
      "tensor([[-0.0322],\n",
      "        [ 0.2204],\n",
      "        [ 0.2756],\n",
      "        [ 0.3526]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0580]],\n",
      "\n",
      "        [[-0.0321]],\n",
      "\n",
      "        [[-0.2274]],\n",
      "\n",
      "        [[ 0.2463]]], dtype=torch.float64)\n",
      "tensor([[0.4051],\n",
      "        [0.4260],\n",
      "        [0.4264],\n",
      "        [0.4265]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6773]],\n",
      "\n",
      "        [[0.9164]],\n",
      "\n",
      "        [[0.4219]],\n",
      "\n",
      "        [[0.1735]]], dtype=torch.float64)\n",
      "tensor([[0.5287],\n",
      "        [0.6046],\n",
      "        [0.6219],\n",
      "        [0.5992]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0067]],\n",
      "\n",
      "        [[ 0.4751]],\n",
      "\n",
      "        [[ 0.8922]],\n",
      "\n",
      "        [[ 1.1394]]], dtype=torch.float64)\n",
      "tensor([[0.6880],\n",
      "        [0.6697],\n",
      "        [0.7308],\n",
      "        [0.6965]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8506]],\n",
      "\n",
      "        [[0.4300]],\n",
      "\n",
      "        [[0.2833]],\n",
      "\n",
      "        [[0.5225]]], dtype=torch.float64)\n",
      "tensor([[0.6707],\n",
      "        [0.6464],\n",
      "        [0.8042],\n",
      "        [0.7024]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5664]],\n",
      "\n",
      "        [[1.1290]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.4393]]], dtype=torch.float64)\n",
      "tensor([[0.7139],\n",
      "        [0.7719],\n",
      "        [0.8560],\n",
      "        [0.5853]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1712]],\n",
      "\n",
      "        [[0.6877]],\n",
      "\n",
      "        [[0.9384]],\n",
      "\n",
      "        [[0.5444]]], dtype=torch.float64)\n",
      "tensor([[0.6057],\n",
      "        [0.5685],\n",
      "        [0.7335],\n",
      "        [0.9125]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7050]],\n",
      "\n",
      "        [[0.4254]],\n",
      "\n",
      "        [[0.3457]],\n",
      "\n",
      "        [[0.7015]]], dtype=torch.float64)\n",
      "tensor([[0.7118],\n",
      "        [0.3296],\n",
      "        [0.2486],\n",
      "        [0.2846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8910]],\n",
      "\n",
      "        [[0.4185]],\n",
      "\n",
      "        [[0.1805]],\n",
      "\n",
      "        [[0.0788]]], dtype=torch.float64)\n",
      "tensor([[0.3590],\n",
      "        [0.3960],\n",
      "        [0.3384],\n",
      "        [0.2900]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13970:  10%|▉         | 303/3067 [00:00<00:08, 338.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0876]],\n",
      "\n",
      "        [[ 0.2717]],\n",
      "\n",
      "        [[ 0.5594]],\n",
      "\n",
      "        [[ 0.5606]]], dtype=torch.float64)\n",
      "tensor([[0.2011],\n",
      "        [0.1861],\n",
      "        [0.2592],\n",
      "        [0.3871]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0603]],\n",
      "\n",
      "        [[-0.1673]],\n",
      "\n",
      "        [[-0.1257]],\n",
      "\n",
      "        [[ 0.2925]]], dtype=torch.float64)\n",
      "tensor([[0.4201],\n",
      "        [0.5367],\n",
      "        [0.7435],\n",
      "        [0.5960]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8575]],\n",
      "\n",
      "        [[1.1729]],\n",
      "\n",
      "        [[0.8402]],\n",
      "\n",
      "        [[0.1204]]], dtype=torch.float64)\n",
      "tensor([[0.3270],\n",
      "        [0.4819],\n",
      "        [0.9425],\n",
      "        [1.0065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3383]],\n",
      "\n",
      "        [[ 0.4601]],\n",
      "\n",
      "        [[ 1.4502]],\n",
      "\n",
      "        [[ 1.6709]]], dtype=torch.float64)\n",
      "tensor([[0.9247],\n",
      "        [0.8993],\n",
      "        [0.8917],\n",
      "        [0.9031]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2665]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.4924]],\n",
      "\n",
      "        [[1.0066]]], dtype=torch.float64)\n",
      "tensor([[1.1821],\n",
      "        [0.9414],\n",
      "        [0.4864],\n",
      "        [0.4136]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4468]],\n",
      "\n",
      "        [[0.9003]],\n",
      "\n",
      "        [[0.6184]],\n",
      "\n",
      "        [[0.1805]]], dtype=torch.float64)\n",
      "tensor([[0.5466],\n",
      "        [0.5826],\n",
      "        [0.5237],\n",
      "        [0.4513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2012]],\n",
      "\n",
      "        [[0.3561]],\n",
      "\n",
      "        [[0.5490]],\n",
      "\n",
      "        [[0.8645]]], dtype=torch.float64)\n",
      "tensor([[0.3766],\n",
      "        [0.3240],\n",
      "        [0.4152],\n",
      "        [0.4585]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3133]],\n",
      "\n",
      "        [[ 0.0349]],\n",
      "\n",
      "        [[-0.1327]],\n",
      "\n",
      "        [[ 0.3156]]], dtype=torch.float64)\n",
      "tensor([[0.6698],\n",
      "        [0.7133],\n",
      "        [0.8118],\n",
      "        [0.7444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9037]],\n",
      "\n",
      "        [[1.2457]],\n",
      "\n",
      "        [[1.0008]],\n",
      "\n",
      "        [[0.4370]]], dtype=torch.float64)\n",
      "tensor([[0.6668],\n",
      "        [0.6839],\n",
      "        [1.0547],\n",
      "        [0.8421]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1908]],\n",
      "\n",
      "        [[1.1418]],\n",
      "\n",
      "        [[1.3890]],\n",
      "\n",
      "        [[1.2423]]], dtype=torch.float64)\n",
      "tensor([[0.9441],\n",
      "        [0.9314],\n",
      "        [0.9184],\n",
      "        [0.8186]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2538]],\n",
      "\n",
      "        [[0.9141]],\n",
      "\n",
      "        [[0.5906]],\n",
      "\n",
      "        [[0.9326]]], dtype=torch.float64)\n",
      "tensor([[0.8251],\n",
      "        [0.5851],\n",
      "        [0.6268],\n",
      "        [0.5038]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8356]],\n",
      "\n",
      "        [[1.0666]],\n",
      "\n",
      "        [[0.5467]],\n",
      "\n",
      "        [[0.4000]]], dtype=torch.float64)\n",
      "tensor([[0.5333],\n",
      "        [0.6687],\n",
      "        [0.6543],\n",
      "        [0.4488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0788]],\n",
      "\n",
      "        [[0.5536]],\n",
      "\n",
      "        [[0.8309]],\n",
      "\n",
      "        [[0.9465]]], dtype=torch.float64)\n",
      "tensor([[0.4391],\n",
      "        [0.4757],\n",
      "        [0.4375],\n",
      "        [0.4514]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5132]],\n",
      "\n",
      "        [[ 0.2220]],\n",
      "\n",
      "        [[-0.1049]],\n",
      "\n",
      "        [[ 0.1077]]], dtype=torch.float64)\n",
      "tensor([[0.4584],\n",
      "        [0.3691],\n",
      "        [0.3401],\n",
      "        [0.3909]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3018]],\n",
      "\n",
      "        [[0.7662]],\n",
      "\n",
      "        [[0.4092]],\n",
      "\n",
      "        [[0.1377]]], dtype=torch.float64)\n",
      "tensor([[0.5128],\n",
      "        [0.4644],\n",
      "        [0.2884],\n",
      "        [0.2822]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0152]],\n",
      "\n",
      "        [[0.1712]],\n",
      "\n",
      "        [[0.3954]],\n",
      "\n",
      "        [[0.6773]]], dtype=torch.float64)\n",
      "tensor([[0.3702],\n",
      "        [0.5434],\n",
      "        [0.5813],\n",
      "        [0.4691]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3734]],\n",
      "\n",
      "        [[0.2636]],\n",
      "\n",
      "        [[0.1238]],\n",
      "\n",
      "        [[0.3260]]], dtype=torch.float64)\n",
      "tensor([[0.4308],\n",
      "        [0.5077],\n",
      "        [0.5315],\n",
      "        [0.5304]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6519]],\n",
      "\n",
      "        [[0.9176]],\n",
      "\n",
      "        [[0.8448]],\n",
      "\n",
      "        [[0.4624]]], dtype=torch.float64)\n",
      "tensor([[0.6186],\n",
      "        [0.5376],\n",
      "        [0.6594],\n",
      "        [0.6728]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2694]],\n",
      "\n",
      "        [[0.4346]],\n",
      "\n",
      "        [[0.9153]],\n",
      "\n",
      "        [[1.2989]]], dtype=torch.float64)\n",
      "tensor([[0.8741],\n",
      "        [0.9023],\n",
      "        [0.9215],\n",
      "        [0.7062]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2677]],\n",
      "\n",
      "        [[0.8841]],\n",
      "\n",
      "        [[0.5952]],\n",
      "\n",
      "        [[0.5144]]], dtype=torch.float64)\n",
      "tensor([[0.5756],\n",
      "        [0.3876],\n",
      "        [0.3938],\n",
      "        [0.6004]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5756]],\n",
      "\n",
      "        [[0.6819]],\n",
      "\n",
      "        [[0.6184]],\n",
      "\n",
      "        [[0.6126]]], dtype=torch.float64)\n",
      "tensor([[0.8499],\n",
      "        [0.8706],\n",
      "        [0.8389],\n",
      "        [0.8283]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6484]],\n",
      "\n",
      "        [[0.7628]],\n",
      "\n",
      "        [[0.8864]],\n",
      "\n",
      "        [[1.4006]]], dtype=torch.float64)\n",
      "tensor([[0.9370],\n",
      "        [0.9154],\n",
      "        [1.0038],\n",
      "        [0.9309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1995]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[0.8194]],\n",
      "\n",
      "        [[0.7986]]], dtype=torch.float64)\n",
      "tensor([[0.8193],\n",
      "        [0.7100],\n",
      "        [0.5094],\n",
      "        [0.6750]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9511]],\n",
      "\n",
      "        [[0.8679]],\n",
      "\n",
      "        [[0.7385]],\n",
      "\n",
      "        [[0.7212]]], dtype=torch.float64)\n",
      "tensor([[0.9460],\n",
      "        [0.9365],\n",
      "        [0.9793],\n",
      "        [0.7961]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6992]],\n",
      "\n",
      "        [[0.8379]],\n",
      "\n",
      "        [[1.1764]],\n",
      "\n",
      "        [[1.2400]]], dtype=torch.float64)\n",
      "tensor([[0.8499],\n",
      "        [0.8730],\n",
      "        [0.7514],\n",
      "        [0.6223]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1233]],\n",
      "\n",
      "        [[0.5525]],\n",
      "\n",
      "        [[0.2232]],\n",
      "\n",
      "        [[0.5710]]], dtype=torch.float64)\n",
      "tensor([[1.1534],\n",
      "        [1.1383],\n",
      "        [1.1161],\n",
      "        [1.0257]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5011]],\n",
      "\n",
      "        [[1.6467]],\n",
      "\n",
      "        [[1.4710]],\n",
      "\n",
      "        [[0.7408]]], dtype=torch.float64)\n",
      "tensor([[0.8759],\n",
      "        [0.8856],\n",
      "        [1.3851],\n",
      "        [1.3121]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4127]],\n",
      "\n",
      "        [[1.2065]],\n",
      "\n",
      "        [[1.7160]],\n",
      "\n",
      "        [[1.8616]]], dtype=torch.float64)\n",
      "tensor([[1.3248],\n",
      "        [1.2716],\n",
      "        [1.1197],\n",
      "        [1.0784]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6201]],\n",
      "\n",
      "        [[1.0285]],\n",
      "\n",
      "        [[0.6865]],\n",
      "\n",
      "        [[1.2943]]], dtype=torch.float64)\n",
      "tensor([[1.5818],\n",
      "        [1.2907],\n",
      "        [1.1660],\n",
      "        [1.2570]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8142]],\n",
      "\n",
      "        [[1.2376]],\n",
      "\n",
      "        [[1.3486]],\n",
      "\n",
      "        [[1.1233]]], dtype=torch.float64)\n",
      "tensor([[1.3215],\n",
      "        [1.2653],\n",
      "        [1.5003],\n",
      "        [1.4981]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9222]],\n",
      "\n",
      "        [[1.0678]],\n",
      "\n",
      "        [[1.7969]],\n",
      "\n",
      "        [[1.9806]]], dtype=torch.float64)\n",
      "tensor([[1.2475],\n",
      "        [1.2200],\n",
      "        [1.2584],\n",
      "        [1.1912]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4572]],\n",
      "\n",
      "        [[1.1498]],\n",
      "\n",
      "        [[0.8656]],\n",
      "\n",
      "        [[1.1579]]], dtype=torch.float64)\n",
      "tensor([[1.4404],\n",
      "        [1.4729],\n",
      "        [1.4910],\n",
      "        [1.4437]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8362]],\n",
      "\n",
      "        [[2.1111]],\n",
      "\n",
      "        [[1.7818]],\n",
      "\n",
      "        [[1.3162]]], dtype=torch.float64)\n",
      "tensor([[1.3803],\n",
      "        [1.3802],\n",
      "        [1.3464],\n",
      "        [1.3460]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9765]],\n",
      "\n",
      "        [[1.3775]],\n",
      "\n",
      "        [[1.3717]],\n",
      "\n",
      "        [[1.8142]]], dtype=torch.float64)\n",
      "tensor([[1.4598],\n",
      "        [1.2692],\n",
      "        [1.1718],\n",
      "        [1.1194]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5288]],\n",
      "\n",
      "        [[0.9476]],\n",
      "\n",
      "        [[0.7281]],\n",
      "\n",
      "        [[1.2480]]], dtype=torch.float64)\n",
      "tensor([[1.3164],\n",
      "        [1.2656],\n",
      "        [1.3263],\n",
      "        [1.1419]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6940]],\n",
      "\n",
      "        [[1.9124]],\n",
      "\n",
      "        [[1.4941]],\n",
      "\n",
      "        [[0.8275]]], dtype=torch.float64)\n",
      "tensor([[0.9536],\n",
      "        [0.8854],\n",
      "        [1.1296],\n",
      "        [0.9063]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4346]],\n",
      "\n",
      "        [[0.7293]],\n",
      "\n",
      "        [[1.1903]],\n",
      "\n",
      "        [[1.3590]]], dtype=torch.float64)\n",
      "tensor([[1.2377],\n",
      "        [0.8624],\n",
      "        [0.8634],\n",
      "        [0.8528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2665]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[0.3803]],\n",
      "\n",
      "        [[0.8136]]], dtype=torch.float64)\n",
      "tensor([[1.1069],\n",
      "        [0.8558],\n",
      "        [0.7808],\n",
      "        [0.7703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4271]],\n",
      "\n",
      "        [[0.5687]],\n",
      "\n",
      "        [[0.7963]],\n",
      "\n",
      "        [[0.5456]]], dtype=torch.float64)\n",
      "tensor([[0.7535],\n",
      "        [0.8283],\n",
      "        [0.6933],\n",
      "        [0.7229]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5121]],\n",
      "\n",
      "        [[0.6253]],\n",
      "\n",
      "        [[0.9500]],\n",
      "\n",
      "        [[1.0181]]], dtype=torch.float64)\n",
      "tensor([[0.5177],\n",
      "        [0.6471],\n",
      "        [0.7754],\n",
      "        [0.7908]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6819]],\n",
      "\n",
      "        [[0.4739]],\n",
      "\n",
      "        [[0.2937]],\n",
      "\n",
      "        [[0.6022]]], dtype=torch.float64)\n",
      "tensor([[0.6309],\n",
      "        [0.5783],\n",
      "        [0.6761],\n",
      "        [0.6649]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9303]],\n",
      "\n",
      "        [[0.8656]],\n",
      "\n",
      "        [[0.7593]],\n",
      "\n",
      "        [[0.4023]]], dtype=torch.float64)\n",
      "tensor([[0.7329],\n",
      "        [0.7247],\n",
      "        [0.6722],\n",
      "        [0.4490]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1712]],\n",
      "\n",
      "        [[0.5028]],\n",
      "\n",
      "        [[0.8067]],\n",
      "\n",
      "        [[0.5513]]], dtype=torch.float64)\n",
      "tensor([[0.3346],\n",
      "        [0.3935],\n",
      "        [0.6880],\n",
      "        [0.7061]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2486]],\n",
      "\n",
      "        [[0.2775]],\n",
      "\n",
      "        [[0.2059]],\n",
      "\n",
      "        [[0.3838]]], dtype=torch.float64)\n",
      "tensor([[0.6016],\n",
      "        [0.6006],\n",
      "        [0.4180],\n",
      "        [0.4806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5617]],\n",
      "\n",
      "        [[0.5664]],\n",
      "\n",
      "        [[0.1862]],\n",
      "\n",
      "        [[0.2036]]], dtype=torch.float64)\n",
      "tensor([[0.7069],\n",
      "        [0.7441],\n",
      "        [1.0217],\n",
      "        [1.0123]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2140]],\n",
      "\n",
      "        [[0.4115]],\n",
      "\n",
      "        [[1.1071]],\n",
      "\n",
      "        [[1.2792]]], dtype=torch.float64)\n",
      "tensor([[1.0869],\n",
      "        [1.0667],\n",
      "        [1.2023],\n",
      "        [1.1822]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1498]],\n",
      "\n",
      "        [[0.8333]],\n",
      "\n",
      "        [[0.7801]],\n",
      "\n",
      "        [[1.1660]]], dtype=torch.float64)\n",
      "tensor([[1.3059],\n",
      "        [1.2420],\n",
      "        [1.4110],\n",
      "        [1.3376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5508]],\n",
      "\n",
      "        [[1.7160]],\n",
      "\n",
      "        [[1.5219]],\n",
      "\n",
      "        [[1.0759]]], dtype=torch.float64)\n",
      "tensor([[1.2503],\n",
      "        [1.2440],\n",
      "        [1.3571],\n",
      "        [1.3413]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8402]],\n",
      "\n",
      "        [[1.1637]],\n",
      "\n",
      "        [[1.5496]],\n",
      "\n",
      "        [[1.6074]]], dtype=torch.float64)\n",
      "tensor([[1.2900],\n",
      "        [1.2981],\n",
      "        [1.3284],\n",
      "        [1.4741]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3289]],\n",
      "\n",
      "        [[1.0239]],\n",
      "\n",
      "        [[1.0331]],\n",
      "\n",
      "        [[1.2457]]], dtype=torch.float64)\n",
      "tensor([[1.3093],\n",
      "        [1.2355],\n",
      "        [1.3649],\n",
      "        [1.2336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4595]],\n",
      "\n",
      "        [[1.5912]],\n",
      "\n",
      "        [[1.4468]],\n",
      "\n",
      "        [[0.9557]]], dtype=torch.float64)\n",
      "tensor([[1.1505],\n",
      "        [1.1218],\n",
      "        [1.3801],\n",
      "        [1.4049]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6495]],\n",
      "\n",
      "        [[1.2977]],\n",
      "\n",
      "        [[1.8200]],\n",
      "\n",
      "        [[1.9806]]], dtype=torch.float64)\n",
      "tensor([[1.4051],\n",
      "        [1.2015],\n",
      "        [0.9927],\n",
      "        [1.0300]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6548]],\n",
      "\n",
      "        [[0.8344]],\n",
      "\n",
      "        [[0.4635]],\n",
      "\n",
      "        [[1.3382]]], dtype=torch.float64)\n",
      "tensor([[1.6677],\n",
      "        [1.2163],\n",
      "        [1.2029],\n",
      "        [1.0679]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8084]],\n",
      "\n",
      "        [[1.6721]],\n",
      "\n",
      "        [[1.4398]],\n",
      "\n",
      "        [[0.7027]]], dtype=torch.float64)\n",
      "tensor([[0.7992],\n",
      "        [0.8635],\n",
      "        [0.7047],\n",
      "        [0.6473]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5017]],\n",
      "\n",
      "        [[0.6426]],\n",
      "\n",
      "        [[0.7974]],\n",
      "\n",
      "        [[1.0135]]], dtype=torch.float64)\n",
      "tensor([[0.6162],\n",
      "        [0.5690],\n",
      "        [0.7769],\n",
      "        [0.8365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7339]],\n",
      "\n",
      "        [[0.4797]],\n",
      "\n",
      "        [[0.4046]],\n",
      "\n",
      "        [[0.6750]]], dtype=torch.float64)\n",
      "tensor([[0.7651],\n",
      "        [0.7116],\n",
      "        [0.7662],\n",
      "        [0.6028]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8205]],\n",
      "\n",
      "        [[0.8749]],\n",
      "\n",
      "        [[0.6045]],\n",
      "\n",
      "        [[0.4855]]], dtype=torch.float64)\n",
      "tensor([[0.7563],\n",
      "        [0.7322],\n",
      "        [0.7830],\n",
      "        [0.7402]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2070]],\n",
      "\n",
      "        [[0.5906]],\n",
      "\n",
      "        [[1.0077]],\n",
      "\n",
      "        [[1.1002]]], dtype=torch.float64)\n",
      "tensor([[0.8366],\n",
      "        [0.7137],\n",
      "        [0.7350],\n",
      "        [0.6971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7674]],\n",
      "\n",
      "        [[0.4011]],\n",
      "\n",
      "        [[0.2660]],\n",
      "\n",
      "        [[0.4959]]], dtype=torch.float64)\n",
      "tensor([[1.0098],\n",
      "        [1.2342],\n",
      "        [1.4637],\n",
      "        [1.3143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2631]],\n",
      "\n",
      "        [[1.8465]],\n",
      "\n",
      "        [[1.6663]],\n",
      "\n",
      "        [[1.2169]]], dtype=torch.float64)\n",
      "tensor([[1.2357],\n",
      "        [1.1048],\n",
      "        [1.4093],\n",
      "        [1.4268]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1695]],\n",
      "\n",
      "        [[0.9234]],\n",
      "\n",
      "        [[1.6028]],\n",
      "\n",
      "        [[1.9540]]], dtype=torch.float64)\n",
      "tensor([[1.4856],\n",
      "        [1.3016],\n",
      "        [1.3600],\n",
      "        [1.4844]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7391]],\n",
      "\n",
      "        [[1.1348]],\n",
      "\n",
      "        [[1.1614]],\n",
      "\n",
      "        [[1.6709]]], dtype=torch.float64)\n",
      "tensor([[1.4121],\n",
      "        [1.1651],\n",
      "        [1.1432],\n",
      "        [1.0156]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3151]],\n",
      "\n",
      "        [[1.1314]],\n",
      "\n",
      "        [[1.2977]],\n",
      "\n",
      "        [[0.6935]]], dtype=torch.float64)\n",
      "tensor([[0.9189],\n",
      "        [0.9614],\n",
      "        [0.9287],\n",
      "        [0.9312]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6010]],\n",
      "\n",
      "        [[0.9315]],\n",
      "\n",
      "        [[1.0840]],\n",
      "\n",
      "        [[1.3139]]], dtype=torch.float64)\n",
      "tensor([[0.5847],\n",
      "        [0.7909],\n",
      "        [0.8009],\n",
      "        [0.7935]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8021]],\n",
      "\n",
      "        [[0.6022]],\n",
      "\n",
      "        [[0.4358]],\n",
      "\n",
      "        [[0.6403]]], dtype=torch.float64)\n",
      "tensor([[0.6724],\n",
      "        [0.6352],\n",
      "        [0.6738],\n",
      "        [0.6159]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9430]],\n",
      "\n",
      "        [[0.8852]],\n",
      "\n",
      "        [[0.6969]],\n",
      "\n",
      "        [[0.5051]]], dtype=torch.float64)\n",
      "tensor([[0.6874],\n",
      "        [0.7267],\n",
      "        [0.8634],\n",
      "        [0.8775]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3376]],\n",
      "\n",
      "        [[0.7408]],\n",
      "\n",
      "        [[1.2076]],\n",
      "\n",
      "        [[1.3532]]], dtype=torch.float64)\n",
      "tensor([[0.9741],\n",
      "        [0.8173],\n",
      "        [0.7480],\n",
      "        [0.7828]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0551]],\n",
      "\n",
      "        [[0.5536]],\n",
      "\n",
      "        [[0.2683]],\n",
      "\n",
      "        [[0.8656]]], dtype=torch.float64)\n",
      "tensor([[1.2728],\n",
      "        [1.3953],\n",
      "        [1.4025],\n",
      "        [1.3087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7830]],\n",
      "\n",
      "        [[2.1158]],\n",
      "\n",
      "        [[1.7888]],\n",
      "\n",
      "        [[1.0551]]], dtype=torch.float64)\n",
      "tensor([[1.2464],\n",
      "        [0.9346],\n",
      "        [0.8917],\n",
      "        [1.0308]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8587]],\n",
      "\n",
      "        [[0.7870]],\n",
      "\n",
      "        [[1.2943]],\n",
      "\n",
      "        [[1.5750]]], dtype=torch.float64)\n",
      "tensor([[1.0419],\n",
      "        [0.9719],\n",
      "        [0.8684],\n",
      "        [0.7354]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2769]],\n",
      "\n",
      "        [[0.6287]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.7790]]], dtype=torch.float64)\n",
      "tensor([[1.2558],\n",
      "        [1.3337],\n",
      "        [1.3552],\n",
      "        [1.1457]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6894]],\n",
      "\n",
      "        [[1.9725]],\n",
      "\n",
      "        [[1.5300]],\n",
      "\n",
      "        [[0.7443]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13970:  12%|█▏        | 373/3067 [00:01<00:07, 339.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9922],\n",
      "        [1.0372],\n",
      "        [1.2078],\n",
      "        [1.0221]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5617]],\n",
      "\n",
      "        [[1.3659]],\n",
      "\n",
      "        [[1.5565]],\n",
      "\n",
      "        [[1.4237]]], dtype=torch.float64)\n",
      "tensor([[0.9949],\n",
      "        [0.8873],\n",
      "        [0.7252],\n",
      "        [0.6773]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1452]],\n",
      "\n",
      "        [[0.5744]],\n",
      "\n",
      "        [[0.2163]],\n",
      "\n",
      "        [[0.4462]]], dtype=torch.float64)\n",
      "tensor([[0.9558],\n",
      "        [0.8741],\n",
      "        [0.8573],\n",
      "        [0.8555]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0609]],\n",
      "\n",
      "        [[1.2561]],\n",
      "\n",
      "        [[1.0147]],\n",
      "\n",
      "        [[0.4358]]], dtype=torch.float64)\n",
      "tensor([[0.6645],\n",
      "        [0.6098],\n",
      "        [1.3610],\n",
      "        [1.4937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0684]],\n",
      "\n",
      "        [[0.7362]],\n",
      "\n",
      "        [[1.7195]],\n",
      "\n",
      "        [[1.9505]]], dtype=torch.float64)\n",
      "tensor([[1.4815],\n",
      "        [1.2060],\n",
      "        [0.9801],\n",
      "        [0.8843]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6802]],\n",
      "\n",
      "        [[0.8182]],\n",
      "\n",
      "        [[0.3896]],\n",
      "\n",
      "        [[0.7882]]], dtype=torch.float64)\n",
      "tensor([[1.6834],\n",
      "        [1.5186],\n",
      "        [1.3402],\n",
      "        [1.2815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1481]],\n",
      "\n",
      "        [[1.8200]],\n",
      "\n",
      "        [[1.3786]],\n",
      "\n",
      "        [[1.1602]]], dtype=torch.float64)\n",
      "tensor([[1.2018],\n",
      "        [0.9079],\n",
      "        [0.8698],\n",
      "        [0.9133]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8090]],\n",
      "\n",
      "        [[0.5837]],\n",
      "\n",
      "        [[1.0366]],\n",
      "\n",
      "        [[1.2111]]], dtype=torch.float64)\n",
      "tensor([[0.9161],\n",
      "        [0.9755],\n",
      "        [0.9031],\n",
      "        [0.7588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9765]],\n",
      "\n",
      "        [[0.6646]],\n",
      "\n",
      "        [[0.3561]],\n",
      "\n",
      "        [[0.8309]]], dtype=torch.float64)\n",
      "tensor([[1.1281],\n",
      "        [1.0999],\n",
      "        [1.0721],\n",
      "        [0.9585]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2688]],\n",
      "\n",
      "        [[1.4757]],\n",
      "\n",
      "        [[1.2088]],\n",
      "\n",
      "        [[0.5063]]], dtype=torch.float64)\n",
      "tensor([[0.7328],\n",
      "        [0.6886],\n",
      "        [1.2532],\n",
      "        [1.3014]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1365]],\n",
      "\n",
      "        [[0.7027]],\n",
      "\n",
      "        [[1.4907]],\n",
      "\n",
      "        [[1.7241]]], dtype=torch.float64)\n",
      "tensor([[1.3864],\n",
      "        [1.1890],\n",
      "        [0.9604],\n",
      "        [0.8689]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4341]],\n",
      "\n",
      "        [[0.7512]],\n",
      "\n",
      "        [[0.3850]],\n",
      "\n",
      "        [[0.9107]]], dtype=torch.float64)\n",
      "tensor([[1.4851],\n",
      "        [1.5072],\n",
      "        [1.5229],\n",
      "        [1.2536]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7379]],\n",
      "\n",
      "        [[1.9309]],\n",
      "\n",
      "        [[1.6062]],\n",
      "\n",
      "        [[0.9211]]], dtype=torch.float64)\n",
      "tensor([[1.1240],\n",
      "        [1.0265],\n",
      "        [1.6067],\n",
      "        [1.6369]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5594]],\n",
      "\n",
      "        [[1.1510]],\n",
      "\n",
      "        [[1.9251]],\n",
      "\n",
      "        [[2.1238]]], dtype=torch.float64)\n",
      "tensor([[1.5874],\n",
      "        [1.4244],\n",
      "        [1.1777],\n",
      "        [1.0478]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6883]],\n",
      "\n",
      "        [[1.1637]],\n",
      "\n",
      "        [[0.5860]],\n",
      "\n",
      "        [[1.1314]]], dtype=torch.float64)\n",
      "tensor([[1.5864],\n",
      "        [1.6186],\n",
      "        [1.4823],\n",
      "        [1.2496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9286]],\n",
      "\n",
      "        [[2.0360]],\n",
      "\n",
      "        [[1.3717]],\n",
      "\n",
      "        [[1.0643]]], dtype=torch.float64)\n",
      "tensor([[1.3130],\n",
      "        [1.2474],\n",
      "        [1.2635],\n",
      "        [1.2524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9257]],\n",
      "\n",
      "        [[0.8841]],\n",
      "\n",
      "        [[1.4063]],\n",
      "\n",
      "        [[1.6755]]], dtype=torch.float64)\n",
      "tensor([[1.2494],\n",
      "        [1.2579],\n",
      "        [1.2120],\n",
      "        [1.0395]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5126]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[0.7420]],\n",
      "\n",
      "        [[1.0239]]], dtype=torch.float64)\n",
      "tensor([[1.5467],\n",
      "        [1.2554],\n",
      "        [0.9354],\n",
      "        [1.0088]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8558]],\n",
      "\n",
      "        [[1.1002]],\n",
      "\n",
      "        [[0.9973]],\n",
      "\n",
      "        [[0.7790]]], dtype=torch.float64)\n",
      "tensor([[1.1516],\n",
      "        [1.1008],\n",
      "        [1.1430],\n",
      "        [0.9032]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8725]],\n",
      "\n",
      "        [[0.8633]],\n",
      "\n",
      "        [[1.1868]],\n",
      "\n",
      "        [[1.3463]]], dtype=torch.float64)\n",
      "tensor([[1.0148],\n",
      "        [1.0685],\n",
      "        [1.1990],\n",
      "        [1.0552]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1290]],\n",
      "\n",
      "        [[0.9696]],\n",
      "\n",
      "        [[0.8009]],\n",
      "\n",
      "        [[0.9361]]], dtype=torch.float64)\n",
      "tensor([[0.9823],\n",
      "        [1.0770],\n",
      "        [0.9211],\n",
      "        [0.8656]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2619]],\n",
      "\n",
      "        [[1.3740]],\n",
      "\n",
      "        [[0.8148]],\n",
      "\n",
      "        [[0.7316]]], dtype=torch.float64)\n",
      "tensor([[0.9004],\n",
      "        [0.9245],\n",
      "        [0.8878],\n",
      "        [0.8376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5479]],\n",
      "\n",
      "        [[0.7882]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[1.3128]]], dtype=torch.float64)\n",
      "tensor([[0.8619],\n",
      "        [0.8105],\n",
      "        [0.7221],\n",
      "        [0.6159]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0251]],\n",
      "\n",
      "        [[0.4670]],\n",
      "\n",
      "        [[0.2752]],\n",
      "\n",
      "        [[0.5895]]], dtype=torch.float64)\n",
      "tensor([[0.8376],\n",
      "        [0.8413],\n",
      "        [0.9048],\n",
      "        [0.7455]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0262]],\n",
      "\n",
      "        [[1.4884]],\n",
      "\n",
      "        [[1.0112]],\n",
      "\n",
      "        [[0.4751]]], dtype=torch.float64)\n",
      "tensor([[0.6418],\n",
      "        [0.5316],\n",
      "        [1.1722],\n",
      "        [1.3824]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0880]],\n",
      "\n",
      "        [[0.5872]],\n",
      "\n",
      "        [[1.7148]],\n",
      "\n",
      "        [[2.1481]]], dtype=torch.float64)\n",
      "tensor([[1.3318],\n",
      "        [1.1122],\n",
      "        [0.9083],\n",
      "        [0.8084]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6028]],\n",
      "\n",
      "        [[0.8702]],\n",
      "\n",
      "        [[0.3930]],\n",
      "\n",
      "        [[0.9349]]], dtype=torch.float64)\n",
      "tensor([[1.4344],\n",
      "        [1.5953],\n",
      "        [1.5409],\n",
      "        [1.3321]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1689]],\n",
      "\n",
      "        [[2.4185]],\n",
      "\n",
      "        [[1.9251]],\n",
      "\n",
      "        [[1.2480]]], dtype=torch.float64)\n",
      "tensor([[1.3820],\n",
      "        [1.1959],\n",
      "        [1.4542],\n",
      "        [1.5098]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0043]],\n",
      "\n",
      "        [[1.1903]],\n",
      "\n",
      "        [[1.8951]],\n",
      "\n",
      "        [[2.1897]]], dtype=torch.float64)\n",
      "tensor([[1.2387],\n",
      "        [1.1262],\n",
      "        [1.0685],\n",
      "        [0.9075]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2319]],\n",
      "\n",
      "        [[1.0990]],\n",
      "\n",
      "        [[0.7096]],\n",
      "\n",
      "        [[0.9315]]], dtype=torch.float64)\n",
      "tensor([[0.9155],\n",
      "        [0.9864],\n",
      "        [0.9575],\n",
      "        [0.8575]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3266]],\n",
      "\n",
      "        [[1.6455]],\n",
      "\n",
      "        [[1.2388]],\n",
      "\n",
      "        [[0.4970]]], dtype=torch.float64)\n",
      "tensor([[0.6983],\n",
      "        [0.6565],\n",
      "        [1.2704],\n",
      "        [1.5524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1504]],\n",
      "\n",
      "        [[0.6611]],\n",
      "\n",
      "        [[1.8720]],\n",
      "\n",
      "        [[2.2567]]], dtype=torch.float64)\n",
      "tensor([[1.6115],\n",
      "        [1.3775],\n",
      "        [1.4218],\n",
      "        [1.2899]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7934]],\n",
      "\n",
      "        [[1.3255]],\n",
      "\n",
      "        [[1.0251]],\n",
      "\n",
      "        [[1.3024]]], dtype=torch.float64)\n",
      "tensor([[1.8571],\n",
      "        [2.0347],\n",
      "        [1.9576],\n",
      "        [1.6977]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3907]],\n",
      "\n",
      "        [[2.7385]],\n",
      "\n",
      "        [[2.2729]],\n",
      "\n",
      "        [[1.6536]]], dtype=torch.float64)\n",
      "tensor([[1.8717],\n",
      "        [1.5242],\n",
      "        [1.3790],\n",
      "        [1.3707]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4341]],\n",
      "\n",
      "        [[1.1764]],\n",
      "\n",
      "        [[1.3024]],\n",
      "\n",
      "        [[1.5022]]], dtype=torch.float64)\n",
      "tensor([[1.0374],\n",
      "        [0.8521],\n",
      "        [0.8872],\n",
      "        [0.8365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8275]],\n",
      "\n",
      "        [[0.6103]],\n",
      "\n",
      "        [[0.3630]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[1.0434],\n",
      "        [0.8114],\n",
      "        [0.7985],\n",
      "        [0.7155]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1683]],\n",
      "\n",
      "        [[1.2400]],\n",
      "\n",
      "        [[0.8645]],\n",
      "\n",
      "        [[0.2810]]], dtype=torch.float64)\n",
      "tensor([[0.6838],\n",
      "        [0.4878],\n",
      "        [1.0672],\n",
      "        [1.0895]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0164]],\n",
      "\n",
      "        [[0.1816]],\n",
      "\n",
      "        [[1.3590]],\n",
      "\n",
      "        [[1.5369]]], dtype=torch.float64)\n",
      "tensor([[1.0382],\n",
      "        [1.0041],\n",
      "        [0.9407],\n",
      "        [0.7143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1649]],\n",
      "\n",
      "        [[0.7177]],\n",
      "\n",
      "        [[0.2556]],\n",
      "\n",
      "        [[0.8263]]], dtype=torch.float64)\n",
      "tensor([[1.2160],\n",
      "        [1.4065],\n",
      "        [1.4571],\n",
      "        [1.1758]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5727]],\n",
      "\n",
      "        [[1.9933]],\n",
      "\n",
      "        [[1.5519]],\n",
      "\n",
      "        [[1.0251]]], dtype=torch.float64)\n",
      "tensor([[1.0287],\n",
      "        [1.0584],\n",
      "        [1.6823],\n",
      "        [1.6763]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6784]],\n",
      "\n",
      "        [[1.0019]],\n",
      "\n",
      "        [[1.9736]],\n",
      "\n",
      "        [[1.6132]]], dtype=torch.float64)\n",
      "tensor([[1.4152],\n",
      "        [1.3118],\n",
      "        [1.4639],\n",
      "        [1.4467]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5138]],\n",
      "\n",
      "        [[1.0655]],\n",
      "\n",
      "        [[1.0089]],\n",
      "\n",
      "        [[1.1337]]], dtype=torch.float64)\n",
      "tensor([[1.3757],\n",
      "        [1.2761],\n",
      "        [1.3241],\n",
      "        [1.2870]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2249]],\n",
      "\n",
      "        [[1.4664]],\n",
      "\n",
      "        [[1.2480]],\n",
      "\n",
      "        [[0.8587]]], dtype=torch.float64)\n",
      "tensor([[1.1892],\n",
      "        [0.9028],\n",
      "        [1.5347],\n",
      "        [1.6291]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5802]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[1.8870]],\n",
      "\n",
      "        [[2.0407]]], dtype=torch.float64)\n",
      "tensor([[1.5139],\n",
      "        [1.3206],\n",
      "        [1.2022],\n",
      "        [1.0404]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7033]],\n",
      "\n",
      "        [[0.9835]],\n",
      "\n",
      "        [[0.6391]],\n",
      "\n",
      "        [[0.9234]]], dtype=torch.float64)\n",
      "tensor([[1.4522],\n",
      "        [1.5076],\n",
      "        [1.1872],\n",
      "        [0.9467]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9113]],\n",
      "\n",
      "        [[1.9136]],\n",
      "\n",
      "        [[1.2203]],\n",
      "\n",
      "        [[0.8425]]], dtype=torch.float64)\n",
      "tensor([[0.9537],\n",
      "        [0.7550],\n",
      "        [0.7120],\n",
      "        [0.5678]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5698]],\n",
      "\n",
      "        [[0.7270]],\n",
      "\n",
      "        [[0.8413]],\n",
      "\n",
      "        [[0.9372]]], dtype=torch.float64)\n",
      "tensor([[0.5731],\n",
      "        [0.5174],\n",
      "        [0.3312],\n",
      "        [0.2213]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5432]],\n",
      "\n",
      "        [[ 0.0626]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[ 0.1458]]], dtype=torch.float64)\n",
      "tensor([[0.7689],\n",
      "        [0.7338],\n",
      "        [0.6681],\n",
      "        [0.6359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1163]],\n",
      "\n",
      "        [[1.3000]],\n",
      "\n",
      "        [[0.7870]],\n",
      "\n",
      "        [[0.2971]]], dtype=torch.float64)\n",
      "tensor([[0.5361],\n",
      "        [0.3513],\n",
      "        [1.0232],\n",
      "        [1.1145]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1350]],\n",
      "\n",
      "        [[ 0.2359]],\n",
      "\n",
      "        [[ 1.5762]],\n",
      "\n",
      "        [[ 1.8154]]], dtype=torch.float64)\n",
      "tensor([[1.1550],\n",
      "        [0.8351],\n",
      "        [0.6408],\n",
      "        [0.8114]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3509]],\n",
      "\n",
      "        [[0.4670]],\n",
      "\n",
      "        [[0.2740]],\n",
      "\n",
      "        [[0.9430]]], dtype=torch.float64)\n",
      "tensor([[1.5400],\n",
      "        [1.6929],\n",
      "        [1.6222],\n",
      "        [1.1905]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2278]],\n",
      "\n",
      "        [[2.4196]],\n",
      "\n",
      "        [[1.9968]],\n",
      "\n",
      "        [[0.8956]]], dtype=torch.float64)\n",
      "tensor([[1.1190],\n",
      "        [1.0773],\n",
      "        [1.1600],\n",
      "        [1.0562]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7824]],\n",
      "\n",
      "        [[1.0054]],\n",
      "\n",
      "        [[1.4167]],\n",
      "\n",
      "        [[1.5773]]], dtype=torch.float64)\n",
      "tensor([[0.9592],\n",
      "        [0.9054],\n",
      "        [0.9491],\n",
      "        [0.8366]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1591]],\n",
      "\n",
      "        [[0.7824]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[0.8252]]], dtype=torch.float64)\n",
      "tensor([[0.9462],\n",
      "        [0.6788],\n",
      "        [0.6605],\n",
      "        [0.6350]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7974]],\n",
      "\n",
      "        [[1.1244]],\n",
      "\n",
      "        [[0.7986]],\n",
      "\n",
      "        [[0.5825]]], dtype=torch.float64)\n",
      "tensor([[0.7541],\n",
      "        [0.7503],\n",
      "        [0.7396],\n",
      "        [0.5748]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4936]],\n",
      "\n",
      "        [[0.6368]],\n",
      "\n",
      "        [[0.9627]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[0.1724],\n",
      "        [0.2912],\n",
      "        [0.4911],\n",
      "        [0.5697]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2613]],\n",
      "\n",
      "        [[0.1654]],\n",
      "\n",
      "        [[0.1562]],\n",
      "\n",
      "        [[0.3226]]], dtype=torch.float64)\n",
      "tensor([[0.4631],\n",
      "        [0.4341],\n",
      "        [0.3659],\n",
      "        [0.4026]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5987]],\n",
      "\n",
      "        [[0.7258]],\n",
      "\n",
      "        [[0.2798]],\n",
      "\n",
      "        [[0.1828]]], dtype=torch.float64)\n",
      "tensor([[0.5460],\n",
      "        [0.4268],\n",
      "        [0.6281],\n",
      "        [0.4635]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0760]],\n",
      "\n",
      "        [[ 0.1966]],\n",
      "\n",
      "        [[ 0.6056]],\n",
      "\n",
      "        [[ 0.8171]]], dtype=torch.float64)\n",
      "tensor([[0.4899],\n",
      "        [0.5067],\n",
      "        [0.5235],\n",
      "        [0.3482]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5132]],\n",
      "\n",
      "        [[ 0.1504]],\n",
      "\n",
      "        [[-0.0772]],\n",
      "\n",
      "        [[ 0.0164]]], dtype=torch.float64)\n",
      "tensor([[0.7744],\n",
      "        [0.9460],\n",
      "        [0.9041],\n",
      "        [0.6848]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1660]],\n",
      "\n",
      "        [[1.5161]],\n",
      "\n",
      "        [[0.9534]],\n",
      "\n",
      "        [[0.3179]]], dtype=torch.float64)\n",
      "tensor([[0.5535],\n",
      "        [0.4623],\n",
      "        [1.0169],\n",
      "        [1.2572]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[ 0.2775]],\n",
      "\n",
      "        [[ 1.5727]],\n",
      "\n",
      "        [[ 1.9193]]], dtype=torch.float64)\n",
      "tensor([[1.1397],\n",
      "        [0.8578],\n",
      "        [0.6727],\n",
      "        [0.4816]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2065]],\n",
      "\n",
      "        [[0.3907]],\n",
      "\n",
      "        [[0.1666]],\n",
      "\n",
      "        [[0.3757]]], dtype=torch.float64)\n",
      "tensor([[1.1205],\n",
      "        [1.1848],\n",
      "        [1.0619],\n",
      "        [0.8260]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6652]],\n",
      "\n",
      "        [[1.8304]],\n",
      "\n",
      "        [[1.2076]],\n",
      "\n",
      "        [[0.5791]]], dtype=torch.float64)\n",
      "tensor([[0.7207],\n",
      "        [0.7596],\n",
      "        [0.7996],\n",
      "        [0.6261]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2151]],\n",
      "\n",
      "        [[0.6796]],\n",
      "\n",
      "        [[0.8517]],\n",
      "\n",
      "        [[1.0216]]], dtype=torch.float64)\n",
      "tensor([[0.5053],\n",
      "        [0.6604],\n",
      "        [0.8503],\n",
      "        [0.6853]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7905]],\n",
      "\n",
      "        [[0.6703]],\n",
      "\n",
      "        [[0.4901]],\n",
      "\n",
      "        [[0.4543]]], dtype=torch.float64)\n",
      "tensor([[0.6211],\n",
      "        [0.4713],\n",
      "        [0.5256],\n",
      "        [0.5664]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9211]],\n",
      "\n",
      "        [[1.0331]],\n",
      "\n",
      "        [[0.7501]],\n",
      "\n",
      "        [[0.4393]]], dtype=torch.float64)\n",
      "tensor([[0.6622],\n",
      "        [0.4714],\n",
      "        [0.5803],\n",
      "        [0.4436]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2059]],\n",
      "\n",
      "        [[0.4000]],\n",
      "\n",
      "        [[0.7639]],\n",
      "\n",
      "        [[1.0123]]], dtype=torch.float64)\n",
      "tensor([[0.4660],\n",
      "        [0.4788],\n",
      "        [0.5281],\n",
      "        [0.4730]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7085]],\n",
      "\n",
      "        [[0.1643]],\n",
      "\n",
      "        [[0.1134]],\n",
      "\n",
      "        [[0.2960]]], dtype=torch.float64)\n",
      "tensor([[0.3758],\n",
      "        [0.2507],\n",
      "        [0.0753],\n",
      "        [0.2728]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3699]],\n",
      "\n",
      "        [[0.4092]],\n",
      "\n",
      "        [[0.1134]],\n",
      "\n",
      "        [[0.0152]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.15527:  14%|█▍        | 441/3067 [00:01<00:07, 333.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3932],\n",
      "        [0.4216],\n",
      "        [0.2262],\n",
      "        [0.0556]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0337]],\n",
      "\n",
      "        [[0.1481]],\n",
      "\n",
      "        [[0.2463]],\n",
      "\n",
      "        [[0.3226]]], dtype=torch.float64)\n",
      "tensor([[-0.0027],\n",
      "        [ 0.3633],\n",
      "        [ 0.6541],\n",
      "        [ 0.6388]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3526]],\n",
      "\n",
      "        [[0.4450]],\n",
      "\n",
      "        [[0.4370]],\n",
      "\n",
      "        [[0.3572]]], dtype=torch.float64)\n",
      "tensor([[0.4502],\n",
      "        [0.3880],\n",
      "        [0.5388],\n",
      "        [0.7130]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4589]],\n",
      "\n",
      "        [[0.7628]],\n",
      "\n",
      "        [[0.7535]],\n",
      "\n",
      "        [[0.6946]]], dtype=torch.float64)\n",
      "tensor([[0.9035],\n",
      "        [0.7352],\n",
      "        [0.4712],\n",
      "        [0.4434]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5952]],\n",
      "\n",
      "        [[0.4439]],\n",
      "\n",
      "        [[0.4728]],\n",
      "\n",
      "        [[0.7986]]], dtype=torch.float64)\n",
      "tensor([[0.6608],\n",
      "        [0.6957],\n",
      "        [0.6432],\n",
      "        [0.4855]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9153]],\n",
      "\n",
      "        [[0.6565]],\n",
      "\n",
      "        [[0.4069]],\n",
      "\n",
      "        [[0.2891]]], dtype=torch.float64)\n",
      "tensor([[0.3398],\n",
      "        [0.4342],\n",
      "        [0.4750],\n",
      "        [0.4366]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4289]],\n",
      "\n",
      "        [[0.9315]],\n",
      "\n",
      "        [[0.6750]],\n",
      "\n",
      "        [[0.4381]]], dtype=torch.float64)\n",
      "tensor([[0.5427],\n",
      "        [0.3182],\n",
      "        [0.5385],\n",
      "        [0.7706]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1007]],\n",
      "\n",
      "        [[0.1296]],\n",
      "\n",
      "        [[0.9604]],\n",
      "\n",
      "        [[1.2134]]], dtype=torch.float64)\n",
      "tensor([[0.6603],\n",
      "        [0.6286],\n",
      "        [0.4463],\n",
      "        [0.2974]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8217]],\n",
      "\n",
      "        [[ 0.3445]],\n",
      "\n",
      "        [[ 0.0141]],\n",
      "\n",
      "        [[-0.0402]]], dtype=torch.float64)\n",
      "tensor([[0.6568],\n",
      "        [1.0721],\n",
      "        [0.8819],\n",
      "        [0.6644]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2041]],\n",
      "\n",
      "        [[1.5415]],\n",
      "\n",
      "        [[1.0874]],\n",
      "\n",
      "        [[0.4208]]], dtype=torch.float64)\n",
      "tensor([[0.6007],\n",
      "        [0.4520],\n",
      "        [0.8930],\n",
      "        [1.1453]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1377]],\n",
      "\n",
      "        [[0.3896]],\n",
      "\n",
      "        [[1.4410]],\n",
      "\n",
      "        [[1.6351]]], dtype=torch.float64)\n",
      "tensor([[0.9595],\n",
      "        [0.7977],\n",
      "        [0.8938],\n",
      "        [0.8543]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0147]],\n",
      "\n",
      "        [[0.6519]],\n",
      "\n",
      "        [[0.5721]],\n",
      "\n",
      "        [[0.6276]]], dtype=torch.float64)\n",
      "tensor([[0.7759],\n",
      "        [0.6513],\n",
      "        [0.5351],\n",
      "        [0.6582]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7004]],\n",
      "\n",
      "        [[0.8587]],\n",
      "\n",
      "        [[0.7535]],\n",
      "\n",
      "        [[0.4219]]], dtype=torch.float64)\n",
      "tensor([[0.6303],\n",
      "        [0.6924],\n",
      "        [0.9435],\n",
      "        [1.0299]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2844]],\n",
      "\n",
      "        [[0.4716]],\n",
      "\n",
      "        [[1.2307]],\n",
      "\n",
      "        [[1.4641]]], dtype=torch.float64)\n",
      "tensor([[0.8876],\n",
      "        [0.7094],\n",
      "        [0.6684],\n",
      "        [0.4754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9211]],\n",
      "\n",
      "        [[0.4242]],\n",
      "\n",
      "        [[0.1423]],\n",
      "\n",
      "        [[0.3503]]], dtype=torch.float64)\n",
      "tensor([[0.8114],\n",
      "        [0.7895],\n",
      "        [0.7094],\n",
      "        [0.8118]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3012]],\n",
      "\n",
      "        [[1.2203]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.7859]]], dtype=torch.float64)\n",
      "tensor([[0.8636],\n",
      "        [0.8262],\n",
      "        [0.5412],\n",
      "        [0.3325]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6299]],\n",
      "\n",
      "        [[0.5987]],\n",
      "\n",
      "        [[0.2937]],\n",
      "\n",
      "        [[0.5086]]], dtype=torch.float64)\n",
      "tensor([[0.3265],\n",
      "        [0.3418],\n",
      "        [0.3396],\n",
      "        [0.2409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3468]],\n",
      "\n",
      "        [[ 0.1285]],\n",
      "\n",
      "        [[-0.0564]],\n",
      "\n",
      "        [[-0.1223]]], dtype=torch.float64)\n",
      "tensor([[0.2437],\n",
      "        [0.3668],\n",
      "        [0.2003],\n",
      "        [0.0779]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5883]],\n",
      "\n",
      "        [[ 0.6727]],\n",
      "\n",
      "        [[ 0.3052]],\n",
      "\n",
      "        [[-0.2089]]], dtype=torch.float64)\n",
      "tensor([[-0.0173],\n",
      "        [-0.0982],\n",
      "        [ 0.3374],\n",
      "        [ 0.5390]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4354]],\n",
      "\n",
      "        [[-0.4065]],\n",
      "\n",
      "        [[ 0.7847]],\n",
      "\n",
      "        [[ 0.9823]]], dtype=torch.float64)\n",
      "tensor([[ 0.3899],\n",
      "        [ 0.2023],\n",
      "        [ 0.0956],\n",
      "        [-0.1113]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3873]],\n",
      "\n",
      "        [[-0.0853]],\n",
      "\n",
      "        [[-0.4261]],\n",
      "\n",
      "        [[-0.4793]]], dtype=torch.float64)\n",
      "tensor([[0.2510],\n",
      "        [0.7056],\n",
      "        [0.5382],\n",
      "        [0.3458]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8922]],\n",
      "\n",
      "        [[1.2030]],\n",
      "\n",
      "        [[0.5225]],\n",
      "\n",
      "        [[0.0175]]], dtype=torch.float64)\n",
      "tensor([[ 0.2519],\n",
      "        [-0.0264],\n",
      "        [ 0.3634],\n",
      "        [ 0.5092]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1685]],\n",
      "\n",
      "        [[-0.3187]],\n",
      "\n",
      "        [[ 0.8691]],\n",
      "\n",
      "        [[ 0.8829]]], dtype=torch.float64)\n",
      "tensor([[0.4030],\n",
      "        [0.4740],\n",
      "        [0.6796],\n",
      "        [0.6412]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5698]],\n",
      "\n",
      "        [[0.4762]],\n",
      "\n",
      "        [[0.4843]],\n",
      "\n",
      "        [[0.4820]]], dtype=torch.float64)\n",
      "tensor([[0.5574],\n",
      "        [0.4009],\n",
      "        [0.3074],\n",
      "        [0.4186]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8229]],\n",
      "\n",
      "        [[0.5721]],\n",
      "\n",
      "        [[0.4924]],\n",
      "\n",
      "        [[0.5074]]], dtype=torch.float64)\n",
      "tensor([[0.4080],\n",
      "        [0.0935],\n",
      "        [0.1555],\n",
      "        [0.1664]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0922]],\n",
      "\n",
      "        [[-0.2008]],\n",
      "\n",
      "        [[ 0.2082]],\n",
      "\n",
      "        [[ 0.4323]]], dtype=torch.float64)\n",
      "tensor([[0.1957],\n",
      "        [0.3556],\n",
      "        [0.6466],\n",
      "        [0.5908]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3480]],\n",
      "\n",
      "        [[0.4647]],\n",
      "\n",
      "        [[0.4716]],\n",
      "\n",
      "        [[0.4601]]], dtype=torch.float64)\n",
      "tensor([[ 0.5299],\n",
      "        [ 0.0630],\n",
      "        [-0.0088],\n",
      "        [ 0.0908]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7997]],\n",
      "\n",
      "        [[ 0.2070]],\n",
      "\n",
      "        [[ 0.0406]],\n",
      "\n",
      "        [[-0.0841]]], dtype=torch.float64)\n",
      "tensor([[-0.0533],\n",
      "        [-0.0854],\n",
      "        [-0.0195],\n",
      "        [-0.0860]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2517]],\n",
      "\n",
      "        [[-0.1800]],\n",
      "\n",
      "        [[ 0.1435]],\n",
      "\n",
      "        [[ 0.1365]]], dtype=torch.float64)\n",
      "tensor([[-0.1291],\n",
      "        [-0.0299],\n",
      "        [-0.0179],\n",
      "        [-0.1213]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0310]],\n",
      "\n",
      "        [[-0.1662]],\n",
      "\n",
      "        [[-0.4770]],\n",
      "\n",
      "        [[-0.1639]]], dtype=torch.float64)\n",
      "tensor([[0.2836],\n",
      "        [0.1838],\n",
      "        [0.2516],\n",
      "        [0.3655]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4104]],\n",
      "\n",
      "        [[0.6472]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.4843]]], dtype=torch.float64)\n",
      "tensor([[0.5208],\n",
      "        [0.5080],\n",
      "        [0.2696],\n",
      "        [0.1201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4427]],\n",
      "\n",
      "        [[0.3688]],\n",
      "\n",
      "        [[0.4924]],\n",
      "\n",
      "        [[0.3307]]], dtype=torch.float64)\n",
      "tensor([[0.0714],\n",
      "        [0.0258],\n",
      "        [0.2438],\n",
      "        [0.1574]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1389]],\n",
      "\n",
      "        [[-0.0310]],\n",
      "\n",
      "        [[-0.0576]],\n",
      "\n",
      "        [[-0.2043]]], dtype=torch.float64)\n",
      "tensor([[0.2606],\n",
      "        [0.2184],\n",
      "        [0.0437],\n",
      "        [0.1620]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4300]],\n",
      "\n",
      "        [[0.4866]],\n",
      "\n",
      "        [[0.0614]],\n",
      "\n",
      "        [[0.1446]]], dtype=torch.float64)\n",
      "tensor([[0.4205],\n",
      "        [0.5781],\n",
      "        [0.7041],\n",
      "        [0.6547]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2140]],\n",
      "\n",
      "        [[0.4820]],\n",
      "\n",
      "        [[0.9939]],\n",
      "\n",
      "        [[1.0539]]], dtype=torch.float64)\n",
      "tensor([[0.4612],\n",
      "        [0.6087],\n",
      "        [0.9597],\n",
      "        [0.9108]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5895]],\n",
      "\n",
      "        [[0.8390]],\n",
      "\n",
      "        [[0.8286]],\n",
      "\n",
      "        [[1.0389]]], dtype=torch.float64)\n",
      "tensor([[1.0517],\n",
      "        [0.9801],\n",
      "        [0.7928],\n",
      "        [0.8038]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2781]],\n",
      "\n",
      "        [[1.4930]],\n",
      "\n",
      "        [[1.1002]],\n",
      "\n",
      "        [[1.3971]]], dtype=torch.float64)\n",
      "tensor([[1.2800],\n",
      "        [0.9994],\n",
      "        [0.7682],\n",
      "        [0.1533]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1059]],\n",
      "\n",
      "        [[1.0944]],\n",
      "\n",
      "        [[0.5467]],\n",
      "\n",
      "        [[0.3930]]], dtype=torch.float64)\n",
      "tensor([[ 0.0180],\n",
      "        [ 0.0532],\n",
      "        [ 0.0159],\n",
      "        [-0.2279]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1608]],\n",
      "\n",
      "        [[-0.0067]],\n",
      "\n",
      "        [[-0.3048]],\n",
      "\n",
      "        [[-0.4781]]], dtype=torch.float64)\n",
      "tensor([[-0.0074],\n",
      "        [-0.0407],\n",
      "        [-0.2508],\n",
      "        [-0.2519]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1516]],\n",
      "\n",
      "        [[ 0.2186]],\n",
      "\n",
      "        [[-0.1650]],\n",
      "\n",
      "        [[-0.3233]]], dtype=torch.float64)\n",
      "tensor([[-0.0301],\n",
      "        [ 0.0877],\n",
      "        [ 0.3287],\n",
      "        [ 0.2576]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2748]],\n",
      "\n",
      "        [[-0.0194]],\n",
      "\n",
      "        [[ 0.3387]],\n",
      "\n",
      "        [[ 0.3642]]], dtype=torch.float64)\n",
      "tensor([[0.1932],\n",
      "        [0.2227],\n",
      "        [0.3620],\n",
      "        [0.2551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2833]],\n",
      "\n",
      "        [[0.1989]],\n",
      "\n",
      "        [[0.1412]],\n",
      "\n",
      "        [[0.1227]]], dtype=torch.float64)\n",
      "tensor([[0.0581],\n",
      "        [0.1234],\n",
      "        [0.1359],\n",
      "        [0.0671]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2683]],\n",
      "\n",
      "        [[ 0.2290]],\n",
      "\n",
      "        [[ 0.1007]],\n",
      "\n",
      "        [[-0.0287]]], dtype=torch.float64)\n",
      "tensor([[ 0.0100],\n",
      "        [-0.1325],\n",
      "        [-0.2263],\n",
      "        [-0.3477]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2170]],\n",
      "\n",
      "        [[-0.2332]],\n",
      "\n",
      "        [[-0.2598]],\n",
      "\n",
      "        [[-0.1893]]], dtype=torch.float64)\n",
      "tensor([[-0.5770],\n",
      "        [-0.4474],\n",
      "        [-0.3258],\n",
      "        [-0.3123]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4712]],\n",
      "\n",
      "        [[-0.4446]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.4689]]], dtype=torch.float64)\n",
      "tensor([[-0.3598],\n",
      "        [-0.5781],\n",
      "        [-0.7200],\n",
      "        [-0.7116]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2297]],\n",
      "\n",
      "        [[-0.5994]],\n",
      "\n",
      "        [[-0.8016]],\n",
      "\n",
      "        [[-0.8698]]], dtype=torch.float64)\n",
      "tensor([[-0.6069],\n",
      "        [-0.6193],\n",
      "        [-0.6577],\n",
      "        [-0.6440]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9160]],\n",
      "\n",
      "        [[-0.8987]],\n",
      "\n",
      "        [[-0.5948]],\n",
      "\n",
      "        [[-0.5590]]], dtype=torch.float64)\n",
      "tensor([[-0.8976],\n",
      "        [-0.8423],\n",
      "        [-0.6959],\n",
      "        [-0.6547]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7705]],\n",
      "\n",
      "        [[-0.9796]],\n",
      "\n",
      "        [[-0.9461]],\n",
      "\n",
      "        [[-0.9634]]], dtype=torch.float64)\n",
      "tensor([[-0.7647],\n",
      "        [-0.8539],\n",
      "        [-0.8801],\n",
      "        [-0.7034]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8144]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-0.8236]],\n",
      "\n",
      "        [[-0.7947]]], dtype=torch.float64)\n",
      "tensor([[-0.5541],\n",
      "        [-0.5706],\n",
      "        [-0.5509],\n",
      "        [-0.3256]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7970]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.2852]]], dtype=torch.float64)\n",
      "tensor([[-0.5014],\n",
      "        [-0.5897],\n",
      "        [-0.4673],\n",
      "        [-0.4574]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4908]],\n",
      "\n",
      "        [[-0.6884]],\n",
      "\n",
      "        [[-0.6826]],\n",
      "\n",
      "        [[-0.6249]]], dtype=torch.float64)\n",
      "tensor([[-0.4132],\n",
      "        [-0.5125],\n",
      "        [-0.6347],\n",
      "        [-0.5391]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.5509]],\n",
      "\n",
      "        [[-0.6156]],\n",
      "\n",
      "        [[-0.5902]]], dtype=torch.float64)\n",
      "tensor([[-0.4138],\n",
      "        [-0.4387],\n",
      "        [-0.4452],\n",
      "        [-0.5643]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6480]],\n",
      "\n",
      "        [[-0.6642]],\n",
      "\n",
      "        [[-0.7196]],\n",
      "\n",
      "        [[-0.4423]]], dtype=torch.float64)\n",
      "tensor([[-0.7037],\n",
      "        [-0.6500],\n",
      "        [-0.5829],\n",
      "        [-0.6916]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6410]],\n",
      "\n",
      "        [[-0.7520]],\n",
      "\n",
      "        [[-0.9703]],\n",
      "\n",
      "        [[-1.1587]]], dtype=torch.float64)\n",
      "tensor([[-0.5952],\n",
      "        [-0.2557],\n",
      "        [-0.6799],\n",
      "        [-0.8846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2898]],\n",
      "\n",
      "        [[-0.1246]],\n",
      "\n",
      "        [[-0.8421]],\n",
      "\n",
      "        [[-1.2199]]], dtype=torch.float64)\n",
      "tensor([[-0.9800],\n",
      "        [-1.0134],\n",
      "        [-0.6450],\n",
      "        [-0.3317]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4498]],\n",
      "\n",
      "        [[-1.3886]],\n",
      "\n",
      "        [[-0.3383]],\n",
      "\n",
      "        [[-0.1893]]], dtype=torch.float64)\n",
      "tensor([[-0.6649],\n",
      "        [-0.8246],\n",
      "        [-0.9629],\n",
      "        [-0.9824]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8606]],\n",
      "\n",
      "        [[-1.1067]],\n",
      "\n",
      "        [[-1.3586]],\n",
      "\n",
      "        [[-1.0200]]], dtype=torch.float64)\n",
      "tensor([[-0.4737],\n",
      "        [-0.2296],\n",
      "        [-0.5797],\n",
      "        [-0.7361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2332]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-1.0154]]], dtype=torch.float64)\n",
      "tensor([[-0.8029],\n",
      "        [-0.8469],\n",
      "        [-0.6952],\n",
      "        [-0.5194]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1494]],\n",
      "\n",
      "        [[-1.1425]],\n",
      "\n",
      "        [[-0.4215]],\n",
      "\n",
      "        [[-0.4435]]], dtype=torch.float64)\n",
      "tensor([[-0.5743],\n",
      "        [-0.5180],\n",
      "        [-0.3768],\n",
      "        [-0.3488]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5324]],\n",
      "\n",
      "        [[-0.4862]],\n",
      "\n",
      "        [[-0.5093]],\n",
      "\n",
      "        [[-0.5555]]], dtype=torch.float64)\n",
      "tensor([[-0.3428],\n",
      "        [-0.1173],\n",
      "        [-0.2690],\n",
      "        [-0.2520]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1488]],\n",
      "\n",
      "        [[-0.0298]],\n",
      "\n",
      "        [[-0.2031]],\n",
      "\n",
      "        [[-0.2782]]], dtype=torch.float64)\n",
      "tensor([[-0.1850],\n",
      "        [-0.2501],\n",
      "        [-0.0678],\n",
      "        [ 0.0997]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4804]],\n",
      "\n",
      "        [[-0.4724]],\n",
      "\n",
      "        [[ 0.2660]],\n",
      "\n",
      "        [[ 0.0383]]], dtype=torch.float64)\n",
      "tensor([[-0.2460],\n",
      "        [-0.2589],\n",
      "        [ 0.1000],\n",
      "        [ 0.1913]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2228]],\n",
      "\n",
      "        [[-0.3302]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[-0.0911]]], dtype=torch.float64)\n",
      "tensor([[ 0.1933],\n",
      "        [ 0.0937],\n",
      "        [ 0.0448],\n",
      "        [-0.2498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4554]],\n",
      "\n",
      "        [[ 0.3884]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.4377]]], dtype=torch.float64)\n",
      "tensor([[-0.3789],\n",
      "        [-0.4536],\n",
      "        [ 0.0285],\n",
      "        [ 0.0381]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7335]],\n",
      "\n",
      "        [[-0.5151]],\n",
      "\n",
      "        [[ 0.3052]],\n",
      "\n",
      "        [[ 0.1666]]], dtype=torch.float64)\n",
      "tensor([[0.0351],\n",
      "        [0.1901],\n",
      "        [0.2365],\n",
      "        [0.0151]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.14052:  17%|█▋        | 509/3067 [00:01<00:07, 333.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1527]],\n",
      "\n",
      "        [[0.1597]],\n",
      "\n",
      "        [[0.1585]],\n",
      "\n",
      "        [[0.0915]]], dtype=torch.float64)\n",
      "tensor([[-0.0691],\n",
      "        [-0.0675],\n",
      "        [-0.1180],\n",
      "        [ 0.0267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4069]],\n",
      "\n",
      "        [[ 0.2521]],\n",
      "\n",
      "        [[ 0.0337]],\n",
      "\n",
      "        [[-0.0217]]], dtype=torch.float64)\n",
      "tensor([[ 0.1106],\n",
      "        [-0.0250],\n",
      "        [ 0.1195],\n",
      "        [ 0.0595]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0714]],\n",
      "\n",
      "        [[-0.0841]],\n",
      "\n",
      "        [[ 0.3538]],\n",
      "\n",
      "        [[ 0.3145]]], dtype=torch.float64)\n",
      "tensor([[-0.1124],\n",
      "        [-0.1774],\n",
      "        [-0.2086],\n",
      "        [-0.2421]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0968]],\n",
      "\n",
      "        [[-0.2528]],\n",
      "\n",
      "        [[-0.2713]],\n",
      "\n",
      "        [[-0.3302]]], dtype=torch.float64)\n",
      "tensor([[-0.0354],\n",
      "        [-0.0778],\n",
      "        [-0.1768],\n",
      "        [-0.1705]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2382]],\n",
      "\n",
      "        [[ 0.2232]],\n",
      "\n",
      "        [[ 0.0834]],\n",
      "\n",
      "        [[-0.1119]]], dtype=torch.float64)\n",
      "tensor([[-0.1352],\n",
      "        [-0.3768],\n",
      "        [-0.5250],\n",
      "        [-0.4443]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2944]],\n",
      "\n",
      "        [[-0.4238]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[-0.2852]]], dtype=torch.float64)\n",
      "tensor([[-0.6408],\n",
      "        [-0.7907],\n",
      "        [-0.8534],\n",
      "        [-0.9512]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4492]],\n",
      "\n",
      "        [[-0.8144]],\n",
      "\n",
      "        [[-1.0928]],\n",
      "\n",
      "        [[-1.2280]]], dtype=torch.float64)\n",
      "tensor([[-0.8603],\n",
      "        [-0.6927],\n",
      "        [-0.9343],\n",
      "        [-0.9276]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4700]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.9530]],\n",
      "\n",
      "        [[-1.0570]]], dtype=torch.float64)\n",
      "tensor([[-0.8719],\n",
      "        [-0.9181],\n",
      "        [-0.5427],\n",
      "        [-0.2740]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2407]],\n",
      "\n",
      "        [[-1.0859]],\n",
      "\n",
      "        [[-0.1176]],\n",
      "\n",
      "        [[-0.3684]]], dtype=torch.float64)\n",
      "tensor([[-0.6183],\n",
      "        [-0.4690],\n",
      "        [-0.2831],\n",
      "        [-0.3913]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5798]],\n",
      "\n",
      "        [[-0.4157]],\n",
      "\n",
      "        [[-0.5555]],\n",
      "\n",
      "        [[-0.3568]]], dtype=torch.float64)\n",
      "tensor([[-0.2288],\n",
      "        [-0.1945],\n",
      "        [-0.3011],\n",
      "        [-0.2345]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1719]],\n",
      "\n",
      "        [[-0.1627]],\n",
      "\n",
      "        [[-0.2598]],\n",
      "\n",
      "        [[-0.2008]]], dtype=torch.float64)\n",
      "tensor([[-0.2754],\n",
      "        [-0.3403],\n",
      "        [-0.3850],\n",
      "        [-0.3784]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3245]],\n",
      "\n",
      "        [[-0.3429]],\n",
      "\n",
      "        [[-0.2655]],\n",
      "\n",
      "        [[-0.2320]]], dtype=torch.float64)\n",
      "tensor([[-0.6498],\n",
      "        [-0.7234],\n",
      "        [-0.5646],\n",
      "        [-0.3247]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6838]],\n",
      "\n",
      "        [[-0.8583]],\n",
      "\n",
      "        [[-0.5555]],\n",
      "\n",
      "        [[-0.4700]]], dtype=torch.float64)\n",
      "tensor([[-0.3083],\n",
      "        [-0.3585],\n",
      "        [-0.5117],\n",
      "        [-0.5246]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1789]],\n",
      "\n",
      "        [[-0.3141]],\n",
      "\n",
      "        [[-0.5324]],\n",
      "\n",
      "        [[-0.6630]]], dtype=torch.float64)\n",
      "tensor([[-0.4735],\n",
      "        [-0.3796],\n",
      "        [-0.3506],\n",
      "        [-0.3687]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5012]],\n",
      "\n",
      "        [[-0.3637]],\n",
      "\n",
      "        [[-0.0529]],\n",
      "\n",
      "        [[-0.1442]]], dtype=torch.float64)\n",
      "tensor([[-0.5044],\n",
      "        [-0.4725],\n",
      "        [-0.4413],\n",
      "        [-0.4997]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4146]],\n",
      "\n",
      "        [[-0.5082]],\n",
      "\n",
      "        [[-0.5717]],\n",
      "\n",
      "        [[-0.5255]]], dtype=torch.float64)\n",
      "tensor([[-0.1824],\n",
      "        [-0.2149],\n",
      "        [-0.3770],\n",
      "        [-0.5247]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1192]],\n",
      "\n",
      "        [[-0.0402]],\n",
      "\n",
      "        [[-0.1939]],\n",
      "\n",
      "        [[-0.7346]]], dtype=torch.float64)\n",
      "tensor([[-0.5517],\n",
      "        [-0.6342],\n",
      "        [-0.4180],\n",
      "        [-0.4825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7658]],\n",
      "\n",
      "        [[-0.7115]],\n",
      "\n",
      "        [[-0.1465]],\n",
      "\n",
      "        [[-0.2563]]], dtype=torch.float64)\n",
      "tensor([[-0.5136],\n",
      "        [-0.5948],\n",
      "        [-0.5845],\n",
      "        [-0.7247]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4400]],\n",
      "\n",
      "        [[-0.7404]],\n",
      "\n",
      "        [[-0.7993]],\n",
      "\n",
      "        [[-0.9438]]], dtype=torch.float64)\n",
      "tensor([[-0.6351],\n",
      "        [-0.4775],\n",
      "        [-0.5552],\n",
      "        [-0.6776]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2551]],\n",
      "\n",
      "        [[-0.2736]],\n",
      "\n",
      "        [[-0.4377]],\n",
      "\n",
      "        [[-0.6168]]], dtype=torch.float64)\n",
      "tensor([[-0.5325],\n",
      "        [-0.5229],\n",
      "        [-0.6631],\n",
      "        [-0.7751]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5636]],\n",
      "\n",
      "        [[-0.6376]],\n",
      "\n",
      "        [[-0.7023]],\n",
      "\n",
      "        [[-0.6480]]], dtype=torch.float64)\n",
      "tensor([[-0.7155],\n",
      "        [-0.5974],\n",
      "        [-0.5229],\n",
      "        [-0.5056]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6514]],\n",
      "\n",
      "        [[-0.6630]],\n",
      "\n",
      "        [[-0.6849]],\n",
      "\n",
      "        [[-0.6803]]], dtype=torch.float64)\n",
      "tensor([[-0.4691],\n",
      "        [-0.5935],\n",
      "        [-0.5926],\n",
      "        [-0.5600]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4308]],\n",
      "\n",
      "        [[-0.4365]],\n",
      "\n",
      "        [[-0.5740]],\n",
      "\n",
      "        [[-0.6422]]], dtype=torch.float64)\n",
      "tensor([[-0.4813],\n",
      "        [-0.4648],\n",
      "        [-0.4149],\n",
      "        [-0.5222]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6318]],\n",
      "\n",
      "        [[-0.4897]],\n",
      "\n",
      "        [[-0.2621]],\n",
      "\n",
      "        [[-0.3071]]], dtype=torch.float64)\n",
      "tensor([[-0.5240],\n",
      "        [-0.5256],\n",
      "        [-0.6654],\n",
      "        [-0.6707]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4007]],\n",
      "\n",
      "        [[-0.6249]],\n",
      "\n",
      "        [[-0.8663]],\n",
      "\n",
      "        [[-0.7739]]], dtype=torch.float64)\n",
      "tensor([[-0.3383],\n",
      "        [-0.4805],\n",
      "        [-0.5082],\n",
      "        [-0.4295]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[-0.3545]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[-0.5128]]], dtype=torch.float64)\n",
      "tensor([[-0.3656],\n",
      "        [-0.3561],\n",
      "        [-0.1141],\n",
      "        [ 0.0755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4065]],\n",
      "\n",
      "        [[-0.5059]],\n",
      "\n",
      "        [[ 0.1631]],\n",
      "\n",
      "        [[ 0.1897]]], dtype=torch.float64)\n",
      "tensor([[0.0990],\n",
      "        [0.2096],\n",
      "        [0.1679],\n",
      "        [0.0155]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2694]],\n",
      "\n",
      "        [[ 0.0499]],\n",
      "\n",
      "        [[-0.0841]],\n",
      "\n",
      "        [[-0.1627]]], dtype=torch.float64)\n",
      "tensor([[-0.0255],\n",
      "        [ 0.0149],\n",
      "        [-0.0013],\n",
      "        [ 0.1191]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2394]],\n",
      "\n",
      "        [[0.3364]],\n",
      "\n",
      "        [[0.2255]],\n",
      "\n",
      "        [[0.1019]]], dtype=torch.float64)\n",
      "tensor([[ 0.0019],\n",
      "        [-0.0718],\n",
      "        [ 0.0073],\n",
      "        [-0.0768]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0071]],\n",
      "\n",
      "        [[-0.0818]],\n",
      "\n",
      "        [[ 0.3734]],\n",
      "\n",
      "        [[ 0.1157]]], dtype=torch.float64)\n",
      "tensor([[-0.1426],\n",
      "        [-0.1254],\n",
      "        [-0.2107],\n",
      "        [-0.4007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0449]],\n",
      "\n",
      "        [[-0.1431]],\n",
      "\n",
      "        [[-0.4284]],\n",
      "\n",
      "        [[-0.5475]]], dtype=torch.float64)\n",
      "tensor([[-0.3936],\n",
      "        [-0.2404],\n",
      "        [-0.0405],\n",
      "        [ 0.2911]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2297]],\n",
      "\n",
      "        [[-0.0610]],\n",
      "\n",
      "        [[ 0.0892]],\n",
      "\n",
      "        [[ 0.1481]]], dtype=torch.float64)\n",
      "tensor([[ 0.3242],\n",
      "        [ 0.2344],\n",
      "        [ 0.1312],\n",
      "        [-0.1292]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0984]],\n",
      "\n",
      "        [[ 0.0695]],\n",
      "\n",
      "        [[ 0.1631]],\n",
      "\n",
      "        [[-0.1015]]], dtype=torch.float64)\n",
      "tensor([[-0.1968],\n",
      "        [-0.1566],\n",
      "        [-0.2602],\n",
      "        [-0.1719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1165]],\n",
      "\n",
      "        [[-0.1673]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.2112]]], dtype=torch.float64)\n",
      "tensor([[-0.1658],\n",
      "        [-0.2896],\n",
      "        [-0.2739],\n",
      "        [-0.0883]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0464]],\n",
      "\n",
      "        [[-0.0090]],\n",
      "\n",
      "        [[ 0.0187]],\n",
      "\n",
      "        [[ 0.0695]]], dtype=torch.float64)\n",
      "tensor([[-0.0196],\n",
      "        [-0.0450],\n",
      "        [-0.0698],\n",
      "        [-0.0795]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0275]],\n",
      "\n",
      "        [[-0.0587]],\n",
      "\n",
      "        [[ 0.3006]],\n",
      "\n",
      "        [[ 0.1573]]], dtype=torch.float64)\n",
      "tensor([[-0.3233],\n",
      "        [-0.4160],\n",
      "        [-0.4028],\n",
      "        [-0.4957]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1777]],\n",
      "\n",
      "        [[-0.3880]],\n",
      "\n",
      "        [[-0.5833]],\n",
      "\n",
      "        [[-0.6202]]], dtype=torch.float64)\n",
      "tensor([[-0.1804],\n",
      "        [ 0.1391],\n",
      "        [-0.1712],\n",
      "        [-0.2759]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1562]],\n",
      "\n",
      "        [[ 0.5502]],\n",
      "\n",
      "        [[ 0.0152]],\n",
      "\n",
      "        [[-0.0518]]], dtype=torch.float64)\n",
      "tensor([[-0.1993],\n",
      "        [-0.1916],\n",
      "        [-0.1555],\n",
      "        [-0.0052]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1974]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[ 0.1758]],\n",
      "\n",
      "        [[ 0.3411]]], dtype=torch.float64)\n",
      "tensor([[-0.0398],\n",
      "        [ 0.0462],\n",
      "        [ 0.2126],\n",
      "        [ 0.0262]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0603]],\n",
      "\n",
      "        [[0.0626]],\n",
      "\n",
      "        [[0.1943]],\n",
      "\n",
      "        [[0.0291]]], dtype=torch.float64)\n",
      "tensor([[ 0.0112],\n",
      "        [ 0.0096],\n",
      "        [-0.0272],\n",
      "        [ 0.0194]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4612]],\n",
      "\n",
      "        [[0.2914]],\n",
      "\n",
      "        [[0.1204]],\n",
      "\n",
      "        [[0.1458]]], dtype=torch.float64)\n",
      "tensor([[-0.0677],\n",
      "        [-0.1813],\n",
      "        [-0.2361],\n",
      "        [-0.3125]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[-0.2817]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[ 0.0707]]], dtype=torch.float64)\n",
      "tensor([[-0.1694],\n",
      "        [-0.0268],\n",
      "        [ 0.0356],\n",
      "        [-0.1788]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1493]],\n",
      "\n",
      "        [[ 0.0083]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[-0.1119]]], dtype=torch.float64)\n",
      "tensor([[-0.1260],\n",
      "        [-0.1856],\n",
      "        [ 0.0042],\n",
      "        [ 0.2668]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1377]],\n",
      "\n",
      "        [[-0.1454]],\n",
      "\n",
      "        [[ 0.3087]],\n",
      "\n",
      "        [[ 0.2787]]], dtype=torch.float64)\n",
      "tensor([[0.2942],\n",
      "        [0.1534],\n",
      "        [0.0189],\n",
      "        [0.0218]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1989]],\n",
      "\n",
      "        [[0.1550]],\n",
      "\n",
      "        [[0.4635]],\n",
      "\n",
      "        [[0.2371]]], dtype=torch.float64)\n",
      "tensor([[-0.1985],\n",
      "        [-0.0745],\n",
      "        [ 0.0547],\n",
      "        [-0.2242]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0210]],\n",
      "\n",
      "        [[ 0.0141]],\n",
      "\n",
      "        [[-0.0992]],\n",
      "\n",
      "        [[-0.2702]]], dtype=torch.float64)\n",
      "tensor([[-0.1638],\n",
      "        [-0.2587],\n",
      "        [-0.2711],\n",
      "        [-0.2020]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0287]],\n",
      "\n",
      "        [[-0.1049]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[-0.2471]]], dtype=torch.float64)\n",
      "tensor([[-0.0945],\n",
      "        [-0.2438],\n",
      "        [-0.1768],\n",
      "        [-0.2609]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2205]],\n",
      "\n",
      "        [[-0.3487]],\n",
      "\n",
      "        [[ 0.0406]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[-0.4180],\n",
      "        [-0.3309],\n",
      "        [-0.2734],\n",
      "        [-0.2755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3522]],\n",
      "\n",
      "        [[-0.4492]],\n",
      "\n",
      "        [[-0.5139]],\n",
      "\n",
      "        [[-0.4019]]], dtype=torch.float64)\n",
      "tensor([[-0.2165],\n",
      "        [-0.2231],\n",
      "        [-0.2980],\n",
      "        [-0.1079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1188]],\n",
      "\n",
      "        [[-0.1731]],\n",
      "\n",
      "        [[-0.0830]],\n",
      "\n",
      "        [[-0.0113]]], dtype=torch.float64)\n",
      "tensor([[-0.0421],\n",
      "        [-0.0270],\n",
      "        [-0.1798],\n",
      "        [-0.1935]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1327]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[ 0.1527]],\n",
      "\n",
      "        [[ 0.1435]]], dtype=torch.float64)\n",
      "tensor([[-0.3349],\n",
      "        [-0.2564],\n",
      "        [-0.2708],\n",
      "        [-0.5125]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1304]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.4908]],\n",
      "\n",
      "        [[-0.7000]]], dtype=torch.float64)\n",
      "tensor([[-0.6050],\n",
      "        [-0.3732],\n",
      "        [-0.3900],\n",
      "        [-0.2786]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.3672]],\n",
      "\n",
      "        [[-0.4077]],\n",
      "\n",
      "        [[-0.4631]]], dtype=torch.float64)\n",
      "tensor([[-0.3838],\n",
      "        [-0.5090],\n",
      "        [-0.5925],\n",
      "        [-0.5378]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5787]],\n",
      "\n",
      "        [[-0.6688]],\n",
      "\n",
      "        [[-0.5891]],\n",
      "\n",
      "        [[-0.5313]]], dtype=torch.float64)\n",
      "tensor([[-0.5804],\n",
      "        [-0.7242],\n",
      "        [-0.7635],\n",
      "        [-0.8658]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7358]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-1.2488]],\n",
      "\n",
      "        [[-1.2083]]], dtype=torch.float64)\n",
      "tensor([[-0.6850],\n",
      "        [-0.4964],\n",
      "        [-0.6798],\n",
      "        [-0.6555]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5267]],\n",
      "\n",
      "        [[-0.6769]],\n",
      "\n",
      "        [[-0.9461]],\n",
      "\n",
      "        [[-0.8224]]], dtype=torch.float64)\n",
      "tensor([[-0.5274],\n",
      "        [-0.5349],\n",
      "        [-0.4436],\n",
      "        [-0.3851]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8941]],\n",
      "\n",
      "        [[-0.7439]],\n",
      "\n",
      "        [[-0.3372]],\n",
      "\n",
      "        [[-0.2956]]], dtype=torch.float64)\n",
      "tensor([[-0.4888],\n",
      "        [-0.5383],\n",
      "        [-0.4296],\n",
      "        [-0.5035]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5613]],\n",
      "\n",
      "        [[-0.6156]],\n",
      "\n",
      "        [[-0.6018]],\n",
      "\n",
      "        [[-0.6792]]], dtype=torch.float64)\n",
      "tensor([[-0.4920],\n",
      "        [-0.6395],\n",
      "        [-0.7056],\n",
      "        [-0.8734]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.6815]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-1.2869]]], dtype=torch.float64)\n",
      "tensor([[-0.8128],\n",
      "        [-0.8923],\n",
      "        [-0.7811],\n",
      "        [-0.5606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2187]],\n",
      "\n",
      "        [[-1.2673]],\n",
      "\n",
      "        [[-0.8444]],\n",
      "\n",
      "        [[-0.7034]]], dtype=torch.float64)\n",
      "tensor([[-0.6494],\n",
      "        [-0.6347],\n",
      "        [-0.4145],\n",
      "        [-0.2375]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6561]],\n",
      "\n",
      "        [[-0.6780]],\n",
      "\n",
      "        [[-0.6341]],\n",
      "\n",
      "        [[-0.4828]]], dtype=torch.float64)\n",
      "tensor([[-0.1962],\n",
      "        [-0.1603],\n",
      "        [-0.2587],\n",
      "        [-0.0121]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1234]],\n",
      "\n",
      "        [[-0.1535]],\n",
      "\n",
      "        [[-0.1777]],\n",
      "\n",
      "        [[-0.0968]]], dtype=torch.float64)\n",
      "tensor([[-0.0439],\n",
      "        [-0.3566],\n",
      "        [-0.5025],\n",
      "        [-0.2951]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2933]],\n",
      "\n",
      "        [[-0.7057]],\n",
      "\n",
      "        [[-0.3580]],\n",
      "\n",
      "        [[-0.3187]]], dtype=torch.float64)\n",
      "tensor([[-0.6479],\n",
      "        [-0.6341],\n",
      "        [-0.4022],\n",
      "        [-0.2242]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7589]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.3152]]], dtype=torch.float64)\n",
      "tensor([[-0.2634],\n",
      "        [-0.4271],\n",
      "        [-0.5907],\n",
      "        [-0.5055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2251]],\n",
      "\n",
      "        [[-0.3845]],\n",
      "\n",
      "        [[-0.4550]],\n",
      "\n",
      "        [[-0.4539]]], dtype=torch.float64)\n",
      "tensor([[-0.4515],\n",
      "        [-0.4578],\n",
      "        [-0.4882],\n",
      "        [-0.4618]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4238]],\n",
      "\n",
      "        [[-0.4550]],\n",
      "\n",
      "        [[-0.3834]],\n",
      "\n",
      "        [[-0.4100]]], dtype=torch.float64)\n",
      "tensor([[-0.6998],\n",
      "        [-0.8828],\n",
      "        [-0.7771],\n",
      "        [-0.5864]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-1.0189]],\n",
      "\n",
      "        [[-0.9368]],\n",
      "\n",
      "        [[-0.8063]]], dtype=torch.float64)\n",
      "tensor([[-0.4603],\n",
      "        [-0.4543],\n",
      "        [-0.3914],\n",
      "        [-0.3966]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5313]],\n",
      "\n",
      "        [[-0.2736]],\n",
      "\n",
      "        [[-0.3094]],\n",
      "\n",
      "        [[-0.5255]]], dtype=torch.float64)\n",
      "tensor([[-0.6621],\n",
      "        [-0.6188],\n",
      "        [-0.9748],\n",
      "        [-1.0984]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8883]],\n",
      "\n",
      "        [[-0.8028]],\n",
      "\n",
      "        [[-0.9530]],\n",
      "\n",
      "        [[-0.9322]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.14052:  19%|█▉        | 579/3067 [00:01<00:07, 333.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0875],\n",
      "        [-1.0119],\n",
      "        [-0.9153],\n",
      "        [-0.9122]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9565]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.0258]],\n",
      "\n",
      "        [[-1.0431]]], dtype=torch.float64)\n",
      "tensor([[-1.0578],\n",
      "        [-1.1551],\n",
      "        [-1.1889],\n",
      "        [-1.1322]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0166]],\n",
      "\n",
      "        [[-1.0397]],\n",
      "\n",
      "        [[-1.1725]],\n",
      "\n",
      "        [[-1.2176]]], dtype=torch.float64)\n",
      "tensor([[-1.1043],\n",
      "        [-1.2288],\n",
      "        [-1.3582],\n",
      "        [-1.4571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2788]],\n",
      "\n",
      "        [[-1.4487]],\n",
      "\n",
      "        [[-1.3978]],\n",
      "\n",
      "        [[-1.4256]]], dtype=torch.float64)\n",
      "tensor([[-1.4345],\n",
      "        [-1.4317],\n",
      "        [-1.3401],\n",
      "        [-1.2636]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4660]],\n",
      "\n",
      "        [[-1.4914]],\n",
      "\n",
      "        [[-1.5388]],\n",
      "\n",
      "        [[-1.5272]]], dtype=torch.float64)\n",
      "tensor([[-1.4269],\n",
      "        [-1.4680],\n",
      "        [-1.4670],\n",
      "        [-1.3467]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4683]],\n",
      "\n",
      "        [[-1.4487]],\n",
      "\n",
      "        [[-1.4221]],\n",
      "\n",
      "        [[-1.3609]]], dtype=torch.float64)\n",
      "tensor([[-1.2368],\n",
      "        [-1.2316],\n",
      "        [-1.3087],\n",
      "        [-1.4115]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3447]],\n",
      "\n",
      "        [[-1.4001]],\n",
      "\n",
      "        [[-1.2915]],\n",
      "\n",
      "        [[-1.3216]]], dtype=torch.float64)\n",
      "tensor([[-1.4147],\n",
      "        [-1.3651],\n",
      "        [-1.2976],\n",
      "        [-1.2575]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2973]],\n",
      "\n",
      "        [[-1.3574]],\n",
      "\n",
      "        [[-1.4279]],\n",
      "\n",
      "        [[-1.4256]]], dtype=torch.float64)\n",
      "tensor([[-1.3306],\n",
      "        [-1.4312],\n",
      "        [-1.5518],\n",
      "        [-1.5311]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3978]],\n",
      "\n",
      "        [[-1.4718]],\n",
      "\n",
      "        [[-1.7086]],\n",
      "\n",
      "        [[-1.8912]]], dtype=torch.float64)\n",
      "tensor([[-1.5965],\n",
      "        [-1.5617],\n",
      "        [-1.5912],\n",
      "        [-1.7113]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9432]],\n",
      "\n",
      "        [[-1.9859]],\n",
      "\n",
      "        [[-1.7248]],\n",
      "\n",
      "        [[-1.7884]]], dtype=torch.float64)\n",
      "tensor([[-1.7681],\n",
      "        [-1.6631],\n",
      "        [-1.5641],\n",
      "        [-1.5389]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7722]],\n",
      "\n",
      "        [[-1.8912]],\n",
      "\n",
      "        [[-1.7826]],\n",
      "\n",
      "        [[-2.0807]]], dtype=torch.float64)\n",
      "tensor([[-2.1513],\n",
      "        [-2.3912],\n",
      "        [-2.4617],\n",
      "        [-2.4205]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3742]],\n",
      "\n",
      "        [[-2.6214]],\n",
      "\n",
      "        [[-2.6884]],\n",
      "\n",
      "        [[-2.8213]]], dtype=torch.float64)\n",
      "tensor([[-2.4943],\n",
      "        [-2.4904],\n",
      "        [-2.5848],\n",
      "        [-2.6394]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.8929]],\n",
      "\n",
      "        [[-3.0131]],\n",
      "\n",
      "        [[-2.8825]],\n",
      "\n",
      "        [[-2.9253]]], dtype=torch.float64)\n",
      "tensor([[-2.7381],\n",
      "        [-2.5577],\n",
      "        [-2.4390],\n",
      "        [-2.5095]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.8872]],\n",
      "\n",
      "        [[-2.8409]],\n",
      "\n",
      "        [[-2.9519]],\n",
      "\n",
      "        [[-3.0593]]], dtype=torch.float64)\n",
      "tensor([[-2.4741],\n",
      "        [-2.1627],\n",
      "        [-2.0482],\n",
      "        [-1.6863]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3349]],\n",
      "\n",
      "        [[-2.1593]],\n",
      "\n",
      "        [[-1.9732]],\n",
      "\n",
      "        [[-1.5908]]], dtype=torch.float64)\n",
      "tensor([[-1.6891],\n",
      "        [-1.6571],\n",
      "        [-1.5093],\n",
      "        [-1.6705]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5758]],\n",
      "\n",
      "        [[-1.6266]],\n",
      "\n",
      "        [[-1.3817]],\n",
      "\n",
      "        [[-1.4441]]], dtype=torch.float64)\n",
      "tensor([[-1.7475],\n",
      "        [-1.4978],\n",
      "        [-1.2799],\n",
      "        [-1.2583]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2858]],\n",
      "\n",
      "        [[-1.1344]],\n",
      "\n",
      "        [[-1.1101]],\n",
      "\n",
      "        [[-1.0119]]], dtype=torch.float64)\n",
      "tensor([[-0.7613],\n",
      "        [-0.5261],\n",
      "        [-0.8518],\n",
      "        [-0.9453]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3949]],\n",
      "\n",
      "        [[-0.2286]],\n",
      "\n",
      "        [[-0.4885]],\n",
      "\n",
      "        [[-0.7520]]], dtype=torch.float64)\n",
      "tensor([[-1.2818],\n",
      "        [-1.3937],\n",
      "        [-1.3616],\n",
      "        [-1.2611]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1067]],\n",
      "\n",
      "        [[-1.1125]],\n",
      "\n",
      "        [[-0.9969]],\n",
      "\n",
      "        [[-1.0639]]], dtype=torch.float64)\n",
      "tensor([[-1.6721],\n",
      "        [-1.5169],\n",
      "        [-1.5321],\n",
      "        [-1.5221]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3008]],\n",
      "\n",
      "        [[-1.2303]],\n",
      "\n",
      "        [[-1.1598]],\n",
      "\n",
      "        [[-1.1806]]], dtype=torch.float64)\n",
      "tensor([[-1.4018],\n",
      "        [-1.4077],\n",
      "        [-1.4755],\n",
      "        [-1.3492]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9218]],\n",
      "\n",
      "        [[-0.9865]],\n",
      "\n",
      "        [[-1.0420]],\n",
      "\n",
      "        [[-1.0166]]], dtype=torch.float64)\n",
      "tensor([[-1.1891],\n",
      "        [-0.8748],\n",
      "        [-0.6100],\n",
      "        [-0.9018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9218]],\n",
      "\n",
      "        [[-0.5047]],\n",
      "\n",
      "        [[-0.3302]],\n",
      "\n",
      "        [[-0.5590]]], dtype=torch.float64)\n",
      "tensor([[-0.9140],\n",
      "        [-0.9091],\n",
      "        [-1.0277],\n",
      "        [-1.2049]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5625]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.7624]],\n",
      "\n",
      "        [[-0.9230]]], dtype=torch.float64)\n",
      "tensor([[-0.9330],\n",
      "        [-0.9309],\n",
      "        [-1.3468],\n",
      "        [-1.4035]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5625]],\n",
      "\n",
      "        [[-0.8005]],\n",
      "\n",
      "        [[-1.0119]],\n",
      "\n",
      "        [[-1.1252]]], dtype=torch.float64)\n",
      "tensor([[-1.3768],\n",
      "        [-1.4788],\n",
      "        [-1.4758],\n",
      "        [-1.2621]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2811]],\n",
      "\n",
      "        [[-1.4325]],\n",
      "\n",
      "        [[-0.9969]],\n",
      "\n",
      "        [[-1.0177]]], dtype=torch.float64)\n",
      "tensor([[-1.2961],\n",
      "        [-0.9404],\n",
      "        [-0.9972],\n",
      "        [-0.8231]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8640]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.7832]],\n",
      "\n",
      "        [[-0.7554]]], dtype=torch.float64)\n",
      "tensor([[-0.8965],\n",
      "        [-1.1194],\n",
      "        [-1.1801],\n",
      "        [-1.3355]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7196]],\n",
      "\n",
      "        [[-0.7277]],\n",
      "\n",
      "        [[-0.8860]],\n",
      "\n",
      "        [[-1.2962]]], dtype=torch.float64)\n",
      "tensor([[-1.4836],\n",
      "        [-1.4972],\n",
      "        [-1.6053],\n",
      "        [-1.2759]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5076]],\n",
      "\n",
      "        [[-1.6208]],\n",
      "\n",
      "        [[-1.2569]],\n",
      "\n",
      "        [[-0.9611]]], dtype=torch.float64)\n",
      "tensor([[-1.1764],\n",
      "        [-1.1759],\n",
      "        [-1.0223],\n",
      "        [-1.0390]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1876]],\n",
      "\n",
      "        [[-1.1413]],\n",
      "\n",
      "        [[-1.0801]],\n",
      "\n",
      "        [[-1.0628]]], dtype=torch.float64)\n",
      "tensor([[-0.7286],\n",
      "        [-0.6748],\n",
      "        [-1.0693],\n",
      "        [-1.2065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5093]],\n",
      "\n",
      "        [[-0.8698]],\n",
      "\n",
      "        [[-1.0154]],\n",
      "\n",
      "        [[-1.1286]]], dtype=torch.float64)\n",
      "tensor([[-1.0911],\n",
      "        [-1.1887],\n",
      "        [-1.3097],\n",
      "        [-1.3958]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1552]],\n",
      "\n",
      "        [[-1.1806]],\n",
      "\n",
      "        [[-1.2014]],\n",
      "\n",
      "        [[-1.2060]]], dtype=torch.float64)\n",
      "tensor([[-1.2941],\n",
      "        [-1.3775],\n",
      "        [-1.3395],\n",
      "        [-1.4487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2072]],\n",
      "\n",
      "        [[-1.3817]],\n",
      "\n",
      "        [[-1.4776]],\n",
      "\n",
      "        [[-1.5111]]], dtype=torch.float64)\n",
      "tensor([[-1.5436],\n",
      "        [-1.5445],\n",
      "        [-1.5648],\n",
      "        [-1.3815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5111]],\n",
      "\n",
      "        [[-1.5111]],\n",
      "\n",
      "        [[-1.5180]],\n",
      "\n",
      "        [[-1.5111]]], dtype=torch.float64)\n",
      "tensor([[-1.3193],\n",
      "        [-1.3026],\n",
      "        [-1.3677],\n",
      "        [-1.4939]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5492]],\n",
      "\n",
      "        [[-1.5030]],\n",
      "\n",
      "        [[-1.4845]],\n",
      "\n",
      "        [[-1.6694]]], dtype=torch.float64)\n",
      "tensor([[-1.7958],\n",
      "        [-1.7902],\n",
      "        [-1.6144],\n",
      "        [-1.4124]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8796]],\n",
      "\n",
      "        [[-2.0229]],\n",
      "\n",
      "        [[-1.7549]],\n",
      "\n",
      "        [[-1.6185]]], dtype=torch.float64)\n",
      "tensor([[-1.3124],\n",
      "        [-1.2750],\n",
      "        [-1.6982],\n",
      "        [-1.7053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2858]],\n",
      "\n",
      "        [[-1.3135]],\n",
      "\n",
      "        [[-1.6902]],\n",
      "\n",
      "        [[-1.7572]]], dtype=torch.float64)\n",
      "tensor([[-1.6713],\n",
      "        [-1.6963],\n",
      "        [-1.6430],\n",
      "        [-1.4730]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8196]],\n",
      "\n",
      "        [[-1.8300]],\n",
      "\n",
      "        [[-1.5758]],\n",
      "\n",
      "        [[-1.6520]]], dtype=torch.float64)\n",
      "tensor([[-1.6345],\n",
      "        [-1.7138],\n",
      "        [-1.9275],\n",
      "        [-2.0844]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8172]],\n",
      "\n",
      "        [[-2.1708]],\n",
      "\n",
      "        [[-2.5359]],\n",
      "\n",
      "        [[-2.7242]]], dtype=torch.float64)\n",
      "tensor([[-1.9880],\n",
      "        [-1.6246],\n",
      "        [-1.9484],\n",
      "        [-1.9578]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9490]],\n",
      "\n",
      "        [[-1.9201]],\n",
      "\n",
      "        [[-2.2910]],\n",
      "\n",
      "        [[-2.2101]]], dtype=torch.float64)\n",
      "tensor([[-1.9253],\n",
      "        [-1.8586],\n",
      "        [-1.8656],\n",
      "        [-1.7431]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1997]],\n",
      "\n",
      "        [[-2.2205]],\n",
      "\n",
      "        [[-1.8889]],\n",
      "\n",
      "        [[-1.8750]]], dtype=torch.float64)\n",
      "tensor([[-1.9440],\n",
      "        [-1.9236],\n",
      "        [-1.8741],\n",
      "        [-1.8101]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2008]],\n",
      "\n",
      "        [[-2.3095]],\n",
      "\n",
      "        [[-2.1419]],\n",
      "\n",
      "        [[-2.0275]]], dtype=torch.float64)\n",
      "tensor([[-1.8281],\n",
      "        [-1.6750],\n",
      "        [-2.0132],\n",
      "        [-2.2333]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7121]],\n",
      "\n",
      "        [[-1.7352]],\n",
      "\n",
      "        [[-2.2216]],\n",
      "\n",
      "        [[-2.3926]]], dtype=torch.float64)\n",
      "tensor([[-2.3414],\n",
      "        [-2.2712],\n",
      "        [-2.4203],\n",
      "        [-2.4836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4504]],\n",
      "\n",
      "        [[-2.2702]],\n",
      "\n",
      "        [[-2.1847]],\n",
      "\n",
      "        [[-2.0564]]], dtype=torch.float64)\n",
      "tensor([[-2.5249],\n",
      "        [-2.3384],\n",
      "        [-2.1885],\n",
      "        [-1.9755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8692]],\n",
      "\n",
      "        [[-1.7837]],\n",
      "\n",
      "        [[-1.7514]],\n",
      "\n",
      "        [[-1.6405]]], dtype=torch.float64)\n",
      "tensor([[-1.9702],\n",
      "        [-2.0281],\n",
      "        [-2.0832],\n",
      "        [-2.0421]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5792]],\n",
      "\n",
      "        [[-1.6220]],\n",
      "\n",
      "        [[-1.6566]],\n",
      "\n",
      "        [[-1.6844]]], dtype=torch.float64)\n",
      "tensor([[-1.8928],\n",
      "        [-1.8351],\n",
      "        [-1.9234],\n",
      "        [-1.9133]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6613]],\n",
      "\n",
      "        [[-1.6647]],\n",
      "\n",
      "        [[-1.6000]],\n",
      "\n",
      "        [[-1.6335]]], dtype=torch.float64)\n",
      "tensor([[-1.8464],\n",
      "        [-1.8157],\n",
      "        [-1.7583],\n",
      "        [-1.8236]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6936]],\n",
      "\n",
      "        [[-1.6647]],\n",
      "\n",
      "        [[-1.8045]],\n",
      "\n",
      "        [[-1.8334]]], dtype=torch.float64)\n",
      "tensor([[-1.9898],\n",
      "        [-2.0443],\n",
      "        [-2.0274],\n",
      "        [-1.9080]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8588]],\n",
      "\n",
      "        [[-1.8612]],\n",
      "\n",
      "        [[-1.8692]],\n",
      "\n",
      "        [[-1.8843]]], dtype=torch.float64)\n",
      "tensor([[-1.7519],\n",
      "        [-1.7635],\n",
      "        [-1.7369],\n",
      "        [-1.7305]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8773]],\n",
      "\n",
      "        [[-1.9039]],\n",
      "\n",
      "        [[-1.6844]],\n",
      "\n",
      "        [[-1.6405]]], dtype=torch.float64)\n",
      "tensor([[-1.8968],\n",
      "        [-2.0293],\n",
      "        [-2.2359],\n",
      "        [-2.3102]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9975]],\n",
      "\n",
      "        [[-2.3510]],\n",
      "\n",
      "        [[-2.6977]],\n",
      "\n",
      "        [[-2.7682]]], dtype=torch.float64)\n",
      "tensor([[-2.1373],\n",
      "        [-1.7912],\n",
      "        [-1.5855],\n",
      "        [-1.3679]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0206]],\n",
      "\n",
      "        [[-1.7502]],\n",
      "\n",
      "        [[-1.5261]],\n",
      "\n",
      "        [[-1.4868]]], dtype=torch.float64)\n",
      "tensor([[-1.2868],\n",
      "        [-1.2604],\n",
      "        [-1.2232],\n",
      "        [-1.1604]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5180]],\n",
      "\n",
      "        [[-1.4337]],\n",
      "\n",
      "        [[-1.1402]],\n",
      "\n",
      "        [[-1.1714]]], dtype=torch.float64)\n",
      "tensor([[-1.2572],\n",
      "        [-1.2171],\n",
      "        [-1.1925],\n",
      "        [-1.2183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2627]],\n",
      "\n",
      "        [[-1.3482]],\n",
      "\n",
      "        [[-1.3713]],\n",
      "\n",
      "        [[-1.3736]]], dtype=torch.float64)\n",
      "tensor([[-1.2749],\n",
      "        [-1.3411],\n",
      "        [-1.4219],\n",
      "        [-1.3605]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2072]],\n",
      "\n",
      "        [[-1.1829]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.2996]]], dtype=torch.float64)\n",
      "tensor([[-1.2385],\n",
      "        [-1.1078],\n",
      "        [-1.2681],\n",
      "        [-1.2921]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3227]],\n",
      "\n",
      "        [[-1.3643]],\n",
      "\n",
      "        [[-1.3632]],\n",
      "\n",
      "        [[-1.3100]]], dtype=torch.float64)\n",
      "tensor([[-1.4120],\n",
      "        [-1.4050],\n",
      "        [-1.0654],\n",
      "        [-1.0167]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5192]],\n",
      "\n",
      "        [[-1.4487]],\n",
      "\n",
      "        [[-1.3470]],\n",
      "\n",
      "        [[-1.2372]]], dtype=torch.float64)\n",
      "tensor([[-0.9508],\n",
      "        [-0.8930],\n",
      "        [-0.9436],\n",
      "        [-0.8762]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9669]],\n",
      "\n",
      "        [[-0.9160]],\n",
      "\n",
      "        [[-0.8456]],\n",
      "\n",
      "        [[-0.7554]]], dtype=torch.float64)\n",
      "tensor([[-0.7197],\n",
      "        [-0.8175],\n",
      "        [-0.8317],\n",
      "        [-0.9352]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7947]],\n",
      "\n",
      "        [[-0.8571]],\n",
      "\n",
      "        [[-0.6861]],\n",
      "\n",
      "        [[-0.7000]]], dtype=torch.float64)\n",
      "tensor([[-0.9752],\n",
      "        [-1.0380],\n",
      "        [-0.9565],\n",
      "        [-0.9256]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8975]],\n",
      "\n",
      "        [[-1.0200]],\n",
      "\n",
      "        [[-1.0420]],\n",
      "\n",
      "        [[-1.0408]]], dtype=torch.float64)\n",
      "tensor([[-0.9467],\n",
      "        [-0.9520],\n",
      "        [-1.0038],\n",
      "        [-1.0451]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9045]],\n",
      "\n",
      "        [[-0.7947]],\n",
      "\n",
      "        [[-0.9391]],\n",
      "\n",
      "        [[-1.0293]]], dtype=torch.float64)\n",
      "tensor([[-1.0095],\n",
      "        [-1.0795],\n",
      "        [-1.0756],\n",
      "        [-0.9912]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1332]],\n",
      "\n",
      "        [[-1.2026]],\n",
      "\n",
      "        [[-0.9022]],\n",
      "\n",
      "        [[-0.9218]]], dtype=torch.float64)\n",
      "tensor([[-1.1700],\n",
      "        [-1.3570],\n",
      "        [-1.5176],\n",
      "        [-1.6110]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1725]],\n",
      "\n",
      "        [[-1.4048]],\n",
      "\n",
      "        [[-1.6197]],\n",
      "\n",
      "        [[-1.7560]]], dtype=torch.float64)\n",
      "tensor([[-1.7182],\n",
      "        [-1.8786],\n",
      "        [-1.9084],\n",
      "        [-1.8845]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7930]],\n",
      "\n",
      "        [[-1.8069]],\n",
      "\n",
      "        [[-1.8947]],\n",
      "\n",
      "        [[-1.9235]]], dtype=torch.float64)\n",
      "tensor([[-1.7674],\n",
      "        [-1.7299],\n",
      "        [-1.6926],\n",
      "        [-1.8172]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9293]],\n",
      "\n",
      "        [[-1.8843]],\n",
      "\n",
      "        [[-1.7445]],\n",
      "\n",
      "        [[-1.7410]]], dtype=torch.float64)\n",
      "tensor([[-1.6943],\n",
      "        [-1.6560],\n",
      "        [-1.6227],\n",
      "        [-1.6369]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6774]],\n",
      "\n",
      "        [[-1.7953]],\n",
      "\n",
      "        [[-1.8484]],\n",
      "\n",
      "        [[-1.8958]]], dtype=torch.float64)\n",
      "tensor([[-1.6708],\n",
      "        [-1.6836],\n",
      "        [-1.6522],\n",
      "        [-1.6238]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6798]],\n",
      "\n",
      "        [[-1.5908]],\n",
      "\n",
      "        [[-1.6335]],\n",
      "\n",
      "        [[-1.6844]]], dtype=torch.float64)\n",
      "tensor([[-1.5772],\n",
      "        [-1.6324],\n",
      "        [-1.6175],\n",
      "        [-1.5937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8172]],\n",
      "\n",
      "        [[-1.8288]],\n",
      "\n",
      "        [[-1.6659]],\n",
      "\n",
      "        [[-1.6093]]], dtype=torch.float64)\n",
      "tensor([[-1.6677],\n",
      "        [-1.6141],\n",
      "        [-1.5598],\n",
      "        [-1.5270]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.12862:  21%|██        | 648/3067 [00:01<00:07, 333.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.6058]],\n",
      "\n",
      "        [[-1.6509]],\n",
      "\n",
      "        [[-1.6566]],\n",
      "\n",
      "        [[-1.7537]]], dtype=torch.float64)\n",
      "tensor([[-1.6523],\n",
      "        [-1.6677],\n",
      "        [-1.9559],\n",
      "        [-2.0799]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5792]],\n",
      "\n",
      "        [[-1.6532]],\n",
      "\n",
      "        [[-1.8646]],\n",
      "\n",
      "        [[-2.0310]]], dtype=torch.float64)\n",
      "tensor([[-2.1498],\n",
      "        [-2.3139],\n",
      "        [-2.4887],\n",
      "        [-2.4135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2401]],\n",
      "\n",
      "        [[-2.5197]],\n",
      "\n",
      "        [[-2.3661]],\n",
      "\n",
      "        [[-2.3718]]], dtype=torch.float64)\n",
      "tensor([[-2.6387],\n",
      "        [-2.7088],\n",
      "        [-2.7188],\n",
      "        [-2.7229]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6699]],\n",
      "\n",
      "        [[-2.9195]],\n",
      "\n",
      "        [[-3.1021]],\n",
      "\n",
      "        [[-3.0755]]], dtype=torch.float64)\n",
      "tensor([[-2.5063],\n",
      "        [-2.0711],\n",
      "        [-1.7897],\n",
      "        [-1.4532]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2725]],\n",
      "\n",
      "        [[-1.7699]],\n",
      "\n",
      "        [[-1.6081]],\n",
      "\n",
      "        [[-1.6047]]], dtype=torch.float64)\n",
      "tensor([[-1.3542],\n",
      "        [-1.1440],\n",
      "        [-1.0085],\n",
      "        [-1.0452]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2499]],\n",
      "\n",
      "        [[-1.0720]],\n",
      "\n",
      "        [[-0.8155]],\n",
      "\n",
      "        [[-0.9334]]], dtype=torch.float64)\n",
      "tensor([[-1.1660],\n",
      "        [-1.0999],\n",
      "        [-1.0755],\n",
      "        [-1.0299]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0789]],\n",
      "\n",
      "        [[-1.1125]],\n",
      "\n",
      "        [[-1.1529]],\n",
      "\n",
      "        [[-1.1564]]], dtype=torch.float64)\n",
      "tensor([[-1.0080],\n",
      "        [-0.9947],\n",
      "        [-1.0095],\n",
      "        [-1.0195]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8675]],\n",
      "\n",
      "        [[-0.9276]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-1.1564]]], dtype=torch.float64)\n",
      "tensor([[-1.1500],\n",
      "        [-1.2180],\n",
      "        [-1.2069],\n",
      "        [-1.2263]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2315]],\n",
      "\n",
      "        [[-1.3482]],\n",
      "\n",
      "        [[-1.2164]],\n",
      "\n",
      "        [[-1.2546]]], dtype=torch.float64)\n",
      "tensor([[-1.5821],\n",
      "        [-1.4962],\n",
      "        [-1.5731],\n",
      "        [-1.7707]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5249]],\n",
      "\n",
      "        [[-1.5469]],\n",
      "\n",
      "        [[-1.7988]],\n",
      "\n",
      "        [[-2.0356]]], dtype=torch.float64)\n",
      "tensor([[-1.5485],\n",
      "        [-1.3677],\n",
      "        [-1.5584],\n",
      "        [-1.6905]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3516]],\n",
      "\n",
      "        [[-1.0697]],\n",
      "\n",
      "        [[-1.6289]],\n",
      "\n",
      "        [[-1.6624]]], dtype=torch.float64)\n",
      "tensor([[-1.4012],\n",
      "        [-1.3182],\n",
      "        [-1.3095],\n",
      "        [-1.3094]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3990]],\n",
      "\n",
      "        [[-1.4325]],\n",
      "\n",
      "        [[-1.1228]],\n",
      "\n",
      "        [[-1.1887]]], dtype=torch.float64)\n",
      "tensor([[-1.4225],\n",
      "        [-1.4505],\n",
      "        [-1.4972],\n",
      "        [-1.7707]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3539]],\n",
      "\n",
      "        [[-1.3274]],\n",
      "\n",
      "        [[-1.6659]],\n",
      "\n",
      "        [[-1.8011]]], dtype=torch.float64)\n",
      "tensor([[-1.5050],\n",
      "        [-1.2009],\n",
      "        [-1.1442],\n",
      "        [-0.9350]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0836]],\n",
      "\n",
      "        [[-1.0096]],\n",
      "\n",
      "        [[-0.9126]],\n",
      "\n",
      "        [[-0.8132]]], dtype=torch.float64)\n",
      "tensor([[-0.9040],\n",
      "        [-1.0702],\n",
      "        [-1.0592],\n",
      "        [-1.0712]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9946]],\n",
      "\n",
      "        [[-1.1252]],\n",
      "\n",
      "        [[-0.7785]],\n",
      "\n",
      "        [[-0.8767]]], dtype=torch.float64)\n",
      "tensor([[-1.2959],\n",
      "        [-1.3869],\n",
      "        [-1.4812],\n",
      "        [-1.3511]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1587]],\n",
      "\n",
      "        [[-1.4337]],\n",
      "\n",
      "        [[-1.5550]],\n",
      "\n",
      "        [[-1.3262]]], dtype=torch.float64)\n",
      "tensor([[-0.9061],\n",
      "        [-0.6946],\n",
      "        [-0.9135],\n",
      "        [-1.0626]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5833]],\n",
      "\n",
      "        [[-0.5775]],\n",
      "\n",
      "        [[-0.8663]],\n",
      "\n",
      "        [[-1.1182]]], dtype=torch.float64)\n",
      "tensor([[-1.1355],\n",
      "        [-1.1857],\n",
      "        [-1.0559],\n",
      "        [-1.0110]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1852]],\n",
      "\n",
      "        [[-1.3285]],\n",
      "\n",
      "        [[-0.9195]],\n",
      "\n",
      "        [[-0.9981]]], dtype=torch.float64)\n",
      "tensor([[-1.2488],\n",
      "        [-1.2605],\n",
      "        [-1.1999],\n",
      "        [-1.1249]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2280]],\n",
      "\n",
      "        [[-1.2187]],\n",
      "\n",
      "        [[-1.1922]],\n",
      "\n",
      "        [[-1.1795]]], dtype=torch.float64)\n",
      "tensor([[-1.1403],\n",
      "        [-1.0552],\n",
      "        [-1.1807],\n",
      "        [-1.2524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9565]],\n",
      "\n",
      "        [[-0.8964]],\n",
      "\n",
      "        [[-1.0108]],\n",
      "\n",
      "        [[-1.1575]]], dtype=torch.float64)\n",
      "tensor([[-1.3766],\n",
      "        [-1.5112],\n",
      "        [-1.8132],\n",
      "        [-1.9135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3794]],\n",
      "\n",
      "        [[-1.6127]],\n",
      "\n",
      "        [[-1.7029]],\n",
      "\n",
      "        [[-1.8230]]], dtype=torch.float64)\n",
      "tensor([[-1.9025],\n",
      "        [-1.7978],\n",
      "        [-1.6717],\n",
      "        [-1.6529]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8346]],\n",
      "\n",
      "        [[-1.7445]],\n",
      "\n",
      "        [[-1.7884]],\n",
      "\n",
      "        [[-1.8380]]], dtype=torch.float64)\n",
      "tensor([[-1.7572],\n",
      "        [-1.9054],\n",
      "        [-2.0140],\n",
      "        [-1.9760]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8415]],\n",
      "\n",
      "        [[-1.8669]],\n",
      "\n",
      "        [[-2.1015]],\n",
      "\n",
      "        [[-1.9617]]], dtype=torch.float64)\n",
      "tensor([[-1.7266],\n",
      "        [-1.6812],\n",
      "        [-1.6809],\n",
      "        [-1.6972]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8935]],\n",
      "\n",
      "        [[-2.0079]],\n",
      "\n",
      "        [[-1.7017]],\n",
      "\n",
      "        [[-1.7086]]], dtype=torch.float64)\n",
      "tensor([[-1.8491],\n",
      "        [-1.7355],\n",
      "        [-1.6782],\n",
      "        [-1.6624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8219]],\n",
      "\n",
      "        [[-1.8392]],\n",
      "\n",
      "        [[-1.8762]],\n",
      "\n",
      "        [[-1.8843]]], dtype=torch.float64)\n",
      "tensor([[-1.6166],\n",
      "        [-1.7906],\n",
      "        [-1.8723],\n",
      "        [-1.8647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7537]],\n",
      "\n",
      "        [[-1.7375]],\n",
      "\n",
      "        [[-1.8739]],\n",
      "\n",
      "        [[-1.8993]]], dtype=torch.float64)\n",
      "tensor([[-1.8805],\n",
      "        [-1.8214],\n",
      "        [-1.7752],\n",
      "        [-1.7853]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9455]],\n",
      "\n",
      "        [[-1.8346]],\n",
      "\n",
      "        [[-1.7110]],\n",
      "\n",
      "        [[-1.7040]]], dtype=torch.float64)\n",
      "tensor([[-1.8716],\n",
      "        [-1.6924],\n",
      "        [-1.5202],\n",
      "        [-1.4772]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7491]],\n",
      "\n",
      "        [[-1.6255]],\n",
      "\n",
      "        [[-1.5388]],\n",
      "\n",
      "        [[-1.5007]]], dtype=torch.float64)\n",
      "tensor([[-1.4033],\n",
      "        [-1.4995],\n",
      "        [-1.5372],\n",
      "        [-1.5409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3505]],\n",
      "\n",
      "        [[-1.4105]],\n",
      "\n",
      "        [[-1.4880]],\n",
      "\n",
      "        [[-1.6035]]], dtype=torch.float64)\n",
      "tensor([[-1.5843],\n",
      "        [-1.6644],\n",
      "        [-1.6010],\n",
      "        [-1.5458]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7225]],\n",
      "\n",
      "        [[-1.6774]],\n",
      "\n",
      "        [[-1.4105]],\n",
      "\n",
      "        [[-1.4960]]], dtype=torch.float64)\n",
      "tensor([[-1.7232],\n",
      "        [-1.7028],\n",
      "        [-1.6429],\n",
      "        [-1.7224]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6578]],\n",
      "\n",
      "        [[-1.7133]],\n",
      "\n",
      "        [[-1.8704]],\n",
      "\n",
      "        [[-1.8311]]], dtype=torch.float64)\n",
      "tensor([[-1.5243],\n",
      "        [-1.4786],\n",
      "        [-1.6903],\n",
      "        [-1.7197]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2927]],\n",
      "\n",
      "        [[-1.3886]],\n",
      "\n",
      "        [[-1.5781]],\n",
      "\n",
      "        [[-1.6878]]], dtype=torch.float64)\n",
      "tensor([[-1.6487],\n",
      "        [-1.5970],\n",
      "        [-1.4372],\n",
      "        [-1.4474]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7156]],\n",
      "\n",
      "        [[-1.7294]],\n",
      "\n",
      "        [[-1.3747]],\n",
      "\n",
      "        [[-1.4487]]], dtype=torch.float64)\n",
      "tensor([[-1.5222],\n",
      "        [-1.6698],\n",
      "        [-1.6450],\n",
      "        [-1.5121]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5457]],\n",
      "\n",
      "        [[-1.8334]],\n",
      "\n",
      "        [[-1.7687]],\n",
      "\n",
      "        [[-1.6948]]], dtype=torch.float64)\n",
      "tensor([[-1.4295],\n",
      "        [-1.4519],\n",
      "        [-1.6598],\n",
      "        [-1.9934]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4221]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.8924]],\n",
      "\n",
      "        [[-2.3487]]], dtype=torch.float64)\n",
      "tensor([[-2.1657],\n",
      "        [-2.2275],\n",
      "        [-1.5859],\n",
      "        [-0.9259]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6156]],\n",
      "\n",
      "        [[-2.4724]],\n",
      "\n",
      "        [[-1.0801]],\n",
      "\n",
      "        [[-0.7462]]], dtype=torch.float64)\n",
      "tensor([[-1.0650],\n",
      "        [-1.1188],\n",
      "        [-1.0434],\n",
      "        [-0.9503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1402]],\n",
      "\n",
      "        [[-1.2407]],\n",
      "\n",
      "        [[-1.1309]],\n",
      "\n",
      "        [[-0.9518]]], dtype=torch.float64)\n",
      "tensor([[-0.6807],\n",
      "        [-0.5085],\n",
      "        [-0.8372],\n",
      "        [-1.0101]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.4319]],\n",
      "\n",
      "        [[-0.9438]],\n",
      "\n",
      "        [[-1.2141]]], dtype=torch.float64)\n",
      "tensor([[-1.1432],\n",
      "        [-0.9809],\n",
      "        [-0.7252],\n",
      "        [-0.5228]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2395]],\n",
      "\n",
      "        [[-0.9415]],\n",
      "\n",
      "        [[-0.6018]],\n",
      "\n",
      "        [[-0.4793]]], dtype=torch.float64)\n",
      "tensor([[-0.6365],\n",
      "        [-0.8287],\n",
      "        [-0.9093],\n",
      "        [-0.9622]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8016]],\n",
      "\n",
      "        [[-0.9565]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-1.1483]]], dtype=torch.float64)\n",
      "tensor([[-0.9925],\n",
      "        [-0.8376],\n",
      "        [-1.0466],\n",
      "        [-1.1719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7208]],\n",
      "\n",
      "        [[-0.7289]],\n",
      "\n",
      "        [[-1.0397]],\n",
      "\n",
      "        [[-1.2696]]], dtype=torch.float64)\n",
      "tensor([[-1.2151],\n",
      "        [-1.1233],\n",
      "        [-0.9746],\n",
      "        [-0.9679]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2650]],\n",
      "\n",
      "        [[-1.2176]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-0.8409]]], dtype=torch.float64)\n",
      "tensor([[-1.0121],\n",
      "        [-1.1107],\n",
      "        [-1.0847],\n",
      "        [-1.0987]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0131]],\n",
      "\n",
      "        [[-1.2419]],\n",
      "\n",
      "        [[-1.2476]],\n",
      "\n",
      "        [[-1.1852]]], dtype=torch.float64)\n",
      "tensor([[-0.6824],\n",
      "        [-0.6205],\n",
      "        [-0.5509],\n",
      "        [-0.4920]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.4423]],\n",
      "\n",
      "        [[-0.4400]],\n",
      "\n",
      "        [[-0.3187]]], dtype=torch.float64)\n",
      "tensor([[-0.4345],\n",
      "        [-0.3423],\n",
      "        [-0.3318],\n",
      "        [-0.5300]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5590]],\n",
      "\n",
      "        [[-0.3094]],\n",
      "\n",
      "        [[-0.3741]],\n",
      "\n",
      "        [[-0.9264]]], dtype=torch.float64)\n",
      "tensor([[-1.0214],\n",
      "        [-1.0242],\n",
      "        [-0.9956],\n",
      "        [-0.9252]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0709]],\n",
      "\n",
      "        [[-1.1101]],\n",
      "\n",
      "        [[-1.1332]],\n",
      "\n",
      "        [[-1.1090]]], dtype=torch.float64)\n",
      "tensor([[-0.7264],\n",
      "        [-0.0806],\n",
      "        [-0.4429],\n",
      "        [-0.7003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4030]],\n",
      "\n",
      "        [[-0.1477]],\n",
      "\n",
      "        [[-0.5740]],\n",
      "\n",
      "        [[-1.0015]]], dtype=torch.float64)\n",
      "tensor([[-0.8796],\n",
      "        [-0.5811],\n",
      "        [-0.1418],\n",
      "        [-0.2282]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6676]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-0.0056]],\n",
      "\n",
      "        [[ 0.0984]]], dtype=torch.float64)\n",
      "tensor([[-0.3893],\n",
      "        [-0.4609],\n",
      "        [-0.3667],\n",
      "        [-0.2753]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3314]],\n",
      "\n",
      "        [[-0.3094]],\n",
      "\n",
      "        [[-0.4146]],\n",
      "\n",
      "        [[-0.2933]]], dtype=torch.float64)\n",
      "tensor([[-0.1941],\n",
      "        [-0.2376],\n",
      "        [-0.4068],\n",
      "        [-0.5738]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0206]],\n",
      "\n",
      "        [[ 0.0626]],\n",
      "\n",
      "        [[-0.4250]],\n",
      "\n",
      "        [[-0.6052]]], dtype=torch.float64)\n",
      "tensor([[-0.7530],\n",
      "        [-0.7901],\n",
      "        [-0.4965],\n",
      "        [-0.3007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7439]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.2563]],\n",
      "\n",
      "        [[-0.0772]]], dtype=torch.float64)\n",
      "tensor([[-0.5519],\n",
      "        [-0.7019],\n",
      "        [-0.6608],\n",
      "        [-0.6059]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4550]],\n",
      "\n",
      "        [[-0.5971]],\n",
      "\n",
      "        [[-0.5093]],\n",
      "\n",
      "        [[-0.5336]]], dtype=torch.float64)\n",
      "tensor([[-0.3548],\n",
      "        [ 0.0690],\n",
      "        [-0.1205],\n",
      "        [-0.3538]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2556]],\n",
      "\n",
      "        [[ 0.5132]],\n",
      "\n",
      "        [[ 0.0580]],\n",
      "\n",
      "        [[-0.2367]]], dtype=torch.float64)\n",
      "tensor([[-0.4505],\n",
      "        [-0.6737],\n",
      "        [-0.7128],\n",
      "        [-0.6849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5740]],\n",
      "\n",
      "        [[-0.4735]],\n",
      "\n",
      "        [[-0.4065]],\n",
      "\n",
      "        [[-0.3811]]], dtype=torch.float64)\n",
      "tensor([[-0.8594],\n",
      "        [-0.8927],\n",
      "        [-0.8801],\n",
      "        [-1.0065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8479]],\n",
      "\n",
      "        [[-0.9253]],\n",
      "\n",
      "        [[-1.0651]],\n",
      "\n",
      "        [[-1.0836]]], dtype=torch.float64)\n",
      "tensor([[-0.8987],\n",
      "        [-0.9699],\n",
      "        [-1.1042],\n",
      "        [-1.0541]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5833]],\n",
      "\n",
      "        [[-0.5555]],\n",
      "\n",
      "        [[-0.8871]],\n",
      "\n",
      "        [[-1.0477]]], dtype=torch.float64)\n",
      "tensor([[-1.0731],\n",
      "        [-1.0186],\n",
      "        [-0.9823],\n",
      "        [-0.8927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1332]],\n",
      "\n",
      "        [[-0.9830]],\n",
      "\n",
      "        [[-0.5948]],\n",
      "\n",
      "        [[-0.5787]]], dtype=torch.float64)\n",
      "tensor([[-1.0757],\n",
      "        [-1.3123],\n",
      "        [-1.3493],\n",
      "        [-1.4041]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0015]],\n",
      "\n",
      "        [[-1.4475]],\n",
      "\n",
      "        [[-1.6139]],\n",
      "\n",
      "        [[-1.1621]]], dtype=torch.float64)\n",
      "tensor([[-1.1821],\n",
      "        [-1.2277],\n",
      "        [-1.3301],\n",
      "        [-1.3982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9854]],\n",
      "\n",
      "        [[-0.9010]],\n",
      "\n",
      "        [[-1.2673]],\n",
      "\n",
      "        [[-1.4949]]], dtype=torch.float64)\n",
      "tensor([[-1.3625],\n",
      "        [-1.4739],\n",
      "        [-1.5253],\n",
      "        [-1.4989]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5584]],\n",
      "\n",
      "        [[-1.5411]],\n",
      "\n",
      "        [[-1.3666]],\n",
      "\n",
      "        [[-1.1772]]], dtype=torch.float64)\n",
      "tensor([[-1.4037],\n",
      "        [-1.2959],\n",
      "        [-1.1212],\n",
      "        [-1.0848]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4025]],\n",
      "\n",
      "        [[-1.4868]],\n",
      "\n",
      "        [[-1.3539]],\n",
      "\n",
      "        [[-1.4591]]], dtype=torch.float64)\n",
      "tensor([[-1.5686],\n",
      "        [-1.6681],\n",
      "        [-1.6356],\n",
      "        [-1.6072]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5804]],\n",
      "\n",
      "        [[-1.4383]],\n",
      "\n",
      "        [[-1.5515]],\n",
      "\n",
      "        [[-1.7167]]], dtype=torch.float64)\n",
      "tensor([[-1.5438],\n",
      "        [-1.5740],\n",
      "        [-1.5794],\n",
      "        [-1.4956]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7560]],\n",
      "\n",
      "        [[-1.8727]],\n",
      "\n",
      "        [[-1.4036]],\n",
      "\n",
      "        [[-1.2800]]], dtype=torch.float64)\n",
      "tensor([[-1.5817],\n",
      "        [-1.5587],\n",
      "        [-1.4623],\n",
      "        [-1.5067]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5908]],\n",
      "\n",
      "        [[-1.5723]],\n",
      "\n",
      "        [[-1.6462]],\n",
      "\n",
      "        [[-1.4729]]], dtype=torch.float64)\n",
      "tensor([[-1.3013],\n",
      "        [-1.3670],\n",
      "        [-1.4120],\n",
      "        [-1.5371]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3447]],\n",
      "\n",
      "        [[-1.3458]],\n",
      "\n",
      "        [[-1.5203]],\n",
      "\n",
      "        [[-1.7999]]], dtype=torch.float64)\n",
      "tensor([[-1.6077],\n",
      "        [-1.8406],\n",
      "        [-1.5861],\n",
      "        [-1.5003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1569]],\n",
      "\n",
      "        [[-2.2297]],\n",
      "\n",
      "        [[-1.4464]],\n",
      "\n",
      "        [[-1.2303]]], dtype=torch.float64)\n",
      "tensor([[-1.4590],\n",
      "        [-1.5781],\n",
      "        [-1.6020],\n",
      "        [-1.6167]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4152]],\n",
      "\n",
      "        [[-1.7352]],\n",
      "\n",
      "        [[-2.0634]],\n",
      "\n",
      "        [[-1.5099]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.12739:  23%|██▎       | 716/3067 [00:02<00:07, 330.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4136],\n",
      "        [-1.1954],\n",
      "        [-1.2498],\n",
      "        [-1.3289]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0443]],\n",
      "\n",
      "        [[-0.9230]],\n",
      "\n",
      "        [[-1.1263]],\n",
      "\n",
      "        [[-1.3897]]], dtype=torch.float64)\n",
      "tensor([[-1.3937],\n",
      "        [-1.3781],\n",
      "        [-1.4324],\n",
      "        [-1.2426]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6023]],\n",
      "\n",
      "        [[-1.7202]],\n",
      "\n",
      "        [[-1.3100]],\n",
      "\n",
      "        [[-1.1263]]], dtype=torch.float64)\n",
      "tensor([[-1.3700],\n",
      "        [-1.3990],\n",
      "        [-1.1760],\n",
      "        [-1.0185]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6197]],\n",
      "\n",
      "        [[-1.5758]],\n",
      "\n",
      "        [[-1.4787]],\n",
      "\n",
      "        [[-1.1286]]], dtype=torch.float64)\n",
      "tensor([[-0.8542],\n",
      "        [-0.6996],\n",
      "        [-0.8690],\n",
      "        [-0.7705]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7762]],\n",
      "\n",
      "        [[-0.5509]],\n",
      "\n",
      "        [[-0.7947]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-0.8086],\n",
      "        [-0.7948],\n",
      "        [-0.7623],\n",
      "        [-0.7518]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9114]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.6584]],\n",
      "\n",
      "        [[-0.6711]]], dtype=torch.float64)\n",
      "tensor([[-0.7559],\n",
      "        [-0.6378],\n",
      "        [-0.6039],\n",
      "        [-0.6778]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6919]],\n",
      "\n",
      "        [[-0.6711]],\n",
      "\n",
      "        [[-0.7242]],\n",
      "\n",
      "        [[-0.7832]]], dtype=torch.float64)\n",
      "tensor([[-0.6918],\n",
      "        [-0.5407],\n",
      "        [-0.5781],\n",
      "        [-0.7062]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4250]],\n",
      "\n",
      "        [[-0.4828]],\n",
      "\n",
      "        [[-0.5960]],\n",
      "\n",
      "        [[-0.9981]]], dtype=torch.float64)\n",
      "tensor([[-1.0209],\n",
      "        [-1.0115],\n",
      "        [-0.9458],\n",
      "        [-0.7191]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1714]],\n",
      "\n",
      "        [[-1.0108]],\n",
      "\n",
      "        [[-0.7647]],\n",
      "\n",
      "        [[-0.7612]]], dtype=torch.float64)\n",
      "tensor([[-0.7308],\n",
      "        [-0.5431],\n",
      "        [-0.5548],\n",
      "        [-0.7734]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6006]],\n",
      "\n",
      "        [[-0.5867]],\n",
      "\n",
      "        [[-0.7785]],\n",
      "\n",
      "        [[-0.9634]]], dtype=torch.float64)\n",
      "tensor([[-0.9091],\n",
      "        [-0.9490],\n",
      "        [-0.8635],\n",
      "        [-0.8197]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8178]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.7323]],\n",
      "\n",
      "        [[-0.8548]]], dtype=torch.float64)\n",
      "tensor([[-0.6944],\n",
      "        [-0.5179],\n",
      "        [-0.2541],\n",
      "        [-0.1774]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6873]],\n",
      "\n",
      "        [[-0.5463]],\n",
      "\n",
      "        [[-0.0784]],\n",
      "\n",
      "        [[ 0.1042]]], dtype=torch.float64)\n",
      "tensor([[-0.3833],\n",
      "        [-0.5699],\n",
      "        [-0.7262],\n",
      "        [-0.9648]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3568]],\n",
      "\n",
      "        [[-0.7185]],\n",
      "\n",
      "        [[-1.0789]],\n",
      "\n",
      "        [[-0.7774]]], dtype=torch.float64)\n",
      "tensor([[-0.0503],\n",
      "        [ 0.0641],\n",
      "        [-0.0571],\n",
      "        [-0.3622]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4785]],\n",
      "\n",
      "        [[ 0.6495]],\n",
      "\n",
      "        [[ 0.0591]],\n",
      "\n",
      "        [[-0.3811]]], dtype=torch.float64)\n",
      "tensor([[-0.4388],\n",
      "        [-0.4523],\n",
      "        [ 0.2703],\n",
      "        [ 0.3398]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5775]],\n",
      "\n",
      "        [[-0.3788]],\n",
      "\n",
      "        [[ 0.7177]],\n",
      "\n",
      "        [[ 0.8067]]], dtype=torch.float64)\n",
      "tensor([[0.3279],\n",
      "        [0.2188],\n",
      "        [0.1140],\n",
      "        [0.1116]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2694]],\n",
      "\n",
      "        [[0.1319]],\n",
      "\n",
      "        [[0.0661]],\n",
      "\n",
      "        [[0.1204]]], dtype=torch.float64)\n",
      "tensor([[0.2807],\n",
      "        [0.4184],\n",
      "        [0.4272],\n",
      "        [0.4590]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5479]],\n",
      "\n",
      "        [[0.6322]],\n",
      "\n",
      "        [[0.4993]],\n",
      "\n",
      "        [[0.3988]]], dtype=torch.float64)\n",
      "tensor([[0.5088],\n",
      "        [0.4163],\n",
      "        [0.4060],\n",
      "        [0.1774]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2636]],\n",
      "\n",
      "        [[0.3307]],\n",
      "\n",
      "        [[0.4855]],\n",
      "\n",
      "        [[0.1377]]], dtype=torch.float64)\n",
      "tensor([[ 0.0859],\n",
      "        [-0.0597],\n",
      "        [-0.3632],\n",
      "        [-0.4427]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0888]],\n",
      "\n",
      "        [[-0.4758]],\n",
      "\n",
      "        [[-0.6988]],\n",
      "\n",
      "        [[-0.5278]]], dtype=torch.float64)\n",
      "tensor([[0.0262],\n",
      "        [0.0912],\n",
      "        [0.1046],\n",
      "        [0.1001]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1296]],\n",
      "\n",
      "        [[ 0.3203]],\n",
      "\n",
      "        [[ 0.1389]],\n",
      "\n",
      "        [[-0.1835]]], dtype=torch.float64)\n",
      "tensor([[-0.1759],\n",
      "        [-0.3703],\n",
      "        [ 0.0805],\n",
      "        [ 0.0307]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6283]],\n",
      "\n",
      "        [[-0.5082]],\n",
      "\n",
      "        [[ 0.4173]],\n",
      "\n",
      "        [[ 0.3757]]], dtype=torch.float64)\n",
      "tensor([[-0.0735],\n",
      "        [-0.3852],\n",
      "        [-0.5929],\n",
      "        [-0.7249]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1719]],\n",
      "\n",
      "        [[-0.6792]],\n",
      "\n",
      "        [[-1.0027]],\n",
      "\n",
      "        [[-0.5821]]], dtype=torch.float64)\n",
      "tensor([[0.1496],\n",
      "        [0.3866],\n",
      "        [0.3316],\n",
      "        [0.2963]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7235]],\n",
      "\n",
      "        [[1.0297]],\n",
      "\n",
      "        [[0.4739]],\n",
      "\n",
      "        [[0.0545]]], dtype=torch.float64)\n",
      "tensor([[ 0.0364],\n",
      "        [-0.1710],\n",
      "        [ 0.3845],\n",
      "        [ 0.6326]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3048]],\n",
      "\n",
      "        [[-0.1350]],\n",
      "\n",
      "        [[ 1.0493]],\n",
      "\n",
      "        [[ 1.2966]]], dtype=torch.float64)\n",
      "tensor([[0.5373],\n",
      "        [0.4257],\n",
      "        [0.2453],\n",
      "        [0.0268]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6484]],\n",
      "\n",
      "        [[ 0.2983]],\n",
      "\n",
      "        [[ 0.0302]],\n",
      "\n",
      "        [[-0.0599]]], dtype=torch.float64)\n",
      "tensor([[ 0.4886],\n",
      "        [ 0.7517],\n",
      "        [ 0.3721],\n",
      "        [-0.2120]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.2434]],\n",
      "\n",
      "        [[ 1.4329]],\n",
      "\n",
      "        [[-0.2910]],\n",
      "\n",
      "        [[-0.3418]]], dtype=torch.float64)\n",
      "tensor([[-0.0872],\n",
      "        [-0.0915],\n",
      "        [-0.0683],\n",
      "        [ 0.0143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-3.1637e-01]],\n",
      "\n",
      "        [[-2.4589e-01]],\n",
      "\n",
      "        [[ 2.0721e-04]],\n",
      "\n",
      "        [[ 5.3356e-02]]], dtype=torch.float64)\n",
      "tensor([[-0.0853],\n",
      "        [-0.3151],\n",
      "        [-0.2746],\n",
      "        [-0.1234]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2517]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-0.5232]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[ 0.0985],\n",
      "        [ 0.0148],\n",
      "        [ 0.0107],\n",
      "        [-0.0757]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1042]],\n",
      "\n",
      "        [[ 0.1770]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[-0.1800]]], dtype=torch.float64)\n",
      "tensor([[-0.0613],\n",
      "        [ 0.0375],\n",
      "        [ 0.3065],\n",
      "        [ 0.1552]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3152]],\n",
      "\n",
      "        [[-0.0899]],\n",
      "\n",
      "        [[ 0.3630]],\n",
      "\n",
      "        [[ 0.1319]]], dtype=torch.float64)\n",
      "tensor([[0.1019],\n",
      "        [0.0230],\n",
      "        [0.0463],\n",
      "        [0.0132]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1789]],\n",
      "\n",
      "        [[-0.1523]],\n",
      "\n",
      "        [[-0.3302]],\n",
      "\n",
      "        [[-0.2251]]], dtype=torch.float64)\n",
      "tensor([[0.3532],\n",
      "        [0.6278],\n",
      "        [0.3707],\n",
      "        [0.2073]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7940]],\n",
      "\n",
      "        [[ 1.0643]],\n",
      "\n",
      "        [[ 0.6149]],\n",
      "\n",
      "        [[-0.0899]]], dtype=torch.float64)\n",
      "tensor([[ 0.0176],\n",
      "        [-0.2086],\n",
      "        [-0.0572],\n",
      "        [ 0.0176]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2782]],\n",
      "\n",
      "        [[-0.4458]],\n",
      "\n",
      "        [[-0.0714]],\n",
      "\n",
      "        [[ 0.1481]]], dtype=torch.float64)\n",
      "tensor([[-0.1580],\n",
      "        [-0.3824],\n",
      "        [-0.4597],\n",
      "        [-0.5324]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3141]],\n",
      "\n",
      "        [[-0.6202]],\n",
      "\n",
      "        [[-0.7624]],\n",
      "\n",
      "        [[-0.4481]]], dtype=torch.float64)\n",
      "tensor([[-0.1638],\n",
      "        [-0.2213],\n",
      "        [-0.3859],\n",
      "        [-0.6736]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2078]],\n",
      "\n",
      "        [[-0.1165]],\n",
      "\n",
      "        [[-0.4227]],\n",
      "\n",
      "        [[-0.8964]]], dtype=torch.float64)\n",
      "tensor([[-0.7701],\n",
      "        [-0.8324],\n",
      "        [-0.1244],\n",
      "        [-0.2570]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2349]],\n",
      "\n",
      "        [[-0.7127]],\n",
      "\n",
      "        [[-0.0553]],\n",
      "\n",
      "        [[ 0.1689]]], dtype=torch.float64)\n",
      "tensor([[-0.4817],\n",
      "        [-0.7511],\n",
      "        [-0.8430],\n",
      "        [-0.5678]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3765]],\n",
      "\n",
      "        [[-0.9946]],\n",
      "\n",
      "        [[-0.9472]],\n",
      "\n",
      "        [[-0.5579]]], dtype=torch.float64)\n",
      "tensor([[ 0.0261],\n",
      "        [ 0.0058],\n",
      "        [ 0.0213],\n",
      "        [-0.1480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2105]],\n",
      "\n",
      "        [[ 0.3376]],\n",
      "\n",
      "        [[ 0.0129]],\n",
      "\n",
      "        [[-0.2794]]], dtype=torch.float64)\n",
      "tensor([[-0.1658],\n",
      "        [-0.0516],\n",
      "        [ 0.1728],\n",
      "        [ 0.1197]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4400]],\n",
      "\n",
      "        [[-0.0472]],\n",
      "\n",
      "        [[ 0.2498]],\n",
      "\n",
      "        [[ 0.3665]]], dtype=torch.float64)\n",
      "tensor([[ 0.0192],\n",
      "        [-0.2945],\n",
      "        [-0.1635],\n",
      "        [-0.2215]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1512]],\n",
      "\n",
      "        [[-0.4677]],\n",
      "\n",
      "        [[-0.3233]],\n",
      "\n",
      "        [[-0.3152]]], dtype=torch.float64)\n",
      "tensor([[-0.2726],\n",
      "        [-0.1351],\n",
      "        [-0.3345],\n",
      "        [-0.5846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0703]],\n",
      "\n",
      "        [[ 0.0175]],\n",
      "\n",
      "        [[-0.3222]],\n",
      "\n",
      "        [[-0.7566]]], dtype=torch.float64)\n",
      "tensor([[-0.6081],\n",
      "        [-0.5375],\n",
      "        [ 0.2012],\n",
      "        [ 0.1249]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8687]],\n",
      "\n",
      "        [[-0.4481]],\n",
      "\n",
      "        [[ 0.3861]],\n",
      "\n",
      "        [[ 0.5664]]], dtype=torch.float64)\n",
      "tensor([[-0.0369],\n",
      "        [-0.2721],\n",
      "        [-0.4040],\n",
      "        [-0.3953]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0857]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[-0.7589]],\n",
      "\n",
      "        [[-0.1292]]], dtype=torch.float64)\n",
      "tensor([[ 0.2890],\n",
      "        [ 0.3288],\n",
      "        [ 0.1563],\n",
      "        [-0.2092]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6299]],\n",
      "\n",
      "        [[ 1.0066]],\n",
      "\n",
      "        [[ 0.4242]],\n",
      "\n",
      "        [[-0.1338]]], dtype=torch.float64)\n",
      "tensor([[-0.2801],\n",
      "        [-0.3574],\n",
      "        [ 0.4415],\n",
      "        [ 0.4442]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7023]],\n",
      "\n",
      "        [[-0.2390]],\n",
      "\n",
      "        [[ 1.1094]],\n",
      "\n",
      "        [[ 0.8887]]], dtype=torch.float64)\n",
      "tensor([[ 0.2906],\n",
      "        [ 0.2211],\n",
      "        [ 0.3313],\n",
      "        [-0.1077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2948]],\n",
      "\n",
      "        [[ 0.0418]],\n",
      "\n",
      "        [[-0.2609]],\n",
      "\n",
      "        [[-0.1072]]], dtype=torch.float64)\n",
      "tensor([[-0.0926],\n",
      "        [-0.1070],\n",
      "        [-0.1974],\n",
      "        [-0.1248]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1793]],\n",
      "\n",
      "        [[ 0.3133]],\n",
      "\n",
      "        [[ 0.0326]],\n",
      "\n",
      "        [[-0.1304]]], dtype=torch.float64)\n",
      "tensor([[-0.1091],\n",
      "        [-0.3212],\n",
      "        [-0.3694],\n",
      "        [-0.3586]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4250]],\n",
      "\n",
      "        [[-0.4781]],\n",
      "\n",
      "        [[-0.3938]],\n",
      "\n",
      "        [[-0.1142]]], dtype=torch.float64)\n",
      "tensor([[-0.3967],\n",
      "        [-0.4789],\n",
      "        [-0.4236],\n",
      "        [-0.5766]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5521]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-0.8999]]], dtype=torch.float64)\n",
      "tensor([[-0.6114],\n",
      "        [-0.5459],\n",
      "        [-0.6247],\n",
      "        [-0.5824]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5902]],\n",
      "\n",
      "        [[-0.4955]],\n",
      "\n",
      "        [[-0.5775]],\n",
      "\n",
      "        [[-0.6249]]], dtype=torch.float64)\n",
      "tensor([[-0.4633],\n",
      "        [-0.4814],\n",
      "        [-0.5216],\n",
      "        [-0.2984]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6965]],\n",
      "\n",
      "        [[-0.7693]],\n",
      "\n",
      "        [[-0.6422]],\n",
      "\n",
      "        [[-0.1015]]], dtype=torch.float64)\n",
      "tensor([[-0.1150],\n",
      "        [-0.1910],\n",
      "        [-0.2269],\n",
      "        [-0.3157]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2089]],\n",
      "\n",
      "        [[-0.2505]],\n",
      "\n",
      "        [[-0.4908]],\n",
      "\n",
      "        [[-0.4308]]], dtype=torch.float64)\n",
      "tensor([[ 0.0102],\n",
      "        [ 0.0675],\n",
      "        [-0.0218],\n",
      "        [-0.1265]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1620]],\n",
      "\n",
      "        [[ 0.3214]],\n",
      "\n",
      "        [[ 0.0337]],\n",
      "\n",
      "        [[-0.1384]]], dtype=torch.float64)\n",
      "tensor([[-0.1256],\n",
      "        [-0.3478],\n",
      "        [-0.1373],\n",
      "        [-0.2807]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4770]],\n",
      "\n",
      "        [[-0.3926]],\n",
      "\n",
      "        [[-0.1662]],\n",
      "\n",
      "        [[-0.3996]]], dtype=torch.float64)\n",
      "tensor([[-0.4313],\n",
      "        [-0.3431],\n",
      "        [-0.1430],\n",
      "        [-0.2712]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4781]],\n",
      "\n",
      "        [[-0.4573]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.5636]]], dtype=torch.float64)\n",
      "tensor([[-0.3917],\n",
      "        [-0.4392],\n",
      "        [-0.4742],\n",
      "        [-0.3601]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4689]],\n",
      "\n",
      "        [[-0.5579]],\n",
      "\n",
      "        [[-0.5475]],\n",
      "\n",
      "        [[-0.6122]]], dtype=torch.float64)\n",
      "tensor([[-0.3018],\n",
      "        [-0.3368],\n",
      "        [-0.1828],\n",
      "        [-0.0915]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6815]],\n",
      "\n",
      "        [[-0.4030]],\n",
      "\n",
      "        [[-0.1246]],\n",
      "\n",
      "        [[ 0.0626]]], dtype=torch.float64)\n",
      "tensor([[-0.2008],\n",
      "        [-0.4574],\n",
      "        [-0.6596],\n",
      "        [-0.6279]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2921]],\n",
      "\n",
      "        [[-0.7185]],\n",
      "\n",
      "        [[-1.1332]],\n",
      "\n",
      "        [[-0.5093]]], dtype=torch.float64)\n",
      "tensor([[-0.0141],\n",
      "        [ 0.1073],\n",
      "        [ 0.1336],\n",
      "        [-0.2382]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2140]],\n",
      "\n",
      "        [[ 0.7986]],\n",
      "\n",
      "        [[ 0.1666]],\n",
      "\n",
      "        [[-0.6642]]], dtype=torch.float64)\n",
      "tensor([[-0.5072],\n",
      "        [-0.4880],\n",
      "        [ 0.4332],\n",
      "        [ 0.4398]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0235]],\n",
      "\n",
      "        [[-0.2355]],\n",
      "\n",
      "        [[ 0.8494]],\n",
      "\n",
      "        [[ 0.9962]]], dtype=torch.float64)\n",
      "tensor([[ 0.3465],\n",
      "        [ 0.1192],\n",
      "        [-0.2100],\n",
      "        [-0.2026]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5802]],\n",
      "\n",
      "        [[-0.2528]],\n",
      "\n",
      "        [[-0.6653]],\n",
      "\n",
      "        [[ 0.0291]]], dtype=torch.float64)\n",
      "tensor([[ 0.3585],\n",
      "        [ 0.2298],\n",
      "        [-0.0071],\n",
      "        [-0.0807]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 4.5428e-01]],\n",
      "\n",
      "        [[ 4.7508e-01]],\n",
      "\n",
      "        [[ 2.0721e-04]],\n",
      "\n",
      "        [[-8.7604e-02]]], dtype=torch.float64)\n",
      "tensor([[ 0.0541],\n",
      "        [-0.1332],\n",
      "        [ 0.3083],\n",
      "        [ 0.2923]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3314]],\n",
      "\n",
      "        [[ 0.0383]],\n",
      "\n",
      "        [[ 0.6010]],\n",
      "\n",
      "        [[ 0.8148]]], dtype=torch.float64)\n",
      "tensor([[ 0.2216],\n",
      "        [-0.1629],\n",
      "        [-0.3375],\n",
      "        [-0.3913]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2452]],\n",
      "\n",
      "        [[-0.2112]],\n",
      "\n",
      "        [[-0.5174]],\n",
      "\n",
      "        [[-0.4296]]], dtype=torch.float64)\n",
      "tensor([[-0.4267],\n",
      "        [-0.2663],\n",
      "        [-0.4859],\n",
      "        [-0.6581]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5787]],\n",
      "\n",
      "        [[-0.2286]],\n",
      "\n",
      "        [[-0.5914]],\n",
      "\n",
      "        [[-0.8733]]], dtype=torch.float64)\n",
      "tensor([[-0.6305],\n",
      "        [-0.4713],\n",
      "        [-0.3627],\n",
      "        [-0.2253]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0200]],\n",
      "\n",
      "        [[-0.5810]],\n",
      "\n",
      "        [[-0.0853]],\n",
      "\n",
      "        [[ 0.2313]]], dtype=torch.float64)\n",
      "tensor([[-0.3613],\n",
      "        [-0.6166],\n",
      "        [-0.7669],\n",
      "        [-0.6934]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2124]],\n",
      "\n",
      "        [[-0.9299]],\n",
      "\n",
      "        [[-1.2858]],\n",
      "\n",
      "        [[-0.5821]]], dtype=torch.float64)\n",
      "tensor([[ 0.0963],\n",
      "        [ 0.0514],\n",
      "        [-0.0257],\n",
      "        [-0.2765]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4601]],\n",
      "\n",
      "        [[ 0.5629]],\n",
      "\n",
      "        [[ 0.1839]],\n",
      "\n",
      "        [[-0.5243]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.12739:  26%|██▌       | 785/3067 [00:02<00:06, 335.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4993],\n",
      "        [-0.4535],\n",
      "        [ 0.3884],\n",
      "        [ 0.4086]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9449]],\n",
      "\n",
      "        [[-0.2193]],\n",
      "\n",
      "        [[ 0.9153]],\n",
      "\n",
      "        [[ 0.9604]]], dtype=torch.float64)\n",
      "tensor([[ 0.2384],\n",
      "        [ 0.2098],\n",
      "        [-0.0232],\n",
      "        [-0.0943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4889]],\n",
      "\n",
      "        [[ 0.0557]],\n",
      "\n",
      "        [[-0.6214]],\n",
      "\n",
      "        [[ 0.0672]]], dtype=torch.float64)\n",
      "tensor([[0.6778],\n",
      "        [0.7515],\n",
      "        [0.6830],\n",
      "        [0.5141]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2758]],\n",
      "\n",
      "        [[1.4260]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.2498]]], dtype=torch.float64)\n",
      "tensor([[0.4258],\n",
      "        [0.4316],\n",
      "        [0.3271],\n",
      "        [0.4411]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1974]],\n",
      "\n",
      "        [[ 0.4266]],\n",
      "\n",
      "        [[ 0.4866]],\n",
      "\n",
      "        [[ 0.8090]]], dtype=torch.float64)\n",
      "tensor([[0.3413],\n",
      "        [0.2531],\n",
      "        [0.3953],\n",
      "        [0.3567]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3965]],\n",
      "\n",
      "        [[0.1493]],\n",
      "\n",
      "        [[0.0418]],\n",
      "\n",
      "        [[0.1932]]], dtype=torch.float64)\n",
      "tensor([[0.3859],\n",
      "        [0.3426],\n",
      "        [0.3400],\n",
      "        [0.0902]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6842]],\n",
      "\n",
      "        [[ 0.8182]],\n",
      "\n",
      "        [[ 0.4034]],\n",
      "\n",
      "        [[-0.3314]]], dtype=torch.float64)\n",
      "tensor([[-0.0988],\n",
      "        [ 0.0122],\n",
      "        [ 0.6005],\n",
      "        [ 0.6274]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6988]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[ 0.9199]],\n",
      "\n",
      "        [[ 1.3162]]], dtype=torch.float64)\n",
      "tensor([[0.6091],\n",
      "        [0.4103],\n",
      "        [0.2347],\n",
      "        [0.2700]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7524]],\n",
      "\n",
      "        [[-0.0252]],\n",
      "\n",
      "        [[-0.3961]],\n",
      "\n",
      "        [[ 0.4462]]], dtype=torch.float64)\n",
      "tensor([[0.9460],\n",
      "        [0.9949],\n",
      "        [0.8721],\n",
      "        [0.6593]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6201]],\n",
      "\n",
      "        [[1.7241]],\n",
      "\n",
      "        [[1.3000]],\n",
      "\n",
      "        [[0.4219]]], dtype=torch.float64)\n",
      "tensor([[0.4755],\n",
      "        [0.8552],\n",
      "        [1.0337],\n",
      "        [0.8784]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2763]],\n",
      "\n",
      "        [[1.1718]],\n",
      "\n",
      "        [[1.4086]],\n",
      "\n",
      "        [[1.3151]]], dtype=torch.float64)\n",
      "tensor([[0.6238],\n",
      "        [0.5566],\n",
      "        [0.4981],\n",
      "        [0.4437]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8298]],\n",
      "\n",
      "        [[0.3838]],\n",
      "\n",
      "        [[0.1516]],\n",
      "\n",
      "        [[0.3260]]], dtype=torch.float64)\n",
      "tensor([[0.4050],\n",
      "        [0.3632],\n",
      "        [0.3405],\n",
      "        [0.3673]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5005]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[0.4508]],\n",
      "\n",
      "        [[0.0846]]], dtype=torch.float64)\n",
      "tensor([[0.3439],\n",
      "        [0.2657],\n",
      "        [0.2772],\n",
      "        [0.2059]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0957]],\n",
      "\n",
      "        [[ 0.0684]],\n",
      "\n",
      "        [[ 0.3434]],\n",
      "\n",
      "        [[ 0.1920]]], dtype=torch.float64)\n",
      "tensor([[0.1286],\n",
      "        [0.2561],\n",
      "        [0.3490],\n",
      "        [0.3364]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1308]],\n",
      "\n",
      "        [[0.0938]],\n",
      "\n",
      "        [[0.0222]],\n",
      "\n",
      "        [[0.2498]]], dtype=torch.float64)\n",
      "tensor([[0.4035],\n",
      "        [0.2393],\n",
      "        [0.0369],\n",
      "        [0.1170]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5629]],\n",
      "\n",
      "        [[ 0.3618]],\n",
      "\n",
      "        [[-0.0841]],\n",
      "\n",
      "        [[-0.1581]]], dtype=torch.float64)\n",
      "tensor([[ 0.2088],\n",
      "        [ 0.2601],\n",
      "        [ 0.0403],\n",
      "        [-0.1847]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1315]],\n",
      "\n",
      "        [[-0.1176]],\n",
      "\n",
      "        [[-0.1442]],\n",
      "\n",
      "        [[-0.1685]]], dtype=torch.float64)\n",
      "tensor([[-0.2188],\n",
      "        [-0.2344],\n",
      "        [-0.5090],\n",
      "        [-0.4985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1904]],\n",
      "\n",
      "        [[-0.4781]],\n",
      "\n",
      "        [[-0.8259]],\n",
      "\n",
      "        [[-0.5694]]], dtype=torch.float64)\n",
      "tensor([[-0.2144],\n",
      "        [-0.0481],\n",
      "        [-0.2146],\n",
      "        [-0.1342]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1454]],\n",
      "\n",
      "        [[ 0.1215]],\n",
      "\n",
      "        [[-0.0079]],\n",
      "\n",
      "        [[-0.3672]]], dtype=torch.float64)\n",
      "tensor([[-0.2677],\n",
      "        [-0.1531],\n",
      "        [-0.1896],\n",
      "        [-0.2793]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5243]],\n",
      "\n",
      "        [[-0.4100]],\n",
      "\n",
      "        [[-0.4007]],\n",
      "\n",
      "        [[-0.4238]]], dtype=torch.float64)\n",
      "tensor([[-0.3175],\n",
      "        [-0.2269],\n",
      "        [-0.0673],\n",
      "        [ 0.0529]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4400]],\n",
      "\n",
      "        [[-0.4562]],\n",
      "\n",
      "        [[-0.4273]],\n",
      "\n",
      "        [[-0.3141]]], dtype=torch.float64)\n",
      "tensor([[ 0.1133],\n",
      "        [ 0.0166],\n",
      "        [-0.1240],\n",
      "        [-0.1895]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1500]],\n",
      "\n",
      "        [[-0.1338]],\n",
      "\n",
      "        [[-0.2609]],\n",
      "\n",
      "        [[-0.4365]]], dtype=torch.float64)\n",
      "tensor([[-0.1114],\n",
      "        [ 0.1047],\n",
      "        [ 0.2030],\n",
      "        [ 0.1435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4596]],\n",
      "\n",
      "        [[ 0.1192]],\n",
      "\n",
      "        [[ 0.3711]],\n",
      "\n",
      "        [[ 0.5225]]], dtype=torch.float64)\n",
      "tensor([[ 0.1886],\n",
      "        [ 0.2504],\n",
      "        [-0.0359],\n",
      "        [ 0.0068]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1908]],\n",
      "\n",
      "        [[-0.1916]],\n",
      "\n",
      "        [[-0.5833]],\n",
      "\n",
      "        [[ 0.1932]]], dtype=torch.float64)\n",
      "tensor([[0.6459],\n",
      "        [0.3442],\n",
      "        [0.1646],\n",
      "        [0.2448]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7593]],\n",
      "\n",
      "        [[ 0.1331]],\n",
      "\n",
      "        [[ 0.0903]],\n",
      "\n",
      "        [[-0.0264]]], dtype=torch.float64)\n",
      "tensor([[ 0.2948],\n",
      "        [ 0.2499],\n",
      "        [ 0.0010],\n",
      "        [-0.0929]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0899]],\n",
      "\n",
      "        [[-0.0714]],\n",
      "\n",
      "        [[-0.1812]],\n",
      "\n",
      "        [[ 0.0141]]], dtype=torch.float64)\n",
      "tensor([[-0.1193],\n",
      "        [-0.0251],\n",
      "        [ 0.0646],\n",
      "        [ 0.1497]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1026]],\n",
      "\n",
      "        [[-0.1997]],\n",
      "\n",
      "        [[-0.2667]],\n",
      "\n",
      "        [[-0.1488]]], dtype=torch.float64)\n",
      "tensor([[ 0.1457],\n",
      "        [ 0.0637],\n",
      "        [-0.0437],\n",
      "        [ 0.0811]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1493]],\n",
      "\n",
      "        [[ 0.1516]],\n",
      "\n",
      "        [[-0.0391]],\n",
      "\n",
      "        [[-0.0541]]], dtype=torch.float64)\n",
      "tensor([[0.2072],\n",
      "        [0.2682],\n",
      "        [0.4092],\n",
      "        [0.3058]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1315]],\n",
      "\n",
      "        [[ 0.1966]],\n",
      "\n",
      "        [[ 0.4508]],\n",
      "\n",
      "        [[ 0.5340]]], dtype=torch.float64)\n",
      "tensor([[ 0.2330],\n",
      "        [-0.0207],\n",
      "        [ 0.0281],\n",
      "        [ 0.0876]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1377]],\n",
      "\n",
      "        [[-0.1951]],\n",
      "\n",
      "        [[-0.2933]],\n",
      "\n",
      "        [[-0.2055]]], dtype=torch.float64)\n",
      "tensor([[ 0.0016],\n",
      "        [-0.0872],\n",
      "        [-0.2413],\n",
      "        [-0.1660]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1176]],\n",
      "\n",
      "        [[-0.1165]],\n",
      "\n",
      "        [[-0.1777]],\n",
      "\n",
      "        [[-0.2852]]], dtype=torch.float64)\n",
      "tensor([[-0.0573],\n",
      "        [-0.0376],\n",
      "        [-0.0869],\n",
      "        [-0.1406]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3499]],\n",
      "\n",
      "        [[-0.2840]],\n",
      "\n",
      "        [[-0.0957]],\n",
      "\n",
      "        [[-0.2193]]], dtype=torch.float64)\n",
      "tensor([[-0.2505],\n",
      "        [-0.1731],\n",
      "        [-0.1248],\n",
      "        [-0.0912]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3326]],\n",
      "\n",
      "        [[-0.4169]],\n",
      "\n",
      "        [[-0.4851]],\n",
      "\n",
      "        [[-0.4053]]], dtype=torch.float64)\n",
      "tensor([[-0.2377],\n",
      "        [-0.3007],\n",
      "        [-0.2929],\n",
      "        [-0.2359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4342]],\n",
      "\n",
      "        [[-0.2782]],\n",
      "\n",
      "        [[-0.4088]],\n",
      "\n",
      "        [[-0.4088]]], dtype=torch.float64)\n",
      "tensor([[-0.1115],\n",
      "        [ 0.0254],\n",
      "        [ 0.0669],\n",
      "        [ 0.1263]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3464]],\n",
      "\n",
      "        [[-0.0541]],\n",
      "\n",
      "        [[ 0.3734]],\n",
      "\n",
      "        [[ 0.4543]]], dtype=torch.float64)\n",
      "tensor([[ 0.1694],\n",
      "        [ 0.0856],\n",
      "        [-0.2035],\n",
      "        [ 0.1597]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1677]],\n",
      "\n",
      "        [[-0.3406]],\n",
      "\n",
      "        [[-0.6838]],\n",
      "\n",
      "        [[ 0.3653]]], dtype=torch.float64)\n",
      "tensor([[0.3571],\n",
      "        [0.3067],\n",
      "        [0.2784],\n",
      "        [0.2345]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6507]],\n",
      "\n",
      "        [[ 0.5687]],\n",
      "\n",
      "        [[ 0.2602]],\n",
      "\n",
      "        [[-0.0102]]], dtype=torch.float64)\n",
      "tensor([[ 0.3041],\n",
      "        [ 0.1387],\n",
      "        [ 0.0010],\n",
      "        [-0.0169]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1581]],\n",
      "\n",
      "        [[-0.1708]],\n",
      "\n",
      "        [[ 0.2001]],\n",
      "\n",
      "        [[ 0.2417]]], dtype=torch.float64)\n",
      "tensor([[ 0.0218],\n",
      "        [ 0.0831],\n",
      "        [ 0.0053],\n",
      "        [-0.0952]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0268]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[-0.3938]],\n",
      "\n",
      "        [[-0.4157]]], dtype=torch.float64)\n",
      "tensor([[-0.0572],\n",
      "        [-0.1248],\n",
      "        [-0.0234],\n",
      "        [ 0.1550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1800]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.0518]],\n",
      "\n",
      "        [[ 0.0326]]], dtype=torch.float64)\n",
      "tensor([[0.3816],\n",
      "        [0.2153],\n",
      "        [0.2200],\n",
      "        [0.1210]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0460]],\n",
      "\n",
      "        [[-0.0009]],\n",
      "\n",
      "        [[ 0.1781]],\n",
      "\n",
      "        [[ 0.1770]]], dtype=torch.float64)\n",
      "tensor([[0.0835],\n",
      "        [0.1961],\n",
      "        [0.3813],\n",
      "        [0.3585]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0302]],\n",
      "\n",
      "        [[ 0.0164]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[ 0.1331]]], dtype=torch.float64)\n",
      "tensor([[0.4473],\n",
      "        [0.5212],\n",
      "        [0.7378],\n",
      "        [0.3623]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8229]],\n",
      "\n",
      "        [[1.1198]],\n",
      "\n",
      "        [[0.7813]],\n",
      "\n",
      "        [[0.0614]]], dtype=torch.float64)\n",
      "tensor([[0.2342],\n",
      "        [0.2802],\n",
      "        [0.7513],\n",
      "        [0.6790]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2343]],\n",
      "\n",
      "        [[ 0.5560]],\n",
      "\n",
      "        [[ 1.1094]],\n",
      "\n",
      "        [[ 1.2307]]], dtype=torch.float64)\n",
      "tensor([[0.4460],\n",
      "        [0.3904],\n",
      "        [0.5771],\n",
      "        [0.6848]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4011]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.3607]],\n",
      "\n",
      "        [[0.7212]]], dtype=torch.float64)\n",
      "tensor([[0.7866],\n",
      "        [0.9317],\n",
      "        [0.8314],\n",
      "        [0.6428]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1810]],\n",
      "\n",
      "        [[1.5207]],\n",
      "\n",
      "        [[0.9511]],\n",
      "\n",
      "        [[0.6010]]], dtype=torch.float64)\n",
      "tensor([[0.5559],\n",
      "        [0.7330],\n",
      "        [0.9503],\n",
      "        [0.7097]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2775]],\n",
      "\n",
      "        [[1.0759]],\n",
      "\n",
      "        [[1.4329]],\n",
      "\n",
      "        [[1.3983]]], dtype=torch.float64)\n",
      "tensor([[0.6449],\n",
      "        [0.6038],\n",
      "        [0.4597],\n",
      "        [0.4060]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9280]],\n",
      "\n",
      "        [[0.3145]],\n",
      "\n",
      "        [[0.1932]],\n",
      "\n",
      "        [[0.4797]]], dtype=torch.float64)\n",
      "tensor([[0.5313],\n",
      "        [0.5612],\n",
      "        [0.4612],\n",
      "        [0.2995]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8991]],\n",
      "\n",
      "        [[1.0863]],\n",
      "\n",
      "        [[0.4785]],\n",
      "\n",
      "        [[0.1493]]], dtype=torch.float64)\n",
      "tensor([[0.2161],\n",
      "        [0.0135],\n",
      "        [0.2908],\n",
      "        [0.2426]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0968]],\n",
      "\n",
      "        [[-0.0888]],\n",
      "\n",
      "        [[ 0.5432]],\n",
      "\n",
      "        [[ 0.3572]]], dtype=torch.float64)\n",
      "tensor([[0.1926],\n",
      "        [0.2890],\n",
      "        [0.3979],\n",
      "        [0.3629]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2971]],\n",
      "\n",
      "        [[0.1758]],\n",
      "\n",
      "        [[0.2140]],\n",
      "\n",
      "        [[0.0418]]], dtype=torch.float64)\n",
      "tensor([[0.1681],\n",
      "        [0.3244],\n",
      "        [0.3934],\n",
      "        [0.3367]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2186]],\n",
      "\n",
      "        [[0.6796]],\n",
      "\n",
      "        [[0.4312]],\n",
      "\n",
      "        [[0.1562]]], dtype=torch.float64)\n",
      "tensor([[0.4251],\n",
      "        [0.4892],\n",
      "        [0.4905],\n",
      "        [0.4407]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1469]],\n",
      "\n",
      "        [[0.4705]],\n",
      "\n",
      "        [[0.6519]],\n",
      "\n",
      "        [[0.7894]]], dtype=torch.float64)\n",
      "tensor([[0.4563],\n",
      "        [0.3281],\n",
      "        [0.1778],\n",
      "        [0.1799]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5583]],\n",
      "\n",
      "        [[-0.0171]],\n",
      "\n",
      "        [[-0.3014]],\n",
      "\n",
      "        [[ 0.2567]]], dtype=torch.float64)\n",
      "tensor([[0.7240],\n",
      "        [0.7417],\n",
      "        [0.7328],\n",
      "        [0.5908]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0378]],\n",
      "\n",
      "        [[1.2203]],\n",
      "\n",
      "        [[0.8286]],\n",
      "\n",
      "        [[0.3815]]], dtype=torch.float64)\n",
      "tensor([[0.5786],\n",
      "        [0.5360],\n",
      "        [0.5993],\n",
      "        [0.6067]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2821]],\n",
      "\n",
      "        [[0.3642]],\n",
      "\n",
      "        [[0.8148]],\n",
      "\n",
      "        [[0.7859]]], dtype=torch.float64)\n",
      "tensor([[ 0.3954],\n",
      "        [ 0.2097],\n",
      "        [-0.0299],\n",
      "        [-0.0274]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4208]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[-0.2956]],\n",
      "\n",
      "        [[-0.0518]]], dtype=torch.float64)\n",
      "tensor([[0.1068],\n",
      "        [0.1230],\n",
      "        [0.0490],\n",
      "        [0.1009]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3584]],\n",
      "\n",
      "        [[ 0.1527]],\n",
      "\n",
      "        [[ 0.1077]],\n",
      "\n",
      "        [[-0.0691]]], dtype=torch.float64)\n",
      "tensor([[0.1593],\n",
      "        [0.1971],\n",
      "        [0.1417],\n",
      "        [0.0737]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0229]],\n",
      "\n",
      "        [[ 0.0765]],\n",
      "\n",
      "        [[ 0.1019]],\n",
      "\n",
      "        [[ 0.0822]]], dtype=torch.float64)\n",
      "tensor([[0.0812],\n",
      "        [0.2541],\n",
      "        [0.2267],\n",
      "        [0.1708]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0984]],\n",
      "\n",
      "        [[-0.0564]],\n",
      "\n",
      "        [[-0.0703]],\n",
      "\n",
      "        [[ 0.0222]]], dtype=torch.float64)\n",
      "tensor([[0.1814],\n",
      "        [0.1399],\n",
      "        [0.3608],\n",
      "        [0.4704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1273]],\n",
      "\n",
      "        [[0.4474]],\n",
      "\n",
      "        [[0.5028]],\n",
      "\n",
      "        [[0.4531]]], dtype=torch.float64)\n",
      "tensor([[0.6266],\n",
      "        [0.5207],\n",
      "        [0.6194],\n",
      "        [0.6709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3642]],\n",
      "\n",
      "        [[0.4081]],\n",
      "\n",
      "        [[1.0193]],\n",
      "\n",
      "        [[1.3081]]], dtype=torch.float64)\n",
      "tensor([[0.7865],\n",
      "        [0.6102],\n",
      "        [0.4439],\n",
      "        [0.6329]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8772]],\n",
      "\n",
      "        [[ 0.3133]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[ 0.7235]]], dtype=torch.float64)\n",
      "tensor([[0.7696],\n",
      "        [0.9263],\n",
      "        [0.8834],\n",
      "        [0.6278]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0597]],\n",
      "\n",
      "        [[1.4283]],\n",
      "\n",
      "        [[0.9303]],\n",
      "\n",
      "        [[0.2914]]], dtype=torch.float64)\n",
      "tensor([[0.4478],\n",
      "        [0.6391],\n",
      "        [1.2012],\n",
      "        [1.2396]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1130]],\n",
      "\n",
      "        [[ 0.8887]],\n",
      "\n",
      "        [[ 1.6085]],\n",
      "\n",
      "        [[ 1.8489]]], dtype=torch.float64)\n",
      "tensor([[1.2380],\n",
      "        [0.9749],\n",
      "        [0.7438],\n",
      "        [0.8806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3786]],\n",
      "\n",
      "        [[0.6854]],\n",
      "\n",
      "        [[0.3041]],\n",
      "\n",
      "        [[1.2966]]], dtype=torch.float64)\n",
      "tensor([[1.5628],\n",
      "        [1.5600],\n",
      "        [1.3584],\n",
      "        [1.1169]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0418]],\n",
      "\n",
      "        [[2.2024]],\n",
      "\n",
      "        [[1.6074]],\n",
      "\n",
      "        [[1.0216]]], dtype=torch.float64)\n",
      "tensor([[1.1022],\n",
      "        [1.0966],\n",
      "        [1.0490],\n",
      "        [0.8040]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8587]],\n",
      "\n",
      "        [[1.2457]],\n",
      "\n",
      "        [[1.1995]],\n",
      "\n",
      "        [[1.2873]]], dtype=torch.float64)\n",
      "tensor([[0.9257],\n",
      "        [0.7182],\n",
      "        [0.5787],\n",
      "        [0.6976]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0528]],\n",
      "\n",
      "        [[0.5317]],\n",
      "\n",
      "        [[0.1377]],\n",
      "\n",
      "        [[0.8760]]], dtype=torch.float64)\n",
      "tensor([[1.2367],\n",
      "        [1.4087],\n",
      "        [1.2861],\n",
      "        [1.1662]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7437]],\n",
      "\n",
      "        [[1.8962]],\n",
      "\n",
      "        [[1.4780]],\n",
      "\n",
      "        [[1.0147]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13125:  28%|██▊       | 858/3067 [00:02<00:06, 349.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1654],\n",
      "        [1.2334],\n",
      "        [1.6427],\n",
      "        [1.7642]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8402]],\n",
      "\n",
      "        [[1.5357]],\n",
      "\n",
      "        [[2.0118]],\n",
      "\n",
      "        [[2.2972]]], dtype=torch.float64)\n",
      "tensor([[1.6576],\n",
      "        [1.4611],\n",
      "        [1.4406],\n",
      "        [1.4772]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8200]],\n",
      "\n",
      "        [[1.2688]],\n",
      "\n",
      "        [[1.1568]],\n",
      "\n",
      "        [[1.3370]]], dtype=torch.float64)\n",
      "tensor([[1.7099],\n",
      "        [1.8165],\n",
      "        [1.7864],\n",
      "        [1.5749]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0753]],\n",
      "\n",
      "        [[2.2452]],\n",
      "\n",
      "        [[1.8304]],\n",
      "\n",
      "        [[1.2492]]], dtype=torch.float64)\n",
      "tensor([[1.4545],\n",
      "        [1.6151],\n",
      "        [1.6121],\n",
      "        [1.2793]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1475]],\n",
      "\n",
      "        [[1.5854]],\n",
      "\n",
      "        [[1.7391]],\n",
      "\n",
      "        [[1.7714]]], dtype=torch.float64)\n",
      "tensor([[1.4323],\n",
      "        [1.2044],\n",
      "        [1.3052],\n",
      "        [1.1628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3740]],\n",
      "\n",
      "        [[1.0978]],\n",
      "\n",
      "        [[0.9476]],\n",
      "\n",
      "        [[0.9014]]], dtype=torch.float64)\n",
      "tensor([[1.0401],\n",
      "        [1.0212],\n",
      "        [0.3568],\n",
      "        [0.5475]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0123]],\n",
      "\n",
      "        [[1.3393]],\n",
      "\n",
      "        [[0.4531]],\n",
      "\n",
      "        [[0.2983]]], dtype=torch.float64)\n",
      "tensor([[0.5839],\n",
      "        [0.6634],\n",
      "        [0.5472],\n",
      "        [0.6123]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1504]],\n",
      "\n",
      "        [[0.5421]],\n",
      "\n",
      "        [[0.7974]],\n",
      "\n",
      "        [[0.9384]]], dtype=torch.float64)\n",
      "tensor([[0.6022],\n",
      "        [0.5173],\n",
      "        [0.5583],\n",
      "        [0.6235]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5432]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.1770]],\n",
      "\n",
      "        [[0.4323]]], dtype=torch.float64)\n",
      "tensor([[0.6628],\n",
      "        [0.6649],\n",
      "        [0.6831],\n",
      "        [0.7911]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7015]],\n",
      "\n",
      "        [[0.7917]],\n",
      "\n",
      "        [[0.6819]],\n",
      "\n",
      "        [[0.4312]]], dtype=torch.float64)\n",
      "tensor([[0.7853],\n",
      "        [0.8116],\n",
      "        [0.7938],\n",
      "        [0.7720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2532]],\n",
      "\n",
      "        [[0.5386]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[1.0713]]], dtype=torch.float64)\n",
      "tensor([[0.5677],\n",
      "        [0.4998],\n",
      "        [0.5208],\n",
      "        [0.4844]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6449]],\n",
      "\n",
      "        [[ 0.2729]],\n",
      "\n",
      "        [[-0.0252]],\n",
      "\n",
      "        [[ 0.3919]]], dtype=torch.float64)\n",
      "tensor([[0.4582],\n",
      "        [0.6561],\n",
      "        [0.6908],\n",
      "        [0.6476]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7870]],\n",
      "\n",
      "        [[1.1048]],\n",
      "\n",
      "        [[0.9419]],\n",
      "\n",
      "        [[0.5629]]], dtype=torch.float64)\n",
      "tensor([[0.6290],\n",
      "        [0.6346],\n",
      "        [0.8915],\n",
      "        [0.8650]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1781]],\n",
      "\n",
      "        [[0.6784]],\n",
      "\n",
      "        [[1.1348]],\n",
      "\n",
      "        [[1.3636]]], dtype=torch.float64)\n",
      "tensor([[0.9569],\n",
      "        [0.8713],\n",
      "        [0.7681],\n",
      "        [0.9141]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1071]],\n",
      "\n",
      "        [[0.7339]],\n",
      "\n",
      "        [[0.3006]],\n",
      "\n",
      "        [[0.8055]]], dtype=torch.float64)\n",
      "tensor([[1.0286],\n",
      "        [1.0845],\n",
      "        [0.7060],\n",
      "        [0.5577]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3139]],\n",
      "\n",
      "        [[1.1833]],\n",
      "\n",
      "        [[0.5860]],\n",
      "\n",
      "        [[0.2047]]], dtype=torch.float64)\n",
      "tensor([[0.4198],\n",
      "        [0.3866],\n",
      "        [0.4394],\n",
      "        [0.3835]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0356]],\n",
      "\n",
      "        [[ 0.1793]],\n",
      "\n",
      "        [[ 0.3642]],\n",
      "\n",
      "        [[ 0.6877]]], dtype=torch.float64)\n",
      "tensor([[0.3937],\n",
      "        [0.3193],\n",
      "        [0.3026],\n",
      "        [0.4745]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3595]],\n",
      "\n",
      "        [[ 0.0060]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[ 0.4069]]], dtype=torch.float64)\n",
      "tensor([[0.4464],\n",
      "        [0.3677],\n",
      "        [0.5807],\n",
      "        [0.4617]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5583]],\n",
      "\n",
      "        [[0.6103]],\n",
      "\n",
      "        [[0.4069]],\n",
      "\n",
      "        [[0.1493]]], dtype=torch.float64)\n",
      "tensor([[0.4074],\n",
      "        [0.3971],\n",
      "        [0.4972],\n",
      "        [0.4299]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0992]],\n",
      "\n",
      "        [[ 0.1285]],\n",
      "\n",
      "        [[ 0.5825]],\n",
      "\n",
      "        [[ 0.6784]]], dtype=torch.float64)\n",
      "tensor([[0.3799],\n",
      "        [0.4137],\n",
      "        [0.1724],\n",
      "        [0.5205]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4439]],\n",
      "\n",
      "        [[-0.0945]],\n",
      "\n",
      "        [[-0.4492]],\n",
      "\n",
      "        [[ 0.6461]]], dtype=torch.float64)\n",
      "tensor([[0.8348],\n",
      "        [0.7381],\n",
      "        [0.7908],\n",
      "        [0.7052]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9696]],\n",
      "\n",
      "        [[1.0239]],\n",
      "\n",
      "        [[0.7004]],\n",
      "\n",
      "        [[0.2093]]], dtype=torch.float64)\n",
      "tensor([[0.4681],\n",
      "        [0.6874],\n",
      "        [1.0696],\n",
      "        [1.0443]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2228]],\n",
      "\n",
      "        [[ 0.8356]],\n",
      "\n",
      "        [[ 1.2561]],\n",
      "\n",
      "        [[ 1.2873]]], dtype=torch.float64)\n",
      "tensor([[0.8837],\n",
      "        [0.9234],\n",
      "        [0.8446],\n",
      "        [1.0744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9962]],\n",
      "\n",
      "        [[0.6519]],\n",
      "\n",
      "        [[0.3203]],\n",
      "\n",
      "        [[1.2376]]], dtype=torch.float64)\n",
      "tensor([[1.1827],\n",
      "        [1.1287],\n",
      "        [1.3686],\n",
      "        [1.1005]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4653]],\n",
      "\n",
      "        [[1.7495]],\n",
      "\n",
      "        [[1.3613]],\n",
      "\n",
      "        [[0.6449]]], dtype=torch.float64)\n",
      "tensor([[0.7958],\n",
      "        [0.8814],\n",
      "        [1.5060],\n",
      "        [1.1416]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3549]],\n",
      "\n",
      "        [[1.1660]],\n",
      "\n",
      "        [[1.8142]],\n",
      "\n",
      "        [[1.6039]]], dtype=torch.float64)\n",
      "tensor([[1.1914],\n",
      "        [1.1230],\n",
      "        [1.0144],\n",
      "        [1.0158]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2515]],\n",
      "\n",
      "        [[0.8933]],\n",
      "\n",
      "        [[0.6750]],\n",
      "\n",
      "        [[0.9811]]], dtype=torch.float64)\n",
      "tensor([[1.0541],\n",
      "        [1.0895],\n",
      "        [0.9446],\n",
      "        [0.8951]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4029]],\n",
      "\n",
      "        [[1.5461]],\n",
      "\n",
      "        [[1.1175]],\n",
      "\n",
      "        [[0.5040]]], dtype=torch.float64)\n",
      "tensor([[0.6777],\n",
      "        [0.9370],\n",
      "        [1.2611],\n",
      "        [1.2766]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0915]],\n",
      "\n",
      "        [[1.1568]],\n",
      "\n",
      "        [[1.5797]],\n",
      "\n",
      "        [[1.7738]]], dtype=torch.float64)\n",
      "tensor([[1.2221],\n",
      "        [1.0429],\n",
      "        [0.7702],\n",
      "        [1.0656]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4029]],\n",
      "\n",
      "        [[0.6068]],\n",
      "\n",
      "        [[0.1920]],\n",
      "\n",
      "        [[1.5727]]], dtype=torch.float64)\n",
      "tensor([[1.4814],\n",
      "        [1.4382],\n",
      "        [1.4266],\n",
      "        [1.2046]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8962]],\n",
      "\n",
      "        [[2.0025]],\n",
      "\n",
      "        [[1.6709]],\n",
      "\n",
      "        [[0.8298]]], dtype=torch.float64)\n",
      "tensor([[0.9373],\n",
      "        [1.1855],\n",
      "        [1.6437],\n",
      "        [1.6424]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4601]],\n",
      "\n",
      "        [[1.5092]],\n",
      "\n",
      "        [[2.1389]],\n",
      "\n",
      "        [[2.2625]]], dtype=torch.float64)\n",
      "tensor([[1.6865],\n",
      "        [1.3860],\n",
      "        [1.3589],\n",
      "        [1.4522]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8315]],\n",
      "\n",
      "        [[1.1776]],\n",
      "\n",
      "        [[0.9407]],\n",
      "\n",
      "        [[1.3555]]], dtype=torch.float64)\n",
      "tensor([[1.5561],\n",
      "        [1.5141],\n",
      "        [1.5072],\n",
      "        [1.3664]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8130]],\n",
      "\n",
      "        [[2.1019]],\n",
      "\n",
      "        [[1.5900]],\n",
      "\n",
      "        [[1.0066]]], dtype=torch.float64)\n",
      "tensor([[1.2393],\n",
      "        [1.3231],\n",
      "        [1.7732],\n",
      "        [1.7093]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6657]],\n",
      "\n",
      "        [[1.4294]],\n",
      "\n",
      "        [[2.1481]],\n",
      "\n",
      "        [[2.1666]]], dtype=torch.float64)\n",
      "tensor([[1.6042],\n",
      "        [1.5186],\n",
      "        [1.2506],\n",
      "        [1.3336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6940]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[1.4294]]], dtype=torch.float64)\n",
      "tensor([[1.7789],\n",
      "        [1.7108],\n",
      "        [1.5978],\n",
      "        [1.5155]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1481]],\n",
      "\n",
      "        [[2.1666]],\n",
      "\n",
      "        [[1.6940]],\n",
      "\n",
      "        [[1.2065]]], dtype=torch.float64)\n",
      "tensor([[1.3845],\n",
      "        [1.4668],\n",
      "        [2.0696],\n",
      "        [1.8882]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7836]],\n",
      "\n",
      "        [[1.5935]],\n",
      "\n",
      "        [[2.3468]],\n",
      "\n",
      "        [[2.4393]]], dtype=torch.float64)\n",
      "tensor([[1.9051],\n",
      "        [1.6868],\n",
      "        [1.5764],\n",
      "        [1.6673]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0164]],\n",
      "\n",
      "        [[1.4514]],\n",
      "\n",
      "        [[1.0227]],\n",
      "\n",
      "        [[1.9251]]], dtype=torch.float64)\n",
      "tensor([[2.1798],\n",
      "        [1.9420],\n",
      "        [1.9387],\n",
      "        [1.6937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.4404]],\n",
      "\n",
      "        [[2.5306]],\n",
      "\n",
      "        [[2.1158]],\n",
      "\n",
      "        [[1.3243]]], dtype=torch.float64)\n",
      "tensor([[1.4899],\n",
      "        [1.5855],\n",
      "        [1.6003],\n",
      "        [1.7208]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0008]],\n",
      "\n",
      "        [[1.7599]],\n",
      "\n",
      "        [[1.7495]],\n",
      "\n",
      "        [[2.0072]]], dtype=torch.float64)\n",
      "tensor([[1.6604],\n",
      "        [1.4012],\n",
      "        [1.4875],\n",
      "        [1.5479]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2596]],\n",
      "\n",
      "        [[0.9996]],\n",
      "\n",
      "        [[0.8922]],\n",
      "\n",
      "        [[1.5265]]], dtype=torch.float64)\n",
      "tensor([[1.8867],\n",
      "        [1.4411],\n",
      "        [1.3536],\n",
      "        [1.2588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8327]],\n",
      "\n",
      "        [[1.6929]],\n",
      "\n",
      "        [[1.1753]],\n",
      "\n",
      "        [[0.9084]]], dtype=torch.float64)\n",
      "tensor([[1.2867],\n",
      "        [0.9802],\n",
      "        [0.8209],\n",
      "        [0.8839]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7385]],\n",
      "\n",
      "        [[0.5294]],\n",
      "\n",
      "        [[0.8956]],\n",
      "\n",
      "        [[1.1036]]], dtype=torch.float64)\n",
      "tensor([[0.7831],\n",
      "        [0.7478],\n",
      "        [0.6709],\n",
      "        [0.8207]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7686]],\n",
      "\n",
      "        [[0.2613]],\n",
      "\n",
      "        [[0.0025]],\n",
      "\n",
      "        [[0.9361]]], dtype=torch.float64)\n",
      "tensor([[1.0093],\n",
      "        [1.0839],\n",
      "        [1.0824],\n",
      "        [1.0289]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4133]],\n",
      "\n",
      "        [[1.5669]],\n",
      "\n",
      "        [[1.2099]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[0.9395],\n",
      "        [0.9826],\n",
      "        [1.5607],\n",
      "        [1.5699]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3907]],\n",
      "\n",
      "        [[1.1903]],\n",
      "\n",
      "        [[2.0233]],\n",
      "\n",
      "        [[2.2047]]], dtype=torch.float64)\n",
      "tensor([[1.5491],\n",
      "        [1.4401],\n",
      "        [1.1797],\n",
      "        [1.3499]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7911]],\n",
      "\n",
      "        [[1.1198]],\n",
      "\n",
      "        [[0.6126]],\n",
      "\n",
      "        [[1.6189]]], dtype=torch.float64)\n",
      "tensor([[1.9930],\n",
      "        [2.0589],\n",
      "        [1.9867],\n",
      "        [1.5926]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.4855]],\n",
      "\n",
      "        [[2.7455]],\n",
      "\n",
      "        [[2.1724]],\n",
      "\n",
      "        [[1.2307]]], dtype=torch.float64)\n",
      "tensor([[1.4858],\n",
      "        [1.6532],\n",
      "        [2.2168],\n",
      "        [2.1279]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1302]],\n",
      "\n",
      "        [[1.9794]],\n",
      "\n",
      "        [[2.7385]],\n",
      "\n",
      "        [[2.7951]]], dtype=torch.float64)\n",
      "tensor([[2.1433],\n",
      "        [1.9761],\n",
      "        [1.7886],\n",
      "        [1.8038]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3388]],\n",
      "\n",
      "        [[1.6028]],\n",
      "\n",
      "        [[1.2862]],\n",
      "\n",
      "        [[2.1215]]], dtype=torch.float64)\n",
      "tensor([[2.3633],\n",
      "        [2.3554],\n",
      "        [2.0794],\n",
      "        [1.8410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.8148]],\n",
      "\n",
      "        [[2.9303]],\n",
      "\n",
      "        [[2.1238]],\n",
      "\n",
      "        [[1.6536]]], dtype=torch.float64)\n",
      "tensor([[1.9320],\n",
      "        [1.9320],\n",
      "        [2.3887],\n",
      "        [2.1480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3555]],\n",
      "\n",
      "        [[1.9944]],\n",
      "\n",
      "        [[2.6750]],\n",
      "\n",
      "        [[2.7189]]], dtype=torch.float64)\n",
      "tensor([[1.9346],\n",
      "        [1.3616],\n",
      "        [1.4810],\n",
      "        [1.6079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9887]],\n",
      "\n",
      "        [[1.0447]],\n",
      "\n",
      "        [[1.0077]],\n",
      "\n",
      "        [[1.5623]]], dtype=torch.float64)\n",
      "tensor([[1.7259],\n",
      "        [1.6609],\n",
      "        [1.6520],\n",
      "        [1.5777]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7530]],\n",
      "\n",
      "        [[2.1192]],\n",
      "\n",
      "        [[1.7010]],\n",
      "\n",
      "        [[1.2353]]], dtype=torch.float64)\n",
      "tensor([[1.5159],\n",
      "        [1.5501],\n",
      "        [2.0675],\n",
      "        [2.1274]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8437]],\n",
      "\n",
      "        [[1.6883]],\n",
      "\n",
      "        [[2.3341]],\n",
      "\n",
      "        [[2.6634]]], dtype=torch.float64)\n",
      "tensor([[2.2365],\n",
      "        [1.8077],\n",
      "        [1.5901],\n",
      "        [1.6716]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2232]],\n",
      "\n",
      "        [[1.1706]],\n",
      "\n",
      "        [[1.1059]],\n",
      "\n",
      "        [[1.3463]]], dtype=torch.float64)\n",
      "tensor([[1.6711],\n",
      "        [1.6974],\n",
      "        [1.5226],\n",
      "        [1.5224]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7922]],\n",
      "\n",
      "        [[1.8881]],\n",
      "\n",
      "        [[1.6016]],\n",
      "\n",
      "        [[1.0516]]], dtype=torch.float64)\n",
      "tensor([[1.3057],\n",
      "        [1.4726],\n",
      "        [1.9945],\n",
      "        [2.1789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6761]],\n",
      "\n",
      "        [[1.6917]],\n",
      "\n",
      "        [[2.3272]],\n",
      "\n",
      "        [[2.7859]]], dtype=torch.float64)\n",
      "tensor([[2.1708],\n",
      "        [1.8692],\n",
      "        [1.6593],\n",
      "        [1.5050]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2937]],\n",
      "\n",
      "        [[1.4976]],\n",
      "\n",
      "        [[1.1833]],\n",
      "\n",
      "        [[1.3659]]], dtype=torch.float64)\n",
      "tensor([[1.5101],\n",
      "        [1.2062],\n",
      "        [0.9961],\n",
      "        [1.1658]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8743]],\n",
      "\n",
      "        [[0.9650]],\n",
      "\n",
      "        [[0.9234]],\n",
      "\n",
      "        [[0.8899]]], dtype=torch.float64)\n",
      "tensor([[1.2468],\n",
      "        [1.1508],\n",
      "        [0.9737],\n",
      "        [1.0491]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7582]],\n",
      "\n",
      "        [[0.9442]],\n",
      "\n",
      "        [[1.3035]],\n",
      "\n",
      "        [[1.7842]]], dtype=torch.float64)\n",
      "tensor([[0.9911],\n",
      "        [0.8889],\n",
      "        [0.7937],\n",
      "        [0.9026]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2700]],\n",
      "\n",
      "        [[0.5444]],\n",
      "\n",
      "        [[0.1562]],\n",
      "\n",
      "        [[0.8968]]], dtype=torch.float64)\n",
      "tensor([[1.2510],\n",
      "        [1.0125],\n",
      "        [1.0335],\n",
      "        [0.9770]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5854]],\n",
      "\n",
      "        [[1.7391]],\n",
      "\n",
      "        [[1.3821]],\n",
      "\n",
      "        [[0.6553]]], dtype=torch.float64)\n",
      "tensor([[0.8397],\n",
      "        [0.9171],\n",
      "        [1.3756],\n",
      "        [1.1853]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2521]],\n",
      "\n",
      "        [[1.2677]],\n",
      "\n",
      "        [[1.8731]],\n",
      "\n",
      "        [[2.0534]]], dtype=torch.float64)\n",
      "tensor([[1.2616],\n",
      "        [1.3809],\n",
      "        [1.2854],\n",
      "        [1.3394]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6513]],\n",
      "\n",
      "        [[1.1649]],\n",
      "\n",
      "        [[0.6969]],\n",
      "\n",
      "        [[1.5577]]], dtype=torch.float64)\n",
      "tensor([[1.7643],\n",
      "        [1.8728],\n",
      "        [1.8094],\n",
      "        [1.4544]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3942]],\n",
      "\n",
      "        [[2.7166]],\n",
      "\n",
      "        [[2.3711]],\n",
      "\n",
      "        [[1.4179]]], dtype=torch.float64)\n",
      "tensor([[1.4631],\n",
      "        [1.5471],\n",
      "        [1.7199],\n",
      "        [1.6233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4052]],\n",
      "\n",
      "        [[1.4560]],\n",
      "\n",
      "        [[2.1446]],\n",
      "\n",
      "        [[1.4398]]], dtype=torch.float64)\n",
      "tensor([[1.1405],\n",
      "        [1.2950],\n",
      "        [1.4507],\n",
      "        [1.4166]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2122]],\n",
      "\n",
      "        [[1.0794]],\n",
      "\n",
      "        [[0.9615]],\n",
      "\n",
      "        [[1.0990]]], dtype=torch.float64)\n",
      "tensor([[1.2444],\n",
      "        [0.9890],\n",
      "        [0.8194],\n",
      "        [0.9729]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2423]],\n",
      "\n",
      "        [[0.9939]],\n",
      "\n",
      "        [[0.7743]],\n",
      "\n",
      "        [[0.7350]]], dtype=torch.float64)\n",
      "tensor([[1.1126],\n",
      "        [1.0471],\n",
      "        [0.9087],\n",
      "        [0.7371]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7015]],\n",
      "\n",
      "        [[0.7766]],\n",
      "\n",
      "        [[1.1764]],\n",
      "\n",
      "        [[1.1175]]], dtype=torch.float64)\n",
      "tensor([[0.6966],\n",
      "        [0.6754],\n",
      "        [0.5937],\n",
      "        [0.6434]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7304]],\n",
      "\n",
      "        [[0.3896]],\n",
      "\n",
      "        [[0.1319]],\n",
      "\n",
      "        [[0.4439]]], dtype=torch.float64)\n",
      "tensor([[0.7622],\n",
      "        [0.7502],\n",
      "        [0.8153],\n",
      "        [0.7625]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0435]],\n",
      "\n",
      "        [[1.4167]],\n",
      "\n",
      "        [[0.9580]],\n",
      "\n",
      "        [[0.3434]]], dtype=torch.float64)\n",
      "tensor([[0.6703],\n",
      "        [0.6946],\n",
      "        [0.8993],\n",
      "        [1.0823]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2036]],\n",
      "\n",
      "        [[0.3907]],\n",
      "\n",
      "        [[1.2665]],\n",
      "\n",
      "        [[0.8725]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.14109:  29%|██▉       | 894/3067 [00:02<00:06, 342.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7120],\n",
      "        [0.7612],\n",
      "        [0.9304],\n",
      "        [1.0164]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6842]],\n",
      "\n",
      "        [[0.4936]],\n",
      "\n",
      "        [[0.4728]],\n",
      "\n",
      "        [[0.8691]]], dtype=torch.float64)\n",
      "tensor([[1.1301],\n",
      "        [1.1550],\n",
      "        [1.0697],\n",
      "        [1.0003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2908]],\n",
      "\n",
      "        [[1.5149]],\n",
      "\n",
      "        [[1.0216]],\n",
      "\n",
      "        [[0.7200]]], dtype=torch.float64)\n",
      "tensor([[1.0328],\n",
      "        [0.9477],\n",
      "        [1.1700],\n",
      "        [0.9594]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3792]],\n",
      "\n",
      "        [[0.8564]],\n",
      "\n",
      "        [[0.8991]],\n",
      "\n",
      "        [[1.2735]]], dtype=torch.float64)\n",
      "tensor([[0.8129],\n",
      "        [0.9291],\n",
      "        [0.9290],\n",
      "        [0.8751]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7963]],\n",
      "\n",
      "        [[0.6241]],\n",
      "\n",
      "        [[0.4000]],\n",
      "\n",
      "        [[0.7073]]], dtype=torch.float64)\n",
      "tensor([[0.8428],\n",
      "        [0.5603],\n",
      "        [0.6925],\n",
      "        [0.6039]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8818]],\n",
      "\n",
      "        [[1.1094]],\n",
      "\n",
      "        [[0.5398]],\n",
      "\n",
      "        [[0.3722]]], dtype=torch.float64)\n",
      "tensor([[0.7792],\n",
      "        [0.7698],\n",
      "        [0.7745],\n",
      "        [0.8669]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2532]],\n",
      "\n",
      "        [[0.6703]],\n",
      "\n",
      "        [[1.1545]],\n",
      "\n",
      "        [[1.4479]]], dtype=torch.float64)\n",
      "tensor([[0.8849],\n",
      "        [0.7859],\n",
      "        [0.6658],\n",
      "        [0.7159]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8321]],\n",
      "\n",
      "        [[0.3364]],\n",
      "\n",
      "        [[0.0580]],\n",
      "\n",
      "        [[0.8517]]], dtype=torch.float64)\n",
      "tensor([[1.1972],\n",
      "        [1.2317],\n",
      "        [1.1534],\n",
      "        [1.0864]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5993]],\n",
      "\n",
      "        [[1.6536]],\n",
      "\n",
      "        [[1.3324]],\n",
      "\n",
      "        [[0.8390]]], dtype=torch.float64)\n",
      "tensor([[0.9726],\n",
      "        [0.9731],\n",
      "        [1.4182],\n",
      "        [1.5486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4612]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[1.9806]],\n",
      "\n",
      "        [[2.0014]]], dtype=torch.float64)\n",
      "tensor([[1.4810],\n",
      "        [1.2743],\n",
      "        [1.2205],\n",
      "        [1.1286]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7322]],\n",
      "\n",
      "        [[1.1082]],\n",
      "\n",
      "        [[0.8286]],\n",
      "\n",
      "        [[1.1302]]], dtype=torch.float64)\n",
      "tensor([[1.3028],\n",
      "        [1.1799],\n",
      "        [0.8890],\n",
      "        [0.8777]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5253]],\n",
      "\n",
      "        [[1.6721]],\n",
      "\n",
      "        [[0.8205]],\n",
      "\n",
      "        [[0.7628]]], dtype=torch.float64)\n",
      "tensor([[1.0647],\n",
      "        [1.0097],\n",
      "        [0.7948],\n",
      "        [0.6780]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7385]],\n",
      "\n",
      "        [[0.6784]],\n",
      "\n",
      "        [[0.8598]],\n",
      "\n",
      "        [[0.7616]]], dtype=torch.float64)\n",
      "tensor([[0.7242],\n",
      "        [0.6728],\n",
      "        [0.5902],\n",
      "        [0.5143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6507]],\n",
      "\n",
      "        [[0.2867]],\n",
      "\n",
      "        [[0.0360]],\n",
      "\n",
      "        [[0.6207]]], dtype=torch.float64)\n",
      "tensor([[1.0591],\n",
      "        [1.0397],\n",
      "        [1.0485],\n",
      "        [0.7953]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4190]],\n",
      "\n",
      "        [[1.4352]],\n",
      "\n",
      "        [[1.1152]],\n",
      "\n",
      "        [[0.5964]]], dtype=torch.float64)\n",
      "tensor([[0.7867],\n",
      "        [0.6960],\n",
      "        [1.1355],\n",
      "        [0.8663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2694]],\n",
      "\n",
      "        [[0.9095]],\n",
      "\n",
      "        [[1.4167]],\n",
      "\n",
      "        [[1.3012]]], dtype=torch.float64)\n",
      "tensor([[0.5701],\n",
      "        [0.6987],\n",
      "        [0.8843],\n",
      "        [0.7935]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6611]],\n",
      "\n",
      "        [[0.6646]],\n",
      "\n",
      "        [[0.5456]],\n",
      "\n",
      "        [[0.6207]]], dtype=torch.float64)\n",
      "tensor([[0.6179],\n",
      "        [0.3964],\n",
      "        [0.5017],\n",
      "        [0.6624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5687]],\n",
      "\n",
      "        [[0.5606]],\n",
      "\n",
      "        [[0.5606]],\n",
      "\n",
      "        [[0.5687]]], dtype=torch.float64)\n",
      "tensor([[0.9114],\n",
      "        [0.8528],\n",
      "        [0.8692],\n",
      "        [0.9447]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5918]],\n",
      "\n",
      "        [[0.6981]],\n",
      "\n",
      "        [[1.3405]],\n",
      "\n",
      "        [[1.4687]]], dtype=torch.float64)\n",
      "tensor([[1.0114],\n",
      "        [1.0076],\n",
      "        [0.8638],\n",
      "        [0.7415]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1579]],\n",
      "\n",
      "        [[0.6807]],\n",
      "\n",
      "        [[0.3214]],\n",
      "\n",
      "        [[0.8610]]], dtype=torch.float64)\n",
      "tensor([[1.1051],\n",
      "        [1.0614],\n",
      "        [0.9868],\n",
      "        [0.7851]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4237]],\n",
      "\n",
      "        [[1.4595]],\n",
      "\n",
      "        [[0.9465]],\n",
      "\n",
      "        [[0.6334]]], dtype=torch.float64)\n",
      "tensor([[0.8621],\n",
      "        [0.8601],\n",
      "        [0.9348],\n",
      "        [0.9641]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5456]],\n",
      "\n",
      "        [[0.7790]],\n",
      "\n",
      "        [[1.2307]],\n",
      "\n",
      "        [[1.3416]]], dtype=torch.float64)\n",
      "tensor([[0.9264],\n",
      "        [0.8473],\n",
      "        [0.8679],\n",
      "        [0.8005]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0227]],\n",
      "\n",
      "        [[0.6565]],\n",
      "\n",
      "        [[0.3861]],\n",
      "\n",
      "        [[0.9696]]], dtype=torch.float64)\n",
      "tensor([[1.1939],\n",
      "        [1.2197],\n",
      "        [1.0842],\n",
      "        [0.9557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6051]],\n",
      "\n",
      "        [[1.7934]],\n",
      "\n",
      "        [[1.2261]],\n",
      "\n",
      "        [[0.6969]]], dtype=torch.float64)\n",
      "tensor([[0.8387],\n",
      "        [0.7868],\n",
      "        [0.8411],\n",
      "        [1.0131]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3896]],\n",
      "\n",
      "        [[0.7778]],\n",
      "\n",
      "        [[0.9592]],\n",
      "\n",
      "        [[1.5069]]], dtype=torch.float64)\n",
      "tensor([[1.1107],\n",
      "        [0.9768],\n",
      "        [0.8746],\n",
      "        [0.8330]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1776]],\n",
      "\n",
      "        [[0.6981]],\n",
      "\n",
      "        [[0.4705]],\n",
      "\n",
      "        [[0.5791]]], dtype=torch.float64)\n",
      "tensor([[0.7126],\n",
      "        [0.7154],\n",
      "        [0.7564],\n",
      "        [0.8056]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7743]],\n",
      "\n",
      "        [[1.1903]],\n",
      "\n",
      "        [[0.7709]],\n",
      "\n",
      "        [[0.7108]]], dtype=torch.float64)\n",
      "tensor([[0.9565],\n",
      "        [0.9280],\n",
      "        [1.0519],\n",
      "        [0.6264]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6184]],\n",
      "\n",
      "        [[0.7651]],\n",
      "\n",
      "        [[1.2111]],\n",
      "\n",
      "        [[0.9788]]], dtype=torch.float64)\n",
      "tensor([[0.6282],\n",
      "        [0.6357],\n",
      "        [0.8913],\n",
      "        [0.8410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6519]],\n",
      "\n",
      "        [[0.5594]],\n",
      "\n",
      "        [[0.5456]],\n",
      "\n",
      "        [[0.7847]]], dtype=torch.float64)\n",
      "tensor([[0.7712],\n",
      "        [0.7166],\n",
      "        [0.6848],\n",
      "        [0.6578]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9060]],\n",
      "\n",
      "        [[1.1302]],\n",
      "\n",
      "        [[0.8529]],\n",
      "\n",
      "        [[0.5675]]], dtype=torch.float64)\n",
      "tensor([[0.7307],\n",
      "        [0.7259],\n",
      "        [0.5536],\n",
      "        [0.6373]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5571]],\n",
      "\n",
      "        [[0.5375]],\n",
      "\n",
      "        [[0.6796]],\n",
      "\n",
      "        [[0.9800]]], dtype=torch.float64)\n",
      "tensor([[0.7950],\n",
      "        [0.6910],\n",
      "        [0.7445],\n",
      "        [0.6887]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7200]],\n",
      "\n",
      "        [[0.4589]],\n",
      "\n",
      "        [[0.3283]],\n",
      "\n",
      "        [[0.5421]]], dtype=torch.float64)\n",
      "tensor([[0.8527],\n",
      "        [0.8129],\n",
      "        [0.6377],\n",
      "        [0.5978]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0898]],\n",
      "\n",
      "        [[0.9800]],\n",
      "\n",
      "        [[0.6322]],\n",
      "\n",
      "        [[0.5051]]], dtype=torch.float64)\n",
      "tensor([[0.8173],\n",
      "        [0.7355],\n",
      "        [0.7348],\n",
      "        [0.4738]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3734]],\n",
      "\n",
      "        [[0.5305]],\n",
      "\n",
      "        [[0.8229]],\n",
      "\n",
      "        [[0.5664]]], dtype=torch.float64)\n",
      "tensor([[0.3286],\n",
      "        [0.4975],\n",
      "        [0.6932],\n",
      "        [0.8091]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4219]],\n",
      "\n",
      "        [[0.3156]],\n",
      "\n",
      "        [[0.4612]],\n",
      "\n",
      "        [[0.6784]]], dtype=torch.float64)\n",
      "tensor([[0.9349],\n",
      "        [0.8261],\n",
      "        [0.7893],\n",
      "        [0.8321]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8772]],\n",
      "\n",
      "        [[1.0713]],\n",
      "\n",
      "        [[0.8217]],\n",
      "\n",
      "        [[0.6149]]], dtype=torch.float64)\n",
      "tensor([[0.7437],\n",
      "        [0.7485],\n",
      "        [0.7561],\n",
      "        [0.8196]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4150]],\n",
      "\n",
      "        [[0.7015]],\n",
      "\n",
      "        [[1.1290]],\n",
      "\n",
      "        [[1.4098]]], dtype=torch.float64)\n",
      "tensor([[0.7585],\n",
      "        [0.6341],\n",
      "        [0.4972],\n",
      "        [0.5385]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8610]],\n",
      "\n",
      "        [[ 0.2255]],\n",
      "\n",
      "        [[-0.0113]],\n",
      "\n",
      "        [[ 0.7062]]], dtype=torch.float64)\n",
      "tensor([[1.0670],\n",
      "        [1.1354],\n",
      "        [1.1880],\n",
      "        [0.9040]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5485]],\n",
      "\n",
      "        [[1.8766]],\n",
      "\n",
      "        [[1.1660]],\n",
      "\n",
      "        [[0.5594]]], dtype=torch.float64)\n",
      "tensor([[0.8005],\n",
      "        [0.7933],\n",
      "        [1.4741],\n",
      "        [1.5852]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2983]],\n",
      "\n",
      "        [[0.9869]],\n",
      "\n",
      "        [[2.0349]],\n",
      "\n",
      "        [[2.2452]]], dtype=torch.float64)\n",
      "tensor([[1.5046],\n",
      "        [1.2711],\n",
      "        [1.1356],\n",
      "        [1.1468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6270]],\n",
      "\n",
      "        [[0.9661]],\n",
      "\n",
      "        [[0.7316]],\n",
      "\n",
      "        [[1.4190]]], dtype=torch.float64)\n",
      "tensor([[1.6807],\n",
      "        [1.5822],\n",
      "        [1.2056],\n",
      "        [0.8940]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0857]],\n",
      "\n",
      "        [[2.3434]],\n",
      "\n",
      "        [[0.9488]],\n",
      "\n",
      "        [[0.8148]]], dtype=torch.float64)\n",
      "tensor([[0.9783],\n",
      "        [0.9779],\n",
      "        [1.2354],\n",
      "        [1.1810]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6842]],\n",
      "\n",
      "        [[1.1267]],\n",
      "\n",
      "        [[1.2388]],\n",
      "\n",
      "        [[1.5461]]], dtype=torch.float64)\n",
      "tensor([[1.1442],\n",
      "        [0.9956],\n",
      "        [0.9936],\n",
      "        [0.9336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3902]],\n",
      "\n",
      "        [[0.9234]],\n",
      "\n",
      "        [[0.7697]],\n",
      "\n",
      "        [[0.9361]]], dtype=torch.float64)\n",
      "tensor([[0.9587],\n",
      "        [0.9272],\n",
      "        [0.6512],\n",
      "        [0.6098]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3809]],\n",
      "\n",
      "        [[1.3751]],\n",
      "\n",
      "        [[0.6888]],\n",
      "\n",
      "        [[0.4254]]], dtype=torch.float64)\n",
      "tensor([[0.6861],\n",
      "        [0.7208],\n",
      "        [0.8606],\n",
      "        [0.6943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2983]],\n",
      "\n",
      "        [[0.6807]],\n",
      "\n",
      "        [[1.0459]],\n",
      "\n",
      "        [[1.0978]]], dtype=torch.float64)\n",
      "tensor([[0.7132],\n",
      "        [0.6276],\n",
      "        [0.7555],\n",
      "        [0.7694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7085]],\n",
      "\n",
      "        [[0.4034]],\n",
      "\n",
      "        [[0.4762]],\n",
      "\n",
      "        [[0.4924]]], dtype=torch.float64)\n",
      "tensor([[1.0321],\n",
      "        [1.1486],\n",
      "        [0.9796],\n",
      "        [1.0800]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5473]],\n",
      "\n",
      "        [[1.4595]],\n",
      "\n",
      "        [[1.2480]],\n",
      "\n",
      "        [[0.9615]]], dtype=torch.float64)\n",
      "tensor([[1.2143],\n",
      "        [1.2703],\n",
      "        [1.1593],\n",
      "        [1.0370]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9084]],\n",
      "\n",
      "        [[1.2134]],\n",
      "\n",
      "        [[1.3335]],\n",
      "\n",
      "        [[1.4352]]], dtype=torch.float64)\n",
      "tensor([[0.8481],\n",
      "        [0.5053],\n",
      "        [0.5948],\n",
      "        [0.4982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6773]],\n",
      "\n",
      "        [[0.4219]],\n",
      "\n",
      "        [[0.2371]],\n",
      "\n",
      "        [[0.4520]]], dtype=torch.float64)\n",
      "tensor([[0.5172],\n",
      "        [0.4859],\n",
      "        [0.3840],\n",
      "        [0.3676]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7593]],\n",
      "\n",
      "        [[0.9280]],\n",
      "\n",
      "        [[0.2440]],\n",
      "\n",
      "        [[0.0672]]], dtype=torch.float64)\n",
      "tensor([[0.4119],\n",
      "        [0.4205],\n",
      "        [0.4596],\n",
      "        [0.5249]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0125]],\n",
      "\n",
      "        [[ 0.1146]],\n",
      "\n",
      "        [[ 0.5190]],\n",
      "\n",
      "        [[ 0.6530]]], dtype=torch.float64)\n",
      "tensor([[0.3489],\n",
      "        [0.4717],\n",
      "        [0.3211],\n",
      "        [0.0853]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2763]],\n",
      "\n",
      "        [[ 0.0753]],\n",
      "\n",
      "        [[-0.1870]],\n",
      "\n",
      "        [[-0.1847]]], dtype=torch.float64)\n",
      "tensor([[-0.0603],\n",
      "        [ 0.0967],\n",
      "        [ 0.0504],\n",
      "        [ 0.2490]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2012]],\n",
      "\n",
      "        [[ 0.2105]],\n",
      "\n",
      "        [[-0.0148]],\n",
      "\n",
      "        [[ 0.0753]]], dtype=torch.float64)\n",
      "tensor([[0.3988],\n",
      "        [0.3467],\n",
      "        [0.4145],\n",
      "        [0.3578]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1238]],\n",
      "\n",
      "        [[0.1181]],\n",
      "\n",
      "        [[0.5825]],\n",
      "\n",
      "        [[0.8598]]], dtype=torch.float64)\n",
      "tensor([[0.3765],\n",
      "        [0.4169],\n",
      "        [0.4904],\n",
      "        [0.3695]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3249]],\n",
      "\n",
      "        [[0.0695]],\n",
      "\n",
      "        [[0.1446]],\n",
      "\n",
      "        [[0.1562]]], dtype=torch.float64)\n",
      "tensor([[0.3715],\n",
      "        [0.3563],\n",
      "        [0.4471],\n",
      "        [0.4265]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5317]],\n",
      "\n",
      "        [[0.4577]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.1851]]], dtype=torch.float64)\n",
      "tensor([[0.5448],\n",
      "        [0.5210],\n",
      "        [0.5698],\n",
      "        [0.3861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1400]],\n",
      "\n",
      "        [[0.4855]],\n",
      "\n",
      "        [[0.6207]],\n",
      "\n",
      "        [[0.7397]]], dtype=torch.float64)\n",
      "tensor([[0.4421],\n",
      "        [0.5090],\n",
      "        [0.5859],\n",
      "        [0.5694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4254]],\n",
      "\n",
      "        [[0.3341]],\n",
      "\n",
      "        [[0.1146]],\n",
      "\n",
      "        [[0.3515]]], dtype=torch.float64)\n",
      "tensor([[0.6383],\n",
      "        [0.4407],\n",
      "        [0.3228],\n",
      "        [0.4342]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6992]],\n",
      "\n",
      "        [[0.8021]],\n",
      "\n",
      "        [[0.4705]],\n",
      "\n",
      "        [[0.1839]]], dtype=torch.float64)\n",
      "tensor([[0.4978],\n",
      "        [0.3533],\n",
      "        [0.2091],\n",
      "        [0.3557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0372]],\n",
      "\n",
      "        [[0.1250]],\n",
      "\n",
      "        [[0.3538]],\n",
      "\n",
      "        [[0.7709]]], dtype=torch.float64)\n",
      "tensor([[ 0.2165],\n",
      "        [-0.0277],\n",
      "        [-0.1904],\n",
      "        [-0.1950]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1435]],\n",
      "\n",
      "        [[-0.3118]],\n",
      "\n",
      "        [[-0.5267]],\n",
      "\n",
      "        [[-0.3314]]], dtype=torch.float64)\n",
      "tensor([[0.2998],\n",
      "        [0.3688],\n",
      "        [0.1893],\n",
      "        [0.2065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6542]],\n",
      "\n",
      "        [[ 0.6946]],\n",
      "\n",
      "        [[ 0.3110]],\n",
      "\n",
      "        [[-0.1361]]], dtype=torch.float64)\n",
      "tensor([[-0.0237],\n",
      "        [-0.2390],\n",
      "        [ 0.3711],\n",
      "        [ 0.3527]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4885]],\n",
      "\n",
      "        [[-0.4042]],\n",
      "\n",
      "        [[ 0.7501]],\n",
      "\n",
      "        [[ 0.7385]]], dtype=torch.float64)\n",
      "tensor([[0.1916],\n",
      "        [0.3076],\n",
      "        [0.1295],\n",
      "        [0.1206]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.14109:  31%|███▏      | 962/3067 [00:02<00:06, 326.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3769]],\n",
      "\n",
      "        [[ 0.0210]],\n",
      "\n",
      "        [[-0.3568]],\n",
      "\n",
      "        [[ 0.2567]]], dtype=torch.float64)\n",
      "tensor([[0.5579],\n",
      "        [0.4764],\n",
      "        [0.4378],\n",
      "        [0.3682]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8494]],\n",
      "\n",
      "        [[0.8541]],\n",
      "\n",
      "        [[0.5340]],\n",
      "\n",
      "        [[0.3942]]], dtype=torch.float64)\n",
      "tensor([[0.6175],\n",
      "        [0.5013],\n",
      "        [0.7608],\n",
      "        [0.6378]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3087]],\n",
      "\n",
      "        [[0.5467]],\n",
      "\n",
      "        [[0.9049]],\n",
      "\n",
      "        [[0.7593]]], dtype=torch.float64)\n",
      "tensor([[0.3701],\n",
      "        [0.4887],\n",
      "        [0.6666],\n",
      "        [0.6593]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4416]],\n",
      "\n",
      "        [[0.4150]],\n",
      "\n",
      "        [[0.3965]],\n",
      "\n",
      "        [[0.6137]]], dtype=torch.float64)\n",
      "tensor([[0.7463],\n",
      "        [0.4939],\n",
      "        [0.4055],\n",
      "        [0.5176]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8159]],\n",
      "\n",
      "        [[0.7027]],\n",
      "\n",
      "        [[0.4439]],\n",
      "\n",
      "        [[0.4092]]], dtype=torch.float64)\n",
      "tensor([[0.7041],\n",
      "        [0.5611],\n",
      "        [0.6841],\n",
      "        [0.7306]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3260]],\n",
      "\n",
      "        [[0.4266]],\n",
      "\n",
      "        [[1.0227]],\n",
      "\n",
      "        [[1.1071]]], dtype=torch.float64)\n",
      "tensor([[0.5882],\n",
      "        [0.4874],\n",
      "        [0.4125],\n",
      "        [0.2778]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5144]],\n",
      "\n",
      "        [[ 0.1354]],\n",
      "\n",
      "        [[-0.0680]],\n",
      "\n",
      "        [[-0.0264]]], dtype=torch.float64)\n",
      "tensor([[0.7400],\n",
      "        [0.9223],\n",
      "        [0.7335],\n",
      "        [0.5651]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1568]],\n",
      "\n",
      "        [[1.3000]],\n",
      "\n",
      "        [[0.6935]],\n",
      "\n",
      "        [[0.2763]]], dtype=torch.float64)\n",
      "tensor([[0.4886],\n",
      "        [0.3122],\n",
      "        [0.9469],\n",
      "        [1.0129]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0183]],\n",
      "\n",
      "        [[ 0.1527]],\n",
      "\n",
      "        [[ 1.4907]],\n",
      "\n",
      "        [[ 1.2342]]], dtype=torch.float64)\n",
      "tensor([[0.7914],\n",
      "        [0.7641],\n",
      "        [0.8097],\n",
      "        [0.5871]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8529]],\n",
      "\n",
      "        [[0.6311]],\n",
      "\n",
      "        [[0.4323]],\n",
      "\n",
      "        [[0.3838]]], dtype=torch.float64)\n",
      "tensor([[0.4465],\n",
      "        [0.4532],\n",
      "        [0.3513],\n",
      "        [0.4114]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7015]],\n",
      "\n",
      "        [[0.8737]],\n",
      "\n",
      "        [[0.3965]],\n",
      "\n",
      "        [[0.0799]]], dtype=torch.float64)\n",
      "tensor([[0.3817],\n",
      "        [0.3987],\n",
      "        [0.4705],\n",
      "        [0.4540]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0968]],\n",
      "\n",
      "        [[ 0.1851]],\n",
      "\n",
      "        [[ 0.5536]],\n",
      "\n",
      "        [[ 0.7108]]], dtype=torch.float64)\n",
      "tensor([[0.5581],\n",
      "        [0.7801],\n",
      "        [0.9016],\n",
      "        [0.6381]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7686]],\n",
      "\n",
      "        [[0.7385]],\n",
      "\n",
      "        [[0.7304]],\n",
      "\n",
      "        [[0.1585]]], dtype=torch.float64)\n",
      "tensor([[0.4195],\n",
      "        [0.4679],\n",
      "        [0.3243],\n",
      "        [0.4361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8240]],\n",
      "\n",
      "        [[0.7963]],\n",
      "\n",
      "        [[0.3734]],\n",
      "\n",
      "        [[0.2301]]], dtype=torch.float64)\n",
      "tensor([[0.4316],\n",
      "        [0.4320],\n",
      "        [0.4744],\n",
      "        [0.3566]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2151]],\n",
      "\n",
      "        [[0.4508]],\n",
      "\n",
      "        [[0.6484]],\n",
      "\n",
      "        [[0.5895]]], dtype=torch.float64)\n",
      "tensor([[0.2573],\n",
      "        [0.3437],\n",
      "        [0.4064],\n",
      "        [0.3652]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3283]],\n",
      "\n",
      "        [[0.1932]],\n",
      "\n",
      "        [[0.1077]],\n",
      "\n",
      "        [[0.2717]]], dtype=torch.float64)\n",
      "tensor([[0.2311],\n",
      "        [0.1382],\n",
      "        [0.0889],\n",
      "        [0.1647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4358]],\n",
      "\n",
      "        [[ 0.4959]],\n",
      "\n",
      "        [[ 0.1030]],\n",
      "\n",
      "        [[-0.0726]]], dtype=torch.float64)\n",
      "tensor([[ 0.0748],\n",
      "        [-0.0852],\n",
      "        [ 0.0636],\n",
      "        [ 0.0442]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3892]],\n",
      "\n",
      "        [[ 0.0302]],\n",
      "\n",
      "        [[ 0.2810]],\n",
      "\n",
      "        [[ 0.3907]]], dtype=torch.float64)\n",
      "tensor([[ 0.0230],\n",
      "        [-0.1968],\n",
      "        [-0.1236],\n",
      "        [-0.1806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0291]],\n",
      "\n",
      "        [[-0.3603]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-0.1454]]], dtype=torch.float64)\n",
      "tensor([[ 0.2291],\n",
      "        [ 0.2080],\n",
      "        [ 0.1012],\n",
      "        [-0.0489]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5652]],\n",
      "\n",
      "        [[ 0.6045]],\n",
      "\n",
      "        [[ 0.0638]],\n",
      "\n",
      "        [[-0.2944]]], dtype=torch.float64)\n",
      "tensor([[0.0126],\n",
      "        [0.1332],\n",
      "        [0.3892],\n",
      "        [0.4234]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3002]],\n",
      "\n",
      "        [[-0.0321]],\n",
      "\n",
      "        [[ 0.6935]],\n",
      "\n",
      "        [[ 0.9892]]], dtype=torch.float64)\n",
      "tensor([[ 0.3573],\n",
      "        [ 0.1873],\n",
      "        [ 0.0297],\n",
      "        [-0.0467]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3815]],\n",
      "\n",
      "        [[-0.1188]],\n",
      "\n",
      "        [[-0.3799]],\n",
      "\n",
      "        [[ 0.0718]]], dtype=torch.float64)\n",
      "tensor([[0.6145],\n",
      "        [0.6285],\n",
      "        [0.4849],\n",
      "        [0.3064]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1094]],\n",
      "\n",
      "        [[1.2145]],\n",
      "\n",
      "        [[0.5929]],\n",
      "\n",
      "        [[0.0233]]], dtype=torch.float64)\n",
      "tensor([[0.1733],\n",
      "        [0.0584],\n",
      "        [0.3954],\n",
      "        [0.8496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2782]],\n",
      "\n",
      "        [[-0.2494]],\n",
      "\n",
      "        [[ 1.1545]],\n",
      "\n",
      "        [[ 1.5184]]], dtype=torch.float64)\n",
      "tensor([[0.6585],\n",
      "        [0.4211],\n",
      "        [0.2441],\n",
      "        [0.0133]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6380]],\n",
      "\n",
      "        [[ 0.1677]],\n",
      "\n",
      "        [[-0.1997]],\n",
      "\n",
      "        [[-0.0217]]], dtype=torch.float64)\n",
      "tensor([[0.7152],\n",
      "        [0.9656],\n",
      "        [0.6990],\n",
      "        [0.4663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3335]],\n",
      "\n",
      "        [[1.5600]],\n",
      "\n",
      "        [[0.7847]],\n",
      "\n",
      "        [[0.4277]]], dtype=torch.float64)\n",
      "tensor([[0.5210],\n",
      "        [0.5407],\n",
      "        [0.9583],\n",
      "        [0.9086]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3122]],\n",
      "\n",
      "        [[0.7212]],\n",
      "\n",
      "        [[1.4144]],\n",
      "\n",
      "        [[1.3578]]], dtype=torch.float64)\n",
      "tensor([[0.5769],\n",
      "        [0.3856],\n",
      "        [0.4802],\n",
      "        [0.4387]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6137]],\n",
      "\n",
      "        [[0.4797]],\n",
      "\n",
      "        [[0.3688]],\n",
      "\n",
      "        [[0.3734]]], dtype=torch.float64)\n",
      "tensor([[ 0.3058],\n",
      "        [ 0.0687],\n",
      "        [-0.0545],\n",
      "        [-0.0687]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1331]],\n",
      "\n",
      "        [[ 0.0314]],\n",
      "\n",
      "        [[-0.1627]],\n",
      "\n",
      "        [[-0.1858]]], dtype=torch.float64)\n",
      "tensor([[-0.0285],\n",
      "        [-0.0408],\n",
      "        [ 0.0719],\n",
      "        [-0.0146]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2089]],\n",
      "\n",
      "        [[-0.1269]],\n",
      "\n",
      "        [[ 0.1042]],\n",
      "\n",
      "        [[ 0.3237]]], dtype=torch.float64)\n",
      "tensor([[-0.0081],\n",
      "        [-0.0213],\n",
      "        [ 0.2200],\n",
      "        [ 0.1392]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0425]],\n",
      "\n",
      "        [[-0.0368]],\n",
      "\n",
      "        [[-0.0206]],\n",
      "\n",
      "        [[-0.0957]]], dtype=torch.float64)\n",
      "tensor([[-0.0821],\n",
      "        [-0.1771],\n",
      "        [-0.1359],\n",
      "        [-0.0524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0610]],\n",
      "\n",
      "        [[-0.1373]],\n",
      "\n",
      "        [[-0.1488]],\n",
      "\n",
      "        [[-0.1084]]], dtype=torch.float64)\n",
      "tensor([[0.0714],\n",
      "        [0.1125],\n",
      "        [0.0693],\n",
      "        [0.0976]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0772]],\n",
      "\n",
      "        [[ 0.0406]],\n",
      "\n",
      "        [[ 0.1423]],\n",
      "\n",
      "        [[ 0.1019]]], dtype=torch.float64)\n",
      "tensor([[-0.1376],\n",
      "        [-0.0525],\n",
      "        [ 0.0877],\n",
      "        [ 0.0015]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0564]],\n",
      "\n",
      "        [[-0.0876]],\n",
      "\n",
      "        [[-0.1708]],\n",
      "\n",
      "        [[-0.1927]]], dtype=torch.float64)\n",
      "tensor([[-0.0489],\n",
      "        [-0.1508],\n",
      "        [-0.2531],\n",
      "        [-0.2071]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0175]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[-0.1569]],\n",
      "\n",
      "        [[-0.2494]]], dtype=torch.float64)\n",
      "tensor([[-0.0863],\n",
      "        [-0.1202],\n",
      "        [ 0.0029],\n",
      "        [-0.0094]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3349]],\n",
      "\n",
      "        [[-0.2355]],\n",
      "\n",
      "        [[ 0.1446]],\n",
      "\n",
      "        [[ 0.2001]]], dtype=torch.float64)\n",
      "tensor([[-0.0870],\n",
      "        [-0.1123],\n",
      "        [ 0.0785],\n",
      "        [ 0.0416]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0680]],\n",
      "\n",
      "        [[-0.1927]],\n",
      "\n",
      "        [[-0.2378]],\n",
      "\n",
      "        [[-0.0495]]], dtype=torch.float64)\n",
      "tensor([[0.2931],\n",
      "        [0.2423],\n",
      "        [0.1285],\n",
      "        [0.2034]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4335]],\n",
      "\n",
      "        [[0.3722]],\n",
      "\n",
      "        [[0.1585]],\n",
      "\n",
      "        [[0.0314]]], dtype=torch.float64)\n",
      "tensor([[0.3358],\n",
      "        [0.3373],\n",
      "        [0.3407],\n",
      "        [0.2939]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0302]],\n",
      "\n",
      "        [[0.1527]],\n",
      "\n",
      "        [[0.3746]],\n",
      "\n",
      "        [[0.4150]]], dtype=torch.float64)\n",
      "tensor([[0.2353],\n",
      "        [0.4108],\n",
      "        [0.4730],\n",
      "        [0.4142]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3780]],\n",
      "\n",
      "        [[0.3145]],\n",
      "\n",
      "        [[0.1342]],\n",
      "\n",
      "        [[0.4497]]], dtype=torch.float64)\n",
      "tensor([[0.6711],\n",
      "        [0.7641],\n",
      "        [0.3578],\n",
      "        [0.2233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0343]],\n",
      "\n",
      "        [[0.9580]],\n",
      "\n",
      "        [[0.2197]],\n",
      "\n",
      "        [[0.0383]]], dtype=torch.float64)\n",
      "tensor([[0.2755],\n",
      "        [0.1573],\n",
      "        [0.4175],\n",
      "        [0.3939]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1188]],\n",
      "\n",
      "        [[ 0.1539]],\n",
      "\n",
      "        [[ 0.6911]],\n",
      "\n",
      "        [[ 0.5571]]], dtype=torch.float64)\n",
      "tensor([[0.1480],\n",
      "        [0.1177],\n",
      "        [0.1806],\n",
      "        [0.1233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1585]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[-0.1280]],\n",
      "\n",
      "        [[ 0.0834]]], dtype=torch.float64)\n",
      "tensor([[0.4423],\n",
      "        [0.5873],\n",
      "        [0.4330],\n",
      "        [0.4982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8645]],\n",
      "\n",
      "        [[0.9188]],\n",
      "\n",
      "        [[0.5814]],\n",
      "\n",
      "        [[0.3988]]], dtype=torch.float64)\n",
      "tensor([[0.5466],\n",
      "        [0.4412],\n",
      "        [0.6549],\n",
      "        [0.6458]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3099]],\n",
      "\n",
      "        [[0.3260]],\n",
      "\n",
      "        [[0.9627]],\n",
      "\n",
      "        [[0.8159]]], dtype=torch.float64)\n",
      "tensor([[0.3853],\n",
      "        [0.3647],\n",
      "        [0.3938],\n",
      "        [0.2310]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4312]],\n",
      "\n",
      "        [[ 0.1874]],\n",
      "\n",
      "        [[-0.0033]],\n",
      "\n",
      "        [[ 0.0718]]], dtype=torch.float64)\n",
      "tensor([[0.3577],\n",
      "        [0.4410],\n",
      "        [0.3432],\n",
      "        [0.5118]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6449]],\n",
      "\n",
      "        [[0.6992]],\n",
      "\n",
      "        [[0.5317]],\n",
      "\n",
      "        [[0.3919]]], dtype=torch.float64)\n",
      "tensor([[0.5655],\n",
      "        [0.1761],\n",
      "        [0.4246],\n",
      "        [0.3582]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1250]],\n",
      "\n",
      "        [[0.1204]],\n",
      "\n",
      "        [[0.6172]],\n",
      "\n",
      "        [[0.8333]]], dtype=torch.float64)\n",
      "tensor([[ 0.2445],\n",
      "        [ 0.0562],\n",
      "        [ 0.0346],\n",
      "        [-0.3613]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3480]],\n",
      "\n",
      "        [[-0.0818]],\n",
      "\n",
      "        [[-0.4620]],\n",
      "\n",
      "        [[-0.4273]]], dtype=torch.float64)\n",
      "tensor([[ 0.1536],\n",
      "        [ 0.2991],\n",
      "        [-0.0143],\n",
      "        [-0.1829]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6507]],\n",
      "\n",
      "        [[ 0.9153]],\n",
      "\n",
      "        [[ 0.1689]],\n",
      "\n",
      "        [[-0.3002]]], dtype=torch.float64)\n",
      "tensor([[-0.4606],\n",
      "        [-0.6356],\n",
      "        [-0.4966],\n",
      "        [-0.0141]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7947]],\n",
      "\n",
      "        [[-0.8340]],\n",
      "\n",
      "        [[-0.0241]],\n",
      "\n",
      "        [[ 0.3965]]], dtype=torch.float64)\n",
      "tensor([[-0.2119],\n",
      "        [-0.3638],\n",
      "        [-0.6297],\n",
      "        [-0.7948]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1015]],\n",
      "\n",
      "        [[-0.6549]],\n",
      "\n",
      "        [[-0.9045]],\n",
      "\n",
      "        [[-1.0316]]], dtype=torch.float64)\n",
      "tensor([[-0.5541],\n",
      "        [-0.1317],\n",
      "        [-0.2504],\n",
      "        [-0.5510]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0014]],\n",
      "\n",
      "        [[ 0.3156]],\n",
      "\n",
      "        [[-0.1558]],\n",
      "\n",
      "        [[-0.5671]]], dtype=torch.float64)\n",
      "tensor([[-0.6190],\n",
      "        [-0.5258],\n",
      "        [-0.6134],\n",
      "        [-0.6758]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7242]],\n",
      "\n",
      "        [[-0.6919]],\n",
      "\n",
      "        [[-0.5359]],\n",
      "\n",
      "        [[-0.5324]]], dtype=torch.float64)\n",
      "tensor([[-0.7236],\n",
      "        [-0.6040],\n",
      "        [-0.4005],\n",
      "        [-0.4940]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.5683]],\n",
      "\n",
      "        [[-0.5440]],\n",
      "\n",
      "        [[-0.5798]]], dtype=torch.float64)\n",
      "tensor([[-0.5412],\n",
      "        [-0.3794],\n",
      "        [-0.5394],\n",
      "        [-0.6662]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4181]],\n",
      "\n",
      "        [[-0.0795]],\n",
      "\n",
      "        [[-0.5405]],\n",
      "\n",
      "        [[-0.8340]]], dtype=torch.float64)\n",
      "tensor([[-0.5283],\n",
      "        [-0.4587],\n",
      "        [-0.3995],\n",
      "        [-0.1428]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6561]],\n",
      "\n",
      "        [[-0.6919]],\n",
      "\n",
      "        [[-0.1523]],\n",
      "\n",
      "        [[ 0.0799]]], dtype=torch.float64)\n",
      "tensor([[-0.2515],\n",
      "        [-0.1577],\n",
      "        [-0.0859],\n",
      "        [-0.0958]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1315]],\n",
      "\n",
      "        [[-0.1858]],\n",
      "\n",
      "        [[-0.2031]],\n",
      "\n",
      "        [[-0.1604]]], dtype=torch.float64)\n",
      "tensor([[-0.0786],\n",
      "        [-0.0853],\n",
      "        [-0.0683],\n",
      "        [-0.1073]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0372]],\n",
      "\n",
      "        [[ 0.0557]],\n",
      "\n",
      "        [[-0.1304]],\n",
      "\n",
      "        [[-0.2505]]], dtype=torch.float64)\n",
      "tensor([[-0.0797],\n",
      "        [-0.0024],\n",
      "        [-0.0943],\n",
      "        [-0.2562]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2875]],\n",
      "\n",
      "        [[-0.3037]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[-0.4284]]], dtype=torch.float64)\n",
      "tensor([[-0.7007],\n",
      "        [-0.6588],\n",
      "        [-0.5510],\n",
      "        [-0.5024]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5775]],\n",
      "\n",
      "        [[-0.5544]],\n",
      "\n",
      "        [[-0.5243]],\n",
      "\n",
      "        [[-0.5555]]], dtype=torch.float64)\n",
      "tensor([[-0.5795],\n",
      "        [-0.4455],\n",
      "        [-0.5678],\n",
      "        [-0.6796]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3568]],\n",
      "\n",
      "        [[-0.1338]],\n",
      "\n",
      "        [[-0.4342]],\n",
      "\n",
      "        [[-0.7716]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13793:  34%|███▎      | 1028/3067 [00:03<00:06, 320.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7929],\n",
      "        [-0.8988],\n",
      "        [-0.6807],\n",
      "        [-0.4122]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2349]],\n",
      "\n",
      "        [[-1.1621]],\n",
      "\n",
      "        [[-0.6468]],\n",
      "\n",
      "        [[-0.2309]]], dtype=torch.float64)\n",
      "tensor([[-0.7418],\n",
      "        [-0.8524],\n",
      "        [-0.7459],\n",
      "        [-0.4234]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8975]],\n",
      "\n",
      "        [[-1.1772]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-0.4828]]], dtype=torch.float64)\n",
      "tensor([[-0.2557],\n",
      "        [-0.3353],\n",
      "        [-0.4851],\n",
      "        [-0.5458]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3603]],\n",
      "\n",
      "        [[-0.4030]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-0.7057]]], dtype=torch.float64)\n",
      "tensor([[-0.4298],\n",
      "        [-0.3072],\n",
      "        [-0.2793],\n",
      "        [-0.3805]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.3857]],\n",
      "\n",
      "        [[-0.3765]],\n",
      "\n",
      "        [[-0.3418]]], dtype=torch.float64)\n",
      "tensor([[-0.6035],\n",
      "        [-0.6394],\n",
      "        [-0.6097],\n",
      "        [-0.5526]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6780]],\n",
      "\n",
      "        [[-0.7473]],\n",
      "\n",
      "        [[-0.7092]],\n",
      "\n",
      "        [[-0.6191]]], dtype=torch.float64)\n",
      "tensor([[-0.3311],\n",
      "        [-0.5975],\n",
      "        [-0.6750],\n",
      "        [-0.5735]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3326]],\n",
      "\n",
      "        [[-0.2956]],\n",
      "\n",
      "        [[-0.6064]],\n",
      "\n",
      "        [[-0.7508]]], dtype=torch.float64)\n",
      "tensor([[-0.6299],\n",
      "        [-0.7050],\n",
      "        [-0.2673],\n",
      "        [-0.3179]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9103]],\n",
      "\n",
      "        [[-0.7612]],\n",
      "\n",
      "        [[-0.0864]],\n",
      "\n",
      "        [[-0.3118]]], dtype=torch.float64)\n",
      "tensor([[-0.5950],\n",
      "        [-0.6673],\n",
      "        [-0.7627],\n",
      "        [-0.8662]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5544]],\n",
      "\n",
      "        [[-0.8883]],\n",
      "\n",
      "        [[-1.1668]],\n",
      "\n",
      "        [[-1.0651]]], dtype=torch.float64)\n",
      "tensor([[-0.4078],\n",
      "        [-0.0771],\n",
      "        [-0.1358],\n",
      "        [ 0.0182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1015]],\n",
      "\n",
      "        [[ 0.0256]],\n",
      "\n",
      "        [[ 0.0718]],\n",
      "\n",
      "        [[-0.0079]]], dtype=torch.float64)\n",
      "tensor([[ 0.0274],\n",
      "        [-0.0775],\n",
      "        [-0.1057],\n",
      "        [-0.2712]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1061]],\n",
      "\n",
      "        [[-0.2147]],\n",
      "\n",
      "        [[ 0.0256]],\n",
      "\n",
      "        [[-0.1396]]], dtype=torch.float64)\n",
      "tensor([[-0.5374],\n",
      "        [-0.5739],\n",
      "        [-0.6382],\n",
      "        [-0.6910]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4851]],\n",
      "\n",
      "        [[-0.6977]],\n",
      "\n",
      "        [[-0.9207]],\n",
      "\n",
      "        [[-0.6445]]], dtype=torch.float64)\n",
      "tensor([[-0.5406],\n",
      "        [-0.5436],\n",
      "        [-0.6990],\n",
      "        [-0.8052]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3476]],\n",
      "\n",
      "        [[-0.2297]],\n",
      "\n",
      "        [[-0.6491]],\n",
      "\n",
      "        [[-1.0685]]], dtype=torch.float64)\n",
      "tensor([[-0.7669],\n",
      "        [-0.5474],\n",
      "        [-0.5215],\n",
      "        [-0.5414]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5879]],\n",
      "\n",
      "        [[-0.6168]],\n",
      "\n",
      "        [[-0.2424]],\n",
      "\n",
      "        [[-0.3129]]], dtype=torch.float64)\n",
      "tensor([[-0.6634],\n",
      "        [-0.7750],\n",
      "        [-0.8133],\n",
      "        [-0.6743]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6295]],\n",
      "\n",
      "        [[-0.9472]],\n",
      "\n",
      "        [[-1.0015]],\n",
      "\n",
      "        [[-0.8190]]], dtype=torch.float64)\n",
      "tensor([[-0.2049],\n",
      "        [-0.2418],\n",
      "        [-0.4295],\n",
      "        [-0.3611]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0113]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[-0.2089]],\n",
      "\n",
      "        [[-0.2378]]], dtype=torch.float64)\n",
      "tensor([[-0.2481],\n",
      "        [-0.0820],\n",
      "        [ 0.0697],\n",
      "        [ 0.0206]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3094]],\n",
      "\n",
      "        [[-0.1211]],\n",
      "\n",
      "        [[ 0.5594]],\n",
      "\n",
      "        [[ 0.2717]]], dtype=torch.float64)\n",
      "tensor([[-0.2593],\n",
      "        [-0.4334],\n",
      "        [-0.5558],\n",
      "        [-0.6240]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2517]],\n",
      "\n",
      "        [[-0.5937]],\n",
      "\n",
      "        [[-0.7670]],\n",
      "\n",
      "        [[-0.6907]]], dtype=torch.float64)\n",
      "tensor([[-0.1078],\n",
      "        [ 0.1861],\n",
      "        [ 0.0295],\n",
      "        [-0.0925]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3572]],\n",
      "\n",
      "        [[ 0.5987]],\n",
      "\n",
      "        [[-0.0252]],\n",
      "\n",
      "        [[-0.1627]]], dtype=torch.float64)\n",
      "tensor([[-0.1985],\n",
      "        [-0.1956],\n",
      "        [ 0.0837],\n",
      "        [ 0.1455]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4654]],\n",
      "\n",
      "        [[-0.1523]],\n",
      "\n",
      "        [[ 0.3237]],\n",
      "\n",
      "        [[ 0.5063]]], dtype=torch.float64)\n",
      "tensor([[-0.0192],\n",
      "        [-0.0129],\n",
      "        [-0.1467],\n",
      "        [-0.3771]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0095]],\n",
      "\n",
      "        [[-0.1003]],\n",
      "\n",
      "        [[-0.3765]],\n",
      "\n",
      "        [[-0.5463]]], dtype=torch.float64)\n",
      "tensor([[-0.1649],\n",
      "        [ 0.1400],\n",
      "        [-0.0148],\n",
      "        [-0.1387]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2671]],\n",
      "\n",
      "        [[ 0.4832]],\n",
      "\n",
      "        [[-0.0645]],\n",
      "\n",
      "        [[-0.2759]]], dtype=torch.float64)\n",
      "tensor([[-0.1657],\n",
      "        [-0.3584],\n",
      "        [-0.2158],\n",
      "        [-0.0590]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4643]],\n",
      "\n",
      "        [[-0.5278]],\n",
      "\n",
      "        [[ 0.0672]],\n",
      "\n",
      "        [[ 0.1654]]], dtype=torch.float64)\n",
      "tensor([[-0.1937],\n",
      "        [-0.3906],\n",
      "        [-0.2069],\n",
      "        [-0.2209]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1904]],\n",
      "\n",
      "        [[-0.3672]],\n",
      "\n",
      "        [[-0.3926]],\n",
      "\n",
      "        [[-0.3626]]], dtype=torch.float64)\n",
      "tensor([[-0.3000],\n",
      "        [-0.1695],\n",
      "        [-0.2789],\n",
      "        [-0.3592]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2401]],\n",
      "\n",
      "        [[-0.0148]],\n",
      "\n",
      "        [[-0.3464]],\n",
      "\n",
      "        [[-0.2378]]], dtype=torch.float64)\n",
      "tensor([[0.0637],\n",
      "        [0.1386],\n",
      "        [0.0889],\n",
      "        [0.0798]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1003]],\n",
      "\n",
      "        [[ 0.0649]],\n",
      "\n",
      "        [[ 0.3018]],\n",
      "\n",
      "        [[ 0.3307]]], dtype=torch.float64)\n",
      "tensor([[0.1661],\n",
      "        [0.3152],\n",
      "        [0.4164],\n",
      "        [0.3947]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3468]],\n",
      "\n",
      "        [[0.2891]],\n",
      "\n",
      "        [[0.3954]],\n",
      "\n",
      "        [[0.5744]]], dtype=torch.float64)\n",
      "tensor([[0.3855],\n",
      "        [0.4125],\n",
      "        [0.3742],\n",
      "        [0.4847]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8009]],\n",
      "\n",
      "        [[0.7951]],\n",
      "\n",
      "        [[0.6958]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[0.5280],\n",
      "        [0.3667],\n",
      "        [0.2159],\n",
      "        [0.1873]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5097]],\n",
      "\n",
      "        [[0.4393]],\n",
      "\n",
      "        [[0.5225]],\n",
      "\n",
      "        [[0.4728]]], dtype=torch.float64)\n",
      "tensor([[0.1969],\n",
      "        [0.3261],\n",
      "        [0.4037],\n",
      "        [0.3521]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3538]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.3665]],\n",
      "\n",
      "        [[0.3884]]], dtype=torch.float64)\n",
      "tensor([[ 0.0305],\n",
      "        [-0.1429],\n",
      "        [-0.2619],\n",
      "        [-0.2261]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0129]],\n",
      "\n",
      "        [[-0.1766]],\n",
      "\n",
      "        [[-0.2182]],\n",
      "\n",
      "        [[-0.3949]]], dtype=torch.float64)\n",
      "tensor([[-0.2714],\n",
      "        [-0.3623],\n",
      "        [-0.5042],\n",
      "        [-0.6991]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4469]],\n",
      "\n",
      "        [[-0.5012]],\n",
      "\n",
      "        [[-0.5498]],\n",
      "\n",
      "        [[-0.6699]]], dtype=torch.float64)\n",
      "tensor([[-0.7661],\n",
      "        [-0.6942],\n",
      "        [-0.6344],\n",
      "        [-0.6820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7855]],\n",
      "\n",
      "        [[-0.8502]],\n",
      "\n",
      "        [[-0.9299]],\n",
      "\n",
      "        [[-0.8791]]], dtype=torch.float64)\n",
      "tensor([[-0.6593],\n",
      "        [-0.6644],\n",
      "        [-0.6499],\n",
      "        [-0.6142]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7161]],\n",
      "\n",
      "        [[-0.7092]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.8525]]], dtype=torch.float64)\n",
      "tensor([[-0.5824],\n",
      "        [-0.5806],\n",
      "        [-0.4988],\n",
      "        [-0.3142]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8594]],\n",
      "\n",
      "        [[-0.8560]],\n",
      "\n",
      "        [[-0.3014]],\n",
      "\n",
      "        [[-0.2078]]], dtype=torch.float64)\n",
      "tensor([[-0.4080],\n",
      "        [-0.5860],\n",
      "        [-0.6513],\n",
      "        [-0.5084]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6029]],\n",
      "\n",
      "        [[-1.0570]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-0.7589]]], dtype=torch.float64)\n",
      "tensor([[-0.3473],\n",
      "        [-0.0730],\n",
      "        [-0.2566],\n",
      "        [-0.2252]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0356]],\n",
      "\n",
      "        [[-0.1003]],\n",
      "\n",
      "        [[-0.2863]],\n",
      "\n",
      "        [[-0.5498]]], dtype=torch.float64)\n",
      "tensor([[-0.5353],\n",
      "        [-0.5394],\n",
      "        [-0.3728],\n",
      "        [-0.5740]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7520]],\n",
      "\n",
      "        [[-0.6977]],\n",
      "\n",
      "        [[-0.3522]],\n",
      "\n",
      "        [[-0.4435]]], dtype=torch.float64)\n",
      "tensor([[-0.4032],\n",
      "        [-0.2338],\n",
      "        [-0.0275],\n",
      "        [-0.0216]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3776]],\n",
      "\n",
      "        [[-0.2459]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[-0.0229]]], dtype=torch.float64)\n",
      "tensor([[-0.0178],\n",
      "        [-0.0635],\n",
      "        [-0.0443],\n",
      "        [ 0.1871]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0614]],\n",
      "\n",
      "        [[0.0418]],\n",
      "\n",
      "        [[0.0799]],\n",
      "\n",
      "        [[0.2763]]], dtype=torch.float64)\n",
      "tensor([[0.4787],\n",
      "        [0.4771],\n",
      "        [0.4260],\n",
      "        [0.3088]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4323]],\n",
      "\n",
      "        [[0.5571]],\n",
      "\n",
      "        [[0.7073]],\n",
      "\n",
      "        [[0.5837]]], dtype=torch.float64)\n",
      "tensor([[0.2286],\n",
      "        [0.4832],\n",
      "        [0.5191],\n",
      "        [0.2829]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5225]],\n",
      "\n",
      "        [[0.5536]],\n",
      "\n",
      "        [[0.2775]],\n",
      "\n",
      "        [[0.3260]]], dtype=torch.float64)\n",
      "tensor([[0.3408],\n",
      "        [0.4218],\n",
      "        [0.2388],\n",
      "        [0.2666]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8621]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.4566]],\n",
      "\n",
      "        [[0.2255]]], dtype=torch.float64)\n",
      "tensor([[ 0.4071],\n",
      "        [ 0.2478],\n",
      "        [ 0.0039],\n",
      "        [-0.3521]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3156]],\n",
      "\n",
      "        [[ 0.1285]],\n",
      "\n",
      "        [[-0.0021]],\n",
      "\n",
      "        [[-0.2632]]], dtype=torch.float64)\n",
      "tensor([[-0.5339],\n",
      "        [-0.6494],\n",
      "        [-0.5692],\n",
      "        [-0.6062]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3869]],\n",
      "\n",
      "        [[-0.5856]],\n",
      "\n",
      "        [[-0.6122]],\n",
      "\n",
      "        [[-0.6156]]], dtype=torch.float64)\n",
      "tensor([[-0.7842],\n",
      "        [-0.9410],\n",
      "        [-0.9681],\n",
      "        [-0.8529]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6618]],\n",
      "\n",
      "        [[-0.7393]],\n",
      "\n",
      "        [[-0.7855]],\n",
      "\n",
      "        [[-0.8155]]], dtype=torch.float64)\n",
      "tensor([[-0.7516],\n",
      "        [-0.7147],\n",
      "        [-0.7810],\n",
      "        [-0.8507]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8236]],\n",
      "\n",
      "        [[-0.8328]],\n",
      "\n",
      "        [[-0.8028]],\n",
      "\n",
      "        [[-0.7936]]], dtype=torch.float64)\n",
      "tensor([[-0.8519],\n",
      "        [-0.7111],\n",
      "        [-0.5979],\n",
      "        [-0.5759]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7959]],\n",
      "\n",
      "        [[-0.7681]],\n",
      "\n",
      "        [[-0.7265]],\n",
      "\n",
      "        [[-0.7023]]], dtype=torch.float64)\n",
      "tensor([[-0.6187],\n",
      "        [-0.6192],\n",
      "        [-0.6356],\n",
      "        [-0.5405]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6480]],\n",
      "\n",
      "        [[-0.6064]],\n",
      "\n",
      "        [[-0.6399]],\n",
      "\n",
      "        [[-0.6734]]], dtype=torch.float64)\n",
      "tensor([[-0.4749],\n",
      "        [-0.5047],\n",
      "        [-0.4709],\n",
      "        [-0.4675]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7254]],\n",
      "\n",
      "        [[-0.6769]],\n",
      "\n",
      "        [[-0.4134]],\n",
      "\n",
      "        [[-0.3996]]], dtype=torch.float64)\n",
      "tensor([[-0.5327],\n",
      "        [-0.4993],\n",
      "        [-0.4099],\n",
      "        [-0.5273]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4677]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.6353]],\n",
      "\n",
      "        [[-0.8941]]], dtype=torch.float64)\n",
      "tensor([[-0.5922],\n",
      "        [-0.3817],\n",
      "        [-0.6918],\n",
      "        [-0.9510]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4331]],\n",
      "\n",
      "        [[-0.4157]],\n",
      "\n",
      "        [[-0.8999]],\n",
      "\n",
      "        [[-1.1956]]], dtype=torch.float64)\n",
      "tensor([[-0.9586],\n",
      "        [-1.0181],\n",
      "        [-1.0806],\n",
      "        [-0.9825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2349]],\n",
      "\n",
      "        [[-1.2823]],\n",
      "\n",
      "        [[-1.1598]],\n",
      "\n",
      "        [[-0.7543]]], dtype=torch.float64)\n",
      "tensor([[-0.8712],\n",
      "        [-0.7750],\n",
      "        [-0.8106],\n",
      "        [-0.7218]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.8236]],\n",
      "\n",
      "        [[-0.8444]]], dtype=torch.float64)\n",
      "tensor([[-0.8053],\n",
      "        [-0.9978],\n",
      "        [-0.9457],\n",
      "        [-0.8600]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0397]],\n",
      "\n",
      "        [[-1.0593]],\n",
      "\n",
      "        [[-1.0558]],\n",
      "\n",
      "        [[-1.0397]]], dtype=torch.float64)\n",
      "tensor([[-0.8054],\n",
      "        [-0.8159],\n",
      "        [-0.9106],\n",
      "        [-0.8776]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9911]],\n",
      "\n",
      "        [[-0.9426]],\n",
      "\n",
      "        [[-0.8594]],\n",
      "\n",
      "        [[-0.8305]]], dtype=torch.float64)\n",
      "tensor([[-0.8485],\n",
      "        [-0.7231],\n",
      "        [-0.8152],\n",
      "        [-0.8915]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7739]],\n",
      "\n",
      "        [[-0.9103]],\n",
      "\n",
      "        [[-1.0397]],\n",
      "\n",
      "        [[-0.9992]]], dtype=torch.float64)\n",
      "tensor([[-0.9102],\n",
      "        [-0.9519],\n",
      "        [-1.0439],\n",
      "        [-0.9878]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8802]],\n",
      "\n",
      "        [[-1.0119]],\n",
      "\n",
      "        [[-1.1182]],\n",
      "\n",
      "        [[-1.1529]]], dtype=torch.float64)\n",
      "tensor([[-0.9919],\n",
      "        [-1.0594],\n",
      "        [-0.9767],\n",
      "        [-0.9436]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3886]],\n",
      "\n",
      "        [[-1.2580]],\n",
      "\n",
      "        [[-0.8375]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-1.0468],\n",
      "        [-1.0901],\n",
      "        [-0.9473],\n",
      "        [-0.9938]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1402]],\n",
      "\n",
      "        [[-1.1598]],\n",
      "\n",
      "        [[-1.1772]],\n",
      "\n",
      "        [[-1.1644]]], dtype=torch.float64)\n",
      "tensor([[-1.0911],\n",
      "        [-1.2599],\n",
      "        [-1.3302],\n",
      "        [-1.3414]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2315]],\n",
      "\n",
      "        [[-1.2962]],\n",
      "\n",
      "        [[-1.3112]],\n",
      "\n",
      "        [[-1.5827]]], dtype=torch.float64)\n",
      "tensor([[-1.4031],\n",
      "        [-1.4652],\n",
      "        [-1.4536],\n",
      "        [-1.4991]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8554]],\n",
      "\n",
      "        [[-1.7306]],\n",
      "\n",
      "        [[-1.5018]],\n",
      "\n",
      "        [[-1.5908]]], dtype=torch.float64)\n",
      "tensor([[-1.7172],\n",
      "        [-1.6390],\n",
      "        [-1.5572],\n",
      "        [-1.6393]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8935]],\n",
      "\n",
      "        [[-1.7699]],\n",
      "\n",
      "        [[-1.9108]],\n",
      "\n",
      "        [[-1.8138]]], dtype=torch.float64)\n",
      "tensor([[-1.6028],\n",
      "        [-1.5366],\n",
      "        [-1.6753],\n",
      "        [-1.5448]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4637]],\n",
      "\n",
      "        [[-1.5076]],\n",
      "\n",
      "        [[-1.5700]],\n",
      "\n",
      "        [[-1.6231]]], dtype=torch.float64)\n",
      "tensor([[-1.4923],\n",
      "        [-1.4903],\n",
      "        [-1.5427],\n",
      "        [-1.6113]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4764]],\n",
      "\n",
      "        [[-1.4949]],\n",
      "\n",
      "        [[-1.3944]],\n",
      "\n",
      "        [[-1.4914]]], dtype=torch.float64)\n",
      "tensor([[-1.6420],\n",
      "        [-1.6214],\n",
      "        [-1.4736],\n",
      "        [-1.5028]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5411]],\n",
      "\n",
      "        [[-1.5504]],\n",
      "\n",
      "        [[-1.5411]],\n",
      "\n",
      "        [[-1.5492]]], dtype=torch.float64)\n",
      "tensor([[-1.6031],\n",
      "        [-1.8328],\n",
      "        [-1.9081],\n",
      "        [-2.0965]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13066:  36%|███▌      | 1095/3067 [00:03<00:06, 325.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5954]],\n",
      "\n",
      "        [[-1.7225]],\n",
      "\n",
      "        [[-1.9143]],\n",
      "\n",
      "        [[-2.1153]]], dtype=torch.float64)\n",
      "tensor([[-2.2008],\n",
      "        [-2.2461],\n",
      "        [-2.3065],\n",
      "        [-2.3788]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3649]],\n",
      "\n",
      "        [[-2.4261]],\n",
      "\n",
      "        [[-2.2424]],\n",
      "\n",
      "        [[-2.3060]]], dtype=torch.float64)\n",
      "tensor([[-2.4287],\n",
      "        [-2.3954],\n",
      "        [-2.0994],\n",
      "        [-2.2927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3869]],\n",
      "\n",
      "        [[-2.4054]],\n",
      "\n",
      "        [[-2.4181]],\n",
      "\n",
      "        [[-2.6283]]], dtype=torch.float64)\n",
      "tensor([[-2.2924],\n",
      "        [-2.3169],\n",
      "        [-2.3246],\n",
      "        [-2.2070]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2390]],\n",
      "\n",
      "        [[-2.3175]],\n",
      "\n",
      "        [[-2.2817]],\n",
      "\n",
      "        [[-2.2783]]], dtype=torch.float64)\n",
      "tensor([[-2.2154],\n",
      "        [-2.3898],\n",
      "        [-2.4695],\n",
      "        [-2.1387]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6318]],\n",
      "\n",
      "        [[-2.8571]],\n",
      "\n",
      "        [[-2.1777]],\n",
      "\n",
      "        [[-2.1789]]], dtype=torch.float64)\n",
      "tensor([[-2.4770],\n",
      "        [-2.4759],\n",
      "        [-2.5129],\n",
      "        [-2.5208]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4088]],\n",
      "\n",
      "        [[-2.6549]],\n",
      "\n",
      "        [[-2.6723]],\n",
      "\n",
      "        [[-2.6769]]], dtype=torch.float64)\n",
      "tensor([[-2.3439],\n",
      "        [-1.8668],\n",
      "        [-2.0144],\n",
      "        [-1.7718]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8588]],\n",
      "\n",
      "        [[-1.8045]],\n",
      "\n",
      "        [[-1.8508]],\n",
      "\n",
      "        [[-1.6070]]], dtype=torch.float64)\n",
      "tensor([[-1.3917],\n",
      "        [-1.3430],\n",
      "        [-1.4957],\n",
      "        [-1.5720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4614]],\n",
      "\n",
      "        [[-1.4337]],\n",
      "\n",
      "        [[-1.3331]],\n",
      "\n",
      "        [[-1.2083]]], dtype=torch.float64)\n",
      "tensor([[-1.4170],\n",
      "        [-1.2985],\n",
      "        [-1.2451],\n",
      "        [-1.3078]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0789]],\n",
      "\n",
      "        [[-1.1656]],\n",
      "\n",
      "        [[-1.1506]],\n",
      "\n",
      "        [[-1.2777]]], dtype=torch.float64)\n",
      "tensor([[-1.5519],\n",
      "        [-1.5849],\n",
      "        [-1.5943],\n",
      "        [-1.5524]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1841]],\n",
      "\n",
      "        [[-1.1760]],\n",
      "\n",
      "        [[-1.2638]],\n",
      "\n",
      "        [[-1.4105]]], dtype=torch.float64)\n",
      "tensor([[-1.6048],\n",
      "        [-1.6665],\n",
      "        [-1.7269],\n",
      "        [-1.7930]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5099]],\n",
      "\n",
      "        [[-1.5261]],\n",
      "\n",
      "        [[-1.4683]],\n",
      "\n",
      "        [[-1.4891]]], dtype=torch.float64)\n",
      "tensor([[-1.8891],\n",
      "        [-1.7509],\n",
      "        [-1.6540],\n",
      "        [-1.5917]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5769]],\n",
      "\n",
      "        [[-1.5792]],\n",
      "\n",
      "        [[-1.5400]],\n",
      "\n",
      "        [[-1.4649]]], dtype=torch.float64)\n",
      "tensor([[-1.5707],\n",
      "        [-1.6024],\n",
      "        [-1.6336],\n",
      "        [-1.6442]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3643]],\n",
      "\n",
      "        [[-1.3181]],\n",
      "\n",
      "        [[-1.4510]],\n",
      "\n",
      "        [[-1.5261]]], dtype=torch.float64)\n",
      "tensor([[-1.5812],\n",
      "        [-1.4692],\n",
      "        [-1.3658],\n",
      "        [-1.4744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5064]],\n",
      "\n",
      "        [[-1.2985]],\n",
      "\n",
      "        [[-1.1032]],\n",
      "\n",
      "        [[-1.1587]]], dtype=torch.float64)\n",
      "tensor([[-1.4896],\n",
      "        [-1.4042],\n",
      "        [-1.2800],\n",
      "        [-1.4308]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2199]],\n",
      "\n",
      "        [[-1.2349]],\n",
      "\n",
      "        [[-1.2673]],\n",
      "\n",
      "        [[-1.4949]]], dtype=torch.float64)\n",
      "tensor([[-1.4650],\n",
      "        [-1.4154],\n",
      "        [-1.4359],\n",
      "        [-1.1819]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2338]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.2049]],\n",
      "\n",
      "        [[-1.0535]]], dtype=torch.float64)\n",
      "tensor([[-0.8103],\n",
      "        [-0.9054],\n",
      "        [-0.8199],\n",
      "        [-0.8598]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9726]],\n",
      "\n",
      "        [[-0.8005]],\n",
      "\n",
      "        [[-0.5902]],\n",
      "\n",
      "        [[-0.6422]]], dtype=torch.float64)\n",
      "tensor([[-0.8509],\n",
      "        [-0.7569],\n",
      "        [-0.8608],\n",
      "        [-0.9773]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6330]],\n",
      "\n",
      "        [[-0.7832]],\n",
      "\n",
      "        [[-1.0154]],\n",
      "\n",
      "        [[-0.8964]]], dtype=torch.float64)\n",
      "tensor([[-1.0073],\n",
      "        [-1.1472],\n",
      "        [-1.3879],\n",
      "        [-1.6267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9091]],\n",
      "\n",
      "        [[-1.1228]],\n",
      "\n",
      "        [[-1.3505]],\n",
      "\n",
      "        [[-1.6151]]], dtype=torch.float64)\n",
      "tensor([[-1.4767],\n",
      "        [-1.6523],\n",
      "        [-1.6879],\n",
      "        [-1.6961]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8554]],\n",
      "\n",
      "        [[-1.9906]],\n",
      "\n",
      "        [[-1.6566]],\n",
      "\n",
      "        [[-1.7410]]], dtype=torch.float64)\n",
      "tensor([[-1.5617],\n",
      "        [-1.5029],\n",
      "        [-1.5656],\n",
      "        [-1.5507]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7098]],\n",
      "\n",
      "        [[-1.7341]],\n",
      "\n",
      "        [[-1.8716]],\n",
      "\n",
      "        [[-1.8103]]], dtype=torch.float64)\n",
      "tensor([[-1.5624],\n",
      "        [-1.4769],\n",
      "        [-1.5860],\n",
      "        [-1.5817]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4914]],\n",
      "\n",
      "        [[-1.5007]],\n",
      "\n",
      "        [[-1.6717]],\n",
      "\n",
      "        [[-1.8057]]], dtype=torch.float64)\n",
      "tensor([[-1.5637],\n",
      "        [-1.5913],\n",
      "        [-1.6600],\n",
      "        [-1.6615]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8600]],\n",
      "\n",
      "        [[-1.8773]],\n",
      "\n",
      "        [[-1.7606]],\n",
      "\n",
      "        [[-1.7433]]], dtype=torch.float64)\n",
      "tensor([[-1.6424],\n",
      "        [-1.5795],\n",
      "        [-1.4882],\n",
      "        [-1.5568]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7641]],\n",
      "\n",
      "        [[-1.7745]],\n",
      "\n",
      "        [[-1.7699]],\n",
      "\n",
      "        [[-2.0818]]], dtype=torch.float64)\n",
      "tensor([[-1.6204],\n",
      "        [-1.5974],\n",
      "        [-1.4454],\n",
      "        [-1.3286]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7410]],\n",
      "\n",
      "        [[-1.6959]],\n",
      "\n",
      "        [[-1.5665]],\n",
      "\n",
      "        [[-1.6139]]], dtype=torch.float64)\n",
      "tensor([[-1.3146],\n",
      "        [-1.3985],\n",
      "        [-1.4360],\n",
      "        [-1.5037]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5665]],\n",
      "\n",
      "        [[-1.6185]],\n",
      "\n",
      "        [[-1.4787]],\n",
      "\n",
      "        [[-1.6705]]], dtype=torch.float64)\n",
      "tensor([[-1.6399],\n",
      "        [-1.6039],\n",
      "        [-1.7532],\n",
      "        [-2.0140]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6982]],\n",
      "\n",
      "        [[-1.9986]],\n",
      "\n",
      "        [[-2.4562]],\n",
      "\n",
      "        [[-2.4781]]], dtype=torch.float64)\n",
      "tensor([[-1.9983],\n",
      "        [-1.6752],\n",
      "        [-1.9104],\n",
      "        [-1.8798]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0010]],\n",
      "\n",
      "        [[-1.8034]],\n",
      "\n",
      "        [[-1.9628]],\n",
      "\n",
      "        [[-2.1361]]], dtype=torch.float64)\n",
      "tensor([[-1.9593],\n",
      "        [-1.7338],\n",
      "        [-1.4353],\n",
      "        [-1.3969]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1593]],\n",
      "\n",
      "        [[-1.8045]],\n",
      "\n",
      "        [[-1.2627]],\n",
      "\n",
      "        [[-1.2684]]], dtype=torch.float64)\n",
      "tensor([[-1.3618],\n",
      "        [-1.0813],\n",
      "        [-0.7341],\n",
      "        [-1.2758]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3181]],\n",
      "\n",
      "        [[-0.9865]],\n",
      "\n",
      "        [[-0.7104]],\n",
      "\n",
      "        [[-1.2569]]], dtype=torch.float64)\n",
      "tensor([[-1.4212],\n",
      "        [-1.6902],\n",
      "        [-1.7013],\n",
      "        [-1.6709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2511]],\n",
      "\n",
      "        [[-1.4960]],\n",
      "\n",
      "        [[-1.5330]],\n",
      "\n",
      "        [[-1.8554]]], dtype=torch.float64)\n",
      "tensor([[-1.8288],\n",
      "        [-1.7217],\n",
      "        [-1.6417],\n",
      "        [-1.4787]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8450]],\n",
      "\n",
      "        [[-1.7040]],\n",
      "\n",
      "        [[-1.3320]],\n",
      "\n",
      "        [[-1.2800]]], dtype=torch.float64)\n",
      "tensor([[-1.5534],\n",
      "        [-1.4608],\n",
      "        [-1.2588],\n",
      "        [-1.3356]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3262]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.2153]],\n",
      "\n",
      "        [[-1.2141]]], dtype=torch.float64)\n",
      "tensor([[-1.3251],\n",
      "        [-1.2844],\n",
      "        [-1.2159],\n",
      "        [-1.2154]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0940]],\n",
      "\n",
      "        [[-1.0477]],\n",
      "\n",
      "        [[-1.0836]],\n",
      "\n",
      "        [[-1.0928]]], dtype=torch.float64)\n",
      "tensor([[-1.1259],\n",
      "        [-1.1958],\n",
      "        [-1.2976],\n",
      "        [-1.3971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0524]],\n",
      "\n",
      "        [[-1.1471]],\n",
      "\n",
      "        [[-0.9842]],\n",
      "\n",
      "        [[-1.2026]]], dtype=torch.float64)\n",
      "tensor([[-1.4018],\n",
      "        [-1.3547],\n",
      "        [-1.3459],\n",
      "        [-1.3875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2280]],\n",
      "\n",
      "        [[-1.2534]],\n",
      "\n",
      "        [[-1.2869]],\n",
      "\n",
      "        [[-1.3100]]], dtype=torch.float64)\n",
      "tensor([[-1.4589],\n",
      "        [-1.5737],\n",
      "        [-1.7156],\n",
      "        [-1.6554]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3019]],\n",
      "\n",
      "        [[-1.4452]],\n",
      "\n",
      "        [[-1.5492]],\n",
      "\n",
      "        [[-1.6047]]], dtype=torch.float64)\n",
      "tensor([[-1.7520],\n",
      "        [-1.6903],\n",
      "        [-1.9063],\n",
      "        [-1.9560]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7676]],\n",
      "\n",
      "        [[-1.7514]],\n",
      "\n",
      "        [[-1.7872]],\n",
      "\n",
      "        [[-1.9455]]], dtype=torch.float64)\n",
      "tensor([[-2.2570],\n",
      "        [-2.3089],\n",
      "        [-2.3269],\n",
      "        [-2.4027]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2216]],\n",
      "\n",
      "        [[-2.3880]],\n",
      "\n",
      "        [[-2.6827]],\n",
      "\n",
      "        [[-2.6283]]], dtype=torch.float64)\n",
      "tensor([[-2.2747],\n",
      "        [-2.0117],\n",
      "        [-1.9176],\n",
      "        [-1.8674]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0934]],\n",
      "\n",
      "        [[-1.7999]],\n",
      "\n",
      "        [[-1.8508]],\n",
      "\n",
      "        [[-1.8843]]], dtype=torch.float64)\n",
      "tensor([[-1.8353],\n",
      "        [-1.6886],\n",
      "        [-1.6220],\n",
      "        [-1.5341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.9189]],\n",
      "\n",
      "        [[-1.7052]],\n",
      "\n",
      "        [[-1.4556]],\n",
      "\n",
      "        [[-1.3366]]], dtype=torch.float64)\n",
      "tensor([[-1.5001],\n",
      "        [-1.3722],\n",
      "        [-1.3914],\n",
      "        [-1.3858]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4071]],\n",
      "\n",
      "        [[-1.4025]],\n",
      "\n",
      "        [[-1.3713]],\n",
      "\n",
      "        [[-1.5249]]], dtype=torch.float64)\n",
      "tensor([[-1.6578],\n",
      "        [-1.8731],\n",
      "        [-2.1034],\n",
      "        [-2.1375]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5654]],\n",
      "\n",
      "        [[-1.9559]],\n",
      "\n",
      "        [[-2.2413]],\n",
      "\n",
      "        [[-2.2621]]], dtype=torch.float64)\n",
      "tensor([[-2.2253],\n",
      "        [-2.4587],\n",
      "        [-2.4835],\n",
      "        [-2.3399]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.5717]],\n",
      "\n",
      "        [[-2.7785]],\n",
      "\n",
      "        [[-2.4805]],\n",
      "\n",
      "        [[-2.3938]]], dtype=torch.float64)\n",
      "tensor([[-2.6075],\n",
      "        [-2.4319],\n",
      "        [-2.2232],\n",
      "        [-2.1701]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6884]],\n",
      "\n",
      "        [[-2.5948]],\n",
      "\n",
      "        [[-2.5024]],\n",
      "\n",
      "        [[-2.3707]]], dtype=torch.float64)\n",
      "tensor([[-2.1701],\n",
      "        [-2.0710],\n",
      "        [-1.9478],\n",
      "        [-2.2083]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1627]],\n",
      "\n",
      "        [[-1.9490]],\n",
      "\n",
      "        [[-2.1246]],\n",
      "\n",
      "        [[-2.2817]]], dtype=torch.float64)\n",
      "tensor([[-2.0218],\n",
      "        [-1.7834],\n",
      "        [-1.6006],\n",
      "        [-1.3877]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0021]],\n",
      "\n",
      "        [[-1.7433]],\n",
      "\n",
      "        [[-1.3146]],\n",
      "\n",
      "        [[-1.1009]]], dtype=torch.float64)\n",
      "tensor([[-1.3925],\n",
      "        [-1.4239],\n",
      "        [-1.4412],\n",
      "        [-1.2484]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2153]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.3516]],\n",
      "\n",
      "        [[-1.1090]]], dtype=torch.float64)\n",
      "tensor([[-1.1678],\n",
      "        [-1.0941],\n",
      "        [-1.2366],\n",
      "        [-1.2133]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8305]],\n",
      "\n",
      "        [[-0.9160]],\n",
      "\n",
      "        [[-1.0062]],\n",
      "\n",
      "        [[-1.0316]]], dtype=torch.float64)\n",
      "tensor([[-1.2239],\n",
      "        [-1.2410],\n",
      "        [-1.2986],\n",
      "        [-1.3747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1610]],\n",
      "\n",
      "        [[-1.0893]],\n",
      "\n",
      "        [[-1.0108]],\n",
      "\n",
      "        [[-1.1783]]], dtype=torch.float64)\n",
      "tensor([[-1.4190],\n",
      "        [-1.3337],\n",
      "        [-1.2208],\n",
      "        [-1.2607]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1413]],\n",
      "\n",
      "        [[-1.1321]],\n",
      "\n",
      "        [[-1.1702]],\n",
      "\n",
      "        [[-1.2026]]], dtype=torch.float64)\n",
      "tensor([[-1.2971],\n",
      "        [-1.3752],\n",
      "        [-1.5580],\n",
      "        [-1.5981]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9946]],\n",
      "\n",
      "        [[-1.2638]],\n",
      "\n",
      "        [[-1.5076]],\n",
      "\n",
      "        [[-1.5711]]], dtype=torch.float64)\n",
      "tensor([[-1.5463],\n",
      "        [-1.7705],\n",
      "        [-1.7400],\n",
      "        [-1.5063]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7710]],\n",
      "\n",
      "        [[-2.0564]],\n",
      "\n",
      "        [[-1.5099]],\n",
      "\n",
      "        [[-1.4926]]], dtype=torch.float64)\n",
      "tensor([[-1.7343],\n",
      "        [-1.9375],\n",
      "        [-1.9027],\n",
      "        [-1.8167]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8993]],\n",
      "\n",
      "        [[-2.1662]],\n",
      "\n",
      "        [[-1.9894]],\n",
      "\n",
      "        [[-2.1500]]], dtype=torch.float64)\n",
      "tensor([[-1.9256],\n",
      "        [-1.6616],\n",
      "        [-1.8259],\n",
      "        [-1.7205]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7699]],\n",
      "\n",
      "        [[-1.7190]],\n",
      "\n",
      "        [[-1.8866]],\n",
      "\n",
      "        [[-1.5885]]], dtype=torch.float64)\n",
      "tensor([[-1.3207],\n",
      "        [-1.0913],\n",
      "        [-0.9559],\n",
      "        [-0.7759]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2257]],\n",
      "\n",
      "        [[-0.9842]],\n",
      "\n",
      "        [[-0.7104]],\n",
      "\n",
      "        [[-0.6168]]], dtype=torch.float64)\n",
      "tensor([[-0.7114],\n",
      "        [-0.4227],\n",
      "        [-0.1812],\n",
      "        [-0.3681]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5509]],\n",
      "\n",
      "        [[-0.2031]],\n",
      "\n",
      "        [[-0.2043]],\n",
      "\n",
      "        [[-0.4978]]], dtype=torch.float64)\n",
      "tensor([[-0.6238],\n",
      "        [-0.5611],\n",
      "        [-0.5280],\n",
      "        [-0.3683]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6468]],\n",
      "\n",
      "        [[-0.4400]],\n",
      "\n",
      "        [[-0.5347]],\n",
      "\n",
      "        [[-0.3198]]], dtype=torch.float64)\n",
      "tensor([[-0.3515],\n",
      "        [-0.3180],\n",
      "        [-0.2605],\n",
      "        [-0.1080]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4481]],\n",
      "\n",
      "        [[-0.2413]],\n",
      "\n",
      "        [[ 0.0487]],\n",
      "\n",
      "        [[-0.0402]]], dtype=torch.float64)\n",
      "tensor([[-0.3004],\n",
      "        [-0.0825],\n",
      "        [-0.2093],\n",
      "        [-0.1550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0060]],\n",
      "\n",
      "        [[-0.3499]],\n",
      "\n",
      "        [[-0.2655]],\n",
      "\n",
      "        [[-0.3326]]], dtype=torch.float64)\n",
      "tensor([[-0.1996],\n",
      "        [-0.6761],\n",
      "        [-0.7661],\n",
      "        [-0.8713]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0425]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.8513]]], dtype=torch.float64)\n",
      "tensor([[-0.9902],\n",
      "        [-1.2395],\n",
      "        [-1.2922],\n",
      "        [-1.3052]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2858]],\n",
      "\n",
      "        [[-1.4568]],\n",
      "\n",
      "        [[-1.3401]],\n",
      "\n",
      "        [[-1.3181]]], dtype=torch.float64)\n",
      "tensor([[-1.4383],\n",
      "        [-1.4695],\n",
      "        [-1.3769],\n",
      "        [-1.2342]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4822]],\n",
      "\n",
      "        [[-1.5573]],\n",
      "\n",
      "        [[-1.4637]],\n",
      "\n",
      "        [[-1.3516]]], dtype=torch.float64)\n",
      "tensor([[-1.1414],\n",
      "        [-0.7866],\n",
      "        [-0.9168],\n",
      "        [-0.7980]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0246]],\n",
      "\n",
      "        [[-0.7531]],\n",
      "\n",
      "        [[-0.8721]],\n",
      "\n",
      "        [[-0.6861]]], dtype=torch.float64)\n",
      "tensor([[-0.5422],\n",
      "        [-0.6447],\n",
      "        [-0.7374],\n",
      "        [-0.8063]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5752]],\n",
      "\n",
      "        [[-0.6098]],\n",
      "\n",
      "        [[-0.5879]],\n",
      "\n",
      "        [[-0.6295]]], dtype=torch.float64)\n",
      "tensor([[-0.8761],\n",
      "        [-0.5662],\n",
      "        [-0.4345],\n",
      "        [-0.3657]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7057]],\n",
      "\n",
      "        [[-0.6133]],\n",
      "\n",
      "        [[-0.4770]],\n",
      "\n",
      "        [[-0.5105]]], dtype=torch.float64)\n",
      "tensor([[-0.4637],\n",
      "        [-0.4094],\n",
      "        [-0.2274],\n",
      "        [-0.0328]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4573]],\n",
      "\n",
      "        [[-0.3141]],\n",
      "\n",
      "        [[-0.1223]],\n",
      "\n",
      "        [[-0.0934]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13066:  38%|███▊      | 1160/3067 [00:03<00:06, 301.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0533],\n",
      "        [ 0.0301],\n",
      "        [ 0.0281],\n",
      "        [ 0.0156]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0044]],\n",
      "\n",
      "        [[ 0.1342]],\n",
      "\n",
      "        [[ 0.3029]],\n",
      "\n",
      "        [[ 0.1469]]], dtype=torch.float64)\n",
      "tensor([[-0.0619],\n",
      "        [-0.1017],\n",
      "        [-0.1512],\n",
      "        [-0.2851]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0441]],\n",
      "\n",
      "        [[-0.0160]],\n",
      "\n",
      "        [[-0.2343]],\n",
      "\n",
      "        [[-0.3118]]], dtype=torch.float64)\n",
      "tensor([[-0.3750],\n",
      "        [-0.3200],\n",
      "        [-0.3247],\n",
      "        [-0.2267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0472]],\n",
      "\n",
      "        [[-0.1384]],\n",
      "\n",
      "        [[-0.1500]],\n",
      "\n",
      "        [[-0.2447]]], dtype=torch.float64)\n",
      "tensor([[-0.2968],\n",
      "        [-0.3476],\n",
      "        [-0.3955],\n",
      "        [-0.2339]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2667]],\n",
      "\n",
      "        [[-0.4920]],\n",
      "\n",
      "        [[-0.1292]],\n",
      "\n",
      "        [[-0.1904]]], dtype=torch.float64)\n",
      "tensor([[-0.6618],\n",
      "        [-0.8640],\n",
      "        [-1.0123],\n",
      "        [-1.0551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-1.0177]],\n",
      "\n",
      "        [[-1.2026]],\n",
      "\n",
      "        [[-1.2615]]], dtype=torch.float64)\n",
      "tensor([[-1.1115],\n",
      "        [-0.4215],\n",
      "        [-0.6590],\n",
      "        [-0.7854]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8375]],\n",
      "\n",
      "        [[-0.1500]],\n",
      "\n",
      "        [[-0.7462]],\n",
      "\n",
      "        [[-0.7092]]], dtype=torch.float64)\n",
      "tensor([[-0.4443],\n",
      "        [-0.3626],\n",
      "        [-0.3709],\n",
      "        [-0.3090]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3441]],\n",
      "\n",
      "        [[-0.4550]],\n",
      "\n",
      "        [[-0.1858]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[-0.4590],\n",
      "        [-0.5677],\n",
      "        [-0.7722],\n",
      "        [-0.7918]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5059]],\n",
      "\n",
      "        [[-0.5960]],\n",
      "\n",
      "        [[-0.9172]],\n",
      "\n",
      "        [[-0.9426]]], dtype=torch.float64)\n",
      "tensor([[-0.8756],\n",
      "        [-0.9514],\n",
      "        [-1.0216],\n",
      "        [-0.9863]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8051]],\n",
      "\n",
      "        [[-0.8248]],\n",
      "\n",
      "        [[-1.0316]],\n",
      "\n",
      "        [[-1.0246]]], dtype=torch.float64)\n",
      "tensor([[-0.8880],\n",
      "        [-0.9181],\n",
      "        [-1.0003],\n",
      "        [-1.2303]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0628]],\n",
      "\n",
      "        [[-1.0789]],\n",
      "\n",
      "        [[-1.0963]],\n",
      "\n",
      "        [[-1.2060]]], dtype=torch.float64)\n",
      "tensor([[-1.2908],\n",
      "        [-1.2280],\n",
      "        [-1.1673],\n",
      "        [-1.2299]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2407]],\n",
      "\n",
      "        [[-1.2650]],\n",
      "\n",
      "        [[-1.3019]],\n",
      "\n",
      "        [[-1.3435]]], dtype=torch.float64)\n",
      "tensor([[-1.2659],\n",
      "        [-1.3360],\n",
      "        [-1.3276],\n",
      "        [-1.2367]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2569]],\n",
      "\n",
      "        [[-1.2823]],\n",
      "\n",
      "        [[-1.3412]],\n",
      "\n",
      "        [[-1.3274]]], dtype=torch.float64)\n",
      "tensor([[-1.1658],\n",
      "        [-1.1903],\n",
      "        [-1.1883],\n",
      "        [-1.1872]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3401]],\n",
      "\n",
      "        [[-1.3874]],\n",
      "\n",
      "        [[-1.1876]],\n",
      "\n",
      "        [[-1.1032]]], dtype=torch.float64)\n",
      "tensor([[-1.3484],\n",
      "        [-1.4209],\n",
      "        [-1.3156],\n",
      "        [-1.2001]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4637]],\n",
      "\n",
      "        [[-1.6162]],\n",
      "\n",
      "        [[-1.5215]],\n",
      "\n",
      "        [[-1.3967]]], dtype=torch.float64)\n",
      "tensor([[-1.0519],\n",
      "        [-1.0436],\n",
      "        [-1.0289],\n",
      "        [-0.9462]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9010]],\n",
      "\n",
      "        [[-0.9726]],\n",
      "\n",
      "        [[-1.0027]],\n",
      "\n",
      "        [[-1.0246]]], dtype=torch.float64)\n",
      "tensor([[-0.9023],\n",
      "        [-0.8752],\n",
      "        [-0.9749],\n",
      "        [-0.9364]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0166]],\n",
      "\n",
      "        [[-1.0270]],\n",
      "\n",
      "        [[-0.9507]],\n",
      "\n",
      "        [[-0.9900]]], dtype=torch.float64)\n",
      "tensor([[-0.9762],\n",
      "        [-0.8887],\n",
      "        [-0.8442],\n",
      "        [-0.7724]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9888]],\n",
      "\n",
      "        [[-0.9553]],\n",
      "\n",
      "        [[-0.9518]],\n",
      "\n",
      "        [[-0.9056]]], dtype=torch.float64)\n",
      "tensor([[-0.8136],\n",
      "        [-0.9858],\n",
      "        [-1.0282],\n",
      "        [-0.9595]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8560]],\n",
      "\n",
      "        [[-0.9438]],\n",
      "\n",
      "        [[-1.0200]],\n",
      "\n",
      "        [[-0.9553]]], dtype=torch.float64)\n",
      "tensor([[-0.8817],\n",
      "        [-0.8787],\n",
      "        [-1.0335],\n",
      "        [-1.0891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0258]],\n",
      "\n",
      "        [[-1.0778]],\n",
      "\n",
      "        [[-0.9542]],\n",
      "\n",
      "        [[-1.0246]]], dtype=torch.float64)\n",
      "tensor([[-1.0794],\n",
      "        [-1.1348],\n",
      "        [-1.2193],\n",
      "        [-1.2801]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1171]],\n",
      "\n",
      "        [[-1.2176]],\n",
      "\n",
      "        [[-1.3643]],\n",
      "\n",
      "        [[-1.4233]]], dtype=torch.float64)\n",
      "tensor([[-1.3927],\n",
      "        [-1.4148],\n",
      "        [-1.4118],\n",
      "        [-1.3903]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3955]],\n",
      "\n",
      "        [[-1.4152]],\n",
      "\n",
      "        [[-1.3817]],\n",
      "\n",
      "        [[-1.4868]]], dtype=torch.float64)\n",
      "tensor([[-1.4740],\n",
      "        [-1.4117],\n",
      "        [-1.3685],\n",
      "        [-1.3255]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5284]],\n",
      "\n",
      "        [[-1.4406]],\n",
      "\n",
      "        [[-1.2603]],\n",
      "\n",
      "        [[-1.1899]]], dtype=torch.float64)\n",
      "tensor([[-1.4141],\n",
      "        [-1.5306],\n",
      "        [-1.6376],\n",
      "        [-1.7849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4313]],\n",
      "\n",
      "        [[-1.7329]],\n",
      "\n",
      "        [[-1.9952]],\n",
      "\n",
      "        [[-2.1812]]], dtype=torch.float64)\n",
      "tensor([[-1.6872],\n",
      "        [-1.3529],\n",
      "        [-1.5580],\n",
      "        [-1.6873]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4868]],\n",
      "\n",
      "        [[-1.2557]],\n",
      "\n",
      "        [[-1.6670]],\n",
      "\n",
      "        [[-1.9131]]], dtype=torch.float64)\n",
      "tensor([[-1.6972],\n",
      "        [-1.6288],\n",
      "        [-1.6599],\n",
      "        [-1.6393]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8508]],\n",
      "\n",
      "        [[-1.8103]],\n",
      "\n",
      "        [[-1.7110]],\n",
      "\n",
      "        [[-1.6601]]], dtype=torch.float64)\n",
      "tensor([[-1.7191],\n",
      "        [-1.7134],\n",
      "        [-1.6293],\n",
      "        [-1.7072]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7294]],\n",
      "\n",
      "        [[-1.7953]],\n",
      "\n",
      "        [[-1.8981]],\n",
      "\n",
      "        [[-1.9490]]], dtype=torch.float64)\n",
      "tensor([[-1.7803],\n",
      "        [-1.6140],\n",
      "        [-1.8210],\n",
      "        [-1.7704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6266]],\n",
      "\n",
      "        [[-1.5746]],\n",
      "\n",
      "        [[-1.7965]],\n",
      "\n",
      "        [[-1.8450]]], dtype=torch.float64)\n",
      "tensor([[-1.7420],\n",
      "        [-1.7699],\n",
      "        [-1.8469],\n",
      "        [-1.3974]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0056]],\n",
      "\n",
      "        [[-2.0218]],\n",
      "\n",
      "        [[-1.5134]],\n",
      "\n",
      "        [[-1.1171]]], dtype=torch.float64)\n",
      "tensor([[-1.5751],\n",
      "        [-1.8771],\n",
      "        [-1.7705],\n",
      "        [-1.6020]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.6613]],\n",
      "\n",
      "        [[-2.0044]],\n",
      "\n",
      "        [[-1.8069]],\n",
      "\n",
      "        [[-1.5954]]], dtype=torch.float64)\n",
      "tensor([[-1.4071],\n",
      "        [-1.1338],\n",
      "        [-1.4106],\n",
      "        [-1.4388]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0940]],\n",
      "\n",
      "        [[-0.9137]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.3505]]], dtype=torch.float64)\n",
      "tensor([[-1.3090],\n",
      "        [-1.1125],\n",
      "        [-1.1448],\n",
      "        [-1.1920]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3539]],\n",
      "\n",
      "        [[-1.1564]],\n",
      "\n",
      "        [[-1.0304]],\n",
      "\n",
      "        [[-0.8271]]], dtype=torch.float64)\n",
      "tensor([[-1.0676],\n",
      "        [-1.1274],\n",
      "        [-0.9066],\n",
      "        [-0.8487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9253]],\n",
      "\n",
      "        [[-1.0616]],\n",
      "\n",
      "        [[-0.9911]],\n",
      "\n",
      "        [[-0.8594]]], dtype=torch.float64)\n",
      "tensor([[-0.6910],\n",
      "        [-0.6807],\n",
      "        [-0.5580],\n",
      "        [-0.4160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5648]],\n",
      "\n",
      "        [[-0.5139]],\n",
      "\n",
      "        [[-0.2806]],\n",
      "\n",
      "        [[-0.1927]]], dtype=torch.float64)\n",
      "tensor([[-0.2460],\n",
      "        [-0.2416],\n",
      "        [-0.0758],\n",
      "        [-0.2476]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1673]],\n",
      "\n",
      "        [[-0.2320]],\n",
      "\n",
      "        [[-0.0113]],\n",
      "\n",
      "        [[-0.0148]]], dtype=torch.float64)\n",
      "tensor([[-0.2371],\n",
      "        [-0.1964],\n",
      "        [-0.0010],\n",
      "        [ 0.0282]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0680]],\n",
      "\n",
      "        [[-0.0460]],\n",
      "\n",
      "        [[ 0.0002]],\n",
      "\n",
      "        [[-0.0391]]], dtype=torch.float64)\n",
      "tensor([[-0.2057],\n",
      "        [-0.2057],\n",
      "        [-0.4544],\n",
      "        [-0.7087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0406]],\n",
      "\n",
      "        [[ 0.2128]],\n",
      "\n",
      "        [[-0.4377]],\n",
      "\n",
      "        [[-0.7670]]], dtype=torch.float64)\n",
      "tensor([[-0.8398],\n",
      "        [-0.9930],\n",
      "        [-0.8590],\n",
      "        [-0.2867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8964]],\n",
      "\n",
      "        [[-1.1552]],\n",
      "\n",
      "        [[-0.2540]],\n",
      "\n",
      "        [[ 0.0996]]], dtype=torch.float64)\n",
      "tensor([[-0.5141],\n",
      "        [-0.4738],\n",
      "        [-0.3703],\n",
      "        [-0.2870]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2956]],\n",
      "\n",
      "        [[-0.2182]],\n",
      "\n",
      "        [[-0.2921]],\n",
      "\n",
      "        [[-0.3314]]], dtype=torch.float64)\n",
      "tensor([[-0.6147],\n",
      "        [-0.6058],\n",
      "        [-0.8538],\n",
      "        [-1.1969]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1696]],\n",
      "\n",
      "        [[-0.1569]],\n",
      "\n",
      "        [[-0.8629]],\n",
      "\n",
      "        [[-1.3285]]], dtype=torch.float64)\n",
      "tensor([[-1.3021],\n",
      "        [-1.3826],\n",
      "        [-1.1338],\n",
      "        [-0.6748]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4718]],\n",
      "\n",
      "        [[-1.5654]],\n",
      "\n",
      "        [[-0.6815]],\n",
      "\n",
      "        [[-0.3707]]], dtype=torch.float64)\n",
      "tensor([[-0.9714],\n",
      "        [-1.2548],\n",
      "        [-1.3715],\n",
      "        [-1.3767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9611]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.5515]],\n",
      "\n",
      "        [[-1.4683]]], dtype=torch.float64)\n",
      "tensor([[-1.1161],\n",
      "        [-0.3923],\n",
      "        [-0.6274],\n",
      "        [-0.6945]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5047]],\n",
      "\n",
      "        [[-0.0934]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-0.6826]]], dtype=torch.float64)\n",
      "tensor([[-0.2400],\n",
      "        [-0.2137],\n",
      "        [-0.1516],\n",
      "        [-0.0888]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3210]],\n",
      "\n",
      "        [[-0.2551]],\n",
      "\n",
      "        [[ 0.1273]],\n",
      "\n",
      "        [[ 0.1365]]], dtype=torch.float64)\n",
      "tensor([[-0.2745],\n",
      "        [-0.5679],\n",
      "        [-1.0189],\n",
      "        [-1.1183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2702]],\n",
      "\n",
      "        [[-0.6942]],\n",
      "\n",
      "        [[-1.1286]],\n",
      "\n",
      "        [[-1.2661]]], dtype=torch.float64)\n",
      "tensor([[-1.1602],\n",
      "        [-1.1280],\n",
      "        [-1.0821],\n",
      "        [-1.0300]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1679]],\n",
      "\n",
      "        [[-1.0027]],\n",
      "\n",
      "        [[-1.2083]],\n",
      "\n",
      "        [[-1.1159]]], dtype=torch.float64)\n",
      "tensor([[-0.8307],\n",
      "        [-0.7957],\n",
      "        [-0.7976],\n",
      "        [-0.6914]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0558]],\n",
      "\n",
      "        [[-0.9634]],\n",
      "\n",
      "        [[-0.8028]],\n",
      "\n",
      "        [[-0.6665]]], dtype=torch.float64)\n",
      "tensor([[-0.6973],\n",
      "        [-0.6952],\n",
      "        [-0.7638],\n",
      "        [-0.7469]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7624]],\n",
      "\n",
      "        [[-0.8814]],\n",
      "\n",
      "        [[-1.0015]],\n",
      "\n",
      "        [[-0.9888]]], dtype=torch.float64)\n",
      "tensor([[-0.7517],\n",
      "        [-0.6319],\n",
      "        [-0.7601],\n",
      "        [-0.8307]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6711]],\n",
      "\n",
      "        [[-0.6584]],\n",
      "\n",
      "        [[-0.8409]],\n",
      "\n",
      "        [[-0.8560]]], dtype=torch.float64)\n",
      "tensor([[-0.6706],\n",
      "        [-0.7236],\n",
      "        [-0.7483],\n",
      "        [-0.7650]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9368]],\n",
      "\n",
      "        [[-1.0085]],\n",
      "\n",
      "        [[-0.8120]],\n",
      "\n",
      "        [[-0.8721]]], dtype=torch.float64)\n",
      "tensor([[-0.8855],\n",
      "        [-0.8811],\n",
      "        [-0.7409],\n",
      "        [-0.7947]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9703]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-0.9796]],\n",
      "\n",
      "        [[-1.0189]]], dtype=torch.float64)\n",
      "tensor([[-0.6963],\n",
      "        [-0.3691],\n",
      "        [-0.7501],\n",
      "        [-1.0638]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3915]],\n",
      "\n",
      "        [[-0.2621]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[-1.2511]]], dtype=torch.float64)\n",
      "tensor([[-1.1410],\n",
      "        [-1.1314],\n",
      "        [-1.1809],\n",
      "        [-1.2434]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3285]],\n",
      "\n",
      "        [[-1.2696]],\n",
      "\n",
      "        [[-1.2211]],\n",
      "\n",
      "        [[-1.2869]]], dtype=torch.float64)\n",
      "tensor([[-1.2897],\n",
      "        [-1.2375],\n",
      "        [-1.2087],\n",
      "        [-1.1976]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3042]],\n",
      "\n",
      "        [[-1.3412]],\n",
      "\n",
      "        [[-1.4117]],\n",
      "\n",
      "        [[-1.4198]]], dtype=torch.float64)\n",
      "tensor([[-1.2774],\n",
      "        [-1.3626],\n",
      "        [-1.3663],\n",
      "        [-1.3257]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3435]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.4105]],\n",
      "\n",
      "        [[-1.4429]]], dtype=torch.float64)\n",
      "tensor([[-1.2421],\n",
      "        [-1.2739],\n",
      "        [-1.3193],\n",
      "        [-1.4092]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4406]],\n",
      "\n",
      "        [[-1.4602]],\n",
      "\n",
      "        [[-1.4221]],\n",
      "\n",
      "        [[-1.3770]]], dtype=torch.float64)\n",
      "tensor([[-1.3993],\n",
      "        [-1.4229],\n",
      "        [-1.4114],\n",
      "        [-1.5224]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3967]],\n",
      "\n",
      "        [[-1.4960]],\n",
      "\n",
      "        [[-1.6497]],\n",
      "\n",
      "        [[-1.7502]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.12796:  40%|███▉      | 1222/3067 [00:03<00:06, 300.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6728],\n",
      "        [-1.7824],\n",
      "        [-1.8326],\n",
      "        [-1.7190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7549]],\n",
      "\n",
      "        [[-1.7988]],\n",
      "\n",
      "        [[-1.9051]],\n",
      "\n",
      "        [[-2.0807]]], dtype=torch.float64)\n",
      "tensor([[-1.9430],\n",
      "        [-1.9854],\n",
      "        [-1.9410],\n",
      "        [-1.8684]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2655]],\n",
      "\n",
      "        [[-2.2309]],\n",
      "\n",
      "        [[-1.9397]],\n",
      "\n",
      "        [[-1.8415]]], dtype=torch.float64)\n",
      "tensor([[-1.9140],\n",
      "        [-2.0043],\n",
      "        [-2.0516],\n",
      "        [-2.0965]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.0229]],\n",
      "\n",
      "        [[-2.2436]],\n",
      "\n",
      "        [[-2.4158]],\n",
      "\n",
      "        [[-2.3776]]], dtype=torch.float64)\n",
      "tensor([[-2.1829],\n",
      "        [-1.9958],\n",
      "        [-2.0208],\n",
      "        [-2.0690]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1974]],\n",
      "\n",
      "        [[-1.7826]],\n",
      "\n",
      "        [[-2.0495]],\n",
      "\n",
      "        [[-2.4019]]], dtype=torch.float64)\n",
      "tensor([[-2.2299],\n",
      "        [-2.3655],\n",
      "        [-2.0794],\n",
      "        [-1.6840]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6341]],\n",
      "\n",
      "        [[-2.6803]],\n",
      "\n",
      "        [[-1.8057]],\n",
      "\n",
      "        [[-1.3574]]], dtype=torch.float64)\n",
      "tensor([[-1.8318],\n",
      "        [-1.9965],\n",
      "        [-2.0839],\n",
      "        [-1.9863]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8854]],\n",
      "\n",
      "        [[-2.1824]],\n",
      "\n",
      "        [[-2.3418]],\n",
      "\n",
      "        [[-1.8669]]], dtype=torch.float64)\n",
      "tensor([[-1.5127],\n",
      "        [-1.1683],\n",
      "        [-1.3139],\n",
      "        [-1.3587]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8918]],\n",
      "\n",
      "        [[-0.4620]],\n",
      "\n",
      "        [[-0.9900]],\n",
      "\n",
      "        [[-1.1009]]], dtype=torch.float64)\n",
      "tensor([[-1.3980],\n",
      "        [-1.6156],\n",
      "        [-1.3035],\n",
      "        [-1.1452]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4649]],\n",
      "\n",
      "        [[-1.4360]],\n",
      "\n",
      "        [[-0.5740]],\n",
      "\n",
      "        [[-0.5359]]], dtype=torch.float64)\n",
      "tensor([[-1.3663],\n",
      "        [-1.4731],\n",
      "        [-1.5005],\n",
      "        [-1.6183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1228]],\n",
      "\n",
      "        [[-1.4348]],\n",
      "\n",
      "        [[-1.5376]],\n",
      "\n",
      "        [[-1.5665]]], dtype=torch.float64)\n",
      "tensor([[-1.2986],\n",
      "        [-0.8850],\n",
      "        [-1.0967],\n",
      "        [-1.2025]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6064]],\n",
      "\n",
      "        [[-0.2505]],\n",
      "\n",
      "        [[-0.8779]],\n",
      "\n",
      "        [[-1.1598]]], dtype=torch.float64)\n",
      "tensor([[-1.2215],\n",
      "        [-1.1790],\n",
      "        [-1.0097],\n",
      "        [-0.6502]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2892]],\n",
      "\n",
      "        [[-1.2187]],\n",
      "\n",
      "        [[-0.8120]],\n",
      "\n",
      "        [[-0.4296]]], dtype=torch.float64)\n",
      "tensor([[-0.7006],\n",
      "        [-1.0015],\n",
      "        [-1.1086],\n",
      "        [-1.3539]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7046]],\n",
      "\n",
      "        [[-1.0616]],\n",
      "\n",
      "        [[-1.3574]],\n",
      "\n",
      "        [[-1.4718]]], dtype=torch.float64)\n",
      "tensor([[-1.0674],\n",
      "        [-0.6822],\n",
      "        [-0.8170],\n",
      "        [-0.9855]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5128]],\n",
      "\n",
      "        [[-0.2413]],\n",
      "\n",
      "        [[-0.6618]],\n",
      "\n",
      "        [[-1.0454]]], dtype=torch.float64)\n",
      "tensor([[-1.0979],\n",
      "        [-1.2052],\n",
      "        [-1.2784],\n",
      "        [-1.2087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2881]],\n",
      "\n",
      "        [[-1.3274]],\n",
      "\n",
      "        [[-1.0905]],\n",
      "\n",
      "        [[-0.7127]]], dtype=torch.float64)\n",
      "tensor([[-1.1629],\n",
      "        [-1.2354],\n",
      "        [-1.4022],\n",
      "        [-1.5200]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9079]],\n",
      "\n",
      "        [[-1.1887]],\n",
      "\n",
      "        [[-1.5157]],\n",
      "\n",
      "        [[-1.5792]]], dtype=torch.float64)\n",
      "tensor([[-1.3957],\n",
      "        [-1.1153],\n",
      "        [-1.2627],\n",
      "        [-1.2224]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8698]],\n",
      "\n",
      "        [[-0.4758]],\n",
      "\n",
      "        [[-0.9045]],\n",
      "\n",
      "        [[-1.2661]]], dtype=torch.float64)\n",
      "tensor([[-1.3342],\n",
      "        [-1.4200],\n",
      "        [-1.3846],\n",
      "        [-1.2124]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4568]],\n",
      "\n",
      "        [[-1.5561]],\n",
      "\n",
      "        [[-1.0720]],\n",
      "\n",
      "        [[-0.7312]]], dtype=torch.float64)\n",
      "tensor([[-1.1285],\n",
      "        [-1.2114],\n",
      "        [-1.2384],\n",
      "        [-1.3969]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9646]],\n",
      "\n",
      "        [[-1.3077]],\n",
      "\n",
      "        [[-1.5711]],\n",
      "\n",
      "        [[-1.4926]]], dtype=torch.float64)\n",
      "tensor([[-0.9865],\n",
      "        [-0.6078],\n",
      "        [-0.8876],\n",
      "        [-1.1456]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6746]],\n",
      "\n",
      "        [[-0.3845]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.4129]]], dtype=torch.float64)\n",
      "tensor([[-1.1568],\n",
      "        [-1.2480],\n",
      "        [-0.9010],\n",
      "        [-0.6423]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.5457]],\n",
      "\n",
      "        [[-1.6624]],\n",
      "\n",
      "        [[-0.5001]],\n",
      "\n",
      "        [[-0.2702]]], dtype=torch.float64)\n",
      "tensor([[-0.7113],\n",
      "        [-1.0607],\n",
      "        [-0.9209],\n",
      "        [-0.9840]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1125]],\n",
      "\n",
      "        [[-1.2996]],\n",
      "\n",
      "        [[-1.2153]],\n",
      "\n",
      "        [[-1.2130]]], dtype=torch.float64)\n",
      "tensor([[-0.9815],\n",
      "        [-1.0481],\n",
      "        [-1.1507],\n",
      "        [-1.1419]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7843]],\n",
      "\n",
      "        [[-0.6757]],\n",
      "\n",
      "        [[-1.0212]],\n",
      "\n",
      "        [[-1.4903]]], dtype=torch.float64)\n",
      "tensor([[-1.2176],\n",
      "        [-1.3855],\n",
      "        [-0.9515],\n",
      "        [-0.8238]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7167]],\n",
      "\n",
      "        [[-1.5434]],\n",
      "\n",
      "        [[-0.7612]],\n",
      "\n",
      "        [[-0.4562]]], dtype=torch.float64)\n",
      "tensor([[-0.9331],\n",
      "        [-1.0246],\n",
      "        [-1.0201],\n",
      "        [-1.0352]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0293]],\n",
      "\n",
      "        [[-1.2777]],\n",
      "\n",
      "        [[-1.4498]],\n",
      "\n",
      "        [[-1.2927]]], dtype=torch.float64)\n",
      "tensor([[-0.7350],\n",
      "        [-0.5066],\n",
      "        [-0.5946],\n",
      "        [-0.7292]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2817]],\n",
      "\n",
      "        [[ 0.0406]],\n",
      "\n",
      "        [[-0.5648]],\n",
      "\n",
      "        [[-1.0142]]], dtype=torch.float64)\n",
      "tensor([[-0.8723],\n",
      "        [-0.8807],\n",
      "        [ 0.0050],\n",
      "        [ 0.1627]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1829]],\n",
      "\n",
      "        [[-1.0616]],\n",
      "\n",
      "        [[ 0.3041]],\n",
      "\n",
      "        [[ 0.3607]]], dtype=torch.float64)\n",
      "tensor([[-0.0893],\n",
      "        [-0.2048],\n",
      "        [-0.3846],\n",
      "        [-0.4397]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0425]],\n",
      "\n",
      "        [[-0.3152]],\n",
      "\n",
      "        [[-0.6965]],\n",
      "\n",
      "        [[-0.6457]]], dtype=torch.float64)\n",
      "tensor([[-0.1693],\n",
      "        [-0.1261],\n",
      "        [-0.2591],\n",
      "        [-0.1013]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1396]],\n",
      "\n",
      "        [[ 0.0164]],\n",
      "\n",
      "        [[-0.1015]],\n",
      "\n",
      "        [[-0.2124]]], dtype=torch.float64)\n",
      "tensor([[-0.0115],\n",
      "        [ 0.0034],\n",
      "        [-0.0928],\n",
      "        [-0.1571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2378]],\n",
      "\n",
      "        [[-0.1927]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[ 0.0210]]], dtype=torch.float64)\n",
      "tensor([[-0.2403],\n",
      "        [-0.3792],\n",
      "        [-0.5789],\n",
      "        [-0.7405]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3464]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-1.0362]],\n",
      "\n",
      "        [[-1.0154]]], dtype=torch.float64)\n",
      "tensor([[-0.2879],\n",
      "        [-0.0453],\n",
      "        [-0.2103],\n",
      "        [-0.4269]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2140]],\n",
      "\n",
      "        [[ 0.5640]],\n",
      "\n",
      "        [[-0.1673]],\n",
      "\n",
      "        [[-0.8063]]], dtype=torch.float64)\n",
      "tensor([[-0.5459],\n",
      "        [-0.6579],\n",
      "        [-0.0224],\n",
      "        [ 0.1361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7554]],\n",
      "\n",
      "        [[-0.5267]],\n",
      "\n",
      "        [[ 0.4312]],\n",
      "\n",
      "        [[ 0.6715]]], dtype=torch.float64)\n",
      "tensor([[ 0.0516],\n",
      "        [ 0.0268],\n",
      "        [-0.0096],\n",
      "        [-0.0943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3191]],\n",
      "\n",
      "        [[ 0.0095]],\n",
      "\n",
      "        [[-0.1604]],\n",
      "\n",
      "        [[-0.3522]]], dtype=torch.float64)\n",
      "tensor([[0.0589],\n",
      "        [0.0298],\n",
      "        [0.0496],\n",
      "        [0.0985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3064]],\n",
      "\n",
      "        [[ 0.3133]],\n",
      "\n",
      "        [[ 0.1215]],\n",
      "\n",
      "        [[-0.1015]]], dtype=torch.float64)\n",
      "tensor([[ 0.0562],\n",
      "        [-0.0715],\n",
      "        [ 0.0065],\n",
      "        [ 0.0088]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2482]],\n",
      "\n",
      "        [[-0.2263]],\n",
      "\n",
      "        [[ 0.4127]],\n",
      "\n",
      "        [[ 0.3272]]], dtype=torch.float64)\n",
      "tensor([[-0.1946],\n",
      "        [-0.2629],\n",
      "        [-0.2236],\n",
      "        [-0.3809]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1997]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.5174]],\n",
      "\n",
      "        [[-0.6653]]], dtype=torch.float64)\n",
      "tensor([[-0.5300],\n",
      "        [-0.5617],\n",
      "        [-0.5745],\n",
      "        [-0.2911]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6849]],\n",
      "\n",
      "        [[-0.5324]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.2008]]], dtype=torch.float64)\n",
      "tensor([[-0.1708],\n",
      "        [-0.2114],\n",
      "        [-0.3657],\n",
      "        [-0.5494]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3233]],\n",
      "\n",
      "        [[-0.4261]],\n",
      "\n",
      "        [[-0.5278]],\n",
      "\n",
      "        [[-0.6561]]], dtype=torch.float64)\n",
      "tensor([[-0.5963],\n",
      "        [-0.5874],\n",
      "        [-0.4945],\n",
      "        [-0.3713]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7300]],\n",
      "\n",
      "        [[-0.7520]],\n",
      "\n",
      "        [[-0.6722]],\n",
      "\n",
      "        [[-0.5740]]], dtype=torch.float64)\n",
      "tensor([[-0.4719],\n",
      "        [-0.5688],\n",
      "        [-0.5961],\n",
      "        [-0.4936]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5659]],\n",
      "\n",
      "        [[-0.5983]],\n",
      "\n",
      "        [[-0.7300]],\n",
      "\n",
      "        [[-0.7196]]], dtype=torch.float64)\n",
      "tensor([[-0.4261],\n",
      "        [-0.5591],\n",
      "        [-0.6964],\n",
      "        [-0.5569]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8294]],\n",
      "\n",
      "        [[-0.8929]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[-0.2863]]], dtype=torch.float64)\n",
      "tensor([[-0.6193],\n",
      "        [-0.7624],\n",
      "        [-0.8138],\n",
      "        [-0.8826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6468]],\n",
      "\n",
      "        [[-1.2673]],\n",
      "\n",
      "        [[-1.4441]],\n",
      "\n",
      "        [[-1.3551]]], dtype=torch.float64)\n",
      "tensor([[-0.5121],\n",
      "        [-0.4614],\n",
      "        [-0.4615],\n",
      "        [-0.5879]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3429]],\n",
      "\n",
      "        [[-0.2863]],\n",
      "\n",
      "        [[-0.5544]],\n",
      "\n",
      "        [[-0.9750]]], dtype=torch.float64)\n",
      "tensor([[-0.7041],\n",
      "        [-0.7888],\n",
      "        [-0.3771],\n",
      "        [-0.1973]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3528]],\n",
      "\n",
      "        [[-0.9923]],\n",
      "\n",
      "        [[-0.0310]],\n",
      "\n",
      "        [[ 0.2405]]], dtype=torch.float64)\n",
      "tensor([[-0.2230],\n",
      "        [-0.5060],\n",
      "        [-0.6657],\n",
      "        [-0.7468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3869]],\n",
      "\n",
      "        [[-0.9750]],\n",
      "\n",
      "        [[-1.2107]],\n",
      "\n",
      "        [[-0.8895]]], dtype=torch.float64)\n",
      "tensor([[-0.1544],\n",
      "        [-0.1454],\n",
      "        [-0.1002],\n",
      "        [-0.3519]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3896]],\n",
      "\n",
      "        [[ 0.5987]],\n",
      "\n",
      "        [[-0.0957]],\n",
      "\n",
      "        [[-0.7358]]], dtype=torch.float64)\n",
      "tensor([[-0.5158],\n",
      "        [-0.5801],\n",
      "        [-0.0716],\n",
      "        [-0.0597]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9819]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[ 0.2648]],\n",
      "\n",
      "        [[ 0.4797]]], dtype=torch.float64)\n",
      "tensor([[-0.1079],\n",
      "        [-0.3436],\n",
      "        [-0.4987],\n",
      "        [-0.6180]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 2.0721e-04]],\n",
      "\n",
      "        [[-6.6531e-01]],\n",
      "\n",
      "        [[-9.9691e-01]],\n",
      "\n",
      "        [[-7.2192e-01]]], dtype=torch.float64)\n",
      "tensor([[-0.0432],\n",
      "        [ 0.0667],\n",
      "        [ 0.0765],\n",
      "        [-0.1818]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3237]],\n",
      "\n",
      "        [[ 0.5987]],\n",
      "\n",
      "        [[ 0.1458]],\n",
      "\n",
      "        [[-0.5856]]], dtype=torch.float64)\n",
      "tensor([[-0.3963],\n",
      "        [-0.5478],\n",
      "        [-0.0080],\n",
      "        [ 0.0748]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8305]],\n",
      "\n",
      "        [[-0.8167]],\n",
      "\n",
      "        [[ 0.4450]],\n",
      "\n",
      "        [[ 0.4901]]], dtype=torch.float64)\n",
      "tensor([[-0.1021],\n",
      "        [-0.1476],\n",
      "        [-0.2501],\n",
      "        [-0.5034]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1100]],\n",
      "\n",
      "        [[-0.1893]],\n",
      "\n",
      "        [[-0.4550]],\n",
      "\n",
      "        [[-0.5463]]], dtype=torch.float64)\n",
      "tensor([[-0.5052],\n",
      "        [-0.5514],\n",
      "        [-0.7204],\n",
      "        [-0.6254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4388]],\n",
      "\n",
      "        [[-0.7462]],\n",
      "\n",
      "        [[-0.7878]],\n",
      "\n",
      "        [[-0.8328]]], dtype=torch.float64)\n",
      "tensor([[-0.7132],\n",
      "        [-0.7723],\n",
      "        [-0.3690],\n",
      "        [-0.3243]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2095]],\n",
      "\n",
      "        [[-1.2476]],\n",
      "\n",
      "        [[-0.2632]],\n",
      "\n",
      "        [[ 0.0406]]], dtype=torch.float64)\n",
      "tensor([[-0.4374],\n",
      "        [-0.6322],\n",
      "        [-0.7317],\n",
      "        [-0.7711]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4296]],\n",
      "\n",
      "        [[-0.9345]],\n",
      "\n",
      "        [[-1.1737]],\n",
      "\n",
      "        [[-0.8513]]], dtype=torch.float64)\n",
      "tensor([[-0.3042],\n",
      "        [-0.3138],\n",
      "        [-0.4804],\n",
      "        [-0.6211]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1169]],\n",
      "\n",
      "        [[ 0.3503]],\n",
      "\n",
      "        [[-0.3788]],\n",
      "\n",
      "        [[-0.8848]]], dtype=torch.float64)\n",
      "tensor([[-0.7594],\n",
      "        [-0.8094],\n",
      "        [-0.1650],\n",
      "        [ 0.0276]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2927]],\n",
      "\n",
      "        [[-0.9045]],\n",
      "\n",
      "        [[ 0.3538]],\n",
      "\n",
      "        [[ 0.7928]]], dtype=torch.float64)\n",
      "tensor([[-0.0544],\n",
      "        [-0.4136],\n",
      "        [-0.6332],\n",
      "        [-0.6760]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0510]],\n",
      "\n",
      "        [[-0.5717]],\n",
      "\n",
      "        [[-1.0327]],\n",
      "\n",
      "        [[-0.7185]]], dtype=torch.float64)\n",
      "tensor([[0.1225],\n",
      "        [0.2004],\n",
      "        [0.1195],\n",
      "        [0.1227]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7974]],\n",
      "\n",
      "        [[ 0.8610]],\n",
      "\n",
      "        [[ 0.4011]],\n",
      "\n",
      "        [[-0.0633]]], dtype=torch.float64)\n",
      "tensor([[0.0867],\n",
      "        [0.0946],\n",
      "        [0.2434],\n",
      "        [0.1882]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0784]],\n",
      "\n",
      "        [[ 0.1354]],\n",
      "\n",
      "        [[ 0.3445]],\n",
      "\n",
      "        [[ 0.2833]]], dtype=torch.float64)\n",
      "tensor([[0.1641],\n",
      "        [0.2624],\n",
      "        [0.4341],\n",
      "        [0.4243]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2914]],\n",
      "\n",
      "        [[0.2787]],\n",
      "\n",
      "        [[0.3445]],\n",
      "\n",
      "        [[0.4612]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.12796:  42%|████▏     | 1284/3067 [00:03<00:06, 291.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3424],\n",
      "        [0.3157],\n",
      "        [0.2920],\n",
      "        [0.3454]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7917]],\n",
      "\n",
      "        [[0.7397]],\n",
      "\n",
      "        [[0.5063]],\n",
      "\n",
      "        [[0.2891]]], dtype=torch.float64)\n",
      "tensor([[0.2396],\n",
      "        [0.1760],\n",
      "        [0.6179],\n",
      "        [0.8019]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0449]],\n",
      "\n",
      "        [[ 0.1712]],\n",
      "\n",
      "        [[ 1.1117]],\n",
      "\n",
      "        [[ 1.4202]]], dtype=torch.float64)\n",
      "tensor([[0.6754],\n",
      "        [0.3930],\n",
      "        [0.2729],\n",
      "        [0.1475]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8517]],\n",
      "\n",
      "        [[0.2290]],\n",
      "\n",
      "        [[0.0164]],\n",
      "\n",
      "        [[0.3746]]], dtype=torch.float64)\n",
      "tensor([[0.7045],\n",
      "        [0.8919],\n",
      "        [0.5255],\n",
      "        [0.3648]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4410]],\n",
      "\n",
      "        [[1.5357]],\n",
      "\n",
      "        [[0.8275]],\n",
      "\n",
      "        [[0.4335]]], dtype=torch.float64)\n",
      "tensor([[ 0.3112],\n",
      "        [ 0.0723],\n",
      "        [-0.0555],\n",
      "        [ 0.0403]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1435]],\n",
      "\n",
      "        [[-0.1881]],\n",
      "\n",
      "        [[ 0.0083]],\n",
      "\n",
      "        [[ 0.2602]]], dtype=torch.float64)\n",
      "tensor([[-0.0006],\n",
      "        [-0.2355],\n",
      "        [-0.2710],\n",
      "        [-0.2963]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1477]],\n",
      "\n",
      "        [[-0.4712]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.4620]]], dtype=torch.float64)\n",
      "tensor([[0.1389],\n",
      "        [0.0638],\n",
      "        [0.0155],\n",
      "        [0.1846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3353]],\n",
      "\n",
      "        [[0.4681]],\n",
      "\n",
      "        [[0.3133]],\n",
      "\n",
      "        [[0.1851]]], dtype=torch.float64)\n",
      "tensor([[0.2759],\n",
      "        [0.3709],\n",
      "        [0.5364],\n",
      "        [0.5156]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0356]],\n",
      "\n",
      "        [[ 0.2093]],\n",
      "\n",
      "        [[ 0.9292]],\n",
      "\n",
      "        [[ 0.9788]]], dtype=torch.float64)\n",
      "tensor([[0.5135],\n",
      "        [0.6080],\n",
      "        [0.5288],\n",
      "        [0.3714]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7859]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.0476]],\n",
      "\n",
      "        [[0.6854]]], dtype=torch.float64)\n",
      "tensor([[0.9468],\n",
      "        [0.6545],\n",
      "        [0.2504],\n",
      "        [0.0831]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.3509]],\n",
      "\n",
      "        [[ 1.0539]],\n",
      "\n",
      "        [[ 0.2532]],\n",
      "\n",
      "        [[-0.1096]]], dtype=torch.float64)\n",
      "tensor([[-0.0501],\n",
      "        [-0.1851],\n",
      "        [-0.0388],\n",
      "        [ 0.1971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4504]],\n",
      "\n",
      "        [[-0.0714]],\n",
      "\n",
      "        [[ 0.3006]],\n",
      "\n",
      "        [[ 0.8217]]], dtype=torch.float64)\n",
      "tensor([[ 0.1971],\n",
      "        [ 0.2506],\n",
      "        [ 0.0267],\n",
      "        [-0.1210]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4716]],\n",
      "\n",
      "        [[ 0.0626]],\n",
      "\n",
      "        [[-0.3845]],\n",
      "\n",
      "        [[-0.2644]]], dtype=torch.float64)\n",
      "tensor([[-0.1060],\n",
      "        [ 0.0266],\n",
      "        [-0.1212],\n",
      "        [-0.1959]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2070]],\n",
      "\n",
      "        [[ 0.5097]],\n",
      "\n",
      "        [[ 0.0626]],\n",
      "\n",
      "        [[-0.5186]]], dtype=torch.float64)\n",
      "tensor([[-0.3860],\n",
      "        [-0.4259],\n",
      "        [ 0.1929],\n",
      "        [ 0.1915]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9091]],\n",
      "\n",
      "        [[-0.4238]],\n",
      "\n",
      "        [[ 0.5109]],\n",
      "\n",
      "        [[ 0.7674]]], dtype=torch.float64)\n",
      "tensor([[ 0.2056],\n",
      "        [ 0.0610],\n",
      "        [-0.1642],\n",
      "        [-0.1995]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3584]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.6849]],\n",
      "\n",
      "        [[-0.2482]]], dtype=torch.float64)\n",
      "tensor([[0.4818],\n",
      "        [0.6756],\n",
      "        [0.5714],\n",
      "        [0.3992]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0724]],\n",
      "\n",
      "        [[1.2065]],\n",
      "\n",
      "        [[0.6773]],\n",
      "\n",
      "        [[0.1689]]], dtype=torch.float64)\n",
      "tensor([[ 0.4063],\n",
      "        [ 0.1794],\n",
      "        [-0.1364],\n",
      "        [-0.1840]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2856]],\n",
      "\n",
      "        [[-0.1696]],\n",
      "\n",
      "        [[-0.1361]],\n",
      "\n",
      "        [[ 0.0718]]], dtype=torch.float64)\n",
      "tensor([[-0.4365],\n",
      "        [-0.4125],\n",
      "        [-0.4324],\n",
      "        [-0.3813]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4077]],\n",
      "\n",
      "        [[-0.6087]],\n",
      "\n",
      "        [[-0.5983]],\n",
      "\n",
      "        [[-0.4654]]], dtype=torch.float64)\n",
      "tensor([[-0.3431],\n",
      "        [-0.1939],\n",
      "        [-0.3412],\n",
      "        [-0.4069]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2182]],\n",
      "\n",
      "        [[ 0.1342]],\n",
      "\n",
      "        [[-0.1234]],\n",
      "\n",
      "        [[-0.5648]]], dtype=torch.float64)\n",
      "tensor([[-0.3943],\n",
      "        [-0.4288],\n",
      "        [-0.2459],\n",
      "        [-0.3299]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7265]],\n",
      "\n",
      "        [[-0.5313]],\n",
      "\n",
      "        [[-0.1038]],\n",
      "\n",
      "        [[-0.0160]]], dtype=torch.float64)\n",
      "tensor([[-0.4349],\n",
      "        [-0.3403],\n",
      "        [-0.3610],\n",
      "        [-0.2373]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2759]],\n",
      "\n",
      "        [[-0.5174]],\n",
      "\n",
      "        [[-0.7404]],\n",
      "\n",
      "        [[-0.4770]]], dtype=torch.float64)\n",
      "tensor([[-0.2199],\n",
      "        [-0.2261],\n",
      "        [-0.2828],\n",
      "        [-0.1360]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1361]],\n",
      "\n",
      "        [[ 0.1781]],\n",
      "\n",
      "        [[-0.0541]],\n",
      "\n",
      "        [[-0.2933]]], dtype=torch.float64)\n",
      "tensor([[-0.0626],\n",
      "        [ 0.0055],\n",
      "        [ 0.1357],\n",
      "        [-0.0081]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4354]],\n",
      "\n",
      "        [[ 0.1111]],\n",
      "\n",
      "        [[ 0.2914]],\n",
      "\n",
      "        [[ 0.2440]]], dtype=torch.float64)\n",
      "tensor([[-0.0696],\n",
      "        [-0.0008],\n",
      "        [ 0.0693],\n",
      "        [ 0.0540]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1030]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.3788]],\n",
      "\n",
      "        [[-0.2598]]], dtype=torch.float64)\n",
      "tensor([[ 0.2816],\n",
      "        [ 0.1648],\n",
      "        [-0.0085],\n",
      "        [-0.0933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4866]],\n",
      "\n",
      "        [[ 0.5017]],\n",
      "\n",
      "        [[ 0.3156]],\n",
      "\n",
      "        [[-0.4585]]], dtype=torch.float64)\n",
      "tensor([[-0.3316],\n",
      "        [-0.3396],\n",
      "        [ 0.3402],\n",
      "        [ 0.4060]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9033]],\n",
      "\n",
      "        [[-0.2494]],\n",
      "\n",
      "        [[ 0.7339]],\n",
      "\n",
      "        [[ 0.9372]]], dtype=torch.float64)\n",
      "tensor([[ 0.1807],\n",
      "        [ 0.2338],\n",
      "        [-0.1227],\n",
      "        [-0.1857]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4508]],\n",
      "\n",
      "        [[-0.1038]],\n",
      "\n",
      "        [[-0.7034]],\n",
      "\n",
      "        [[-0.0414]]], dtype=torch.float64)\n",
      "tensor([[0.5676],\n",
      "        [0.5897],\n",
      "        [0.3841],\n",
      "        [0.3566]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.0077]],\n",
      "\n",
      "        [[ 1.1706]],\n",
      "\n",
      "        [[ 0.7778]],\n",
      "\n",
      "        [[-0.0841]]], dtype=torch.float64)\n",
      "tensor([[-0.0300],\n",
      "        [-0.1297],\n",
      "        [ 0.7173],\n",
      "        [ 0.7820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5255]],\n",
      "\n",
      "        [[ 0.0580]],\n",
      "\n",
      "        [[ 1.2007]],\n",
      "\n",
      "        [[ 1.3474]]], dtype=torch.float64)\n",
      "tensor([[0.5343],\n",
      "        [0.5222],\n",
      "        [0.2418],\n",
      "        [0.1685]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8737]],\n",
      "\n",
      "        [[ 0.1423]],\n",
      "\n",
      "        [[-0.2990]],\n",
      "\n",
      "        [[ 0.2891]]], dtype=torch.float64)\n",
      "tensor([[0.7898],\n",
      "        [0.7791],\n",
      "        [0.6723],\n",
      "        [0.5413]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3382]],\n",
      "\n",
      "        [[1.4387]],\n",
      "\n",
      "        [[0.9580]],\n",
      "\n",
      "        [[0.1573]]], dtype=torch.float64)\n",
      "tensor([[0.2273],\n",
      "        [0.1624],\n",
      "        [0.7490],\n",
      "        [0.8771]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2817]],\n",
      "\n",
      "        [[ 0.3214]],\n",
      "\n",
      "        [[ 1.3035]],\n",
      "\n",
      "        [[ 1.5057]]], dtype=torch.float64)\n",
      "tensor([[0.7790],\n",
      "        [0.6722],\n",
      "        [0.3130],\n",
      "        [0.2338]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.0632]],\n",
      "\n",
      "        [[ 0.3249]],\n",
      "\n",
      "        [[-0.2078]],\n",
      "\n",
      "        [[ 0.4439]]], dtype=torch.float64)\n",
      "tensor([[0.7057],\n",
      "        [0.8407],\n",
      "        [0.6568],\n",
      "        [0.6076]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3035]],\n",
      "\n",
      "        [[1.4826]],\n",
      "\n",
      "        [[1.0516]],\n",
      "\n",
      "        [[0.6738]]], dtype=torch.float64)\n",
      "tensor([[0.5619],\n",
      "        [0.3433],\n",
      "        [0.5997],\n",
      "        [0.5283]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1539]],\n",
      "\n",
      "        [[0.3191]],\n",
      "\n",
      "        [[1.0031]],\n",
      "\n",
      "        [[1.1094]]], dtype=torch.float64)\n",
      "tensor([[0.4463],\n",
      "        [0.3789],\n",
      "        [0.1200],\n",
      "        [0.0541]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7593]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[-0.5290]],\n",
      "\n",
      "        [[ 0.2163]]], dtype=torch.float64)\n",
      "tensor([[0.4481],\n",
      "        [0.2921],\n",
      "        [0.2504],\n",
      "        [0.2352]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7443]],\n",
      "\n",
      "        [[ 0.7270]],\n",
      "\n",
      "        [[ 0.4427]],\n",
      "\n",
      "        [[-0.1766]]], dtype=torch.float64)\n",
      "tensor([[0.0836],\n",
      "        [0.0311],\n",
      "        [0.3067],\n",
      "        [0.2192]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5290]],\n",
      "\n",
      "        [[-0.0553]],\n",
      "\n",
      "        [[ 0.4866]],\n",
      "\n",
      "        [[ 0.0175]]], dtype=torch.float64)\n",
      "tensor([[0.0428],\n",
      "        [0.1190],\n",
      "        [0.2392],\n",
      "        [0.2065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0302]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[-0.1211]],\n",
      "\n",
      "        [[-0.0541]]], dtype=torch.float64)\n",
      "tensor([[0.3253],\n",
      "        [0.2603],\n",
      "        [0.2298],\n",
      "        [0.2958]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3283]],\n",
      "\n",
      "        [[0.4658]],\n",
      "\n",
      "        [[0.3249]],\n",
      "\n",
      "        [[0.0487]]], dtype=torch.float64)\n",
      "tensor([[0.2617],\n",
      "        [0.3408],\n",
      "        [0.6381],\n",
      "        [0.6008]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0449]],\n",
      "\n",
      "        [[ 0.1851]],\n",
      "\n",
      "        [[ 0.8806]],\n",
      "\n",
      "        [[ 1.0320]]], dtype=torch.float64)\n",
      "tensor([[0.7697],\n",
      "        [0.3276],\n",
      "        [0.2796],\n",
      "        [0.2745]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4115]],\n",
      "\n",
      "        [[ 0.0372]],\n",
      "\n",
      "        [[-0.2170]],\n",
      "\n",
      "        [[ 0.2960]]], dtype=torch.float64)\n",
      "tensor([[0.6849],\n",
      "        [0.7747],\n",
      "        [0.5865],\n",
      "        [0.4807]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2261]],\n",
      "\n",
      "        [[1.0724]],\n",
      "\n",
      "        [[0.8171]],\n",
      "\n",
      "        [[0.3838]]], dtype=torch.float64)\n",
      "tensor([[0.4604],\n",
      "        [0.2205],\n",
      "        [0.4074],\n",
      "        [0.4854]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0079]],\n",
      "\n",
      "        [[ 0.1215]],\n",
      "\n",
      "        [[ 0.7824]],\n",
      "\n",
      "        [[ 1.0077]]], dtype=torch.float64)\n",
      "tensor([[ 0.3127],\n",
      "        [ 0.0018],\n",
      "        [-0.1646],\n",
      "        [-0.2550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5814]],\n",
      "\n",
      "        [[-0.0553]],\n",
      "\n",
      "        [[-0.5313]],\n",
      "\n",
      "        [[-0.2447]]], dtype=torch.float64)\n",
      "tensor([[ 0.0614],\n",
      "        [-0.0022],\n",
      "        [-0.0460],\n",
      "        [-0.2486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3561]],\n",
      "\n",
      "        [[ 0.5710]],\n",
      "\n",
      "        [[ 0.1874]],\n",
      "\n",
      "        [[-0.3210]]], dtype=torch.float64)\n",
      "tensor([[-0.2976],\n",
      "        [-0.3586],\n",
      "        [-0.2411],\n",
      "        [-0.2585]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6780]],\n",
      "\n",
      "        [[-0.6237]],\n",
      "\n",
      "        [[-0.2390]],\n",
      "\n",
      "        [[-0.1904]]], dtype=torch.float64)\n",
      "tensor([[-0.3901],\n",
      "        [-0.3853],\n",
      "        [-0.4051],\n",
      "        [-0.4825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3210]],\n",
      "\n",
      "        [[-0.5151]],\n",
      "\n",
      "        [[-0.7381]],\n",
      "\n",
      "        [[-0.8432]]], dtype=torch.float64)\n",
      "tensor([[-0.4067],\n",
      "        [-0.4364],\n",
      "        [-0.4244],\n",
      "        [-0.5386]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2875]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[-1.0385]]], dtype=torch.float64)\n",
      "tensor([[-0.5839],\n",
      "        [-0.4061],\n",
      "        [ 0.0672],\n",
      "        [-0.1129]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2777]],\n",
      "\n",
      "        [[-0.5382]],\n",
      "\n",
      "        [[ 0.1238]],\n",
      "\n",
      "        [[-0.3187]]], dtype=torch.float64)\n",
      "tensor([[-0.2890],\n",
      "        [-0.2043],\n",
      "        [-0.2338],\n",
      "        [-0.2599]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3730]],\n",
      "\n",
      "        [[-0.5948]],\n",
      "\n",
      "        [[-0.9923]],\n",
      "\n",
      "        [[-0.4181]]], dtype=torch.float64)\n",
      "tensor([[0.3036],\n",
      "        [0.2415],\n",
      "        [0.1164],\n",
      "        [0.0398]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3711]],\n",
      "\n",
      "        [[ 0.5895]],\n",
      "\n",
      "        [[ 0.2012]],\n",
      "\n",
      "        [[-0.3996]]], dtype=torch.float64)\n",
      "tensor([[-0.2060],\n",
      "        [-0.0246],\n",
      "        [ 0.7458],\n",
      "        [ 0.7710]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8687]],\n",
      "\n",
      "        [[ 0.0510]],\n",
      "\n",
      "        [[ 0.9500]],\n",
      "\n",
      "        [[ 1.3220]]], dtype=torch.float64)\n",
      "tensor([[0.7255],\n",
      "        [0.5432],\n",
      "        [0.2828],\n",
      "        [0.4104]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8714]],\n",
      "\n",
      "        [[ 0.1828]],\n",
      "\n",
      "        [[-0.5290]],\n",
      "\n",
      "        [[ 0.4959]]], dtype=torch.float64)\n",
      "tensor([[0.9804],\n",
      "        [0.9757],\n",
      "        [0.7678],\n",
      "        [0.6657]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4791]],\n",
      "\n",
      "        [[1.6062]],\n",
      "\n",
      "        [[1.0285]],\n",
      "\n",
      "        [[0.4508]]], dtype=torch.float64)\n",
      "tensor([[0.5142],\n",
      "        [0.3850],\n",
      "        [0.8033],\n",
      "        [0.8464]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3811]],\n",
      "\n",
      "        [[ 0.4150]],\n",
      "\n",
      "        [[ 1.1221]],\n",
      "\n",
      "        [[ 1.2492]]], dtype=torch.float64)\n",
      "tensor([[0.8533],\n",
      "        [0.7568],\n",
      "        [0.6141],\n",
      "        [0.5320]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9534]],\n",
      "\n",
      "        [[ 0.3803]],\n",
      "\n",
      "        [[-0.0194]],\n",
      "\n",
      "        [[ 0.6264]]], dtype=torch.float64)\n",
      "tensor([[1.0565],\n",
      "        [0.9872],\n",
      "        [0.9378],\n",
      "        [0.8197]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3347]],\n",
      "\n",
      "        [[1.6282]],\n",
      "\n",
      "        [[1.1036]],\n",
      "\n",
      "        [[0.5698]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13604:  44%|████▍     | 1349/3067 [00:04<00:05, 302.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5254],\n",
      "        [0.5514],\n",
      "        [1.1634],\n",
      "        [1.1992]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2424]],\n",
      "\n",
      "        [[ 0.7408]],\n",
      "\n",
      "        [[ 1.6917]],\n",
      "\n",
      "        [[ 1.8038]]], dtype=torch.float64)\n",
      "tensor([[1.0492],\n",
      "        [0.8414],\n",
      "        [0.6252],\n",
      "        [0.6041]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2966]],\n",
      "\n",
      "        [[0.4046]],\n",
      "\n",
      "        [[0.0395]],\n",
      "\n",
      "        [[0.8413]]], dtype=torch.float64)\n",
      "tensor([[1.2054],\n",
      "        [1.1822],\n",
      "        [0.7536],\n",
      "        [0.6720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5357]],\n",
      "\n",
      "        [[1.6039]],\n",
      "\n",
      "        [[0.7108]],\n",
      "\n",
      "        [[0.3272]]], dtype=torch.float64)\n",
      "tensor([[0.6583],\n",
      "        [0.5885],\n",
      "        [0.9536],\n",
      "        [0.9312]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1747]],\n",
      "\n",
      "        [[0.3526]],\n",
      "\n",
      "        [[1.2376]],\n",
      "\n",
      "        [[0.8205]]], dtype=torch.float64)\n",
      "tensor([[0.5506],\n",
      "        [0.4516],\n",
      "        [0.3800],\n",
      "        [0.4427]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5225]],\n",
      "\n",
      "        [[ 0.1042]],\n",
      "\n",
      "        [[-0.0622]],\n",
      "\n",
      "        [[ 0.3630]]], dtype=torch.float64)\n",
      "tensor([[0.5118],\n",
      "        [0.5931],\n",
      "        [0.5250],\n",
      "        [0.4087]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7246]],\n",
      "\n",
      "        [[1.0112]],\n",
      "\n",
      "        [[0.6184]],\n",
      "\n",
      "        [[0.0048]]], dtype=torch.float64)\n",
      "tensor([[0.1921],\n",
      "        [0.3734],\n",
      "        [0.8892],\n",
      "        [0.7003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3025]],\n",
      "\n",
      "        [[ 0.4196]],\n",
      "\n",
      "        [[ 1.1568]],\n",
      "\n",
      "        [[ 0.8541]]], dtype=torch.float64)\n",
      "tensor([[0.3964],\n",
      "        [0.2800],\n",
      "        [0.2623],\n",
      "        [0.4435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2902]],\n",
      "\n",
      "        [[-0.0402]],\n",
      "\n",
      "        [[-0.2101]],\n",
      "\n",
      "        [[ 0.1100]]], dtype=torch.float64)\n",
      "tensor([[0.2632],\n",
      "        [0.2692],\n",
      "        [0.2894],\n",
      "        [0.1126]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4266]],\n",
      "\n",
      "        [[ 0.5271]],\n",
      "\n",
      "        [[-0.0264]],\n",
      "\n",
      "        [[-0.2840]]], dtype=torch.float64)\n",
      "tensor([[0.1755],\n",
      "        [0.3279],\n",
      "        [0.4235],\n",
      "        [0.3443]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3834]],\n",
      "\n",
      "        [[ 0.0695]],\n",
      "\n",
      "        [[ 0.5086]],\n",
      "\n",
      "        [[ 0.4323]]], dtype=torch.float64)\n",
      "tensor([[0.3891],\n",
      "        [0.4078],\n",
      "        [0.6247],\n",
      "        [0.7051]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2486]],\n",
      "\n",
      "        [[0.1885]],\n",
      "\n",
      "        [[0.2602]],\n",
      "\n",
      "        [[0.5756]]], dtype=torch.float64)\n",
      "tensor([[0.7283],\n",
      "        [0.6681],\n",
      "        [0.6079],\n",
      "        [0.5045]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8448]],\n",
      "\n",
      "        [[0.9650]],\n",
      "\n",
      "        [[0.5906]],\n",
      "\n",
      "        [[0.1654]]], dtype=torch.float64)\n",
      "tensor([[0.4057],\n",
      "        [0.3960],\n",
      "        [1.0174],\n",
      "        [1.0150]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2043]],\n",
      "\n",
      "        [[ 0.4739]],\n",
      "\n",
      "        [[ 1.4283]],\n",
      "\n",
      "        [[ 1.6790]]], dtype=torch.float64)\n",
      "tensor([[0.9434],\n",
      "        [0.7523],\n",
      "        [0.5488],\n",
      "        [0.5326]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1429]],\n",
      "\n",
      "        [[0.4393]],\n",
      "\n",
      "        [[0.0129]],\n",
      "\n",
      "        [[0.7755]]], dtype=torch.float64)\n",
      "tensor([[1.1950],\n",
      "        [1.0490],\n",
      "        [0.9062],\n",
      "        [0.6264]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1914]],\n",
      "\n",
      "        [[1.7114]],\n",
      "\n",
      "        [[0.5999]],\n",
      "\n",
      "        [[0.4543]]], dtype=torch.float64)\n",
      "tensor([[0.6842],\n",
      "        [0.6756],\n",
      "        [1.0151],\n",
      "        [0.7186]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2821]],\n",
      "\n",
      "        [[0.5941]],\n",
      "\n",
      "        [[1.2920]],\n",
      "\n",
      "        [[1.1198]]], dtype=torch.float64)\n",
      "tensor([[0.8516],\n",
      "        [0.7065],\n",
      "        [0.6345],\n",
      "        [0.6379]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9003]],\n",
      "\n",
      "        [[0.4058]],\n",
      "\n",
      "        [[0.1550]],\n",
      "\n",
      "        [[0.6207]]], dtype=torch.float64)\n",
      "tensor([[0.9917],\n",
      "        [0.9958],\n",
      "        [1.0029],\n",
      "        [0.8472]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3312]],\n",
      "\n",
      "        [[1.4537]],\n",
      "\n",
      "        [[1.0435]],\n",
      "\n",
      "        [[0.5952]]], dtype=torch.float64)\n",
      "tensor([[0.7833],\n",
      "        [0.8807],\n",
      "        [1.2651],\n",
      "        [1.0280]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4497]],\n",
      "\n",
      "        [[1.1337]],\n",
      "\n",
      "        [[1.6813]],\n",
      "\n",
      "        [[1.7033]]], dtype=torch.float64)\n",
      "tensor([[0.9512],\n",
      "        [0.6434],\n",
      "        [0.5558],\n",
      "        [0.6324]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7974]],\n",
      "\n",
      "        [[0.3919]],\n",
      "\n",
      "        [[0.0591]],\n",
      "\n",
      "        [[0.6380]]], dtype=torch.float64)\n",
      "tensor([[0.7317],\n",
      "        [0.7442],\n",
      "        [0.7856],\n",
      "        [0.6471]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1487]],\n",
      "\n",
      "        [[1.4884]],\n",
      "\n",
      "        [[0.9453]],\n",
      "\n",
      "        [[0.2821]]], dtype=torch.float64)\n",
      "tensor([[0.4699],\n",
      "        [0.5607],\n",
      "        [1.1291],\n",
      "        [0.7692]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2390]],\n",
      "\n",
      "        [[ 1.0054]],\n",
      "\n",
      "        [[ 1.7437]],\n",
      "\n",
      "        [[ 1.1591]]], dtype=torch.float64)\n",
      "tensor([[0.4857],\n",
      "        [0.3002],\n",
      "        [0.1964],\n",
      "        [0.4361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5432]],\n",
      "\n",
      "        [[ 0.2567]],\n",
      "\n",
      "        [[-0.5521]],\n",
      "\n",
      "        [[ 0.3480]]], dtype=torch.float64)\n",
      "tensor([[0.5094],\n",
      "        [0.4668],\n",
      "        [0.4633],\n",
      "        [0.4475]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7212]],\n",
      "\n",
      "        [[1.0331]],\n",
      "\n",
      "        [[0.6646]],\n",
      "\n",
      "        [[0.1851]]], dtype=torch.float64)\n",
      "tensor([[0.2876],\n",
      "        [0.6089],\n",
      "        [1.1702],\n",
      "        [1.1883]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3603]],\n",
      "\n",
      "        [[ 0.9037]],\n",
      "\n",
      "        [[ 1.7738]],\n",
      "\n",
      "        [[ 1.8177]]], dtype=torch.float64)\n",
      "tensor([[0.7860],\n",
      "        [0.7809],\n",
      "        [0.6139],\n",
      "        [0.6077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1325]],\n",
      "\n",
      "        [[0.5837]],\n",
      "\n",
      "        [[0.0788]],\n",
      "\n",
      "        [[0.7293]]], dtype=torch.float64)\n",
      "tensor([[0.5598],\n",
      "        [0.3474],\n",
      "        [0.2899],\n",
      "        [0.2854]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8344]],\n",
      "\n",
      "        [[0.7154]],\n",
      "\n",
      "        [[0.3307]],\n",
      "\n",
      "        [[0.0730]]], dtype=torch.float64)\n",
      "tensor([[0.2701],\n",
      "        [0.4222],\n",
      "        [0.5574],\n",
      "        [0.4571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2817]],\n",
      "\n",
      "        [[ 0.4208]],\n",
      "\n",
      "        [[ 0.7582]],\n",
      "\n",
      "        [[ 0.9118]]], dtype=torch.float64)\n",
      "tensor([[0.5140],\n",
      "        [0.4781],\n",
      "        [0.5325],\n",
      "        [0.6927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5872]],\n",
      "\n",
      "        [[0.1493]],\n",
      "\n",
      "        [[0.1828]],\n",
      "\n",
      "        [[0.7582]]], dtype=torch.float64)\n",
      "tensor([[0.8409],\n",
      "        [0.8788],\n",
      "        [0.9304],\n",
      "        [0.8292]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2931]],\n",
      "\n",
      "        [[1.6212]],\n",
      "\n",
      "        [[1.2030]],\n",
      "\n",
      "        [[0.6623]]], dtype=torch.float64)\n",
      "tensor([[0.7058],\n",
      "        [0.8053],\n",
      "        [1.3121],\n",
      "        [1.3492]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1181]],\n",
      "\n",
      "        [[1.1464]],\n",
      "\n",
      "        [[1.9251]],\n",
      "\n",
      "        [[2.2694]]], dtype=torch.float64)\n",
      "tensor([[1.4013],\n",
      "        [1.1502],\n",
      "        [1.1054],\n",
      "        [1.1497]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9078]],\n",
      "\n",
      "        [[1.1961]],\n",
      "\n",
      "        [[0.6553]],\n",
      "\n",
      "        [[1.5149]]], dtype=torch.float64)\n",
      "tensor([[1.3004],\n",
      "        [0.9483],\n",
      "        [0.7075],\n",
      "        [0.6997]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4040]],\n",
      "\n",
      "        [[1.3139]],\n",
      "\n",
      "        [[0.7420]],\n",
      "\n",
      "        [[0.4820]]], dtype=torch.float64)\n",
      "tensor([[0.6133],\n",
      "        [0.5172],\n",
      "        [0.3276],\n",
      "        [0.1757]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0545]],\n",
      "\n",
      "        [[-0.0229]],\n",
      "\n",
      "        [[ 0.1042]],\n",
      "\n",
      "        [[ 0.4104]]], dtype=torch.float64)\n",
      "tensor([[0.3428],\n",
      "        [0.5354],\n",
      "        [0.5925],\n",
      "        [0.6935]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4092]],\n",
      "\n",
      "        [[0.3815]],\n",
      "\n",
      "        [[0.0626]],\n",
      "\n",
      "        [[0.4439]]], dtype=torch.float64)\n",
      "tensor([[0.5768],\n",
      "        [0.6259],\n",
      "        [0.7406],\n",
      "        [0.7328]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9026]],\n",
      "\n",
      "        [[1.2365]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[0.6241]]], dtype=torch.float64)\n",
      "tensor([[0.7840],\n",
      "        [0.8193],\n",
      "        [0.8268],\n",
      "        [0.9470]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2879]],\n",
      "\n",
      "        [[0.7454]],\n",
      "\n",
      "        [[1.2423]],\n",
      "\n",
      "        [[1.5727]]], dtype=torch.float64)\n",
      "tensor([[1.0587],\n",
      "        [1.0052],\n",
      "        [1.0166],\n",
      "        [1.0020]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3959]],\n",
      "\n",
      "        [[0.7766]],\n",
      "\n",
      "        [[0.6287]],\n",
      "\n",
      "        [[1.1186]]], dtype=torch.float64)\n",
      "tensor([[1.3132],\n",
      "        [1.4217],\n",
      "        [1.3925],\n",
      "        [1.4004]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7067]],\n",
      "\n",
      "        [[1.9609]],\n",
      "\n",
      "        [[1.7033]],\n",
      "\n",
      "        [[1.3139]]], dtype=torch.float64)\n",
      "tensor([[1.2973],\n",
      "        [1.2986],\n",
      "        [1.6714],\n",
      "        [1.6002]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7454]],\n",
      "\n",
      "        [[1.5115]],\n",
      "\n",
      "        [[2.0256]],\n",
      "\n",
      "        [[2.2105]]], dtype=torch.float64)\n",
      "tensor([[1.3681],\n",
      "        [1.1039],\n",
      "        [1.0474],\n",
      "        [1.0683]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1071]],\n",
      "\n",
      "        [[0.8541]],\n",
      "\n",
      "        [[0.5768]],\n",
      "\n",
      "        [[1.3428]]], dtype=torch.float64)\n",
      "tensor([[1.5615],\n",
      "        [1.1269],\n",
      "        [0.7892],\n",
      "        [0.9490]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8246]],\n",
      "\n",
      "        [[1.0805]],\n",
      "\n",
      "        [[1.0355]],\n",
      "\n",
      "        [[0.6854]]], dtype=torch.float64)\n",
      "tensor([[0.9408],\n",
      "        [1.2481],\n",
      "        [1.2199],\n",
      "        [1.1545]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5074]],\n",
      "\n",
      "        [[1.3359]],\n",
      "\n",
      "        [[1.5265]],\n",
      "\n",
      "        [[1.2157]]], dtype=torch.float64)\n",
      "tensor([[1.0250],\n",
      "        [1.2127],\n",
      "        [1.2309],\n",
      "        [1.1136]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2977]],\n",
      "\n",
      "        [[1.0031]],\n",
      "\n",
      "        [[0.7582]],\n",
      "\n",
      "        [[0.8205]]], dtype=torch.float64)\n",
      "tensor([[1.0270],\n",
      "        [0.7014],\n",
      "        [0.3505],\n",
      "        [0.5675]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1764]],\n",
      "\n",
      "        [[0.5294]],\n",
      "\n",
      "        [[0.4115]],\n",
      "\n",
      "        [[0.3873]]], dtype=torch.float64)\n",
      "tensor([[0.5606],\n",
      "        [0.7325],\n",
      "        [0.7081],\n",
      "        [0.6098]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1989]],\n",
      "\n",
      "        [[0.7790]],\n",
      "\n",
      "        [[0.9557]],\n",
      "\n",
      "        [[1.0482]]], dtype=torch.float64)\n",
      "tensor([[0.6539],\n",
      "        [0.7363],\n",
      "        [0.4645],\n",
      "        [0.6859]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7616]],\n",
      "\n",
      "        [[ 0.1735]],\n",
      "\n",
      "        [[-0.0922]],\n",
      "\n",
      "        [[ 0.5479]]], dtype=torch.float64)\n",
      "tensor([[0.9467],\n",
      "        [0.8250],\n",
      "        [0.7528],\n",
      "        [0.8328]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9569]],\n",
      "\n",
      "        [[1.0435]],\n",
      "\n",
      "        [[0.7917]],\n",
      "\n",
      "        [[0.4647]]], dtype=torch.float64)\n",
      "tensor([[0.7109],\n",
      "        [0.7723],\n",
      "        [0.9767],\n",
      "        [0.5619]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0765]],\n",
      "\n",
      "        [[0.8980]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[0.7258]]], dtype=torch.float64)\n",
      "tensor([[0.6816],\n",
      "        [0.7532],\n",
      "        [0.7792],\n",
      "        [0.6421]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6264]],\n",
      "\n",
      "        [[0.3942]],\n",
      "\n",
      "        [[0.1296]],\n",
      "\n",
      "        [[0.5225]]], dtype=torch.float64)\n",
      "tensor([[1.0122],\n",
      "        [0.8937],\n",
      "        [0.8889],\n",
      "        [0.8391]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1175]],\n",
      "\n",
      "        [[1.2561]],\n",
      "\n",
      "        [[0.9557]],\n",
      "\n",
      "        [[0.3653]]], dtype=torch.float64)\n",
      "tensor([[0.6842],\n",
      "        [0.7672],\n",
      "        [1.0621],\n",
      "        [0.8764]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0753]],\n",
      "\n",
      "        [[0.7917]],\n",
      "\n",
      "        [[1.2527]],\n",
      "\n",
      "        [[1.1568]]], dtype=torch.float64)\n",
      "tensor([[0.8243],\n",
      "        [0.9015],\n",
      "        [0.7735],\n",
      "        [0.8657]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9661]],\n",
      "\n",
      "        [[0.4323]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.7478]]], dtype=torch.float64)\n",
      "tensor([[1.1026],\n",
      "        [0.9032],\n",
      "        [1.1362],\n",
      "        [1.0132]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4063]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[1.0193]],\n",
      "\n",
      "        [[0.6738]]], dtype=torch.float64)\n",
      "tensor([[1.0153],\n",
      "        [0.9847],\n",
      "        [1.2225],\n",
      "        [1.1854]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5028]],\n",
      "\n",
      "        [[1.0031]],\n",
      "\n",
      "        [[1.5392]],\n",
      "\n",
      "        [[1.7564]]], dtype=torch.float64)\n",
      "tensor([[1.2665],\n",
      "        [1.0165],\n",
      "        [1.0393],\n",
      "        [1.1780]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2018]],\n",
      "\n",
      "        [[0.7015]],\n",
      "\n",
      "        [[0.5536]],\n",
      "\n",
      "        [[1.3543]]], dtype=torch.float64)\n",
      "tensor([[1.3939],\n",
      "        [1.2462],\n",
      "        [1.0945],\n",
      "        [0.7703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7102]],\n",
      "\n",
      "        [[1.3659]],\n",
      "\n",
      "        [[0.6438]],\n",
      "\n",
      "        [[0.5386]]], dtype=torch.float64)\n",
      "tensor([[0.7478],\n",
      "        [0.7302],\n",
      "        [0.8284],\n",
      "        [0.8719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2452]],\n",
      "\n",
      "        [[0.7270]],\n",
      "\n",
      "        [[1.1695]],\n",
      "\n",
      "        [[1.3197]]], dtype=torch.float64)\n",
      "tensor([[0.8976],\n",
      "        [0.9099],\n",
      "        [0.8084],\n",
      "        [0.8990]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1221]],\n",
      "\n",
      "        [[0.5155]],\n",
      "\n",
      "        [[0.4554]],\n",
      "\n",
      "        [[0.8321]]], dtype=torch.float64)\n",
      "tensor([[0.8341],\n",
      "        [0.5382],\n",
      "        [0.5650],\n",
      "        [0.4933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9684]],\n",
      "\n",
      "        [[0.7778]],\n",
      "\n",
      "        [[0.6114]],\n",
      "\n",
      "        [[0.2024]]], dtype=torch.float64)\n",
      "tensor([[0.4928],\n",
      "        [0.5686],\n",
      "        [0.5743],\n",
      "        [0.3920]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1897]],\n",
      "\n",
      "        [[0.4393]],\n",
      "\n",
      "        [[0.5814]],\n",
      "\n",
      "        [[0.7246]]], dtype=torch.float64)\n",
      "tensor([[0.4141],\n",
      "        [0.4902],\n",
      "        [0.6190],\n",
      "        [0.6301]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5282]],\n",
      "\n",
      "        [[0.3977]],\n",
      "\n",
      "        [[0.1908]],\n",
      "\n",
      "        [[0.6519]]], dtype=torch.float64)\n",
      "tensor([[0.7057],\n",
      "        [0.5965],\n",
      "        [0.4601],\n",
      "        [0.5801]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9777]],\n",
      "\n",
      "        [[0.4612]],\n",
      "\n",
      "        [[0.5213]],\n",
      "\n",
      "        [[0.3919]]], dtype=torch.float64)\n",
      "tensor([[0.7761],\n",
      "        [0.7742],\n",
      "        [0.7926],\n",
      "        [0.8579]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3330]],\n",
      "\n",
      "        [[0.6623]],\n",
      "\n",
      "        [[0.9107]],\n",
      "\n",
      "        [[1.4248]]], dtype=torch.float64)\n",
      "tensor([[1.0383],\n",
      "        [0.9593],\n",
      "        [0.9727],\n",
      "        [0.9057]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13976:  46%|████▌     | 1411/3067 [00:04<00:05, 296.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.2423]],\n",
      "\n",
      "        [[0.7882]],\n",
      "\n",
      "        [[0.5710]],\n",
      "\n",
      "        [[0.7454]]], dtype=torch.float64)\n",
      "tensor([[1.2487],\n",
      "        [1.2930],\n",
      "        [0.6746],\n",
      "        [0.6923]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6363]],\n",
      "\n",
      "        [[0.8506]],\n",
      "\n",
      "        [[0.8887]],\n",
      "\n",
      "        [[0.5040]]], dtype=torch.float64)\n",
      "tensor([[0.7490],\n",
      "        [0.8490],\n",
      "        [0.9335],\n",
      "        [0.8160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3214]],\n",
      "\n",
      "        [[0.9303]],\n",
      "\n",
      "        [[1.1568]],\n",
      "\n",
      "        [[1.3624]]], dtype=torch.float64)\n",
      "tensor([[0.5589],\n",
      "        [0.5651],\n",
      "        [0.6810],\n",
      "        [0.6497]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6773]],\n",
      "\n",
      "        [[0.4046]],\n",
      "\n",
      "        [[0.2405]],\n",
      "\n",
      "        [[0.6426]]], dtype=torch.float64)\n",
      "tensor([[0.5835],\n",
      "        [0.4252],\n",
      "        [0.3283],\n",
      "        [0.4325]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8148]],\n",
      "\n",
      "        [[0.3711]],\n",
      "\n",
      "        [[0.3595]],\n",
      "\n",
      "        [[0.1481]]], dtype=torch.float64)\n",
      "tensor([[0.4706],\n",
      "        [0.6295],\n",
      "        [0.6103],\n",
      "        [0.4273]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0453]],\n",
      "\n",
      "        [[0.6368]],\n",
      "\n",
      "        [[0.8529]],\n",
      "\n",
      "        [[0.5167]]], dtype=torch.float64)\n",
      "tensor([[0.3598],\n",
      "        [0.5951],\n",
      "        [0.7661],\n",
      "        [0.8745]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3907]],\n",
      "\n",
      "        [[0.2694]],\n",
      "\n",
      "        [[0.4427]],\n",
      "\n",
      "        [[0.8945]]], dtype=torch.float64)\n",
      "tensor([[0.8956],\n",
      "        [0.8954],\n",
      "        [1.0292],\n",
      "        [0.9543]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1568]],\n",
      "\n",
      "        [[1.5635]],\n",
      "\n",
      "        [[1.2920]],\n",
      "\n",
      "        [[0.6946]]], dtype=torch.float64)\n",
      "tensor([[0.8368],\n",
      "        [0.9382],\n",
      "        [1.2817],\n",
      "        [1.2586]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3630]],\n",
      "\n",
      "        [[1.2180]],\n",
      "\n",
      "        [[1.7171]],\n",
      "\n",
      "        [[2.0048]]], dtype=torch.float64)\n",
      "tensor([[1.2525],\n",
      "        [1.1210],\n",
      "        [0.9185],\n",
      "        [1.0267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5831]],\n",
      "\n",
      "        [[0.8818]],\n",
      "\n",
      "        [[0.4393]],\n",
      "\n",
      "        [[1.3763]]], dtype=torch.float64)\n",
      "tensor([[1.3018],\n",
      "        [1.3216],\n",
      "        [1.2650],\n",
      "        [1.0956]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9517]],\n",
      "\n",
      "        [[2.0927]],\n",
      "\n",
      "        [[1.6802]],\n",
      "\n",
      "        [[0.9407]]], dtype=torch.float64)\n",
      "tensor([[0.9097],\n",
      "        [0.8943],\n",
      "        [1.3455],\n",
      "        [1.3525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3930]],\n",
      "\n",
      "        [[1.3520]],\n",
      "\n",
      "        [[2.0695]],\n",
      "\n",
      "        [[2.2128]]], dtype=torch.float64)\n",
      "tensor([[1.1086],\n",
      "        [0.8650],\n",
      "        [0.8754],\n",
      "        [0.4634]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1880]],\n",
      "\n",
      "        [[0.9765]],\n",
      "\n",
      "        [[0.3734]],\n",
      "\n",
      "        [[0.2059]]], dtype=torch.float64)\n",
      "tensor([[0.2063],\n",
      "        [0.3349],\n",
      "        [0.5458],\n",
      "        [0.5254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3237]],\n",
      "\n",
      "        [[0.8506]],\n",
      "\n",
      "        [[0.6241]],\n",
      "\n",
      "        [[0.0060]]], dtype=torch.float64)\n",
      "tensor([[0.4866],\n",
      "        [0.4682],\n",
      "        [0.3843],\n",
      "        [0.2783]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1639]],\n",
      "\n",
      "        [[ 0.2648]],\n",
      "\n",
      "        [[ 0.7720]],\n",
      "\n",
      "        [[ 0.5918]]], dtype=torch.float64)\n",
      "tensor([[0.2763],\n",
      "        [0.3429],\n",
      "        [0.4015],\n",
      "        [0.3846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2567]],\n",
      "\n",
      "        [[0.1689]],\n",
      "\n",
      "        [[0.0557]],\n",
      "\n",
      "        [[0.3295]]], dtype=torch.float64)\n",
      "tensor([[0.3137],\n",
      "        [0.1625],\n",
      "        [0.2138],\n",
      "        [0.2685]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2683]],\n",
      "\n",
      "        [[0.4150]],\n",
      "\n",
      "        [[0.1620]],\n",
      "\n",
      "        [[0.0718]]], dtype=torch.float64)\n",
      "tensor([[0.2673],\n",
      "        [0.1662],\n",
      "        [0.1472],\n",
      "        [0.2043]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0164]],\n",
      "\n",
      "        [[0.1227]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.3873]]], dtype=torch.float64)\n",
      "tensor([[0.1976],\n",
      "        [0.5158],\n",
      "        [0.6676],\n",
      "        [0.7899]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2914]],\n",
      "\n",
      "        [[0.2625]],\n",
      "\n",
      "        [[0.2798]],\n",
      "\n",
      "        [[0.3792]]], dtype=torch.float64)\n",
      "tensor([[0.6349],\n",
      "        [0.7007],\n",
      "        [0.7207],\n",
      "        [0.7811]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8772]],\n",
      "\n",
      "        [[0.8471]],\n",
      "\n",
      "        [[0.8309]],\n",
      "\n",
      "        [[0.5225]]], dtype=torch.float64)\n",
      "tensor([[0.9079],\n",
      "        [0.8222],\n",
      "        [0.7591],\n",
      "        [0.8737]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4843]],\n",
      "\n",
      "        [[0.5086]],\n",
      "\n",
      "        [[0.7674]],\n",
      "\n",
      "        [[1.1545]]], dtype=torch.float64)\n",
      "tensor([[0.9294],\n",
      "        [0.8301],\n",
      "        [0.7445],\n",
      "        [0.6976]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9604]],\n",
      "\n",
      "        [[0.4705]],\n",
      "\n",
      "        [[0.2833]],\n",
      "\n",
      "        [[0.7859]]], dtype=torch.float64)\n",
      "tensor([[1.5060],\n",
      "        [1.2187],\n",
      "        [1.2803],\n",
      "        [1.1122]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1146]],\n",
      "\n",
      "        [[1.4040]],\n",
      "\n",
      "        [[1.4398]],\n",
      "\n",
      "        [[1.1002]]], dtype=torch.float64)\n",
      "tensor([[0.9781],\n",
      "        [1.0051],\n",
      "        [1.2935],\n",
      "        [1.3189]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5109]],\n",
      "\n",
      "        [[1.1418]],\n",
      "\n",
      "        [[1.7969]],\n",
      "\n",
      "        [[1.9702]]], dtype=torch.float64)\n",
      "tensor([[1.3150],\n",
      "        [0.9497],\n",
      "        [1.0078],\n",
      "        [0.9446]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4595]],\n",
      "\n",
      "        [[0.7940]],\n",
      "\n",
      "        [[0.7200]],\n",
      "\n",
      "        [[0.8552]]], dtype=torch.float64)\n",
      "tensor([[0.9361],\n",
      "        [0.9765],\n",
      "        [1.0289],\n",
      "        [0.9528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3208]],\n",
      "\n",
      "        [[1.5103]],\n",
      "\n",
      "        [[1.1845]],\n",
      "\n",
      "        [[0.6033]]], dtype=torch.float64)\n",
      "tensor([[0.9066],\n",
      "        [1.0493],\n",
      "        [1.3554],\n",
      "        [1.5033]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4566]],\n",
      "\n",
      "        [[1.2608]],\n",
      "\n",
      "        [[1.9274]],\n",
      "\n",
      "        [[2.1054]]], dtype=torch.float64)\n",
      "tensor([[1.4240],\n",
      "        [1.3027],\n",
      "        [1.2286],\n",
      "        [1.2180]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5635]],\n",
      "\n",
      "        [[1.1452]],\n",
      "\n",
      "        [[0.8275]],\n",
      "\n",
      "        [[1.1891]]], dtype=torch.float64)\n",
      "tensor([[1.3964],\n",
      "        [1.4096],\n",
      "        [1.0093],\n",
      "        [0.9576]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6548]],\n",
      "\n",
      "        [[1.8269]],\n",
      "\n",
      "        [[0.8517]],\n",
      "\n",
      "        [[0.7766]]], dtype=torch.float64)\n",
      "tensor([[1.0931],\n",
      "        [1.0176],\n",
      "        [1.1764],\n",
      "        [1.1268]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7027]],\n",
      "\n",
      "        [[1.0978]],\n",
      "\n",
      "        [[1.4768]],\n",
      "\n",
      "        [[1.6409]]], dtype=torch.float64)\n",
      "tensor([[1.1858],\n",
      "        [1.0452],\n",
      "        [0.9085],\n",
      "        [0.9914]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2457]],\n",
      "\n",
      "        [[0.6010]],\n",
      "\n",
      "        [[0.2856]],\n",
      "\n",
      "        [[1.1325]]], dtype=torch.float64)\n",
      "tensor([[1.5080],\n",
      "        [1.4272],\n",
      "        [1.3960],\n",
      "        [1.1850]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7807]],\n",
      "\n",
      "        [[1.8558]],\n",
      "\n",
      "        [[1.5450]],\n",
      "\n",
      "        [[1.0193]]], dtype=torch.float64)\n",
      "tensor([[1.2309],\n",
      "        [1.2205],\n",
      "        [1.4396],\n",
      "        [1.5350]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8425]],\n",
      "\n",
      "        [[1.3278]],\n",
      "\n",
      "        [[1.7102]],\n",
      "\n",
      "        [[1.7530]]], dtype=torch.float64)\n",
      "tensor([[1.0520],\n",
      "        [1.0328],\n",
      "        [0.8834],\n",
      "        [0.8011]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9881]],\n",
      "\n",
      "        [[0.7686]],\n",
      "\n",
      "        [[0.4693]],\n",
      "\n",
      "        [[0.5132]]], dtype=torch.float64)\n",
      "tensor([[0.7688],\n",
      "        [0.6974],\n",
      "        [0.6831],\n",
      "        [0.7304]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8460]],\n",
      "\n",
      "        [[1.0424]],\n",
      "\n",
      "        [[0.6680]],\n",
      "\n",
      "        [[0.4000]]], dtype=torch.float64)\n",
      "tensor([[0.8065],\n",
      "        [0.7543],\n",
      "        [0.8924],\n",
      "        [0.7707]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2717]],\n",
      "\n",
      "        [[0.5744]],\n",
      "\n",
      "        [[1.0447]],\n",
      "\n",
      "        [[0.9176]]], dtype=torch.float64)\n",
      "tensor([[0.6505],\n",
      "        [0.8328],\n",
      "        [0.9635],\n",
      "        [0.9212]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7039]],\n",
      "\n",
      "        [[0.6218]],\n",
      "\n",
      "        [[0.2428]],\n",
      "\n",
      "        [[0.9326]]], dtype=torch.float64)\n",
      "tensor([[1.2443],\n",
      "        [1.1827],\n",
      "        [1.1720],\n",
      "        [1.0633]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4190]],\n",
      "\n",
      "        [[1.6444]],\n",
      "\n",
      "        [[1.3520]],\n",
      "\n",
      "        [[0.9985]]], dtype=torch.float64)\n",
      "tensor([[1.1337],\n",
      "        [1.1901],\n",
      "        [1.0193],\n",
      "        [0.8532]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8876]],\n",
      "\n",
      "        [[1.2515]],\n",
      "\n",
      "        [[1.1649]],\n",
      "\n",
      "        [[0.8194]]], dtype=torch.float64)\n",
      "tensor([[0.5467],\n",
      "        [0.5460],\n",
      "        [0.7467],\n",
      "        [0.8285]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4601]],\n",
      "\n",
      "        [[0.3445]],\n",
      "\n",
      "        [[0.3203]],\n",
      "\n",
      "        [[0.6819]]], dtype=torch.float64)\n",
      "tensor([[0.7716],\n",
      "        [0.7218],\n",
      "        [0.6604],\n",
      "        [0.6433]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0563]],\n",
      "\n",
      "        [[0.9488]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[0.2255]]], dtype=torch.float64)\n",
      "tensor([[0.5819],\n",
      "        [0.7333],\n",
      "        [1.1286],\n",
      "        [1.1596]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0372]],\n",
      "\n",
      "        [[0.6438]],\n",
      "\n",
      "        [[1.4318]],\n",
      "\n",
      "        [[1.5600]]], dtype=torch.float64)\n",
      "tensor([[1.1705],\n",
      "        [1.0724],\n",
      "        [1.1104],\n",
      "        [0.9109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2480]],\n",
      "\n",
      "        [[1.0239]],\n",
      "\n",
      "        [[0.7223]],\n",
      "\n",
      "        [[0.8795]]], dtype=torch.float64)\n",
      "tensor([[1.0497],\n",
      "        [1.0429],\n",
      "        [0.9165],\n",
      "        [0.8738]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2665]],\n",
      "\n",
      "        [[1.3382]],\n",
      "\n",
      "        [[1.1418]],\n",
      "\n",
      "        [[0.7154]]], dtype=torch.float64)\n",
      "tensor([[0.8353],\n",
      "        [0.7890],\n",
      "        [0.9529],\n",
      "        [0.6121]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6068]],\n",
      "\n",
      "        [[0.8749]],\n",
      "\n",
      "        [[1.2053]],\n",
      "\n",
      "        [[0.6311]]], dtype=torch.float64)\n",
      "tensor([[0.4476],\n",
      "        [0.6170],\n",
      "        [0.5308],\n",
      "        [0.5415]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5432]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.3179]],\n",
      "\n",
      "        [[0.4081]]], dtype=torch.float64)\n",
      "tensor([[0.4519],\n",
      "        [0.4213],\n",
      "        [0.5034],\n",
      "        [0.5040]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6218]],\n",
      "\n",
      "        [[0.8852]],\n",
      "\n",
      "        [[0.5606]],\n",
      "\n",
      "        [[0.1770]]], dtype=torch.float64)\n",
      "tensor([[0.4889],\n",
      "        [0.5231],\n",
      "        [0.5248],\n",
      "        [0.4325]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0476]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.6842]],\n",
      "\n",
      "        [[0.7766]]], dtype=torch.float64)\n",
      "tensor([[0.4633],\n",
      "        [0.5743],\n",
      "        [0.6224],\n",
      "        [0.6014]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4762]],\n",
      "\n",
      "        [[0.3653]],\n",
      "\n",
      "        [[0.1862]],\n",
      "\n",
      "        [[0.5964]]], dtype=torch.float64)\n",
      "tensor([[0.5501],\n",
      "        [0.4559],\n",
      "        [0.4569],\n",
      "        [0.5507]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6807]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[0.4531]],\n",
      "\n",
      "        [[0.2116]]], dtype=torch.float64)\n",
      "tensor([[0.5560],\n",
      "        [0.7067],\n",
      "        [0.5475],\n",
      "        [0.5395]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1862]],\n",
      "\n",
      "        [[0.5097]],\n",
      "\n",
      "        [[0.5144]],\n",
      "\n",
      "        [[0.6958]]], dtype=torch.float64)\n",
      "tensor([[0.6102],\n",
      "        [0.6590],\n",
      "        [0.4640],\n",
      "        [0.4705]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5848]],\n",
      "\n",
      "        [[ 0.2336]],\n",
      "\n",
      "        [[-0.1523]],\n",
      "\n",
      "        [[ 0.4266]]], dtype=torch.float64)\n",
      "tensor([[1.0891],\n",
      "        [1.0463],\n",
      "        [1.0095],\n",
      "        [1.0183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3994]],\n",
      "\n",
      "        [[1.5727]],\n",
      "\n",
      "        [[1.1452]],\n",
      "\n",
      "        [[0.8194]]], dtype=torch.float64)\n",
      "tensor([[1.0281],\n",
      "        [0.9168],\n",
      "        [1.2659],\n",
      "        [1.2341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4728]],\n",
      "\n",
      "        [[1.0736]],\n",
      "\n",
      "        [[1.6143]],\n",
      "\n",
      "        [[1.7171]]], dtype=torch.float64)\n",
      "tensor([[1.2139],\n",
      "        [1.1053],\n",
      "        [0.9322],\n",
      "        [0.9789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3162]],\n",
      "\n",
      "        [[0.7189]],\n",
      "\n",
      "        [[0.2810]],\n",
      "\n",
      "        [[0.8448]]], dtype=torch.float64)\n",
      "tensor([[1.2839],\n",
      "        [1.1845],\n",
      "        [1.1133],\n",
      "        [1.0780]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4560]],\n",
      "\n",
      "        [[1.5646]],\n",
      "\n",
      "        [[1.1914]],\n",
      "\n",
      "        [[0.8679]]], dtype=torch.float64)\n",
      "tensor([[1.1109],\n",
      "        [0.9791],\n",
      "        [0.8805],\n",
      "        [0.8108]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6230]],\n",
      "\n",
      "        [[0.8598]],\n",
      "\n",
      "        [[1.0262]],\n",
      "\n",
      "        [[1.1764]]], dtype=torch.float64)\n",
      "tensor([[0.7920],\n",
      "        [0.7411],\n",
      "        [0.7838],\n",
      "        [0.6856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8552]],\n",
      "\n",
      "        [[0.5121]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.3538]]], dtype=torch.float64)\n",
      "tensor([[0.2264],\n",
      "        [0.2495],\n",
      "        [0.3234],\n",
      "        [0.4910]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #2 - Loss = 0.13976:  47%|████▋     | 1441/3067 [00:04<00:05, 295.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4427]],\n",
      "\n",
      "        [[0.4785]],\n",
      "\n",
      "        [[0.4612]],\n",
      "\n",
      "        [[0.4173]]], dtype=torch.float64)\n",
      "tensor([[0.5778],\n",
      "        [0.4731],\n",
      "        [0.4073],\n",
      "        [0.4477]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3075]],\n",
      "\n",
      "        [[0.2151]],\n",
      "\n",
      "        [[0.4878]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[0.4615],\n",
      "        [0.6731],\n",
      "        [0.8466],\n",
      "        [0.8476]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5144]],\n",
      "\n",
      "        [[0.4878]],\n",
      "\n",
      "        [[0.4312]],\n",
      "\n",
      "        [[0.5560]]], dtype=torch.float64)\n",
      "tensor([[0.7863],\n",
      "        [0.7757],\n",
      "        [0.8797],\n",
      "        [0.7606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8621]],\n",
      "\n",
      "        [[0.9026]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.4312]]], dtype=torch.float64)\n",
      "tensor([[0.8021],\n",
      "        [0.7775],\n",
      "        [1.0222],\n",
      "        [1.2783]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3965]],\n",
      "\n",
      "        [[0.4474]],\n",
      "\n",
      "        [[1.3104]],\n",
      "\n",
      "        [[1.6767]]], dtype=torch.float64)\n",
      "tensor([[1.2896],\n",
      "        [1.1430],\n",
      "        [1.0199],\n",
      "        [0.9322]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3543]],\n",
      "\n",
      "        [[0.9268]],\n",
      "\n",
      "        [[0.4358]],\n",
      "\n",
      "        [[1.1394]]], dtype=torch.float64)\n",
      "tensor([[1.5240],\n",
      "        [1.5542],\n",
      "        [1.2948],\n",
      "        [1.1512]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9783]],\n",
      "\n",
      "        [[1.8662]],\n",
      "\n",
      "        [[1.5577]],\n",
      "\n",
      "        [[0.9292]]], dtype=torch.float64)\n",
      "tensor([[1.1256],\n",
      "        [1.0931],\n",
      "        [1.1130],\n",
      "        [1.1513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8575]],\n",
      "\n",
      "        [[1.0274]],\n",
      "\n",
      "        [[1.4941]],\n",
      "\n",
      "        [[1.8026]]], dtype=torch.float64)\n",
      "tensor([[1.2806],\n",
      "        [1.0602],\n",
      "        [0.9612],\n",
      "        [0.9813]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3601]],\n",
      "\n",
      "        [[0.7454]],\n",
      "\n",
      "        [[0.7443]],\n",
      "\n",
      "        [[0.7917]]], dtype=torch.float64)\n",
      "tensor([[1.1331],\n",
      "        [1.2646],\n",
      "        [1.2470],\n",
      "        [1.1426]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3844]],\n",
      "\n",
      "        [[1.7911]],\n",
      "\n",
      "        [[1.4537]],\n",
      "\n",
      "        [[0.9465]]], dtype=torch.float64)\n",
      "tensor([[1.0599],\n",
      "        [1.0378],\n",
      "        [1.5704],\n",
      "        [1.4511]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7108]],\n",
      "\n",
      "        [[1.3128]],\n",
      "\n",
      "        [[1.8858]],\n",
      "\n",
      "        [[2.0187]]], dtype=torch.float64)\n",
      "tensor([[1.4070],\n",
      "        [1.2735],\n",
      "        [1.3117],\n",
      "        [1.0997]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6963]],\n",
      "\n",
      "        [[1.4768]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[0.7027]]], dtype=torch.float64)\n",
      "tensor([[0.8277],\n",
      "        [0.7558],\n",
      "        [0.8082],\n",
      "        [0.6844]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9488]],\n",
      "\n",
      "        [[1.2920]],\n",
      "\n",
      "        [[1.0089]],\n",
      "\n",
      "        [[0.4104]]], dtype=torch.float64)\n",
      "tensor([[0.6702],\n",
      "        [0.7104],\n",
      "        [0.7968],\n",
      "        [0.6159]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2394]],\n",
      "\n",
      "        [[0.9453]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[1.0158]]], dtype=torch.float64)\n",
      "tensor([[0.4338],\n",
      "        [0.4280],\n",
      "        [0.6539],\n",
      "        [0.6912]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4058]],\n",
      "\n",
      "        [[0.3283]],\n",
      "\n",
      "        [[0.3237]],\n",
      "\n",
      "        [[0.6264]]], dtype=torch.float64)\n",
      "tensor([[0.6167],\n",
      "        [0.4489],\n",
      "        [0.3873],\n",
      "        [0.3945]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6449]],\n",
      "\n",
      "        [[0.3954]],\n",
      "\n",
      "        [[0.3006]],\n",
      "\n",
      "        [[0.2798]]], dtype=torch.float64)\n",
      "tensor([[0.5084],\n",
      "        [0.5330],\n",
      "        [0.5032],\n",
      "        [0.5309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1562]],\n",
      "\n",
      "        [[0.3491]],\n",
      "\n",
      "        [[0.7535]],\n",
      "\n",
      "        [[0.8922]]], dtype=torch.float64)\n",
      "tensor([[0.6055],\n",
      "        [0.7174],\n",
      "        [0.8919],\n",
      "        [0.8842]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6149]],\n",
      "\n",
      "        [[0.6010]],\n",
      "\n",
      "        [[0.6438]],\n",
      "\n",
      "        [[0.8656]]], dtype=torch.float64)\n",
      "tensor([[0.9326],\n",
      "        [1.0911],\n",
      "        [0.9699],\n",
      "        [0.9955]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4006]],\n",
      "\n",
      "        [[1.5450]],\n",
      "\n",
      "        [[1.1799]],\n",
      "\n",
      "        [[0.7039]]], dtype=torch.float64)\n",
      "tensor([[0.9109],\n",
      "        [0.9642],\n",
      "        [1.0019],\n",
      "        [0.8780]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6657]],\n",
      "\n",
      "        [[1.1140]],\n",
      "\n",
      "        [[1.0505]],\n",
      "\n",
      "        [[1.3255]]], dtype=torch.float64)\n",
      "tensor([[0.8474],\n",
      "        [0.8879],\n",
      "        [1.0326],\n",
      "        [0.9896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9049]],\n",
      "\n",
      "        [[0.7466]],\n",
      "\n",
      "        [[0.6992]],\n",
      "\n",
      "        [[0.8344]]], dtype=torch.float64)\n",
      "tensor([[0.9738],\n",
      "        [0.9240],\n",
      "        [0.9201],\n",
      "        [0.8359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0713]],\n",
      "\n",
      "        [[1.1533]],\n",
      "\n",
      "        [[0.9638]],\n",
      "\n",
      "        [[0.6761]]], dtype=torch.float64)\n",
      "tensor([[0.9906],\n",
      "        [1.0539],\n",
      "        [1.4194],\n",
      "        [1.4467]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6611]],\n",
      "\n",
      "        [[1.1718]],\n",
      "\n",
      "        [[1.7414]],\n",
      "\n",
      "        [[1.8304]]], dtype=torch.float64)\n",
      "tensor([[0.9119],\n",
      "        [0.9440],\n",
      "        [0.9299],\n",
      "        [0.8217]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9534]],\n",
      "\n",
      "        [[0.7859]],\n",
      "\n",
      "        [[0.4300]],\n",
      "\n",
      "        [[0.6599]]], dtype=torch.float64)\n",
      "tensor([[0.9298],\n",
      "        [0.9250],\n",
      "        [0.9887],\n",
      "        [0.8876]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1175]],\n",
      "\n",
      "        [[1.3902]],\n",
      "\n",
      "        [[0.9557]],\n",
      "\n",
      "        [[0.5779]]], dtype=torch.float64)\n",
      "tensor([[0.8807],\n",
      "        [0.7515],\n",
      "        [1.0739],\n",
      "        [0.9437]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2867]],\n",
      "\n",
      "        [[0.6045]],\n",
      "\n",
      "        [[1.2885]],\n",
      "\n",
      "        [[1.1441]]], dtype=torch.float64)\n",
      "tensor([[0.9543],\n",
      "        [0.9858],\n",
      "        [0.9973],\n",
      "        [0.9959]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9696]],\n",
      "\n",
      "        [[0.7512]],\n",
      "\n",
      "        [[0.5837]],\n",
      "\n",
      "        [[1.0435]]], dtype=torch.float64)\n",
      "tensor([[1.3200],\n",
      "        [1.2600],\n",
      "        [1.2464],\n",
      "        [1.0745]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7287]],\n",
      "\n",
      "        [[1.8061]],\n",
      "\n",
      "        [[1.2007]],\n",
      "\n",
      "        [[0.8021]]], dtype=torch.float64)\n",
      "tensor([[1.0538],\n",
      "        [1.0709],\n",
      "        [1.5704],\n",
      "        [1.7447]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6842]],\n",
      "\n",
      "        [[1.1776]],\n",
      "\n",
      "        [[2.0418]],\n",
      "\n",
      "        [[2.2787]]], dtype=torch.float64)\n",
      "tensor([[1.5244],\n",
      "        [1.4517],\n",
      "        [1.4015],\n",
      "        [1.1189]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6363]],\n",
      "\n",
      "        [[1.3994]],\n",
      "\n",
      "        [[0.8633]],\n",
      "\n",
      "        [[1.0482]]], dtype=torch.float64)\n",
      "tensor([[1.2921],\n",
      "        [0.8815],\n",
      "        [0.8398],\n",
      "        [0.7413]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8240]],\n",
      "\n",
      "        [[1.2330]],\n",
      "\n",
      "        [[0.7963]],\n",
      "\n",
      "        [[0.4404]]], dtype=torch.float64)\n",
      "tensor([[0.6259],\n",
      "        [0.4631],\n",
      "        [1.0945],\n",
      "        [1.1419]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0418]],\n",
      "\n",
      "        [[0.4346]],\n",
      "\n",
      "        [[1.3185]],\n",
      "\n",
      "        [[1.6328]]], dtype=torch.float64)\n",
      "tensor([[1.1591],\n",
      "        [0.9271],\n",
      "        [0.7645],\n",
      "        [0.6833]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1198]],\n",
      "\n",
      "        [[0.5467]],\n",
      "\n",
      "        [[0.2371]],\n",
      "\n",
      "        [[0.4866]]], dtype=torch.float64)\n",
      "tensor([[1.0766],\n",
      "        [1.4730],\n",
      "        [1.4927],\n",
      "        [1.3500]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7021]],\n",
      "\n",
      "        [[1.8477]],\n",
      "\n",
      "        [[1.6397]],\n",
      "\n",
      "        [[1.3324]]], dtype=torch.float64)\n",
      "tensor([[1.3280],\n",
      "        [1.3289],\n",
      "        [1.5610],\n",
      "        [1.4651]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9084]],\n",
      "\n",
      "        [[1.5542]],\n",
      "\n",
      "        [[1.7241]],\n",
      "\n",
      "        [[1.9424]]], dtype=torch.float64)\n",
      "tensor([[1.2822],\n",
      "        [1.1844],\n",
      "        [1.1336],\n",
      "        [1.1527]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3509]],\n",
      "\n",
      "        [[0.9372]],\n",
      "\n",
      "        [[0.7119]],\n",
      "\n",
      "        [[1.0147]]], dtype=torch.float64)\n",
      "tensor([[1.3515],\n",
      "        [1.7793],\n",
      "        [1.7005],\n",
      "        [1.5734]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6859]],\n",
      "\n",
      "        [[2.1319]],\n",
      "\n",
      "        [[1.7876]],\n",
      "\n",
      "        [[1.2839]]], dtype=torch.float64)\n",
      "tensor([[1.4020],\n",
      "        [1.3339],\n",
      "        [1.6420],\n",
      "        [1.7486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0216]],\n",
      "\n",
      "        [[1.2735]],\n",
      "\n",
      "        [[2.1643]],\n",
      "\n",
      "        [[2.2509]]], dtype=torch.float64)\n",
      "tensor([[1.5483],\n",
      "        [0.9300],\n",
      "        [1.0912],\n",
      "        [0.9795]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9788]],\n",
      "\n",
      "        [[0.7662]],\n",
      "\n",
      "        [[0.7027]],\n",
      "\n",
      "        [[0.7454]]], dtype=torch.float64)\n",
      "tensor([[1.2388],\n",
      "        [1.4779],\n",
      "        [1.3375],\n",
      "        [1.2866]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5947]],\n",
      "\n",
      "        [[1.8870]],\n",
      "\n",
      "        [[1.5554]],\n",
      "\n",
      "        [[1.0747]]], dtype=torch.float64)\n",
      "tensor([[1.2556],\n",
      "        [1.2613],\n",
      "        [1.8456],\n",
      "        [1.9985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9176]],\n",
      "\n",
      "        [[1.3347]],\n",
      "\n",
      "        [[2.3723]],\n",
      "\n",
      "        [[2.7466]]], dtype=torch.float64)\n",
      "tensor([[1.7550],\n",
      "        [1.4116],\n",
      "        [1.1727],\n",
      "        [0.8528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1007]],\n",
      "\n",
      "        [[1.1233]],\n",
      "\n",
      "        [[1.0031]],\n",
      "\n",
      "        [[0.4266]]], dtype=torch.float64)\n",
      "tensor([[0.5315],\n",
      "        [0.4758],\n",
      "        [0.5290],\n",
      "        [0.6424]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4993]],\n",
      "\n",
      "        [[0.6368]],\n",
      "\n",
      "        [[0.5317]],\n",
      "\n",
      "        [[0.4000]]], dtype=torch.float64)\n",
      "tensor([[0.6953],\n",
      "        [0.6718],\n",
      "        [0.7543],\n",
      "        [0.7022]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2151]],\n",
      "\n",
      "        [[0.6253]],\n",
      "\n",
      "        [[0.8887]],\n",
      "\n",
      "        [[1.0482]]], dtype=torch.float64)\n",
      "tensor([[0.6884],\n",
      "        [0.6966],\n",
      "        [0.7084],\n",
      "        [0.6732]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7397]],\n",
      "\n",
      "        [[0.4520]],\n",
      "\n",
      "        [[0.2821]],\n",
      "\n",
      "        [[0.6576]]], dtype=torch.float64)\n",
      "tensor([[0.7504],\n",
      "        [0.6415],\n",
      "        [0.4982],\n",
      "        [0.5378]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9349]],\n",
      "\n",
      "        [[1.0840]],\n",
      "\n",
      "        [[0.5664]],\n",
      "\n",
      "        [[0.3145]]], dtype=torch.float64)\n",
      "tensor([[0.4965],\n",
      "        [0.3950],\n",
      "        [0.5304],\n",
      "        [0.3666]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0056]],\n",
      "\n",
      "        [[ 0.4485]],\n",
      "\n",
      "        [[ 0.6218]],\n",
      "\n",
      "        [[ 0.7166]]], dtype=torch.float64)\n",
      "tensor([[0.3791],\n",
      "        [0.4348],\n",
      "        [0.1513],\n",
      "        [0.0605]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5305]],\n",
      "\n",
      "        [[-0.0772]],\n",
      "\n",
      "        [[-0.4192]],\n",
      "\n",
      "        [[-0.0691]]], dtype=torch.float64)\n",
      "tensor([[0.4713],\n",
      "        [0.5867],\n",
      "        [0.5363],\n",
      "        [0.4358]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8252]],\n",
      "\n",
      "        [[ 1.1279]],\n",
      "\n",
      "        [[ 0.4751]],\n",
      "\n",
      "        [[-0.0033]]], dtype=torch.float64)\n",
      "tensor([[0.3365],\n",
      "        [0.4245],\n",
      "        [0.8085],\n",
      "        [0.8390]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1153]],\n",
      "\n",
      "        [[ 0.4485]],\n",
      "\n",
      "        [[ 1.1210]],\n",
      "\n",
      "        [[ 1.2885]]], dtype=torch.float64)\n",
      "tensor([[0.6675],\n",
      "        [0.6008],\n",
      "        [0.4805],\n",
      "        [0.2779]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7535]],\n",
      "\n",
      "        [[ 0.2787]],\n",
      "\n",
      "        [[-0.1049]],\n",
      "\n",
      "        [[ 0.0198]]], dtype=torch.float64)\n",
      "tensor([[0.9240],\n",
      "        [1.1904],\n",
      "        [1.0285],\n",
      "        [0.8614]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4572]],\n",
      "\n",
      "        [[1.8789]],\n",
      "\n",
      "        [[1.1822]],\n",
      "\n",
      "        [[0.6149]]], dtype=torch.float64)\n",
      "tensor([[0.7616],\n",
      "        [0.7039],\n",
      "        [1.3652],\n",
      "        [1.4794]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2267]],\n",
      "\n",
      "        [[0.8182]],\n",
      "\n",
      "        [[1.9078]],\n",
      "\n",
      "        [[2.1065]]], dtype=torch.float64)\n",
      "tensor([[1.2850],\n",
      "        [1.1151],\n",
      "        [0.9881],\n",
      "        [0.9386]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4341]],\n",
      "\n",
      "        [[0.9060]],\n",
      "\n",
      "        [[0.6068]],\n",
      "\n",
      "        [[0.8205]]], dtype=torch.float64)\n",
      "tensor([[1.4070],\n",
      "        [1.5580],\n",
      "        [1.4170],\n",
      "        [1.0944]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9944]],\n",
      "\n",
      "        [[2.2151]],\n",
      "\n",
      "        [[1.4780]],\n",
      "\n",
      "        [[1.0100]]], dtype=torch.float64)\n",
      "tensor([[1.2189],\n",
      "        [1.2103],\n",
      "        [1.0612],\n",
      "        [0.5895]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9719]],\n",
      "\n",
      "        [[1.0528]],\n",
      "\n",
      "        [[1.1787]],\n",
      "\n",
      "        [[1.0655]]], dtype=torch.float64)\n",
      "tensor([[0.6395],\n",
      "        [0.6430],\n",
      "        [0.6612],\n",
      "        [0.7365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7859]],\n",
      "\n",
      "        [[0.3584]],\n",
      "\n",
      "        [[0.2706]],\n",
      "\n",
      "        [[0.6391]]], dtype=torch.float64)\n",
      "tensor([[0.8390],\n",
      "        [0.8289],\n",
      "        [0.7926],\n",
      "        [0.8687]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0690]],\n",
      "\n",
      "        [[1.2804]],\n",
      "\n",
      "        [[0.9222]],\n",
      "\n",
      "        [[0.8852]]], dtype=torch.float64)\n",
      "tensor([[0.9800],\n",
      "        [0.7576],\n",
      "        [0.5417],\n",
      "        [0.4695]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.14173:  49%|████▉     | 1501/3067 [00:04<00:05, 288.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7709]],\n",
      "\n",
      "        [[0.4647]],\n",
      "\n",
      "        [[0.7743]],\n",
      "\n",
      "        [[0.7974]]], dtype=torch.float64)\n",
      "tensor([[0.4343],\n",
      "        [0.5805],\n",
      "        [0.6784],\n",
      "        [0.5660]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5583]],\n",
      "\n",
      "        [[0.3387]],\n",
      "\n",
      "        [[0.2648]],\n",
      "\n",
      "        [[0.2763]]], dtype=torch.float64)\n",
      "tensor([[0.4085],\n",
      "        [0.2992],\n",
      "        [0.3066],\n",
      "        [0.5197]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3468]],\n",
      "\n",
      "        [[0.4982]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.3457]]], dtype=torch.float64)\n",
      "tensor([[0.6462],\n",
      "        [0.6466],\n",
      "        [0.7661],\n",
      "        [0.7465]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2717]],\n",
      "\n",
      "        [[0.6114]],\n",
      "\n",
      "        [[0.9037]],\n",
      "\n",
      "        [[1.0297]]], dtype=torch.float64)\n",
      "tensor([[0.7654],\n",
      "        [0.9385],\n",
      "        [1.1547],\n",
      "        [1.1492]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8783]],\n",
      "\n",
      "        [[0.8298]],\n",
      "\n",
      "        [[0.7558]],\n",
      "\n",
      "        [[1.0100]]], dtype=torch.float64)\n",
      "tensor([[1.3817],\n",
      "        [1.4313],\n",
      "        [1.2574],\n",
      "        [1.2691]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5646]],\n",
      "\n",
      "        [[1.8731]],\n",
      "\n",
      "        [[1.3832]],\n",
      "\n",
      "        [[1.1337]]], dtype=torch.float64)\n",
      "tensor([[1.3381],\n",
      "        [1.3036],\n",
      "        [1.7138],\n",
      "        [1.5557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0054]],\n",
      "\n",
      "        [[1.1441]],\n",
      "\n",
      "        [[2.1354]],\n",
      "\n",
      "        [[2.0175]]], dtype=torch.float64)\n",
      "tensor([[0.6496],\n",
      "        [0.8194],\n",
      "        [0.8504],\n",
      "        [0.8359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7859]],\n",
      "\n",
      "        [[0.6738]],\n",
      "\n",
      "        [[0.4601]],\n",
      "\n",
      "        [[0.7547]]], dtype=torch.float64)\n",
      "tensor([[0.8775],\n",
      "        [0.8243],\n",
      "        [0.9024],\n",
      "        [1.0180]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0459]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[1.0528]],\n",
      "\n",
      "        [[0.9627]]], dtype=torch.float64)\n",
      "tensor([[1.1478],\n",
      "        [1.0680],\n",
      "        [1.0926],\n",
      "        [1.0196]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7917]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[1.2873]],\n",
      "\n",
      "        [[1.3405]]], dtype=torch.float64)\n",
      "tensor([[0.7107],\n",
      "        [0.6832],\n",
      "        [0.7326],\n",
      "        [0.6742]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7917]],\n",
      "\n",
      "        [[0.4739]],\n",
      "\n",
      "        [[0.3122]],\n",
      "\n",
      "        [[0.6553]]], dtype=torch.float64)\n",
      "tensor([[0.6239],\n",
      "        [0.6102],\n",
      "        [0.4042],\n",
      "        [0.5324]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8679]],\n",
      "\n",
      "        [[0.9731]],\n",
      "\n",
      "        [[0.3803]],\n",
      "\n",
      "        [[0.1331]]], dtype=torch.float64)\n",
      "tensor([[0.4821],\n",
      "        [0.4076],\n",
      "        [0.6100],\n",
      "        [0.5919]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1130]],\n",
      "\n",
      "        [[ 0.4208]],\n",
      "\n",
      "        [[ 0.7697]],\n",
      "\n",
      "        [[ 0.9338]]], dtype=torch.float64)\n",
      "tensor([[0.4584],\n",
      "        [0.3751],\n",
      "        [0.1986],\n",
      "        [0.0725]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3422]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.3372]],\n",
      "\n",
      "        [[-0.0264]]], dtype=torch.float64)\n",
      "tensor([[0.6356],\n",
      "        [0.7139],\n",
      "        [0.5227],\n",
      "        [0.6376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8587]],\n",
      "\n",
      "        [[1.0563]],\n",
      "\n",
      "        [[0.6311]],\n",
      "\n",
      "        [[0.3283]]], dtype=torch.float64)\n",
      "tensor([[0.6465],\n",
      "        [0.7445],\n",
      "        [1.1715],\n",
      "        [1.0876]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3630]],\n",
      "\n",
      "        [[0.8691]],\n",
      "\n",
      "        [[1.3070]],\n",
      "\n",
      "        [[1.3509]]], dtype=torch.float64)\n",
      "tensor([[0.8338],\n",
      "        [0.8626],\n",
      "        [0.9608],\n",
      "        [0.8497]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7824]],\n",
      "\n",
      "        [[0.6842]],\n",
      "\n",
      "        [[0.5999]],\n",
      "\n",
      "        [[0.4936]]], dtype=torch.float64)\n",
      "tensor([[0.6370],\n",
      "        [0.3256],\n",
      "        [0.1956],\n",
      "        [0.2943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4728]],\n",
      "\n",
      "        [[0.2509]],\n",
      "\n",
      "        [[0.1654]],\n",
      "\n",
      "        [[0.0857]]], dtype=torch.float64)\n",
      "tensor([[0.3836],\n",
      "        [0.3459],\n",
      "        [0.5254],\n",
      "        [0.4866]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0241]],\n",
      "\n",
      "        [[ 0.1065]],\n",
      "\n",
      "        [[ 0.5236]],\n",
      "\n",
      "        [[ 0.5768]]], dtype=torch.float64)\n",
      "tensor([[ 0.2997],\n",
      "        [ 0.4368],\n",
      "        [ 0.2545],\n",
      "        [-0.0175]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3214]],\n",
      "\n",
      "        [[-0.1165]],\n",
      "\n",
      "        [[-0.3533]],\n",
      "\n",
      "        [[-0.3533]]], dtype=torch.float64)\n",
      "tensor([[0.6195],\n",
      "        [0.6966],\n",
      "        [0.4740],\n",
      "        [0.3641]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8356]],\n",
      "\n",
      "        [[ 1.0528]],\n",
      "\n",
      "        [[ 0.3411]],\n",
      "\n",
      "        [[-0.1454]]], dtype=torch.float64)\n",
      "tensor([[0.2547],\n",
      "        [0.0322],\n",
      "        [0.5959],\n",
      "        [0.7975]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3372]],\n",
      "\n",
      "        [[-0.0968]],\n",
      "\n",
      "        [[ 0.8437]],\n",
      "\n",
      "        [[ 1.2434]]], dtype=torch.float64)\n",
      "tensor([[0.5474],\n",
      "        [0.4528],\n",
      "        [0.4130],\n",
      "        [0.4288]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5236]],\n",
      "\n",
      "        [[ 0.0453]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[ 0.3052]]], dtype=torch.float64)\n",
      "tensor([[0.6474],\n",
      "        [0.5489],\n",
      "        [0.3937],\n",
      "        [0.4534]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9719]],\n",
      "\n",
      "        [[0.9014]],\n",
      "\n",
      "        [[0.5294]],\n",
      "\n",
      "        [[0.0834]]], dtype=torch.float64)\n",
      "tensor([[0.3151],\n",
      "        [0.2133],\n",
      "        [0.4527],\n",
      "        [0.4305]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1800]],\n",
      "\n",
      "        [[ 0.2694]],\n",
      "\n",
      "        [[ 0.6565]],\n",
      "\n",
      "        [[ 0.8749]]], dtype=torch.float64)\n",
      "tensor([[ 0.2792],\n",
      "        [ 0.1078],\n",
      "        [-0.0193],\n",
      "        [-0.1286]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1758]],\n",
      "\n",
      "        [[-0.2297]],\n",
      "\n",
      "        [[-0.4943]],\n",
      "\n",
      "        [[-0.2135]]], dtype=torch.float64)\n",
      "tensor([[0.5444],\n",
      "        [0.7231],\n",
      "        [0.5669],\n",
      "        [0.3481]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9372]],\n",
      "\n",
      "        [[1.2400]],\n",
      "\n",
      "        [[0.5721]],\n",
      "\n",
      "        [[0.0095]]], dtype=torch.float64)\n",
      "tensor([[ 0.1495],\n",
      "        [-0.0393],\n",
      "        [ 0.7269],\n",
      "        [ 0.9684]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2551]],\n",
      "\n",
      "        [[-0.1408]],\n",
      "\n",
      "        [[ 1.2665]],\n",
      "\n",
      "        [[ 1.4780]]], dtype=torch.float64)\n",
      "tensor([[0.7141],\n",
      "        [0.5458],\n",
      "        [0.4448],\n",
      "        [0.3337]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6958]],\n",
      "\n",
      "        [[ 0.2371]],\n",
      "\n",
      "        [[-0.0113]],\n",
      "\n",
      "        [[ 0.2810]]], dtype=torch.float64)\n",
      "tensor([[0.8852],\n",
      "        [1.1507],\n",
      "        [0.8962],\n",
      "        [0.7201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5034]],\n",
      "\n",
      "        [[1.8038]],\n",
      "\n",
      "        [[0.9708]],\n",
      "\n",
      "        [[0.4947]]], dtype=torch.float64)\n",
      "tensor([[0.6626],\n",
      "        [0.6102],\n",
      "        [0.9245],\n",
      "        [0.9449]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2648]],\n",
      "\n",
      "        [[0.3515]],\n",
      "\n",
      "        [[1.2261]],\n",
      "\n",
      "        [[1.2215]]], dtype=torch.float64)\n",
      "tensor([[0.6679],\n",
      "        [0.7345],\n",
      "        [0.7877],\n",
      "        [0.7993]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7836]],\n",
      "\n",
      "        [[0.5178]],\n",
      "\n",
      "        [[0.4693]],\n",
      "\n",
      "        [[0.5918]]], dtype=torch.float64)\n",
      "tensor([[0.8506],\n",
      "        [0.8242],\n",
      "        [0.5510],\n",
      "        [0.4954]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9534]],\n",
      "\n",
      "        [[1.2018]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[0.2717]]], dtype=torch.float64)\n",
      "tensor([[0.4929],\n",
      "        [0.3930],\n",
      "        [0.5819],\n",
      "        [0.9647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0499]],\n",
      "\n",
      "        [[0.0441]],\n",
      "\n",
      "        [[1.2654]],\n",
      "\n",
      "        [[1.5115]]], dtype=torch.float64)\n",
      "tensor([[0.6951],\n",
      "        [0.5186],\n",
      "        [0.4610],\n",
      "        [0.2693]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7270]],\n",
      "\n",
      "        [[ 0.2024]],\n",
      "\n",
      "        [[-0.0599]],\n",
      "\n",
      "        [[-0.1315]]], dtype=torch.float64)\n",
      "tensor([[0.7699],\n",
      "        [1.1421],\n",
      "        [0.8051],\n",
      "        [0.5555]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4838]],\n",
      "\n",
      "        [[1.8569]],\n",
      "\n",
      "        [[0.8795]],\n",
      "\n",
      "        [[0.2163]]], dtype=torch.float64)\n",
      "tensor([[0.4645],\n",
      "        [0.3577],\n",
      "        [0.8373],\n",
      "        [1.0818]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0587]],\n",
      "\n",
      "        [[ 0.3191]],\n",
      "\n",
      "        [[ 1.5981]],\n",
      "\n",
      "        [[ 1.7102]]], dtype=torch.float64)\n",
      "tensor([[0.7526],\n",
      "        [0.5772],\n",
      "        [0.4983],\n",
      "        [0.3624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9164]],\n",
      "\n",
      "        [[ 0.2833]],\n",
      "\n",
      "        [[-0.0321]],\n",
      "\n",
      "        [[ 0.2787]]], dtype=torch.float64)\n",
      "tensor([[0.7902],\n",
      "        [1.0194],\n",
      "        [0.7546],\n",
      "        [0.5119]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5427]],\n",
      "\n",
      "        [[1.7599]],\n",
      "\n",
      "        [[0.8621]],\n",
      "\n",
      "        [[0.2463]]], dtype=torch.float64)\n",
      "tensor([[0.5019],\n",
      "        [0.3873],\n",
      "        [0.8787],\n",
      "        [0.9535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0499]],\n",
      "\n",
      "        [[0.4011]],\n",
      "\n",
      "        [[1.5843]],\n",
      "\n",
      "        [[1.6097]]], dtype=torch.float64)\n",
      "tensor([[0.7433],\n",
      "        [0.6407],\n",
      "        [0.6437],\n",
      "        [0.5348]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8725]],\n",
      "\n",
      "        [[0.4277]],\n",
      "\n",
      "        [[0.3099]],\n",
      "\n",
      "        [[0.5952]]], dtype=torch.float64)\n",
      "tensor([[0.9887],\n",
      "        [0.9976],\n",
      "        [0.7058],\n",
      "        [0.6642]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6640]],\n",
      "\n",
      "        [[1.6051]],\n",
      "\n",
      "        [[0.9708]],\n",
      "\n",
      "        [[0.6958]]], dtype=torch.float64)\n",
      "tensor([[0.8042],\n",
      "        [0.8735],\n",
      "        [0.7000],\n",
      "        [0.5229]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6865]],\n",
      "\n",
      "        [[0.8078]],\n",
      "\n",
      "        [[0.9372]],\n",
      "\n",
      "        [[0.8956]]], dtype=torch.float64)\n",
      "tensor([[0.5108],\n",
      "        [0.7027],\n",
      "        [0.7073],\n",
      "        [0.6100]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7917]],\n",
      "\n",
      "        [[0.6056]],\n",
      "\n",
      "        [[0.3607]],\n",
      "\n",
      "        [[0.7593]]], dtype=torch.float64)\n",
      "tensor([[ 0.6692],\n",
      "        [ 0.6597],\n",
      "        [ 0.2242],\n",
      "        [-0.0649]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9927]],\n",
      "\n",
      "        [[ 0.9996]],\n",
      "\n",
      "        [[-0.1223]],\n",
      "\n",
      "        [[-0.1130]]], dtype=torch.float64)\n",
      "tensor([[ 0.0445],\n",
      "        [-0.1078],\n",
      "        [ 0.0074],\n",
      "        [-0.0391]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2794]],\n",
      "\n",
      "        [[-0.1442]],\n",
      "\n",
      "        [[ 0.1319]],\n",
      "\n",
      "        [[ 0.0014]]], dtype=torch.float64)\n",
      "tensor([[-0.1696],\n",
      "        [-0.0827],\n",
      "        [-0.0744],\n",
      "        [-0.2935]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0922]],\n",
      "\n",
      "        [[-0.1003]],\n",
      "\n",
      "        [[-0.2690]],\n",
      "\n",
      "        [[-0.4423]]], dtype=torch.float64)\n",
      "tensor([[-0.2548],\n",
      "        [-0.2159],\n",
      "        [-0.4728],\n",
      "        [-0.3952]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1200]],\n",
      "\n",
      "        [[-0.4181]],\n",
      "\n",
      "        [[-0.5151]],\n",
      "\n",
      "        [[-0.5347]]], dtype=torch.float64)\n",
      "tensor([[-0.3271],\n",
      "        [-0.3369],\n",
      "        [ 0.0470],\n",
      "        [ 0.0557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6849]],\n",
      "\n",
      "        [[-0.4377]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[ 0.0996]]], dtype=torch.float64)\n",
      "tensor([[-0.2503],\n",
      "        [-0.0204],\n",
      "        [ 0.0947],\n",
      "        [ 0.2259]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1962]],\n",
      "\n",
      "        [[-0.2782]],\n",
      "\n",
      "        [[-0.2205]],\n",
      "\n",
      "        [[-0.0876]]], dtype=torch.float64)\n",
      "tensor([[0.2805],\n",
      "        [0.4073],\n",
      "        [0.5445],\n",
      "        [0.6877]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3457]],\n",
      "\n",
      "        [[0.8679]],\n",
      "\n",
      "        [[0.9257]],\n",
      "\n",
      "        [[0.7397]]], dtype=torch.float64)\n",
      "tensor([[0.8448],\n",
      "        [0.8035],\n",
      "        [0.5391],\n",
      "        [0.4186]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6738]],\n",
      "\n",
      "        [[0.7212]],\n",
      "\n",
      "        [[0.7362]],\n",
      "\n",
      "        [[0.5213]]], dtype=torch.float64)\n",
      "tensor([[0.3898],\n",
      "        [0.4804],\n",
      "        [0.1870],\n",
      "        [0.2408]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5201]],\n",
      "\n",
      "        [[-0.0090]],\n",
      "\n",
      "        [[-0.0992]],\n",
      "\n",
      "        [[-0.0737]]], dtype=torch.float64)\n",
      "tensor([[ 0.0139],\n",
      "        [-0.0736],\n",
      "        [-0.1362],\n",
      "        [-0.1025]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0529]],\n",
      "\n",
      "        [[-0.0483]],\n",
      "\n",
      "        [[-0.1373]],\n",
      "\n",
      "        [[-0.2008]]], dtype=torch.float64)\n",
      "tensor([[ 0.0286],\n",
      "        [-0.0882],\n",
      "        [ 0.0330],\n",
      "        [-0.0439]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3453]],\n",
      "\n",
      "        [[-0.3741]],\n",
      "\n",
      "        [[ 0.2197]],\n",
      "\n",
      "        [[ 0.1943]]], dtype=torch.float64)\n",
      "tensor([[-0.3131],\n",
      "        [-0.4146],\n",
      "        [-0.4576],\n",
      "        [-0.5588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4273]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-1.0454]],\n",
      "\n",
      "        [[-0.9576]]], dtype=torch.float64)\n",
      "tensor([[-0.4215],\n",
      "        [-0.3335],\n",
      "        [-0.6062],\n",
      "        [-0.6762]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4354]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.6491]],\n",
      "\n",
      "        [[-1.0258]]], dtype=torch.float64)\n",
      "tensor([[-0.7198],\n",
      "        [-0.7661],\n",
      "        [-0.5725],\n",
      "        [-0.0781]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2800]],\n",
      "\n",
      "        [[-1.2973]],\n",
      "\n",
      "        [[-0.1234]],\n",
      "\n",
      "        [[ 0.0799]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.14173:  51%|█████     | 1559/3067 [00:04<00:05, 285.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4546],\n",
      "        [-0.6586],\n",
      "        [-0.7573],\n",
      "        [-0.7546]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5232]],\n",
      "\n",
      "        [[-0.9877]],\n",
      "\n",
      "        [[-1.2569]],\n",
      "\n",
      "        [[-0.8467]]], dtype=torch.float64)\n",
      "tensor([[ 0.0004],\n",
      "        [ 0.2121],\n",
      "        [ 0.0205],\n",
      "        [-0.3191]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3572]],\n",
      "\n",
      "        [[ 0.5144]],\n",
      "\n",
      "        [[-0.1200]],\n",
      "\n",
      "        [[-0.3568]]], dtype=torch.float64)\n",
      "tensor([[-0.3093],\n",
      "        [-0.4626],\n",
      "        [ 0.1132],\n",
      "        [ 0.0573]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6457]],\n",
      "\n",
      "        [[-0.7092]],\n",
      "\n",
      "        [[ 0.3930]],\n",
      "\n",
      "        [[ 0.2590]]], dtype=torch.float64)\n",
      "tensor([[-0.2037],\n",
      "        [-0.4464],\n",
      "        [-0.4900],\n",
      "        [-0.3088]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3222]],\n",
      "\n",
      "        [[-0.7554]],\n",
      "\n",
      "        [[-0.7624]],\n",
      "\n",
      "        [[-0.1292]]], dtype=torch.float64)\n",
      "tensor([[ 0.3975],\n",
      "        [ 0.4599],\n",
      "        [-0.2204],\n",
      "        [-0.2859]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8229]],\n",
      "\n",
      "        [[ 0.7928]],\n",
      "\n",
      "        [[-0.2933]],\n",
      "\n",
      "        [[-0.3557]]], dtype=torch.float64)\n",
      "tensor([[-0.1494],\n",
      "        [-0.0412],\n",
      "        [-0.0820],\n",
      "        [-0.1820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[-0.3626]],\n",
      "\n",
      "        [[-0.1396]],\n",
      "\n",
      "        [[-0.1038]]], dtype=torch.float64)\n",
      "tensor([[-0.4249],\n",
      "        [-0.4701],\n",
      "        [-0.3703],\n",
      "        [-0.2542]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3741]],\n",
      "\n",
      "        [[-0.5960]],\n",
      "\n",
      "        [[-0.5036]],\n",
      "\n",
      "        [[-0.3961]]], dtype=torch.float64)\n",
      "tensor([[-0.3419],\n",
      "        [-0.3200],\n",
      "        [-0.6000],\n",
      "        [-0.7367]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1766]],\n",
      "\n",
      "        [[-0.2517]],\n",
      "\n",
      "        [[-0.6642]],\n",
      "\n",
      "        [[-1.0697]]], dtype=torch.float64)\n",
      "tensor([[-0.8562],\n",
      "        [-0.8637],\n",
      "        [-0.5525],\n",
      "        [-0.1951]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2915]],\n",
      "\n",
      "        [[-1.3262]],\n",
      "\n",
      "        [[-0.1280]],\n",
      "\n",
      "        [[-0.0922]]], dtype=torch.float64)\n",
      "tensor([[-0.6047],\n",
      "        [-0.8798],\n",
      "        [-0.9388],\n",
      "        [-0.9429]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7982]],\n",
      "\n",
      "        [[-1.1332]],\n",
      "\n",
      "        [[-1.3932]],\n",
      "\n",
      "        [[-1.4152]]], dtype=torch.float64)\n",
      "tensor([[-0.7187],\n",
      "        [-0.1301],\n",
      "        [-0.5819],\n",
      "        [-0.7719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1858]],\n",
      "\n",
      "        [[ 0.0025]],\n",
      "\n",
      "        [[-0.6953]],\n",
      "\n",
      "        [[-0.9357]]], dtype=torch.float64)\n",
      "tensor([[-0.7921],\n",
      "        [-0.8915],\n",
      "        [-0.4369],\n",
      "        [-0.0659]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3146]],\n",
      "\n",
      "        [[-1.0570]],\n",
      "\n",
      "        [[-0.0183]],\n",
      "\n",
      "        [[ 0.1192]]], dtype=torch.float64)\n",
      "tensor([[-0.4264],\n",
      "        [-0.6161],\n",
      "        [-0.5441],\n",
      "        [-0.4819]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5948]],\n",
      "\n",
      "        [[-0.6780]],\n",
      "\n",
      "        [[-0.6191]],\n",
      "\n",
      "        [[-0.3984]]], dtype=torch.float64)\n",
      "tensor([[ 0.1249],\n",
      "        [ 0.1981],\n",
      "        [-0.1551],\n",
      "        [-0.1869]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3191]],\n",
      "\n",
      "        [[ 0.3653]],\n",
      "\n",
      "        [[ 0.0603]],\n",
      "\n",
      "        [[-0.1789]]], dtype=torch.float64)\n",
      "tensor([[-0.2649],\n",
      "        [-0.4092],\n",
      "        [-0.2160],\n",
      "        [-0.1212]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4620]],\n",
      "\n",
      "        [[-0.3406]],\n",
      "\n",
      "        [[ 0.0822]],\n",
      "\n",
      "        [[ 0.0926]]], dtype=torch.float64)\n",
      "tensor([[-0.2203],\n",
      "        [-0.2528],\n",
      "        [ 0.0440],\n",
      "        [ 0.0795]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1084]],\n",
      "\n",
      "        [[-0.1743]],\n",
      "\n",
      "        [[-0.1072]],\n",
      "\n",
      "        [[-0.1974]]], dtype=torch.float64)\n",
      "tensor([[ 0.0664],\n",
      "        [ 0.1354],\n",
      "        [-0.0844],\n",
      "        [-0.3126]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2891]],\n",
      "\n",
      "        [[ 0.4011]],\n",
      "\n",
      "        [[-0.0795]],\n",
      "\n",
      "        [[-0.5220]]], dtype=torch.float64)\n",
      "tensor([[-0.5665],\n",
      "        [-0.5580],\n",
      "        [-0.3655],\n",
      "        [-0.0113]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8352]],\n",
      "\n",
      "        [[-0.8328]],\n",
      "\n",
      "        [[-0.0680]],\n",
      "\n",
      "        [[ 0.2197]]], dtype=torch.float64)\n",
      "tensor([[-0.0544],\n",
      "        [ 0.1442],\n",
      "        [ 0.2360],\n",
      "        [ 0.0476]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0545]],\n",
      "\n",
      "        [[ 0.0210]],\n",
      "\n",
      "        [[-0.0784]],\n",
      "\n",
      "        [[-0.1442]]], dtype=torch.float64)\n",
      "tensor([[ 0.2087],\n",
      "        [ 0.4048],\n",
      "        [ 0.0576],\n",
      "        [-0.1978]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5479]],\n",
      "\n",
      "        [[ 0.7258]],\n",
      "\n",
      "        [[ 0.0395]],\n",
      "\n",
      "        [[-0.3487]]], dtype=torch.float64)\n",
      "tensor([[-0.2444],\n",
      "        [-0.3496],\n",
      "        [-0.0592],\n",
      "        [ 0.3611]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5093]],\n",
      "\n",
      "        [[-0.6214]],\n",
      "\n",
      "        [[ 0.5097]],\n",
      "\n",
      "        [[ 0.7651]]], dtype=torch.float64)\n",
      "tensor([[0.0897],\n",
      "        [0.1367],\n",
      "        [0.2778],\n",
      "        [0.1242]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2220]],\n",
      "\n",
      "        [[ 0.1250]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.1153]]], dtype=torch.float64)\n",
      "tensor([[0.0794],\n",
      "        [0.1638],\n",
      "        [0.1899],\n",
      "        [0.1889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2856]],\n",
      "\n",
      "        [[0.4485]],\n",
      "\n",
      "        [[0.2775]],\n",
      "\n",
      "        [[0.0141]]], dtype=torch.float64)\n",
      "tensor([[ 0.0688],\n",
      "        [-0.0843],\n",
      "        [ 0.0436],\n",
      "        [ 0.3836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2540]],\n",
      "\n",
      "        [[-0.3337]],\n",
      "\n",
      "        [[ 0.6461]],\n",
      "\n",
      "        [[ 0.5178]]], dtype=torch.float64)\n",
      "tensor([[-0.0433],\n",
      "        [ 0.0560],\n",
      "        [-0.0003],\n",
      "        [-0.2244]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0672]],\n",
      "\n",
      "        [[-0.1662]],\n",
      "\n",
      "        [[-0.2944]],\n",
      "\n",
      "        [[-0.5486]]], dtype=torch.float64)\n",
      "tensor([[ 0.0154],\n",
      "        [ 0.0878],\n",
      "        [-0.2770],\n",
      "        [-0.3329]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0256]],\n",
      "\n",
      "        [[ 0.1435]],\n",
      "\n",
      "        [[-0.3776]],\n",
      "\n",
      "        [[-0.5151]]], dtype=torch.float64)\n",
      "tensor([[-0.2694],\n",
      "        [-0.4090],\n",
      "        [-0.2229],\n",
      "        [ 0.1823]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6699]],\n",
      "\n",
      "        [[-0.7774]],\n",
      "\n",
      "        [[ 0.3318]],\n",
      "\n",
      "        [[ 0.4739]]], dtype=torch.float64)\n",
      "tensor([[ 0.1078],\n",
      "        [-0.2760],\n",
      "        [-0.2183],\n",
      "        [-0.2978]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1719]],\n",
      "\n",
      "        [[-0.4492]],\n",
      "\n",
      "        [[-0.5243]],\n",
      "\n",
      "        [[-0.3973]]], dtype=torch.float64)\n",
      "tensor([[ 0.0459],\n",
      "        [ 0.2421],\n",
      "        [ 0.0102],\n",
      "        [-0.3006]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5225]],\n",
      "\n",
      "        [[ 0.5536]],\n",
      "\n",
      "        [[-0.2066]],\n",
      "\n",
      "        [[-0.5267]]], dtype=torch.float64)\n",
      "tensor([[-0.4175],\n",
      "        [-0.4199],\n",
      "        [-0.2371],\n",
      "        [ 0.0893]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7023]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[ 0.2301]],\n",
      "\n",
      "        [[ 0.4809]]], dtype=torch.float64)\n",
      "tensor([[ 0.0007],\n",
      "        [-0.3314],\n",
      "        [-0.4049],\n",
      "        [-0.6333]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2020]],\n",
      "\n",
      "        [[-0.4724]],\n",
      "\n",
      "        [[-0.7358]],\n",
      "\n",
      "        [[-0.8675]]], dtype=torch.float64)\n",
      "tensor([[-0.3049],\n",
      "        [-0.0552],\n",
      "        [-0.1239],\n",
      "        [-0.1910]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1562]],\n",
      "\n",
      "        [[ 0.3064]],\n",
      "\n",
      "        [[-0.1789]],\n",
      "\n",
      "        [[-0.3429]]], dtype=torch.float64)\n",
      "tensor([[-0.2510],\n",
      "        [-0.6306],\n",
      "        [-0.3849],\n",
      "        [ 0.0220]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7681]],\n",
      "\n",
      "        [[-0.8941]],\n",
      "\n",
      "        [[ 0.1862]],\n",
      "\n",
      "        [[ 0.2798]]], dtype=torch.float64)\n",
      "tensor([[-0.0601],\n",
      "        [-0.4020],\n",
      "        [-0.3621],\n",
      "        [-0.3764]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1223]],\n",
      "\n",
      "        [[-0.4539]],\n",
      "\n",
      "        [[-0.4365]],\n",
      "\n",
      "        [[-0.5012]]], dtype=torch.float64)\n",
      "tensor([[-0.4916],\n",
      "        [-0.5271],\n",
      "        [-0.5232],\n",
      "        [-0.5358]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4400]],\n",
      "\n",
      "        [[-0.3741]],\n",
      "\n",
      "        [[-0.6607]],\n",
      "\n",
      "        [[-0.7115]]], dtype=torch.float64)\n",
      "tensor([[-0.5178],\n",
      "        [-0.6206],\n",
      "        [-0.6112],\n",
      "        [-0.2867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8594]],\n",
      "\n",
      "        [[-0.9981]],\n",
      "\n",
      "        [[-0.1974]],\n",
      "\n",
      "        [[-0.0610]]], dtype=torch.float64)\n",
      "tensor([[-0.3645],\n",
      "        [-0.5643],\n",
      "        [-0.6375],\n",
      "        [-0.6525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4677]],\n",
      "\n",
      "        [[-0.8155]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-1.0628]]], dtype=torch.float64)\n",
      "tensor([[-0.7282],\n",
      "        [-0.3371],\n",
      "        [-0.7603],\n",
      "        [-0.7489]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4643]],\n",
      "\n",
      "        [[-0.3025]],\n",
      "\n",
      "        [[-0.7635]],\n",
      "\n",
      "        [[-0.8733]]], dtype=torch.float64)\n",
      "tensor([[-0.6001],\n",
      "        [-0.5385],\n",
      "        [-0.4799],\n",
      "        [-0.6094]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7912]],\n",
      "\n",
      "        [[-0.6930]],\n",
      "\n",
      "        [[-0.4955]],\n",
      "\n",
      "        [[-0.6041]]], dtype=torch.float64)\n",
      "tensor([[-0.7857],\n",
      "        [-0.7596],\n",
      "        [-0.6584],\n",
      "        [-0.7156]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7023]],\n",
      "\n",
      "        [[-0.7185]],\n",
      "\n",
      "        [[-0.8259]],\n",
      "\n",
      "        [[-1.0408]]], dtype=torch.float64)\n",
      "tensor([[-0.9395],\n",
      "        [-0.8095],\n",
      "        [-0.8025],\n",
      "        [-0.9366]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9865]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-0.7878]],\n",
      "\n",
      "        [[-1.1991]]], dtype=torch.float64)\n",
      "tensor([[-0.7918],\n",
      "        [-0.8521],\n",
      "        [-0.7082],\n",
      "        [-0.5424]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2107]],\n",
      "\n",
      "        [[-1.1829]],\n",
      "\n",
      "        [[-0.4562]],\n",
      "\n",
      "        [[-0.3707]]], dtype=torch.float64)\n",
      "tensor([[-0.8397],\n",
      "        [-0.8720],\n",
      "        [-0.9003],\n",
      "        [-0.9556]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9091]],\n",
      "\n",
      "        [[-1.1748]],\n",
      "\n",
      "        [[-1.3447]],\n",
      "\n",
      "        [[-1.4891]]], dtype=torch.float64)\n",
      "tensor([[-0.9251],\n",
      "        [-0.4638],\n",
      "        [-0.8554],\n",
      "        [-1.0002]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4989]],\n",
      "\n",
      "        [[-0.2886]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.3528]]], dtype=torch.float64)\n",
      "tensor([[-1.0237],\n",
      "        [-1.0896],\n",
      "        [-1.0512],\n",
      "        [-0.6343]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4903]],\n",
      "\n",
      "        [[-1.4822]],\n",
      "\n",
      "        [[-0.6930]],\n",
      "\n",
      "        [[-0.5394]]], dtype=torch.float64)\n",
      "tensor([[-0.9489],\n",
      "        [-1.1399],\n",
      "        [-1.1389],\n",
      "        [-1.1311]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1078]],\n",
      "\n",
      "        [[-1.4741]],\n",
      "\n",
      "        [[-1.5215]],\n",
      "\n",
      "        [[-1.4152]]], dtype=torch.float64)\n",
      "tensor([[-1.2034],\n",
      "        [-1.3106],\n",
      "        [-1.3711],\n",
      "        [-1.1829]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3262]],\n",
      "\n",
      "        [[-1.3505]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.4290]]], dtype=torch.float64)\n",
      "tensor([[-1.1172],\n",
      "        [-1.1695],\n",
      "        [-1.1621],\n",
      "        [-1.1892]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4209]],\n",
      "\n",
      "        [[-1.4175]],\n",
      "\n",
      "        [[-1.2754]],\n",
      "\n",
      "        [[-1.2199]]], dtype=torch.float64)\n",
      "tensor([[-1.3028],\n",
      "        [-1.1868],\n",
      "        [-1.0634],\n",
      "        [-0.9603]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3204]],\n",
      "\n",
      "        [[-1.3944]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.2153]]], dtype=torch.float64)\n",
      "tensor([[-0.9983],\n",
      "        [-1.0315],\n",
      "        [-1.1968],\n",
      "        [-1.1574]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0073]],\n",
      "\n",
      "        [[-0.9646]],\n",
      "\n",
      "        [[-1.2823]],\n",
      "\n",
      "        [[-1.1841]]], dtype=torch.float64)\n",
      "tensor([[-1.0476],\n",
      "        [-0.9479],\n",
      "        [-0.8277],\n",
      "        [-0.7223]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1748]],\n",
      "\n",
      "        [[-1.0720]],\n",
      "\n",
      "        [[-0.5232]],\n",
      "\n",
      "        [[-0.4227]]], dtype=torch.float64)\n",
      "tensor([[-0.7085],\n",
      "        [-0.7020],\n",
      "        [-0.6123],\n",
      "        [-0.5663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5867]],\n",
      "\n",
      "        [[-0.6988]],\n",
      "\n",
      "        [[-0.7127]],\n",
      "\n",
      "        [[-0.6977]]], dtype=torch.float64)\n",
      "tensor([[-0.6512],\n",
      "        [-0.5532],\n",
      "        [-0.5730],\n",
      "        [-0.7663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4319]],\n",
      "\n",
      "        [[-0.2193]],\n",
      "\n",
      "        [[-0.4735]],\n",
      "\n",
      "        [[-0.9888]]], dtype=torch.float64)\n",
      "tensor([[-0.8206],\n",
      "        [-0.8185],\n",
      "        [-0.9109],\n",
      "        [-0.7910]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0813]],\n",
      "\n",
      "        [[-1.1332]],\n",
      "\n",
      "        [[-0.7150]],\n",
      "\n",
      "        [[-0.4804]]], dtype=torch.float64)\n",
      "tensor([[-0.8194],\n",
      "        [-0.7021],\n",
      "        [-0.5380],\n",
      "        [-0.5502]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5787]],\n",
      "\n",
      "        [[-0.5879]],\n",
      "\n",
      "        [[-0.6630]],\n",
      "\n",
      "        [[-0.6676]]], dtype=torch.float64)\n",
      "tensor([[-0.6347],\n",
      "        [-0.3691],\n",
      "        [-0.6345],\n",
      "        [-0.7922]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2886]],\n",
      "\n",
      "        [[-0.0102]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-0.8178]]], dtype=torch.float64)\n",
      "tensor([[-0.9273],\n",
      "        [-1.1101],\n",
      "        [-0.9359],\n",
      "        [-0.4737]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2580]],\n",
      "\n",
      "        [[-1.2187]],\n",
      "\n",
      "        [[-0.3014]],\n",
      "\n",
      "        [[-0.1870]]], dtype=torch.float64)\n",
      "tensor([[-0.7941],\n",
      "        [-0.9215],\n",
      "        [-1.0629],\n",
      "        [-1.1291]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7820]],\n",
      "\n",
      "        [[-0.9634]],\n",
      "\n",
      "        [[-1.1991]],\n",
      "\n",
      "        [[-1.3019]]], dtype=torch.float64)\n",
      "tensor([[-1.0204],\n",
      "        [-0.4391],\n",
      "        [-0.8369],\n",
      "        [-1.0384]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3580]],\n",
      "\n",
      "        [[-0.1026]],\n",
      "\n",
      "        [[-0.7462]],\n",
      "\n",
      "        [[-1.0154]]], dtype=torch.float64)\n",
      "tensor([[-1.0776],\n",
      "        [-1.0777],\n",
      "        [-1.0300],\n",
      "        [-0.6764]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1876]],\n",
      "\n",
      "        [[-1.1806]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.3222]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.14291:  53%|█████▎    | 1620/3067 [00:05<00:04, 289.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9203],\n",
      "        [-1.0880],\n",
      "        [-1.0765],\n",
      "        [-1.0217]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8918]],\n",
      "\n",
      "        [[-1.1148]],\n",
      "\n",
      "        [[-1.2280]],\n",
      "\n",
      "        [[-1.1772]]], dtype=torch.float64)\n",
      "tensor([[-0.7301],\n",
      "        [-0.6341],\n",
      "        [-1.1761],\n",
      "        [-0.8825]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0957]],\n",
      "\n",
      "        [[-0.7046]],\n",
      "\n",
      "        [[-0.9322]],\n",
      "\n",
      "        [[-0.6907]]], dtype=torch.float64)\n",
      "tensor([[-0.5726],\n",
      "        [-0.4109],\n",
      "        [-0.4540],\n",
      "        [-0.5583]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6018]],\n",
      "\n",
      "        [[-0.6353]],\n",
      "\n",
      "        [[-0.3880]],\n",
      "\n",
      "        [[-0.4435]]], dtype=torch.float64)\n",
      "tensor([[-0.5762],\n",
      "        [-0.3785],\n",
      "        [-0.4317],\n",
      "        [-0.4113]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3996]],\n",
      "\n",
      "        [[-0.4932]],\n",
      "\n",
      "        [[-0.5394]],\n",
      "\n",
      "        [[-0.5775]]], dtype=torch.float64)\n",
      "tensor([[-0.3260],\n",
      "        [-0.4261],\n",
      "        [-0.3442],\n",
      "        [-0.3237]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1592]],\n",
      "\n",
      "        [[-0.2436]],\n",
      "\n",
      "        [[-0.2008]],\n",
      "\n",
      "        [[-0.2933]]], dtype=torch.float64)\n",
      "tensor([[-0.3347],\n",
      "        [-0.5719],\n",
      "        [-0.5970],\n",
      "        [-0.5500]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4735]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.1269]],\n",
      "\n",
      "        [[-0.2944]]], dtype=torch.float64)\n",
      "tensor([[-0.9468],\n",
      "        [-1.1310],\n",
      "        [-1.2315],\n",
      "        [-1.2296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9657]],\n",
      "\n",
      "        [[-1.3308]],\n",
      "\n",
      "        [[-1.4776]],\n",
      "\n",
      "        [[-1.4371]]], dtype=torch.float64)\n",
      "tensor([[-0.9109],\n",
      "        [-0.7168],\n",
      "        [-0.9992],\n",
      "        [-0.6725]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3822]],\n",
      "\n",
      "        [[-0.8178]],\n",
      "\n",
      "        [[-0.9403]],\n",
      "\n",
      "        [[-0.6642]]], dtype=torch.float64)\n",
      "tensor([[-0.1596],\n",
      "        [-0.0380],\n",
      "        [-0.3592],\n",
      "        [-0.4106]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1003]],\n",
      "\n",
      "        [[-0.2332]],\n",
      "\n",
      "        [[-0.0703]],\n",
      "\n",
      "        [[-0.2725]]], dtype=torch.float64)\n",
      "tensor([[-0.8303],\n",
      "        [-0.9929],\n",
      "        [-0.9823],\n",
      "        [-0.7845]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9126]],\n",
      "\n",
      "        [[-1.3042]],\n",
      "\n",
      "        [[-1.4105]],\n",
      "\n",
      "        [[-1.0535]]], dtype=torch.float64)\n",
      "tensor([[-0.4972],\n",
      "        [-0.4325],\n",
      "        [-0.2539],\n",
      "        [-0.0123]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3788]],\n",
      "\n",
      "        [[-0.0784]],\n",
      "\n",
      "        [[-0.0841]],\n",
      "\n",
      "        [[ 0.0337]]], dtype=torch.float64)\n",
      "tensor([[ 0.1136],\n",
      "        [-0.0006],\n",
      "        [-0.0412],\n",
      "        [-0.3382]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0326]],\n",
      "\n",
      "        [[-0.0541]],\n",
      "\n",
      "        [[ 0.4081]],\n",
      "\n",
      "        [[-0.4342]]], dtype=torch.float64)\n",
      "tensor([[-0.6955],\n",
      "        [-0.7413],\n",
      "        [-0.8990],\n",
      "        [-0.8673]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5937]],\n",
      "\n",
      "        [[-0.8444]],\n",
      "\n",
      "        [[-1.1679]],\n",
      "\n",
      "        [[-1.0258]]], dtype=torch.float64)\n",
      "tensor([[-0.5255],\n",
      "        [-0.4253],\n",
      "        [-0.3895],\n",
      "        [-0.2053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4053]],\n",
      "\n",
      "        [[-0.4146]],\n",
      "\n",
      "        [[-0.2621]],\n",
      "\n",
      "        [[-0.3129]]], dtype=torch.float64)\n",
      "tensor([[-0.1898],\n",
      "        [-0.1544],\n",
      "        [-0.3175],\n",
      "        [-0.5135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2066]],\n",
      "\n",
      "        [[-0.1812]],\n",
      "\n",
      "        [[-0.2471]],\n",
      "\n",
      "        [[-0.3580]]], dtype=torch.float64)\n",
      "tensor([[-0.5155],\n",
      "        [-0.3989],\n",
      "        [-0.5179],\n",
      "        [-0.6530]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3025]],\n",
      "\n",
      "        [[-0.4169]],\n",
      "\n",
      "        [[-0.7323]],\n",
      "\n",
      "        [[-0.7843]]], dtype=torch.float64)\n",
      "tensor([[-0.7278],\n",
      "        [-0.7690],\n",
      "        [-0.8599],\n",
      "        [-0.8833]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6168]],\n",
      "\n",
      "        [[-0.7820]],\n",
      "\n",
      "        [[-0.9114]],\n",
      "\n",
      "        [[-0.9865]]], dtype=torch.float64)\n",
      "tensor([[-0.7684],\n",
      "        [-0.7707],\n",
      "        [-0.8033],\n",
      "        [-0.8243]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9992]],\n",
      "\n",
      "        [[-0.9750]],\n",
      "\n",
      "        [[-0.7046]],\n",
      "\n",
      "        [[-0.8167]]], dtype=torch.float64)\n",
      "tensor([[-0.8823],\n",
      "        [-0.8373],\n",
      "        [-0.7102],\n",
      "        [-0.6656]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9403]],\n",
      "\n",
      "        [[-0.8120]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[-0.7970]]], dtype=torch.float64)\n",
      "tensor([[-0.7137],\n",
      "        [-0.6529],\n",
      "        [-0.8775],\n",
      "        [-0.6806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5394]],\n",
      "\n",
      "        [[-0.7658]],\n",
      "\n",
      "        [[-0.7023]],\n",
      "\n",
      "        [[-0.6376]]], dtype=torch.float64)\n",
      "tensor([[-0.6975],\n",
      "        [-0.5849],\n",
      "        [-0.6938],\n",
      "        [-0.6682]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5925]],\n",
      "\n",
      "        [[-0.5324]],\n",
      "\n",
      "        [[-0.4596]],\n",
      "\n",
      "        [[-0.5740]]], dtype=torch.float64)\n",
      "tensor([[-0.4877],\n",
      "        [-0.3773],\n",
      "        [-0.1339],\n",
      "        [-0.0530]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4065]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[-0.1373]],\n",
      "\n",
      "        [[-0.4631]]], dtype=torch.float64)\n",
      "tensor([[-0.5488],\n",
      "        [-0.6704],\n",
      "        [-0.8457],\n",
      "        [-0.8551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3245]],\n",
      "\n",
      "        [[-0.6792]],\n",
      "\n",
      "        [[-0.8178]],\n",
      "\n",
      "        [[-0.9657]]], dtype=torch.float64)\n",
      "tensor([[-0.7338],\n",
      "        [-0.7364],\n",
      "        [-0.7917],\n",
      "        [-0.8377]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8964]],\n",
      "\n",
      "        [[-0.9426]],\n",
      "\n",
      "        [[-0.5301]],\n",
      "\n",
      "        [[-0.7912]]], dtype=torch.float64)\n",
      "tensor([[-1.0132],\n",
      "        [-0.9415],\n",
      "        [-1.1096],\n",
      "        [-1.0189]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9449]],\n",
      "\n",
      "        [[-1.1009]],\n",
      "\n",
      "        [[-1.3066]],\n",
      "\n",
      "        [[-1.3736]]], dtype=torch.float64)\n",
      "tensor([[-1.0609],\n",
      "        [-0.9336],\n",
      "        [-1.0947],\n",
      "        [-1.1424]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7982]],\n",
      "\n",
      "        [[-0.9484]],\n",
      "\n",
      "        [[-1.1644]],\n",
      "\n",
      "        [[-1.0893]]], dtype=torch.float64)\n",
      "tensor([[-0.5576],\n",
      "        [-0.4243],\n",
      "        [-0.4901],\n",
      "        [-0.4025]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7785]],\n",
      "\n",
      "        [[-0.6052]],\n",
      "\n",
      "        [[-0.3464]],\n",
      "\n",
      "        [[-0.3083]]], dtype=torch.float64)\n",
      "tensor([[-0.5818],\n",
      "        [-0.7003],\n",
      "        [-0.4482],\n",
      "        [-0.3654]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5579]],\n",
      "\n",
      "        [[-0.8109]],\n",
      "\n",
      "        [[-0.6538]],\n",
      "\n",
      "        [[-0.6642]]], dtype=torch.float64)\n",
      "tensor([[-0.4952],\n",
      "        [-0.5723],\n",
      "        [-0.3833],\n",
      "        [-0.3577]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.2979]],\n",
      "\n",
      "        [[-0.1881]],\n",
      "\n",
      "        [[-0.4238]]], dtype=torch.float64)\n",
      "tensor([[-0.4453],\n",
      "        [-0.3552],\n",
      "        [-0.2716],\n",
      "        [-0.3696]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4261]],\n",
      "\n",
      "        [[-0.4412]],\n",
      "\n",
      "        [[-0.1061]],\n",
      "\n",
      "        [[-0.4296]]], dtype=torch.float64)\n",
      "tensor([[-0.5650],\n",
      "        [-0.6267],\n",
      "        [-0.5694],\n",
      "        [-0.6824]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4458]],\n",
      "\n",
      "        [[-0.6826]],\n",
      "\n",
      "        [[-0.6815]],\n",
      "\n",
      "        [[-0.6514]]], dtype=torch.float64)\n",
      "tensor([[-0.4672],\n",
      "        [-0.5607],\n",
      "        [-0.6494],\n",
      "        [-0.5628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4781]],\n",
      "\n",
      "        [[-0.5128]],\n",
      "\n",
      "        [[-0.6295]],\n",
      "\n",
      "        [[-0.6133]]], dtype=torch.float64)\n",
      "tensor([[-0.5215],\n",
      "        [-0.5128],\n",
      "        [-0.5964],\n",
      "        [-0.4483]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7104]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.6318]],\n",
      "\n",
      "        [[-0.0437]]], dtype=torch.float64)\n",
      "tensor([[-0.7468],\n",
      "        [-0.7831],\n",
      "        [-0.7474],\n",
      "        [-0.7866]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7104]],\n",
      "\n",
      "        [[-0.7416]],\n",
      "\n",
      "        [[-0.7785]],\n",
      "\n",
      "        [[-0.8536]]], dtype=torch.float64)\n",
      "tensor([[-0.8345],\n",
      "        [-0.9581],\n",
      "        [-0.9051],\n",
      "        [-0.7668]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6861]],\n",
      "\n",
      "        [[-0.7924]],\n",
      "\n",
      "        [[-0.7346]],\n",
      "\n",
      "        [[-0.8213]]], dtype=torch.float64)\n",
      "tensor([[-0.7221],\n",
      "        [-0.8367],\n",
      "        [-0.8635],\n",
      "        [-0.9435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9299]],\n",
      "\n",
      "        [[-0.9622]],\n",
      "\n",
      "        [[-0.8999]],\n",
      "\n",
      "        [[-0.8906]]], dtype=torch.float64)\n",
      "tensor([[-1.0516],\n",
      "        [-1.0185],\n",
      "        [-0.8424],\n",
      "        [-0.9883]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0420]],\n",
      "\n",
      "        [[-0.9726]],\n",
      "\n",
      "        [[-1.1564]],\n",
      "\n",
      "        [[-1.2707]]], dtype=torch.float64)\n",
      "tensor([[-0.9259],\n",
      "        [-1.0790],\n",
      "        [-1.1173],\n",
      "        [-0.9104]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0154]],\n",
      "\n",
      "        [[-1.0235]],\n",
      "\n",
      "        [[-1.0339]],\n",
      "\n",
      "        [[-1.0524]]], dtype=torch.float64)\n",
      "tensor([[-0.9378],\n",
      "        [-0.9305],\n",
      "        [-0.9709],\n",
      "        [-1.0577]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2488]],\n",
      "\n",
      "        [[-1.1182]],\n",
      "\n",
      "        [[-1.0789]],\n",
      "\n",
      "        [[-1.1228]]], dtype=torch.float64)\n",
      "tensor([[-1.1485],\n",
      "        [-0.9300],\n",
      "        [-0.7104],\n",
      "        [-0.7535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1113]],\n",
      "\n",
      "        [[-0.7601]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.7716]]], dtype=torch.float64)\n",
      "tensor([[-0.7671],\n",
      "        [-0.8820],\n",
      "        [-0.9391],\n",
      "        [-0.7746]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7866]],\n",
      "\n",
      "        [[-0.8074]],\n",
      "\n",
      "        [[-0.7866]],\n",
      "\n",
      "        [[-0.8444]]], dtype=torch.float64)\n",
      "tensor([[-0.6932],\n",
      "        [-0.7122],\n",
      "        [-0.8096],\n",
      "        [-0.7587]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8479]],\n",
      "\n",
      "        [[-0.9311]],\n",
      "\n",
      "        [[-0.7069]],\n",
      "\n",
      "        [[-0.7473]]], dtype=torch.float64)\n",
      "tensor([[-0.8681],\n",
      "        [-0.7040],\n",
      "        [-0.3001],\n",
      "        [-0.3211]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7185]],\n",
      "\n",
      "        [[-0.4181]],\n",
      "\n",
      "        [[-0.3892]],\n",
      "\n",
      "        [[-0.4134]]], dtype=torch.float64)\n",
      "tensor([[-0.3553],\n",
      "        [-0.3100],\n",
      "        [-0.4659],\n",
      "        [-0.3053]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2736]],\n",
      "\n",
      "        [[-0.2089]],\n",
      "\n",
      "        [[-0.3164]],\n",
      "\n",
      "        [[-0.3291]]], dtype=torch.float64)\n",
      "tensor([[-0.2958],\n",
      "        [-0.2139],\n",
      "        [-0.8103],\n",
      "        [-0.8341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4019]],\n",
      "\n",
      "        [[-0.3314]],\n",
      "\n",
      "        [[-0.9010]],\n",
      "\n",
      "        [[-0.7023]]], dtype=torch.float64)\n",
      "tensor([[-0.9092],\n",
      "        [-0.8253],\n",
      "        [-0.7593],\n",
      "        [-0.5921]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-0.9287]],\n",
      "\n",
      "        [[-0.7878]],\n",
      "\n",
      "        [[-0.7716]]], dtype=torch.float64)\n",
      "tensor([[-0.5879],\n",
      "        [-0.6184],\n",
      "        [-0.7572],\n",
      "        [-0.4694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.5729]],\n",
      "\n",
      "        [[-0.5093]],\n",
      "\n",
      "        [[-0.3730]]], dtype=torch.float64)\n",
      "tensor([[-0.3543],\n",
      "        [-0.2283],\n",
      "        [-0.3831],\n",
      "        [-0.2974]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2621]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.1696]],\n",
      "\n",
      "        [[-0.1165]]], dtype=torch.float64)\n",
      "tensor([[-0.4571],\n",
      "        [-0.3094],\n",
      "        [-0.1576],\n",
      "        [-0.2478]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2678]],\n",
      "\n",
      "        [[-0.2759]],\n",
      "\n",
      "        [[-0.2852]],\n",
      "\n",
      "        [[-0.3071]]], dtype=torch.float64)\n",
      "tensor([[-0.3203],\n",
      "        [-0.3940],\n",
      "        [-0.5204],\n",
      "        [-0.4614]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3014]],\n",
      "\n",
      "        [[-0.2436]],\n",
      "\n",
      "        [[-0.2551]],\n",
      "\n",
      "        [[-0.3510]]], dtype=torch.float64)\n",
      "tensor([[-0.3523],\n",
      "        [-0.3250],\n",
      "        [-0.3629],\n",
      "        [-0.5508]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4042]],\n",
      "\n",
      "        [[-0.5047]],\n",
      "\n",
      "        [[-0.3903]],\n",
      "\n",
      "        [[-0.5787]]], dtype=torch.float64)\n",
      "tensor([[-0.8270],\n",
      "        [-0.5915],\n",
      "        [-0.5488],\n",
      "        [-0.5523]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7208]],\n",
      "\n",
      "        [[-0.6156]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.6792]]], dtype=torch.float64)\n",
      "tensor([[-0.6540],\n",
      "        [-0.6526],\n",
      "        [-0.6924],\n",
      "        [-0.5212]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5001]],\n",
      "\n",
      "        [[-0.5891]],\n",
      "\n",
      "        [[-0.7381]],\n",
      "\n",
      "        [[-0.6376]]], dtype=torch.float64)\n",
      "tensor([[-0.5068],\n",
      "        [-0.8049],\n",
      "        [-0.9566],\n",
      "        [-0.8768]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8698]],\n",
      "\n",
      "        [[-0.9819]],\n",
      "\n",
      "        [[-0.8848]],\n",
      "\n",
      "        [[-0.7970]]], dtype=torch.float64)\n",
      "tensor([[-0.9207],\n",
      "        [-0.8025],\n",
      "        [-0.7397],\n",
      "        [-0.7771]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8016]],\n",
      "\n",
      "        [[-0.8710]],\n",
      "\n",
      "        [[-0.8756]],\n",
      "\n",
      "        [[-1.0119]]], dtype=torch.float64)\n",
      "tensor([[-0.8573],\n",
      "        [-0.8320],\n",
      "        [-0.9137],\n",
      "        [-0.7826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7843]],\n",
      "\n",
      "        [[-0.7855]],\n",
      "\n",
      "        [[-0.8941]],\n",
      "\n",
      "        [[-0.7681]]], dtype=torch.float64)\n",
      "tensor([[-0.5408],\n",
      "        [-0.3838],\n",
      "        [-0.3221],\n",
      "        [-0.0795]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6410]],\n",
      "\n",
      "        [[-0.2574]],\n",
      "\n",
      "        [[ 0.0603]],\n",
      "\n",
      "        [[ 0.1932]]], dtype=torch.float64)\n",
      "tensor([[-0.0072],\n",
      "        [ 0.1294],\n",
      "        [ 0.1599],\n",
      "        [ 0.1420]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2128]],\n",
      "\n",
      "        [[0.3318]],\n",
      "\n",
      "        [[0.3295]],\n",
      "\n",
      "        [[0.2983]]], dtype=torch.float64)\n",
      "tensor([[-0.1092],\n",
      "        [-0.4014],\n",
      "        [-0.5132],\n",
      "        [-0.6127]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1581]],\n",
      "\n",
      "        [[-0.3499]],\n",
      "\n",
      "        [[-0.4700]],\n",
      "\n",
      "        [[-0.5336]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13705:  55%|█████▍    | 1680/3067 [00:05<00:04, 290.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6140],\n",
      "        [-0.5961],\n",
      "        [-0.5392],\n",
      "        [-0.4224]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9137]],\n",
      "\n",
      "        [[-0.7820]],\n",
      "\n",
      "        [[-0.4573]],\n",
      "\n",
      "        [[-0.2228]]], dtype=torch.float64)\n",
      "tensor([[-0.4026],\n",
      "        [-0.2258],\n",
      "        [-0.3416],\n",
      "        [-0.4819]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0957]],\n",
      "\n",
      "        [[-0.1777]],\n",
      "\n",
      "        [[-0.3892]],\n",
      "\n",
      "        [[-0.5047]]], dtype=torch.float64)\n",
      "tensor([[-0.6833],\n",
      "        [-0.6593],\n",
      "        [-0.7125],\n",
      "        [-0.5656]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4215]],\n",
      "\n",
      "        [[-0.5521]],\n",
      "\n",
      "        [[-0.5486]],\n",
      "\n",
      "        [[-0.6942]]], dtype=torch.float64)\n",
      "tensor([[-0.5280],\n",
      "        [-0.5656],\n",
      "        [-0.7671],\n",
      "        [-0.8624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5994]],\n",
      "\n",
      "        [[-0.4666]],\n",
      "\n",
      "        [[-0.8617]],\n",
      "\n",
      "        [[-0.6052]]], dtype=torch.float64)\n",
      "tensor([[-0.7918],\n",
      "        [-0.8414],\n",
      "        [-0.7298],\n",
      "        [-0.8235]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7635]],\n",
      "\n",
      "        [[-0.6861]],\n",
      "\n",
      "        [[-0.9103]],\n",
      "\n",
      "        [[-0.8317]]], dtype=torch.float64)\n",
      "tensor([[-0.8133],\n",
      "        [-0.8667],\n",
      "        [-0.9374],\n",
      "        [-0.7671]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.7577]],\n",
      "\n",
      "        [[-0.7450]],\n",
      "\n",
      "        [[-0.7612]]], dtype=torch.float64)\n",
      "tensor([[-0.5848],\n",
      "        [-0.5572],\n",
      "        [-0.6120],\n",
      "        [-0.6745]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7231]],\n",
      "\n",
      "        [[-0.8294]],\n",
      "\n",
      "        [[-0.7242]],\n",
      "\n",
      "        [[-0.5012]]], dtype=torch.float64)\n",
      "tensor([[-0.6696],\n",
      "        [-0.6580],\n",
      "        [-0.6110],\n",
      "        [-0.6765]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7023]],\n",
      "\n",
      "        [[-0.7265]],\n",
      "\n",
      "        [[-0.6711]],\n",
      "\n",
      "        [[-0.7762]]], dtype=torch.float64)\n",
      "tensor([[-0.6669],\n",
      "        [-0.6967],\n",
      "        [-0.7260],\n",
      "        [-0.5956]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5810]],\n",
      "\n",
      "        [[-0.6249]],\n",
      "\n",
      "        [[-0.6526]],\n",
      "\n",
      "        [[-0.7138]]], dtype=torch.float64)\n",
      "tensor([[-0.6375],\n",
      "        [-0.6659],\n",
      "        [-0.6529],\n",
      "        [-0.7003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7647]],\n",
      "\n",
      "        [[-0.7254]],\n",
      "\n",
      "        [[-0.6364]],\n",
      "\n",
      "        [[-0.7335]]], dtype=torch.float64)\n",
      "tensor([[-0.6841],\n",
      "        [-0.4639],\n",
      "        [-0.3420],\n",
      "        [-0.6454]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4758]],\n",
      "\n",
      "        [[-0.3383]],\n",
      "\n",
      "        [[-0.5359]],\n",
      "\n",
      "        [[-0.7566]]], dtype=torch.float64)\n",
      "tensor([[-0.6420],\n",
      "        [-0.6432],\n",
      "        [-0.6849],\n",
      "        [-0.6739]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4342]],\n",
      "\n",
      "        [[-0.4284]],\n",
      "\n",
      "        [[-0.5324]],\n",
      "\n",
      "        [[-0.5694]]], dtype=torch.float64)\n",
      "tensor([[-0.4324],\n",
      "        [-0.3547],\n",
      "        [-0.4763],\n",
      "        [-0.3794]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5752]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-0.1951]],\n",
      "\n",
      "        [[-0.2159]]], dtype=torch.float64)\n",
      "tensor([[-0.4307],\n",
      "        [-0.3385],\n",
      "        [-0.1712],\n",
      "        [-0.2093]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2702]],\n",
      "\n",
      "        [[-0.3279]],\n",
      "\n",
      "        [[-0.3395]],\n",
      "\n",
      "        [[-0.3245]]], dtype=torch.float64)\n",
      "tensor([[-0.1949],\n",
      "        [-0.2525],\n",
      "        [-0.3706],\n",
      "        [-0.6296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2551]],\n",
      "\n",
      "        [[-0.2020]],\n",
      "\n",
      "        [[-0.7601]],\n",
      "\n",
      "        [[-0.7161]]], dtype=torch.float64)\n",
      "tensor([[-0.6676],\n",
      "        [-0.7866],\n",
      "        [-0.8164],\n",
      "        [-0.9361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8040]],\n",
      "\n",
      "        [[-1.0373]],\n",
      "\n",
      "        [[-0.8328]],\n",
      "\n",
      "        [[-0.9079]]], dtype=torch.float64)\n",
      "tensor([[-0.8628],\n",
      "        [-0.7508],\n",
      "        [-0.7624],\n",
      "        [-0.7803]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8375]],\n",
      "\n",
      "        [[-0.8432]],\n",
      "\n",
      "        [[-0.9334]],\n",
      "\n",
      "        [[-1.0397]]], dtype=torch.float64)\n",
      "tensor([[-0.8496],\n",
      "        [-0.8977],\n",
      "        [-1.0488],\n",
      "        [-0.9556]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7369]],\n",
      "\n",
      "        [[-0.8675]],\n",
      "\n",
      "        [[-1.1021]],\n",
      "\n",
      "        [[-1.2026]]], dtype=torch.float64)\n",
      "tensor([[-0.9557],\n",
      "        [-1.0062],\n",
      "        [-1.0340],\n",
      "        [-1.1109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2927]],\n",
      "\n",
      "        [[-1.3562]],\n",
      "\n",
      "        [[-1.1159]],\n",
      "\n",
      "        [[-1.1286]]], dtype=torch.float64)\n",
      "tensor([[-1.2469],\n",
      "        [-1.2256],\n",
      "        [-1.1496],\n",
      "        [-1.1705]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3285]],\n",
      "\n",
      "        [[-1.3493]],\n",
      "\n",
      "        [[-1.4475]],\n",
      "\n",
      "        [[-1.5423]]], dtype=torch.float64)\n",
      "tensor([[-1.1806],\n",
      "        [-1.0939],\n",
      "        [-1.1591],\n",
      "        [-1.0841]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1691]],\n",
      "\n",
      "        [[-1.0096]],\n",
      "\n",
      "        [[-1.0570]],\n",
      "\n",
      "        [[-1.1356]]], dtype=torch.float64)\n",
      "tensor([[-0.9098],\n",
      "        [-0.9430],\n",
      "        [-0.9575],\n",
      "        [-1.0505]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0974]],\n",
      "\n",
      "        [[-1.0639]],\n",
      "\n",
      "        [[-0.9911]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-1.0908],\n",
      "        [-1.1988],\n",
      "        [-1.2265],\n",
      "        [-1.3158]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0743]],\n",
      "\n",
      "        [[-1.4579]],\n",
      "\n",
      "        [[-1.6093]],\n",
      "\n",
      "        [[-1.7144]]], dtype=torch.float64)\n",
      "tensor([[-1.2175],\n",
      "        [-0.8097],\n",
      "        [-1.0398],\n",
      "        [-0.7354]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8871]],\n",
      "\n",
      "        [[-0.5301]],\n",
      "\n",
      "        [[-0.8409]],\n",
      "\n",
      "        [[-0.9195]]], dtype=torch.float64)\n",
      "tensor([[-0.6664],\n",
      "        [-0.6372],\n",
      "        [-0.6558],\n",
      "        [-0.5880]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8398]],\n",
      "\n",
      "        [[-0.8294]],\n",
      "\n",
      "        [[-0.7092]],\n",
      "\n",
      "        [[-0.4215]]], dtype=torch.float64)\n",
      "tensor([[-0.5856],\n",
      "        [-0.6838],\n",
      "        [-0.7003],\n",
      "        [-0.8724]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5371]],\n",
      "\n",
      "        [[-0.6907]],\n",
      "\n",
      "        [[-0.8375]],\n",
      "\n",
      "        [[-0.9657]]], dtype=torch.float64)\n",
      "tensor([[-0.8873],\n",
      "        [-0.9057],\n",
      "        [-1.0514],\n",
      "        [-1.0030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8063]],\n",
      "\n",
      "        [[-0.7982]],\n",
      "\n",
      "        [[-1.0085]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-0.8713],\n",
      "        [-0.8041],\n",
      "        [-0.8652],\n",
      "        [-0.9183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9114]],\n",
      "\n",
      "        [[-0.9888]],\n",
      "\n",
      "        [[-1.1044]],\n",
      "\n",
      "        [[-0.6283]]], dtype=torch.float64)\n",
      "tensor([[-0.6650],\n",
      "        [-0.5722],\n",
      "        [-0.7291],\n",
      "        [-0.7972]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5602]],\n",
      "\n",
      "        [[-0.9253]],\n",
      "\n",
      "        [[-0.6919]],\n",
      "\n",
      "        [[-0.6376]]], dtype=torch.float64)\n",
      "tensor([[-0.7550],\n",
      "        [-0.7486],\n",
      "        [-0.7081],\n",
      "        [-0.6890]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4966]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-0.4111]],\n",
      "\n",
      "        [[-0.6098]]], dtype=torch.float64)\n",
      "tensor([[-0.6704],\n",
      "        [-0.7476],\n",
      "        [-0.7802],\n",
      "        [-0.7413]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6272]],\n",
      "\n",
      "        [[-0.8167]],\n",
      "\n",
      "        [[-0.4781]],\n",
      "\n",
      "        [[-0.5879]]], dtype=torch.float64)\n",
      "tensor([[-0.8790],\n",
      "        [-0.8712],\n",
      "        [-0.8506],\n",
      "        [-0.8752]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8606]],\n",
      "\n",
      "        [[-0.9807]],\n",
      "\n",
      "        [[-0.9484]],\n",
      "\n",
      "        [[-1.0027]]], dtype=torch.float64)\n",
      "tensor([[-0.9088],\n",
      "        [-0.9097],\n",
      "        [-0.9904],\n",
      "        [-0.9466]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7936]],\n",
      "\n",
      "        [[-0.7681]],\n",
      "\n",
      "        [[-0.8687]],\n",
      "\n",
      "        [[-0.9588]]], dtype=torch.float64)\n",
      "tensor([[-0.8846],\n",
      "        [-0.8772],\n",
      "        [-0.9342],\n",
      "        [-1.0720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9357]],\n",
      "\n",
      "        [[-0.9565]],\n",
      "\n",
      "        [[-0.8791]],\n",
      "\n",
      "        [[-0.9114]]], dtype=torch.float64)\n",
      "tensor([[-1.2737],\n",
      "        [-1.1619],\n",
      "        [-1.1068],\n",
      "        [-1.1624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1621]],\n",
      "\n",
      "        [[-1.1991]],\n",
      "\n",
      "        [[-1.3378]],\n",
      "\n",
      "        [[-1.5296]]], dtype=torch.float64)\n",
      "tensor([[-1.1762],\n",
      "        [-1.0795],\n",
      "        [-1.3193],\n",
      "        [-1.3650]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0466]],\n",
      "\n",
      "        [[-1.0570]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.4718]]], dtype=torch.float64)\n",
      "tensor([[-1.1843],\n",
      "        [-1.1538],\n",
      "        [-1.1741],\n",
      "        [-1.1669]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3562]],\n",
      "\n",
      "        [[-1.3343]],\n",
      "\n",
      "        [[-1.0293]],\n",
      "\n",
      "        [[-1.1252]]], dtype=torch.float64)\n",
      "tensor([[-1.2186],\n",
      "        [-1.1697],\n",
      "        [-1.0550],\n",
      "        [-1.0689]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2014]],\n",
      "\n",
      "        [[-1.1899]],\n",
      "\n",
      "        [[-1.1656]],\n",
      "\n",
      "        [[-1.2338]]], dtype=torch.float64)\n",
      "tensor([[-1.2752],\n",
      "        [-1.4794],\n",
      "        [-1.5748],\n",
      "        [-1.6519]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3008]],\n",
      "\n",
      "        [[-1.3643]],\n",
      "\n",
      "        [[-1.5076]],\n",
      "\n",
      "        [[-1.6694]]], dtype=torch.float64)\n",
      "tensor([[-1.6267],\n",
      "        [-1.6953],\n",
      "        [-1.7629],\n",
      "        [-1.8007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7653]],\n",
      "\n",
      "        [[-1.8115]],\n",
      "\n",
      "        [[-1.7849]],\n",
      "\n",
      "        [[-1.6497]]], dtype=torch.float64)\n",
      "tensor([[-1.7981],\n",
      "        [-1.8878],\n",
      "        [-1.8635],\n",
      "        [-1.8432]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.8011]],\n",
      "\n",
      "        [[-1.9744]],\n",
      "\n",
      "        [[-2.1073]],\n",
      "\n",
      "        [[-2.0899]]], dtype=torch.float64)\n",
      "tensor([[-1.8883],\n",
      "        [-1.7787],\n",
      "        [-1.8921],\n",
      "        [-1.9947]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7468]],\n",
      "\n",
      "        [[-1.5700]],\n",
      "\n",
      "        [[-1.8415]],\n",
      "\n",
      "        [[-2.1442]]], dtype=torch.float64)\n",
      "tensor([[-2.0733],\n",
      "        [-2.1011],\n",
      "        [-2.0745],\n",
      "        [-2.0747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3568]],\n",
      "\n",
      "        [[-2.3915]],\n",
      "\n",
      "        [[-1.9397]],\n",
      "\n",
      "        [[-1.8496]]], dtype=torch.float64)\n",
      "tensor([[-2.2143],\n",
      "        [-2.2908],\n",
      "        [-2.2128],\n",
      "        [-2.2844]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2089]],\n",
      "\n",
      "        [[-2.4169]],\n",
      "\n",
      "        [[-2.5197]],\n",
      "\n",
      "        [[-2.6272]]], dtype=torch.float64)\n",
      "tensor([[-2.4034],\n",
      "        [-2.4134],\n",
      "        [-2.3662],\n",
      "        [-2.4185]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4493]],\n",
      "\n",
      "        [[-2.2170]],\n",
      "\n",
      "        [[-2.3649]],\n",
      "\n",
      "        [[-2.5648]]], dtype=torch.float64)\n",
      "tensor([[-2.5033],\n",
      "        [-2.5510],\n",
      "        [-2.6351],\n",
      "        [-2.5077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.8121]],\n",
      "\n",
      "        [[-2.9056]],\n",
      "\n",
      "        [[-2.7404]],\n",
      "\n",
      "        [[-2.5047]]], dtype=torch.float64)\n",
      "tensor([[-2.6234],\n",
      "        [-2.6311],\n",
      "        [-2.6847],\n",
      "        [-2.8057]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.7300]],\n",
      "\n",
      "        [[-3.1078]],\n",
      "\n",
      "        [[-3.3378]],\n",
      "\n",
      "        [[-3.2268]]], dtype=torch.float64)\n",
      "tensor([[-2.7007],\n",
      "        [-2.2175],\n",
      "        [-2.3415],\n",
      "        [-2.5253]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.4077]],\n",
      "\n",
      "        [[-2.0506]],\n",
      "\n",
      "        [[-2.3695]],\n",
      "\n",
      "        [[-2.7716]]], dtype=torch.float64)\n",
      "tensor([[-2.6578],\n",
      "        [-2.4930],\n",
      "        [-2.3601],\n",
      "        [-2.4309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.7092]],\n",
      "\n",
      "        [[-2.6376]],\n",
      "\n",
      "        [[-2.1477]],\n",
      "\n",
      "        [[-2.1893]]], dtype=torch.float64)\n",
      "tensor([[-2.6126],\n",
      "        [-2.8328],\n",
      "        [-2.8565],\n",
      "        [-3.0345]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.5787]],\n",
      "\n",
      "        [[-2.8640]],\n",
      "\n",
      "        [[-3.1922]],\n",
      "\n",
      "        [[-3.3216]]], dtype=torch.float64)\n",
      "tensor([[-2.9331],\n",
      "        [-2.4677],\n",
      "        [-2.7581],\n",
      "        [-2.8989]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3961]],\n",
      "\n",
      "        [[-2.1465]],\n",
      "\n",
      "        [[-2.5636]],\n",
      "\n",
      "        [[-2.9438]]], dtype=torch.float64)\n",
      "tensor([[-3.0768],\n",
      "        [-3.0906],\n",
      "        [-3.0135],\n",
      "        [-2.9809]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-3.2222]],\n",
      "\n",
      "        [[-3.0605]],\n",
      "\n",
      "        [[-2.6723]],\n",
      "\n",
      "        [[-2.6387]]], dtype=torch.float64)\n",
      "tensor([[-3.1451],\n",
      "        [-3.2782],\n",
      "        [-3.3354],\n",
      "        [-3.2616]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-3.0235]],\n",
      "\n",
      "        [[-3.2615]],\n",
      "\n",
      "        [[-3.4452]],\n",
      "\n",
      "        [[-3.2245]]], dtype=torch.float64)\n",
      "tensor([[-3.0514],\n",
      "        [-2.9341],\n",
      "        [-2.8812],\n",
      "        [-2.6913]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6803]],\n",
      "\n",
      "        [[-2.4493]],\n",
      "\n",
      "        [[-2.3199]],\n",
      "\n",
      "        [[-2.2124]]], dtype=torch.float64)\n",
      "tensor([[-2.4388],\n",
      "        [-2.3923],\n",
      "        [-2.4906],\n",
      "        [-2.5035]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2124]],\n",
      "\n",
      "        [[-2.2008]],\n",
      "\n",
      "        [[-2.1396]],\n",
      "\n",
      "        [[-2.0830]]], dtype=torch.float64)\n",
      "tensor([[-2.5242],\n",
      "        [-2.6748],\n",
      "        [-2.7140],\n",
      "        [-2.5573]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.3742]],\n",
      "\n",
      "        [[-2.6942]],\n",
      "\n",
      "        [[-2.8929]],\n",
      "\n",
      "        [[-2.5267]]], dtype=torch.float64)\n",
      "tensor([[-2.1729],\n",
      "        [-1.9009],\n",
      "        [-2.0124],\n",
      "        [-2.1824]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.7583]],\n",
      "\n",
      "        [[-1.6601]],\n",
      "\n",
      "        [[-1.6590]],\n",
      "\n",
      "        [[-1.9478]]], dtype=torch.float64)\n",
      "tensor([[-2.1226],\n",
      "        [-2.2334],\n",
      "        [-2.4868],\n",
      "        [-2.4911]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1893]],\n",
      "\n",
      "        [[-2.5648]],\n",
      "\n",
      "        [[-2.3418]],\n",
      "\n",
      "        [[-2.3279]]], dtype=torch.float64)\n",
      "tensor([[-2.5564],\n",
      "        [-2.6443],\n",
      "        [-2.5904],\n",
      "        [-2.4217]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.6480]],\n",
      "\n",
      "        [[-3.0790]],\n",
      "\n",
      "        [[-2.8779]],\n",
      "\n",
      "        [[-2.6526]]], dtype=torch.float64)\n",
      "tensor([[-2.2641],\n",
      "        [-2.3398],\n",
      "        [-2.3726],\n",
      "        [-2.5467]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.2586]],\n",
      "\n",
      "        [[-2.2517]],\n",
      "\n",
      "        [[-2.5683]],\n",
      "\n",
      "        [[-2.9819]]], dtype=torch.float64)\n",
      "tensor([[-2.5971],\n",
      "        [-2.4103],\n",
      "        [-2.1515],\n",
      "        [-1.7194]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13705:  57%|█████▋    | 1746/3067 [00:05<00:04, 306.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.1309]],\n",
      "\n",
      "        [[-2.8086]],\n",
      "\n",
      "        [[-2.0818]],\n",
      "\n",
      "        [[-1.6266]]], dtype=torch.float64)\n",
      "tensor([[-2.0031],\n",
      "        [-2.0203],\n",
      "        [-1.7444],\n",
      "        [-1.4581]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-2.1812]],\n",
      "\n",
      "        [[-2.0506]],\n",
      "\n",
      "        [[-1.8554]],\n",
      "\n",
      "        [[-1.5400]]], dtype=torch.float64)\n",
      "tensor([[-1.3330],\n",
      "        [-1.2976],\n",
      "        [-1.2983],\n",
      "        [-1.3384]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.2222]],\n",
      "\n",
      "        [[-1.1829]],\n",
      "\n",
      "        [[-1.2985]],\n",
      "\n",
      "        [[-1.4313]]], dtype=torch.float64)\n",
      "tensor([[-1.2431],\n",
      "        [-1.2454],\n",
      "        [-1.2141],\n",
      "        [-0.9854]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.4221]],\n",
      "\n",
      "        [[-1.3909]],\n",
      "\n",
      "        [[-1.0732]],\n",
      "\n",
      "        [[-0.8271]]], dtype=torch.float64)\n",
      "tensor([[-0.9955],\n",
      "        [-0.9943],\n",
      "        [-0.8938],\n",
      "        [-0.8150]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.9334]],\n",
      "\n",
      "        [[-0.9634]],\n",
      "\n",
      "        [[-0.7393]],\n",
      "\n",
      "        [[-0.8560]]], dtype=torch.float64)\n",
      "tensor([[-0.8624],\n",
      "        [-0.9079],\n",
      "        [-0.9723],\n",
      "        [-0.9675]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6318]],\n",
      "\n",
      "        [[-0.5787]],\n",
      "\n",
      "        [[-0.8074]],\n",
      "\n",
      "        [[-0.9877]]], dtype=torch.float64)\n",
      "tensor([[-0.9669],\n",
      "        [-1.0991],\n",
      "        [-1.0049],\n",
      "        [-0.8637]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0905]],\n",
      "\n",
      "        [[-1.1714]],\n",
      "\n",
      "        [[-0.7046]],\n",
      "\n",
      "        [[-0.5475]]], dtype=torch.float64)\n",
      "tensor([[-0.9267],\n",
      "        [-0.7690],\n",
      "        [-0.5792],\n",
      "        [-0.5794]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7705]],\n",
      "\n",
      "        [[-0.7912]],\n",
      "\n",
      "        [[-0.6514]],\n",
      "\n",
      "        [[-0.5486]]], dtype=torch.float64)\n",
      "tensor([[-0.5763],\n",
      "        [-0.4411],\n",
      "        [-0.6876],\n",
      "        [-0.5824]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3441]],\n",
      "\n",
      "        [[-0.2967]],\n",
      "\n",
      "        [[-0.4758]],\n",
      "\n",
      "        [[-0.5544]]], dtype=torch.float64)\n",
      "tensor([[-0.5527],\n",
      "        [-0.5250],\n",
      "        [-0.3723],\n",
      "        [-0.3608]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7947]],\n",
      "\n",
      "        [[-0.5486]],\n",
      "\n",
      "        [[-0.1904]],\n",
      "\n",
      "        [[-0.3175]]], dtype=torch.float64)\n",
      "tensor([[-0.4732],\n",
      "        [-0.3592],\n",
      "        [-0.3449],\n",
      "        [-0.4417]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3834]],\n",
      "\n",
      "        [[-0.3268]],\n",
      "\n",
      "        [[-0.3973]],\n",
      "\n",
      "        [[-0.8502]]], dtype=torch.float64)\n",
      "tensor([[-0.7908],\n",
      "        [-0.8318],\n",
      "        [-0.8384],\n",
      "        [-0.8970]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5775]],\n",
      "\n",
      "        [[-0.5186]],\n",
      "\n",
      "        [[-0.7832]],\n",
      "\n",
      "        [[-0.9322]]], dtype=torch.float64)\n",
      "tensor([[-0.8780],\n",
      "        [-0.9248],\n",
      "        [-0.9752],\n",
      "        [-0.9572]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0108]],\n",
      "\n",
      "        [[-1.0015]],\n",
      "\n",
      "        [[-0.9033]],\n",
      "\n",
      "        [[-0.7138]]], dtype=torch.float64)\n",
      "tensor([[-1.1368],\n",
      "        [-1.2199],\n",
      "        [-1.1990],\n",
      "        [-1.1355]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1852]],\n",
      "\n",
      "        [[-1.3713]],\n",
      "\n",
      "        [[-1.4429]],\n",
      "\n",
      "        [[-1.2211]]], dtype=torch.float64)\n",
      "tensor([[-0.8193],\n",
      "        [-0.6114],\n",
      "        [-0.8101],\n",
      "        [-0.7619]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6376]],\n",
      "\n",
      "        [[-0.6769]],\n",
      "\n",
      "        [[-0.7843]],\n",
      "\n",
      "        [[-0.7011]]], dtype=torch.float64)\n",
      "tensor([[-0.5712],\n",
      "        [-0.4534],\n",
      "        [-0.3074],\n",
      "        [-0.2604]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6953]],\n",
      "\n",
      "        [[-0.6676]],\n",
      "\n",
      "        [[-0.1546]],\n",
      "\n",
      "        [[ 0.0846]]], dtype=torch.float64)\n",
      "tensor([[-0.4160],\n",
      "        [-0.4034],\n",
      "        [-0.3948],\n",
      "        [-0.3178]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3822]],\n",
      "\n",
      "        [[-0.2066]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.4181]]], dtype=torch.float64)\n",
      "tensor([[-0.3552],\n",
      "        [-0.2120],\n",
      "        [-0.1985],\n",
      "        [-0.1982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0553]],\n",
      "\n",
      "        [[ 0.0037]],\n",
      "\n",
      "        [[-0.0934]],\n",
      "\n",
      "        [[-0.1292]]], dtype=torch.float64)\n",
      "tensor([[ 0.0079],\n",
      "        [ 0.0439],\n",
      "        [-0.0413],\n",
      "        [-0.0146]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0483]],\n",
      "\n",
      "        [[-0.0691]],\n",
      "\n",
      "        [[ 0.2763]],\n",
      "\n",
      "        [[ 0.2579]]], dtype=torch.float64)\n",
      "tensor([[-0.0233],\n",
      "        [ 0.0525],\n",
      "        [-0.2451],\n",
      "        [-0.4960]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1631]],\n",
      "\n",
      "        [[-0.0657]],\n",
      "\n",
      "        [[-0.4492]],\n",
      "\n",
      "        [[-0.6283]]], dtype=torch.float64)\n",
      "tensor([[-0.3931],\n",
      "        [-0.3620],\n",
      "        [-0.5138],\n",
      "        [-0.5325]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1927]],\n",
      "\n",
      "        [[-0.1535]],\n",
      "\n",
      "        [[-0.4088]],\n",
      "\n",
      "        [[-0.5012]]], dtype=torch.float64)\n",
      "tensor([[-0.5012],\n",
      "        [-0.6203],\n",
      "        [-0.5764],\n",
      "        [-0.5853]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6064]],\n",
      "\n",
      "        [[-0.6549]],\n",
      "\n",
      "        [[-0.4897]],\n",
      "\n",
      "        [[-0.3522]]], dtype=torch.float64)\n",
      "tensor([[-0.7332],\n",
      "        [-0.9282],\n",
      "        [-0.9422],\n",
      "        [-0.9642]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7312]],\n",
      "\n",
      "        [[-1.0963]],\n",
      "\n",
      "        [[-1.2788]],\n",
      "\n",
      "        [[-1.1275]]], dtype=torch.float64)\n",
      "tensor([[-0.6186],\n",
      "        [-0.5389],\n",
      "        [-0.5786],\n",
      "        [-0.5377]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3799]],\n",
      "\n",
      "        [[-0.3545]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.6491]]], dtype=torch.float64)\n",
      "tensor([[-0.3995],\n",
      "        [-0.2622],\n",
      "        [-0.2545],\n",
      "        [-0.1594]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5787]],\n",
      "\n",
      "        [[-0.3649]],\n",
      "\n",
      "        [[-0.1384]],\n",
      "\n",
      "        [[ 0.0256]]], dtype=torch.float64)\n",
      "tensor([[-0.0842],\n",
      "        [-0.1252],\n",
      "        [ 0.0349],\n",
      "        [ 0.0579]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0345]],\n",
      "\n",
      "        [[-0.0610]],\n",
      "\n",
      "        [[ 0.0326]],\n",
      "\n",
      "        [[ 0.0279]]], dtype=torch.float64)\n",
      "tensor([[-0.0751],\n",
      "        [-0.0229],\n",
      "        [ 0.0012],\n",
      "        [ 0.0241]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1423]],\n",
      "\n",
      "        [[0.1978]],\n",
      "\n",
      "        [[0.1631]],\n",
      "\n",
      "        [[0.0557]]], dtype=torch.float64)\n",
      "tensor([[ 0.1758],\n",
      "        [ 0.0997],\n",
      "        [-0.0845],\n",
      "        [ 0.0688]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0206]],\n",
      "\n",
      "        [[ 0.0175]],\n",
      "\n",
      "        [[ 0.1608]],\n",
      "\n",
      "        [[ 0.5109]]], dtype=torch.float64)\n",
      "tensor([[0.0553],\n",
      "        [0.1024],\n",
      "        [0.0799],\n",
      "        [0.0165]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1077]],\n",
      "\n",
      "        [[-0.0137]],\n",
      "\n",
      "        [[-0.1084]],\n",
      "\n",
      "        [[-0.3788]]], dtype=torch.float64)\n",
      "tensor([[-0.2575],\n",
      "        [-0.2724],\n",
      "        [-0.3325],\n",
      "        [-0.4306]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2205]],\n",
      "\n",
      "        [[-0.0483]],\n",
      "\n",
      "        [[-0.3637]],\n",
      "\n",
      "        [[-0.6075]]], dtype=torch.float64)\n",
      "tensor([[-0.5005],\n",
      "        [-0.4116],\n",
      "        [-0.2501],\n",
      "        [-0.2114]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6861]],\n",
      "\n",
      "        [[-0.7808]],\n",
      "\n",
      "        [[-0.0576]],\n",
      "\n",
      "        [[ 0.1331]]], dtype=torch.float64)\n",
      "tensor([[-0.2823],\n",
      "        [-0.1585],\n",
      "        [-0.0973],\n",
      "        [-0.1295]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1615]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.3996]],\n",
      "\n",
      "        [[-0.4388]]], dtype=torch.float64)\n",
      "tensor([[-0.1428],\n",
      "        [-0.2183],\n",
      "        [-0.2781],\n",
      "        [-0.3218]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0888]],\n",
      "\n",
      "        [[ 0.0326]],\n",
      "\n",
      "        [[-0.1719]],\n",
      "\n",
      "        [[-0.4273]]], dtype=torch.float64)\n",
      "tensor([[-0.4936],\n",
      "        [-0.6083],\n",
      "        [-0.5109],\n",
      "        [-0.5032]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6526]],\n",
      "\n",
      "        [[-0.7762]],\n",
      "\n",
      "        [[-0.3961]],\n",
      "\n",
      "        [[-0.4446]]], dtype=torch.float64)\n",
      "tensor([[-0.5413],\n",
      "        [-0.5218],\n",
      "        [-0.4353],\n",
      "        [-0.5894]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5197]],\n",
      "\n",
      "        [[-0.6052]],\n",
      "\n",
      "        [[-0.7057]],\n",
      "\n",
      "        [[-0.9599]]], dtype=torch.float64)\n",
      "tensor([[-0.4448],\n",
      "        [-0.5944],\n",
      "        [-0.7184],\n",
      "        [-0.8973]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[-0.2690]],\n",
      "\n",
      "        [[-0.6815]],\n",
      "\n",
      "        [[-1.1587]]], dtype=torch.float64)\n",
      "tensor([[-0.9977],\n",
      "        [-1.0135],\n",
      "        [-0.6140],\n",
      "        [-0.2795]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.3978]],\n",
      "\n",
      "        [[-1.2835]],\n",
      "\n",
      "        [[-0.1408]],\n",
      "\n",
      "        [[-0.1234]]], dtype=torch.float64)\n",
      "tensor([[-0.3934],\n",
      "        [-0.3429],\n",
      "        [-0.4284],\n",
      "        [-0.5830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3337]],\n",
      "\n",
      "        [[-0.6156]],\n",
      "\n",
      "        [[-0.7196]],\n",
      "\n",
      "        [[-0.7034]]], dtype=torch.float64)\n",
      "tensor([[-0.4800],\n",
      "        [-0.3147],\n",
      "        [-0.5683],\n",
      "        [-0.5868]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2205]],\n",
      "\n",
      "        [[-0.1766]],\n",
      "\n",
      "        [[-0.7057]],\n",
      "\n",
      "        [[-0.7508]]], dtype=torch.float64)\n",
      "tensor([[-0.6703],\n",
      "        [-0.8473],\n",
      "        [-0.4453],\n",
      "        [-0.3083]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1298]],\n",
      "\n",
      "        [[-1.0166]],\n",
      "\n",
      "        [[-0.1488]],\n",
      "\n",
      "        [[ 0.0048]]], dtype=torch.float64)\n",
      "tensor([[-0.3967],\n",
      "        [-0.5105],\n",
      "        [-0.4732],\n",
      "        [-0.2160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4781]],\n",
      "\n",
      "        [[-0.7832]],\n",
      "\n",
      "        [[-0.6191]],\n",
      "\n",
      "        [[-0.3418]]], dtype=torch.float64)\n",
      "tensor([[-0.1236],\n",
      "        [-0.1171],\n",
      "        [-0.1165],\n",
      "        [ 0.0204]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1446]],\n",
      "\n",
      "        [[ 0.0880]],\n",
      "\n",
      "        [[-0.0437]],\n",
      "\n",
      "        [[-0.0194]]], dtype=torch.float64)\n",
      "tensor([[-0.0473],\n",
      "        [-0.1298],\n",
      "        [-0.2221],\n",
      "        [-0.2377]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3268]],\n",
      "\n",
      "        [[-0.3060]],\n",
      "\n",
      "        [[-0.1916]],\n",
      "\n",
      "        [[-0.1361]]], dtype=torch.float64)\n",
      "tensor([[-0.1779],\n",
      "        [-0.1987],\n",
      "        [-0.0383],\n",
      "        [-0.0172]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1985]],\n",
      "\n",
      "        [[-0.2528]],\n",
      "\n",
      "        [[-0.1985]],\n",
      "\n",
      "        [[-0.1997]]], dtype=torch.float64)\n",
      "tensor([[-0.1709],\n",
      "        [-0.1410],\n",
      "        [-0.1442],\n",
      "        [-0.0895]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0472]],\n",
      "\n",
      "        [[-0.0067]],\n",
      "\n",
      "        [[-0.1754]],\n",
      "\n",
      "        [[-0.1269]]], dtype=torch.float64)\n",
      "tensor([[-0.0780],\n",
      "        [-0.2289],\n",
      "        [-0.2620],\n",
      "        [-0.2381]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3256]],\n",
      "\n",
      "        [[-0.4308]],\n",
      "\n",
      "        [[-0.2563]],\n",
      "\n",
      "        [[-0.1985]]], dtype=torch.float64)\n",
      "tensor([[-0.2882],\n",
      "        [-0.2820],\n",
      "        [-0.2039],\n",
      "        [-0.2833]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2990]],\n",
      "\n",
      "        [[-0.3372]],\n",
      "\n",
      "        [[-0.4123]],\n",
      "\n",
      "        [[-0.4712]]], dtype=torch.float64)\n",
      "tensor([[-0.3198],\n",
      "        [-0.4320],\n",
      "        [-0.4550],\n",
      "        [-0.4883]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3949]],\n",
      "\n",
      "        [[-0.3510]],\n",
      "\n",
      "        [[-0.4134]],\n",
      "\n",
      "        [[-0.4758]]], dtype=torch.float64)\n",
      "tensor([[-0.2609],\n",
      "        [-0.3112],\n",
      "        [-0.2434],\n",
      "        [-0.0786]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5151]],\n",
      "\n",
      "        [[-0.5810]],\n",
      "\n",
      "        [[ 0.0083]],\n",
      "\n",
      "        [[ 0.6264]]], dtype=torch.float64)\n",
      "tensor([[-0.0549],\n",
      "        [-0.3060],\n",
      "        [-0.4995],\n",
      "        [-0.5503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0171]],\n",
      "\n",
      "        [[-0.6849]],\n",
      "\n",
      "        [[-0.8999]],\n",
      "\n",
      "        [[-0.4654]]], dtype=torch.float64)\n",
      "tensor([[0.0989],\n",
      "        [0.2962],\n",
      "        [0.1328],\n",
      "        [0.0848]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 1.2330]],\n",
      "\n",
      "        [[ 1.3983]],\n",
      "\n",
      "        [[ 0.6796]],\n",
      "\n",
      "        [[-0.1049]]], dtype=torch.float64)\n",
      "tensor([[-0.2212],\n",
      "        [-0.3826],\n",
      "        [ 0.2723],\n",
      "        [ 0.3010]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6110]],\n",
      "\n",
      "        [[-0.2990]],\n",
      "\n",
      "        [[ 1.2885]],\n",
      "\n",
      "        [[ 1.3093]]], dtype=torch.float64)\n",
      "tensor([[ 0.2073],\n",
      "        [ 0.2236],\n",
      "        [ 0.1820],\n",
      "        [-0.1586]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7813]],\n",
      "\n",
      "        [[ 0.3387]],\n",
      "\n",
      "        [[-0.2239]],\n",
      "\n",
      "        [[-0.1673]]], dtype=torch.float64)\n",
      "tensor([[ 0.0617],\n",
      "        [ 0.0535],\n",
      "        [-0.0762],\n",
      "        [-0.0792]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8529]],\n",
      "\n",
      "        [[ 0.1920]],\n",
      "\n",
      "        [[-0.0807]],\n",
      "\n",
      "        [[-0.2055]]], dtype=torch.float64)\n",
      "tensor([[-0.2334],\n",
      "        [-0.3794],\n",
      "        [-0.4776],\n",
      "        [-0.2635]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5451]],\n",
      "\n",
      "        [[-0.4816]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[ 0.1805]]], dtype=torch.float64)\n",
      "tensor([[-0.4252],\n",
      "        [-0.7169],\n",
      "        [-0.8282],\n",
      "        [-0.8431]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3614]],\n",
      "\n",
      "        [[-0.9934]],\n",
      "\n",
      "        [[-1.2858]],\n",
      "\n",
      "        [[-0.9415]]], dtype=torch.float64)\n",
      "tensor([[-0.2138],\n",
      "        [-0.1543],\n",
      "        [-0.1832],\n",
      "        [-0.2529]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2891]],\n",
      "\n",
      "        [[ 0.5733]],\n",
      "\n",
      "        [[ 0.2001]],\n",
      "\n",
      "        [[-0.2355]]], dtype=torch.float64)\n",
      "tensor([[-0.1198],\n",
      "        [-0.3644],\n",
      "        [ 0.0499],\n",
      "        [ 0.2097]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5209]],\n",
      "\n",
      "        [[-0.4181]],\n",
      "\n",
      "        [[ 0.5421]],\n",
      "\n",
      "        [[ 0.7859]]], dtype=torch.float64)\n",
      "tensor([[ 0.1043],\n",
      "        [ 0.0668],\n",
      "        [-0.0499],\n",
      "        [-0.1955]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2070]],\n",
      "\n",
      "        [[-0.2598]],\n",
      "\n",
      "        [[-0.5983]],\n",
      "\n",
      "        [[-0.3892]]], dtype=torch.float64)\n",
      "tensor([[0.0981],\n",
      "        [0.1604],\n",
      "        [0.0413],\n",
      "        [0.0296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4393]],\n",
      "\n",
      "        [[ 0.5352]],\n",
      "\n",
      "        [[ 0.1597]],\n",
      "\n",
      "        [[-0.3487]]], dtype=torch.float64)\n",
      "tensor([[-0.2490],\n",
      "        [-0.3277],\n",
      "        [-0.0792],\n",
      "        [ 0.1706]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6942]],\n",
      "\n",
      "        [[-0.6491]],\n",
      "\n",
      "        [[ 0.3711]],\n",
      "\n",
      "        [[ 0.7142]]], dtype=torch.float64)\n",
      "tensor([[ 0.1550],\n",
      "        [ 0.0223],\n",
      "        [-0.2024],\n",
      "        [-0.3624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2382]],\n",
      "\n",
      "        [[-0.3626]],\n",
      "\n",
      "        [[-0.6884]],\n",
      "\n",
      "        [[-0.7832]]], dtype=torch.float64)\n",
      "tensor([[0.1218],\n",
      "        [0.3494],\n",
      "        [0.3007],\n",
      "        [0.1969]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7119]],\n",
      "\n",
      "        [[ 0.9107]],\n",
      "\n",
      "        [[ 0.3515]],\n",
      "\n",
      "        [[-0.1881]]], dtype=torch.float64)\n",
      "tensor([[-0.0294],\n",
      "        [-0.3091],\n",
      "        [ 0.2578],\n",
      "        [ 0.2024]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6133]],\n",
      "\n",
      "        [[-0.3279]],\n",
      "\n",
      "        [[ 0.8309]],\n",
      "\n",
      "        [[ 1.0505]]], dtype=torch.float64)\n",
      "tensor([[ 0.0928],\n",
      "        [ 0.0530],\n",
      "        [-0.0986],\n",
      "        [-0.3132]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3884]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-0.4100]]], dtype=torch.float64)\n",
      "tensor([[ 0.0799],\n",
      "        [-0.0922],\n",
      "        [-0.1479],\n",
      "        [-0.2591]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2844]],\n",
      "\n",
      "        [[ 0.5144]],\n",
      "\n",
      "        [[ 0.0614]],\n",
      "\n",
      "        [[-0.5405]]], dtype=torch.float64)\n",
      "tensor([[-0.4160],\n",
      "        [-0.5163],\n",
      "        [ 0.1889],\n",
      "        [ 0.4381]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13695:  59%|█████▉    | 1812/3067 [00:05<00:03, 314.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8502]],\n",
      "\n",
      "        [[-0.6838]],\n",
      "\n",
      "        [[ 0.7801]],\n",
      "\n",
      "        [[ 1.0447]]], dtype=torch.float64)\n",
      "tensor([[ 0.3508],\n",
      "        [ 0.1872],\n",
      "        [ 0.0449],\n",
      "        [-0.0811]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4924]],\n",
      "\n",
      "        [[-0.0102]],\n",
      "\n",
      "        [[-0.4897]],\n",
      "\n",
      "        [[ 0.1169]]], dtype=torch.float64)\n",
      "tensor([[0.2748],\n",
      "        [0.4542],\n",
      "        [0.2337],\n",
      "        [0.2394]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8055]],\n",
      "\n",
      "        [[1.1498]],\n",
      "\n",
      "        [[0.5952]],\n",
      "\n",
      "        [[0.3977]]], dtype=torch.float64)\n",
      "tensor([[ 0.2871],\n",
      "        [ 0.0936],\n",
      "        [-0.1120],\n",
      "        [-0.0680]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0996]],\n",
      "\n",
      "        [[-0.0934]],\n",
      "\n",
      "        [[ 0.0545]],\n",
      "\n",
      "        [[-0.0402]]], dtype=torch.float64)\n",
      "tensor([[-0.1914],\n",
      "        [-0.2429],\n",
      "        [-0.1889],\n",
      "        [-0.0529]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3198]],\n",
      "\n",
      "        [[-0.3880]],\n",
      "\n",
      "        [[-0.3187]],\n",
      "\n",
      "        [[-0.1951]]], dtype=torch.float64)\n",
      "tensor([[-0.0556],\n",
      "        [-0.0799],\n",
      "        [-0.1717],\n",
      "        [-0.0889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0298]],\n",
      "\n",
      "        [[-0.0957]],\n",
      "\n",
      "        [[-0.0980]],\n",
      "\n",
      "        [[-0.0772]]], dtype=torch.float64)\n",
      "tensor([[-0.0673],\n",
      "        [-0.1359],\n",
      "        [-0.0768],\n",
      "        [-0.4445]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2112]],\n",
      "\n",
      "        [[-0.0899]],\n",
      "\n",
      "        [[ 0.0395]],\n",
      "\n",
      "        [[-0.3580]]], dtype=torch.float64)\n",
      "tensor([[-0.5640],\n",
      "        [-0.6239],\n",
      "        [-0.6167],\n",
      "        [-0.5867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8063]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-1.0350]],\n",
      "\n",
      "        [[-0.7011]]], dtype=torch.float64)\n",
      "tensor([[-0.3962],\n",
      "        [-0.2475],\n",
      "        [-0.4189],\n",
      "        [-0.3990]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2690]],\n",
      "\n",
      "        [[ 0.0060]],\n",
      "\n",
      "        [[-0.3695]],\n",
      "\n",
      "        [[-0.3429]]], dtype=torch.float64)\n",
      "tensor([[-0.2475],\n",
      "        [-0.2515],\n",
      "        [-0.0926],\n",
      "        [-0.1008]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3545]],\n",
      "\n",
      "        [[-0.3476]],\n",
      "\n",
      "        [[-0.1153]],\n",
      "\n",
      "        [[ 0.0684]]], dtype=torch.float64)\n",
      "tensor([[-0.2211],\n",
      "        [-0.3125],\n",
      "        [-0.3342],\n",
      "        [-0.3157]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1835]],\n",
      "\n",
      "        [[-0.5440]],\n",
      "\n",
      "        [[-0.6688]],\n",
      "\n",
      "        [[-0.4342]]], dtype=torch.float64)\n",
      "tensor([[ 0.1455],\n",
      "        [ 0.2818],\n",
      "        [ 0.1903],\n",
      "        [-0.0323]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6091]],\n",
      "\n",
      "        [[ 0.9638]],\n",
      "\n",
      "        [[ 0.4150]],\n",
      "\n",
      "        [[-0.2852]]], dtype=torch.float64)\n",
      "tensor([[-0.1547],\n",
      "        [-0.0453],\n",
      "        [ 0.1093],\n",
      "        [-0.0941]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3337]],\n",
      "\n",
      "        [[-0.1107]],\n",
      "\n",
      "        [[ 0.3168]],\n",
      "\n",
      "        [[-0.1904]]], dtype=torch.float64)\n",
      "tensor([[-0.4197],\n",
      "        [-0.4786],\n",
      "        [-0.3669],\n",
      "        [-0.3356]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4747]],\n",
      "\n",
      "        [[-0.5417]],\n",
      "\n",
      "        [[-0.6295]],\n",
      "\n",
      "        [[-0.6087]]], dtype=torch.float64)\n",
      "tensor([[-0.3227],\n",
      "        [-0.4944],\n",
      "        [-0.5719],\n",
      "        [-0.5221]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5891]],\n",
      "\n",
      "        [[-0.5509]],\n",
      "\n",
      "        [[-0.5763]],\n",
      "\n",
      "        [[-0.6549]]], dtype=torch.float64)\n",
      "tensor([[-0.4509],\n",
      "        [-0.4590],\n",
      "        [-0.4621],\n",
      "        [-0.5430]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7450]],\n",
      "\n",
      "        [[-0.7566]],\n",
      "\n",
      "        [[-0.6803]],\n",
      "\n",
      "        [[-0.6145]]], dtype=torch.float64)\n",
      "tensor([[-0.5880],\n",
      "        [-0.6132],\n",
      "        [-0.6673],\n",
      "        [-0.4804]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.6364]],\n",
      "\n",
      "        [[-1.1078]],\n",
      "\n",
      "        [[-0.9854]],\n",
      "\n",
      "        [[-0.7127]]], dtype=torch.float64)\n",
      "tensor([[-0.4166],\n",
      "        [-0.5848],\n",
      "        [-0.7425],\n",
      "        [-0.8101]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5532]],\n",
      "\n",
      "        [[-0.4273]],\n",
      "\n",
      "        [[-0.8155]],\n",
      "\n",
      "        [[-1.0385]]], dtype=torch.float64)\n",
      "tensor([[-0.7960],\n",
      "        [-0.7001],\n",
      "        [-0.7695],\n",
      "        [-0.8433]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.1841]],\n",
      "\n",
      "        [[-0.8952]],\n",
      "\n",
      "        [[-0.7312]],\n",
      "\n",
      "        [[-0.5359]]], dtype=torch.float64)\n",
      "tensor([[-0.6928],\n",
      "        [-0.9212],\n",
      "        [-0.9108],\n",
      "        [-0.7036]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8652]],\n",
      "\n",
      "        [[-1.3250]],\n",
      "\n",
      "        [[-1.3539]],\n",
      "\n",
      "        [[-0.6572]]], dtype=torch.float64)\n",
      "tensor([[-0.1404],\n",
      "        [-0.2290],\n",
      "        [-0.3092],\n",
      "        [-0.2175]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2875]],\n",
      "\n",
      "        [[-0.2286]],\n",
      "\n",
      "        [[-0.2910]],\n",
      "\n",
      "        [[-0.1881]]], dtype=torch.float64)\n",
      "tensor([[0.0391],\n",
      "        [0.1202],\n",
      "        [0.3325],\n",
      "        [0.4266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1315]],\n",
      "\n",
      "        [[ 0.0222]],\n",
      "\n",
      "        [[ 0.6091]],\n",
      "\n",
      "        [[ 1.0747]]], dtype=torch.float64)\n",
      "tensor([[0.3255],\n",
      "        [0.3087],\n",
      "        [0.2704],\n",
      "        [0.2407]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.8390]],\n",
      "\n",
      "        [[ 0.3387]],\n",
      "\n",
      "        [[ 0.1169]],\n",
      "\n",
      "        [[-0.0044]]], dtype=torch.float64)\n",
      "tensor([[ 0.0326],\n",
      "        [-0.0294],\n",
      "        [-0.1427],\n",
      "        [-0.1621]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0707]],\n",
      "\n",
      "        [[ 0.0291]],\n",
      "\n",
      "        [[-0.1812]],\n",
      "\n",
      "        [[-0.2759]]], dtype=torch.float64)\n",
      "tensor([[-0.1594],\n",
      "        [-0.1048],\n",
      "        [ 0.1456],\n",
      "        [-0.0390]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3406]],\n",
      "\n",
      "        [[-0.2910]],\n",
      "\n",
      "        [[ 0.3572]],\n",
      "\n",
      "        [[ 0.0014]]], dtype=torch.float64)\n",
      "tensor([[-0.2633],\n",
      "        [-0.2735],\n",
      "        [-0.2795],\n",
      "        [-0.2879]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2274]],\n",
      "\n",
      "        [[-0.3949]],\n",
      "\n",
      "        [[-0.5163]],\n",
      "\n",
      "        [[-0.3337]]], dtype=torch.float64)\n",
      "tensor([[-0.2118],\n",
      "        [-0.0796],\n",
      "        [-0.2308],\n",
      "        [-0.4018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0603]],\n",
      "\n",
      "        [[ 0.2717]],\n",
      "\n",
      "        [[-0.1500]],\n",
      "\n",
      "        [[-0.7323]]], dtype=torch.float64)\n",
      "tensor([[-0.6234],\n",
      "        [-0.6885],\n",
      "        [-0.0659],\n",
      "        [-0.1723]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-1.0350]],\n",
      "\n",
      "        [[-0.5867]],\n",
      "\n",
      "        [[ 0.1816]],\n",
      "\n",
      "        [[ 0.2671]]], dtype=torch.float64)\n",
      "tensor([[-0.2056],\n",
      "        [-0.3336],\n",
      "        [-0.3738],\n",
      "        [-0.4218]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0268]],\n",
      "\n",
      "        [[-0.2390]],\n",
      "\n",
      "        [[-0.4978]],\n",
      "\n",
      "        [[-0.4100]]], dtype=torch.float64)\n",
      "tensor([[-0.1442],\n",
      "        [-0.2896],\n",
      "        [-0.2484],\n",
      "        [-0.1516]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1273]],\n",
      "\n",
      "        [[ 0.1331]],\n",
      "\n",
      "        [[ 0.0256]],\n",
      "\n",
      "        [[-0.1558]]], dtype=torch.float64)\n",
      "tensor([[-0.2106],\n",
      "        [-0.3067],\n",
      "        [-0.3883],\n",
      "        [-0.4789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.5220]],\n",
      "\n",
      "        [[-0.5082]],\n",
      "\n",
      "        [[-0.2193]],\n",
      "\n",
      "        [[-0.0853]]], dtype=torch.float64)\n",
      "tensor([[-0.5656],\n",
      "        [-0.5231],\n",
      "        [-0.6827],\n",
      "        [-0.7084]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4562]],\n",
      "\n",
      "        [[-0.7808]],\n",
      "\n",
      "        [[-1.1945]],\n",
      "\n",
      "        [[-0.6722]]], dtype=torch.float64)\n",
      "tensor([[-0.1918],\n",
      "        [-0.1811],\n",
      "        [-0.3633],\n",
      "        [-0.4601]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1546]],\n",
      "\n",
      "        [[ 0.1123]],\n",
      "\n",
      "        [[-0.1419]],\n",
      "\n",
      "        [[-0.5012]]], dtype=torch.float64)\n",
      "tensor([[-0.4761],\n",
      "        [-0.4366],\n",
      "        [ 0.0448],\n",
      "        [-0.0526]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.7705]],\n",
      "\n",
      "        [[-0.3453]],\n",
      "\n",
      "        [[ 0.0799]],\n",
      "\n",
      "        [[ 0.1597]]], dtype=torch.float64)\n",
      "tensor([[-0.2599],\n",
      "        [-0.3954],\n",
      "        [-0.5877],\n",
      "        [-0.5889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0333]],\n",
      "\n",
      "        [[-0.5625]],\n",
      "\n",
      "        [[-0.9819]],\n",
      "\n",
      "        [[-0.4839]]], dtype=torch.float64)\n",
      "tensor([[0.2131],\n",
      "        [0.1759],\n",
      "        [0.1500],\n",
      "        [0.0195]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6160]],\n",
      "\n",
      "        [[ 0.7374]],\n",
      "\n",
      "        [[ 0.3099]],\n",
      "\n",
      "        [[-0.1396]]], dtype=torch.float64)\n",
      "tensor([[-0.0777],\n",
      "        [-0.0672],\n",
      "        [ 0.1970],\n",
      "        [ 0.0809]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2621]],\n",
      "\n",
      "        [[-0.1442]],\n",
      "\n",
      "        [[ 0.3884]],\n",
      "\n",
      "        [[ 0.4693]]], dtype=torch.float64)\n",
      "tensor([[ 0.0830],\n",
      "        [-0.1359],\n",
      "        [-0.2043],\n",
      "        [-0.0831]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.1469]],\n",
      "\n",
      "        [[-0.2216]],\n",
      "\n",
      "        [[-0.4735]],\n",
      "\n",
      "        [[ 0.2036]]], dtype=torch.float64)\n",
      "tensor([[ 0.2784],\n",
      "        [ 0.1768],\n",
      "        [-0.0047],\n",
      "        [-0.2210]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3803]],\n",
      "\n",
      "        [[ 0.4196]],\n",
      "\n",
      "        [[-0.2771]],\n",
      "\n",
      "        [[-0.1523]]], dtype=torch.float64)\n",
      "tensor([[-0.1317],\n",
      "        [-0.0247],\n",
      "        [ 0.1381],\n",
      "        [ 0.0535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4308]],\n",
      "\n",
      "        [[-0.0703]],\n",
      "\n",
      "        [[ 0.1966]],\n",
      "\n",
      "        [[ 0.3769]]], dtype=torch.float64)\n",
      "tensor([[ 0.0647],\n",
      "        [-0.1745],\n",
      "        [-0.2471],\n",
      "        [-0.1774]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0795]],\n",
      "\n",
      "        [[-0.3175]],\n",
      "\n",
      "        [[-0.6052]],\n",
      "\n",
      "        [[-0.2112]]], dtype=torch.float64)\n",
      "tensor([[ 0.1484],\n",
      "        [ 0.0515],\n",
      "        [-0.0115],\n",
      "        [-0.3349]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2625]],\n",
      "\n",
      "        [[ 0.3630]],\n",
      "\n",
      "        [[-0.1719]],\n",
      "\n",
      "        [[-0.4608]]], dtype=torch.float64)\n",
      "tensor([[-0.2444],\n",
      "        [-0.0587],\n",
      "        [ 0.1461],\n",
      "        [ 0.0557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4261]],\n",
      "\n",
      "        [[-0.0449]],\n",
      "\n",
      "        [[ 0.1874]],\n",
      "\n",
      "        [[ 0.2486]]], dtype=torch.float64)\n",
      "tensor([[-0.0234],\n",
      "        [-0.1499],\n",
      "        [-0.0141],\n",
      "        [ 0.0500]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.0568]],\n",
      "\n",
      "        [[-0.2401]],\n",
      "\n",
      "        [[-0.1743]],\n",
      "\n",
      "        [[ 0.1157]]], dtype=torch.float64)\n",
      "tensor([[0.1740],\n",
      "        [0.2300],\n",
      "        [0.2438],\n",
      "        [0.4032]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4034]],\n",
      "\n",
      "        [[0.6253]],\n",
      "\n",
      "        [[0.5640]],\n",
      "\n",
      "        [[0.4150]]], dtype=torch.float64)\n",
      "tensor([[0.4694],\n",
      "        [0.4271],\n",
      "        [0.6750],\n",
      "        [0.5711]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1573]],\n",
      "\n",
      "        [[0.5502]],\n",
      "\n",
      "        [[1.0666]],\n",
      "\n",
      "        [[0.9754]]], dtype=torch.float64)\n",
      "tensor([[0.4904],\n",
      "        [0.5560],\n",
      "        [0.5094],\n",
      "        [0.4819]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7246]],\n",
      "\n",
      "        [[0.4034]],\n",
      "\n",
      "        [[0.0938]],\n",
      "\n",
      "        [[0.7443]]], dtype=torch.float64)\n",
      "tensor([[0.9656],\n",
      "        [1.0404],\n",
      "        [0.9307],\n",
      "        [0.8296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5947]],\n",
      "\n",
      "        [[1.4791]],\n",
      "\n",
      "        [[1.3370]],\n",
      "\n",
      "        [[0.6322]]], dtype=torch.float64)\n",
      "tensor([[0.6749],\n",
      "        [0.7406],\n",
      "        [1.3561],\n",
      "        [1.5978]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4924]],\n",
      "\n",
      "        [[0.8806]],\n",
      "\n",
      "        [[2.1758]],\n",
      "\n",
      "        [[2.3480]]], dtype=torch.float64)\n",
      "tensor([[1.4975],\n",
      "        [1.2408],\n",
      "        [1.0745],\n",
      "        [1.1069]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9448]],\n",
      "\n",
      "        [[1.2122]],\n",
      "\n",
      "        [[1.0239]],\n",
      "\n",
      "        [[1.4271]]], dtype=torch.float64)\n",
      "tensor([[1.4123],\n",
      "        [1.3682],\n",
      "        [0.9954],\n",
      "        [0.9726]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9471]],\n",
      "\n",
      "        [[2.0776]],\n",
      "\n",
      "        [[1.3671]],\n",
      "\n",
      "        [[0.8448]]], dtype=torch.float64)\n",
      "tensor([[0.8873],\n",
      "        [0.7936],\n",
      "        [1.1112],\n",
      "        [0.9518]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4520]],\n",
      "\n",
      "        [[1.0563]],\n",
      "\n",
      "        [[1.3775]],\n",
      "\n",
      "        [[1.4791]]], dtype=torch.float64)\n",
      "tensor([[0.9017],\n",
      "        [0.8743],\n",
      "        [0.7851],\n",
      "        [0.6119]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1568]],\n",
      "\n",
      "        [[0.7293]],\n",
      "\n",
      "        [[0.3457]],\n",
      "\n",
      "        [[0.3491]]], dtype=torch.float64)\n",
      "tensor([[0.8209],\n",
      "        [1.1590],\n",
      "        [1.1080],\n",
      "        [0.9841]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1857]],\n",
      "\n",
      "        [[1.5854]],\n",
      "\n",
      "        [[1.2411]],\n",
      "\n",
      "        [[0.7316]]], dtype=torch.float64)\n",
      "tensor([[0.8680],\n",
      "        [0.8356],\n",
      "        [1.1158],\n",
      "        [1.3478]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3769]],\n",
      "\n",
      "        [[0.6958]],\n",
      "\n",
      "        [[1.4040]],\n",
      "\n",
      "        [[1.7784]]], dtype=torch.float64)\n",
      "tensor([[1.0494],\n",
      "        [0.9941],\n",
      "        [1.0065],\n",
      "        [0.9374]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0516]],\n",
      "\n",
      "        [[0.8541]],\n",
      "\n",
      "        [[0.5872]],\n",
      "\n",
      "        [[0.6449]]], dtype=torch.float64)\n",
      "tensor([[0.6889],\n",
      "        [0.6905],\n",
      "        [0.4743],\n",
      "        [0.4571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7824]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.5640]],\n",
      "\n",
      "        [[0.0788]]], dtype=torch.float64)\n",
      "tensor([[0.2343],\n",
      "        [0.3031],\n",
      "        [0.8972],\n",
      "        [0.9356]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2286]],\n",
      "\n",
      "        [[ 0.3873]],\n",
      "\n",
      "        [[ 1.1949]],\n",
      "\n",
      "        [[ 1.3751]]], dtype=torch.float64)\n",
      "tensor([[0.8671],\n",
      "        [0.6917],\n",
      "        [0.5551],\n",
      "        [0.5523]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9338]],\n",
      "\n",
      "        [[0.3826]],\n",
      "\n",
      "        [[0.0672]],\n",
      "\n",
      "        [[0.3457]]], dtype=torch.float64)\n",
      "tensor([[ 0.6749],\n",
      "        [ 0.5240],\n",
      "        [-0.0069],\n",
      "        [-0.1273]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.5883]],\n",
      "\n",
      "        [[ 0.4185]],\n",
      "\n",
      "        [[-0.0899]],\n",
      "\n",
      "        [[-0.2910]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13695:  61%|██████    | 1877/3067 [00:05<00:03, 310.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1744],\n",
      "        [-0.0945],\n",
      "        [-0.1137],\n",
      "        [-0.0847]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.4284]],\n",
      "\n",
      "        [[-0.4019]],\n",
      "\n",
      "        [[-0.1800]],\n",
      "\n",
      "        [[-0.1396]]], dtype=torch.float64)\n",
      "tensor([[-0.1455],\n",
      "        [-0.1297],\n",
      "        [ 0.1362],\n",
      "        [ 0.2110]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2055]],\n",
      "\n",
      "        [[-0.2447]],\n",
      "\n",
      "        [[-0.2216]],\n",
      "\n",
      "        [[-0.0217]]], dtype=torch.float64)\n",
      "tensor([[0.3769],\n",
      "        [0.3359],\n",
      "        [0.2178],\n",
      "        [0.2973]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.3468]],\n",
      "\n",
      "        [[ 0.3203]],\n",
      "\n",
      "        [[ 0.2140]],\n",
      "\n",
      "        [[-0.0668]]], dtype=torch.float64)\n",
      "tensor([[0.3813],\n",
      "        [0.5144],\n",
      "        [0.9149],\n",
      "        [1.0478]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0576]],\n",
      "\n",
      "        [[ 0.1920]],\n",
      "\n",
      "        [[ 1.0482]],\n",
      "\n",
      "        [[ 1.3659]]], dtype=torch.float64)\n",
      "tensor([[0.8906],\n",
      "        [0.7343],\n",
      "        [0.6339],\n",
      "        [0.6963]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8956]],\n",
      "\n",
      "        [[0.3896]],\n",
      "\n",
      "        [[0.0718]],\n",
      "\n",
      "        [[0.8032]]], dtype=torch.float64)\n",
      "tensor([[0.9768],\n",
      "        [1.0731],\n",
      "        [1.1041],\n",
      "        [1.0313]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9777]],\n",
      "\n",
      "        [[1.3463]],\n",
      "\n",
      "        [[1.1106]],\n",
      "\n",
      "        [[0.7350]]], dtype=torch.float64)\n",
      "tensor([[0.9919],\n",
      "        [1.0295],\n",
      "        [1.5318],\n",
      "        [1.5541]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3965]],\n",
      "\n",
      "        [[1.2018]],\n",
      "\n",
      "        [[1.6420]],\n",
      "\n",
      "        [[1.9390]]], dtype=torch.float64)\n",
      "tensor([[1.5781],\n",
      "        [1.6207],\n",
      "        [1.6065],\n",
      "        [1.5911]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6732]],\n",
      "\n",
      "        [[1.2746]],\n",
      "\n",
      "        [[1.1984]],\n",
      "\n",
      "        [[1.5346]]], dtype=torch.float64)\n",
      "tensor([[1.9018],\n",
      "        [1.9178],\n",
      "        [1.2946],\n",
      "        [0.7897]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2348]],\n",
      "\n",
      "        [[2.3064]],\n",
      "\n",
      "        [[1.2203]],\n",
      "\n",
      "        [[0.4208]]], dtype=torch.float64)\n",
      "tensor([[0.7149],\n",
      "        [0.4823],\n",
      "        [0.2962],\n",
      "        [0.2548]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2983]],\n",
      "\n",
      "        [[0.0938]],\n",
      "\n",
      "        [[0.2463]],\n",
      "\n",
      "        [[0.4439]]], dtype=torch.float64)\n",
      "tensor([[0.1629],\n",
      "        [0.0878],\n",
      "        [0.0518],\n",
      "        [0.1082]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1072]],\n",
      "\n",
      "        [[-0.3626]],\n",
      "\n",
      "        [[-0.7450]],\n",
      "\n",
      "        [[-0.2759]]], dtype=torch.float64)\n",
      "tensor([[-0.0194],\n",
      "        [-0.1250],\n",
      "        [-0.0673],\n",
      "        [ 0.0954]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1361]],\n",
      "\n",
      "        [[ 0.1377]],\n",
      "\n",
      "        [[-0.0252]],\n",
      "\n",
      "        [[-0.4019]]], dtype=torch.float64)\n",
      "tensor([[-0.1800],\n",
      "        [-0.0708],\n",
      "        [ 0.4578],\n",
      "        [ 0.4767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.8617]],\n",
      "\n",
      "        [[-0.0125]],\n",
      "\n",
      "        [[ 0.5606]],\n",
      "\n",
      "        [[ 0.8668]]], dtype=torch.float64)\n",
      "tensor([[0.4318],\n",
      "        [0.3913],\n",
      "        [0.3426],\n",
      "        [0.4799]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.4635]],\n",
      "\n",
      "        [[ 0.1319]],\n",
      "\n",
      "        [[-0.3580]],\n",
      "\n",
      "        [[ 0.5132]]], dtype=torch.float64)\n",
      "tensor([[ 6.5679e-01],\n",
      "        [ 1.9236e-01],\n",
      "        [ 6.4662e-04],\n",
      "        [-1.1257e-01]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.9419]],\n",
      "\n",
      "        [[ 0.1712]],\n",
      "\n",
      "        [[-0.0564]],\n",
      "\n",
      "        [[-0.3568]]], dtype=torch.float64)\n",
      "tensor([[-0.0166],\n",
      "        [ 0.0971],\n",
      "        [-0.0238],\n",
      "        [ 0.0485]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2678]],\n",
      "\n",
      "        [[-0.1049]],\n",
      "\n",
      "        [[ 0.1608]],\n",
      "\n",
      "        [[ 0.1053]]], dtype=torch.float64)\n",
      "tensor([[-0.0259],\n",
      "        [-0.2071],\n",
      "        [-0.1207],\n",
      "        [ 0.0884]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1662]],\n",
      "\n",
      "        [[-0.4123]],\n",
      "\n",
      "        [[-0.6434]],\n",
      "\n",
      "        [[-0.1384]]], dtype=torch.float64)\n",
      "tensor([[0.0846],\n",
      "        [0.1530],\n",
      "        [0.0728],\n",
      "        [0.0366]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2486]],\n",
      "\n",
      "        [[ 0.4658]],\n",
      "\n",
      "        [[ 0.1677]],\n",
      "\n",
      "        [[-0.2471]]], dtype=torch.float64)\n",
      "tensor([[0.0551],\n",
      "        [0.3015],\n",
      "        [0.4213],\n",
      "        [0.4102]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3603]],\n",
      "\n",
      "        [[ 0.2336]],\n",
      "\n",
      "        [[ 0.7119]],\n",
      "\n",
      "        [[ 1.1117]]], dtype=torch.float64)\n",
      "tensor([[0.5394],\n",
      "        [0.5537],\n",
      "        [0.7008],\n",
      "        [0.7351]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9014]],\n",
      "\n",
      "        [[0.5259]],\n",
      "\n",
      "        [[0.3757]],\n",
      "\n",
      "        [[0.8090]]], dtype=torch.float64)\n",
      "tensor([[0.9287],\n",
      "        [0.9835],\n",
      "        [0.9669],\n",
      "        [0.8902]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2850]],\n",
      "\n",
      "        [[1.7021]],\n",
      "\n",
      "        [[1.3474]],\n",
      "\n",
      "        [[0.7605]]], dtype=torch.float64)\n",
      "tensor([[0.7152],\n",
      "        [0.8507],\n",
      "        [1.1585],\n",
      "        [1.3239]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3260]],\n",
      "\n",
      "        [[1.1325]],\n",
      "\n",
      "        [[1.8142]],\n",
      "\n",
      "        [[2.2348]]], dtype=torch.float64)\n",
      "tensor([[1.2027],\n",
      "        [1.0603],\n",
      "        [0.9554],\n",
      "        [0.8856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6270]],\n",
      "\n",
      "        [[1.2134]],\n",
      "\n",
      "        [[0.6022]],\n",
      "\n",
      "        [[1.0043]]], dtype=torch.float64)\n",
      "tensor([[1.1723],\n",
      "        [1.2718],\n",
      "        [1.1842],\n",
      "        [1.1173]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7807]],\n",
      "\n",
      "        [[1.8743]],\n",
      "\n",
      "        [[1.6420]],\n",
      "\n",
      "        [[1.1926]]], dtype=torch.float64)\n",
      "tensor([[1.0461],\n",
      "        [0.9984],\n",
      "        [1.4271],\n",
      "        [1.4737]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6230]],\n",
      "\n",
      "        [[1.3855]],\n",
      "\n",
      "        [[1.9679]],\n",
      "\n",
      "        [[2.1389]]], dtype=torch.float64)\n",
      "tensor([[1.3819],\n",
      "        [1.2915],\n",
      "        [1.2110],\n",
      "        [1.3444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8489]],\n",
      "\n",
      "        [[1.2816]],\n",
      "\n",
      "        [[0.8494]],\n",
      "\n",
      "        [[1.4144]]], dtype=torch.float64)\n",
      "tensor([[1.5719],\n",
      "        [1.5436],\n",
      "        [1.4245],\n",
      "        [1.3297]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9760]],\n",
      "\n",
      "        [[2.1585]],\n",
      "\n",
      "        [[1.8292]],\n",
      "\n",
      "        [[1.2007]]], dtype=torch.float64)\n",
      "tensor([[1.3805],\n",
      "        [1.1959],\n",
      "        [1.3328],\n",
      "        [1.1731]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8321]],\n",
      "\n",
      "        [[0.8922]],\n",
      "\n",
      "        [[1.4780]],\n",
      "\n",
      "        [[1.6559]]], dtype=torch.float64)\n",
      "tensor([[1.0325],\n",
      "        [0.9207],\n",
      "        [0.8340],\n",
      "        [0.7914]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3104]],\n",
      "\n",
      "        [[0.7443]],\n",
      "\n",
      "        [[0.2775]],\n",
      "\n",
      "        [[0.6241]]], dtype=torch.float64)\n",
      "tensor([[0.8603],\n",
      "        [0.8929],\n",
      "        [0.9132],\n",
      "        [0.7901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1140]],\n",
      "\n",
      "        [[1.3555]],\n",
      "\n",
      "        [[1.0921]],\n",
      "\n",
      "        [[0.4242]]], dtype=torch.float64)\n",
      "tensor([[0.6797],\n",
      "        [0.8038],\n",
      "        [1.1979],\n",
      "        [1.0365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0256]],\n",
      "\n",
      "        [[0.7189]],\n",
      "\n",
      "        [[1.2457]],\n",
      "\n",
      "        [[1.4121]]], dtype=torch.float64)\n",
      "tensor([[1.0049],\n",
      "        [0.9556],\n",
      "        [0.9321],\n",
      "        [1.0527]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1787]],\n",
      "\n",
      "        [[0.5906]],\n",
      "\n",
      "        [[0.4277]],\n",
      "\n",
      "        [[1.0147]]], dtype=torch.float64)\n",
      "tensor([[1.2488],\n",
      "        [1.1717],\n",
      "        [1.1618],\n",
      "        [0.9409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2920]],\n",
      "\n",
      "        [[1.5600]],\n",
      "\n",
      "        [[1.1833]],\n",
      "\n",
      "        [[0.5929]]], dtype=torch.float64)\n",
      "tensor([[0.9085],\n",
      "        [0.9276],\n",
      "        [1.3693],\n",
      "        [1.2881]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3653]],\n",
      "\n",
      "        [[1.0701]],\n",
      "\n",
      "        [[1.5300]],\n",
      "\n",
      "        [[1.6351]]], dtype=torch.float64)\n",
      "tensor([[1.2976],\n",
      "        [1.0920],\n",
      "        [0.8986],\n",
      "        [0.8686]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3081]],\n",
      "\n",
      "        [[0.6553]],\n",
      "\n",
      "        [[0.2833]],\n",
      "\n",
      "        [[1.1256]]], dtype=torch.float64)\n",
      "tensor([[1.2588],\n",
      "        [1.2191],\n",
      "        [1.0465],\n",
      "        [0.8294]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5230]],\n",
      "\n",
      "        [[1.4098]],\n",
      "\n",
      "        [[0.9650]],\n",
      "\n",
      "        [[0.4566]]], dtype=torch.float64)\n",
      "tensor([[0.7161],\n",
      "        [0.8246],\n",
      "        [1.0518],\n",
      "        [1.2410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1908]],\n",
      "\n",
      "        [[0.9349]],\n",
      "\n",
      "        [[1.3728]],\n",
      "\n",
      "        [[1.3948]]], dtype=torch.float64)\n",
      "tensor([[0.9723],\n",
      "        [0.7959],\n",
      "        [0.7341],\n",
      "        [0.7738]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8933]],\n",
      "\n",
      "        [[0.4011]],\n",
      "\n",
      "        [[0.0649]],\n",
      "\n",
      "        [[0.8922]]], dtype=torch.float64)\n",
      "tensor([[1.1823],\n",
      "        [1.0190],\n",
      "        [0.7821],\n",
      "        [0.7179]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4202]],\n",
      "\n",
      "        [[0.7743]],\n",
      "\n",
      "        [[0.6958]],\n",
      "\n",
      "        [[0.4404]]], dtype=torch.float64)\n",
      "tensor([[0.7309],\n",
      "        [0.6054],\n",
      "        [0.5446],\n",
      "        [0.4005]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3237]],\n",
      "\n",
      "        [[0.3676]],\n",
      "\n",
      "        [[0.6507]],\n",
      "\n",
      "        [[0.4843]]], dtype=torch.float64)\n",
      "tensor([[0.3532],\n",
      "        [0.4034],\n",
      "        [0.4486],\n",
      "        [0.5092]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3249]],\n",
      "\n",
      "        [[0.1365]],\n",
      "\n",
      "        [[0.0118]],\n",
      "\n",
      "        [[0.1689]]], dtype=torch.float64)\n",
      "tensor([[0.3252],\n",
      "        [0.4399],\n",
      "        [0.4947],\n",
      "        [0.4123]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6287]],\n",
      "\n",
      "        [[ 0.7593]],\n",
      "\n",
      "        [[ 0.4554]],\n",
      "\n",
      "        [[-0.0449]]], dtype=torch.float64)\n",
      "tensor([[0.2443],\n",
      "        [0.2166],\n",
      "        [0.2983],\n",
      "        [0.1866]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3695]],\n",
      "\n",
      "        [[-0.1673]],\n",
      "\n",
      "        [[ 0.1400]],\n",
      "\n",
      "        [[ 0.2278]]], dtype=torch.float64)\n",
      "tensor([[0.1893],\n",
      "        [0.4205],\n",
      "        [0.5488],\n",
      "        [0.3943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1643]],\n",
      "\n",
      "        [[0.1885]],\n",
      "\n",
      "        [[0.0337]],\n",
      "\n",
      "        [[0.0430]]], dtype=torch.float64)\n",
      "tensor([[0.4007],\n",
      "        [0.5318],\n",
      "        [0.6002],\n",
      "        [0.6004]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3538]],\n",
      "\n",
      "        [[0.6357]],\n",
      "\n",
      "        [[0.4589]],\n",
      "\n",
      "        [[0.2948]]], dtype=torch.float64)\n",
      "tensor([[0.1792],\n",
      "        [0.1253],\n",
      "        [0.1685],\n",
      "        [0.1326]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.2678]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[ 0.2787]],\n",
      "\n",
      "        [[ 0.3930]]], dtype=torch.float64)\n",
      "tensor([[ 0.1838],\n",
      "        [ 0.0346],\n",
      "        [-0.1534],\n",
      "        [ 0.1477]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2324]],\n",
      "\n",
      "        [[-0.3441]],\n",
      "\n",
      "        [[-0.6503]],\n",
      "\n",
      "        [[-0.0726]]], dtype=torch.float64)\n",
      "tensor([[0.5528],\n",
      "        [0.4876],\n",
      "        [0.5648],\n",
      "        [0.7606]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7778]],\n",
      "\n",
      "        [[0.5929]],\n",
      "\n",
      "        [[0.6103]],\n",
      "\n",
      "        [[0.4162]]], dtype=torch.float64)\n",
      "tensor([[0.7313],\n",
      "        [0.7390],\n",
      "        [1.1873],\n",
      "        [1.0613]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2463]],\n",
      "\n",
      "        [[0.7870]],\n",
      "\n",
      "        [[1.3416]],\n",
      "\n",
      "        [[1.1961]]], dtype=torch.float64)\n",
      "tensor([[1.1148],\n",
      "        [1.1889],\n",
      "        [1.2914],\n",
      "        [1.3634]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1418]],\n",
      "\n",
      "        [[1.0528]],\n",
      "\n",
      "        [[0.9188]],\n",
      "\n",
      "        [[1.2700]]], dtype=torch.float64)\n",
      "tensor([[1.1552],\n",
      "        [0.9757],\n",
      "        [0.8741],\n",
      "        [0.8433]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5681]],\n",
      "\n",
      "        [[1.4537]],\n",
      "\n",
      "        [[1.0874]],\n",
      "\n",
      "        [[0.7478]]], dtype=torch.float64)\n",
      "tensor([[0.9977],\n",
      "        [0.9370],\n",
      "        [0.8365],\n",
      "        [0.6990]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6022]],\n",
      "\n",
      "        [[0.9234]],\n",
      "\n",
      "        [[1.2342]],\n",
      "\n",
      "        [[1.3428]]], dtype=torch.float64)\n",
      "tensor([[0.6784],\n",
      "        [0.6175],\n",
      "        [0.5948],\n",
      "        [0.7114]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8182]],\n",
      "\n",
      "        [[0.3480]],\n",
      "\n",
      "        [[0.1181]],\n",
      "\n",
      "        [[0.6842]]], dtype=torch.float64)\n",
      "tensor([[0.7242],\n",
      "        [0.7061],\n",
      "        [0.6821],\n",
      "        [0.7679]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0620]],\n",
      "\n",
      "        [[1.1510]],\n",
      "\n",
      "        [[0.9118]],\n",
      "\n",
      "        [[0.6807]]], dtype=torch.float64)\n",
      "tensor([[0.8705],\n",
      "        [0.8374],\n",
      "        [0.9377],\n",
      "        [0.7578]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4739]],\n",
      "\n",
      "        [[0.7304]],\n",
      "\n",
      "        [[1.0724]],\n",
      "\n",
      "        [[1.0193]]], dtype=torch.float64)\n",
      "tensor([[0.7766],\n",
      "        [0.4276],\n",
      "        [0.4543],\n",
      "        [0.5110]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4381]],\n",
      "\n",
      "        [[0.1238]],\n",
      "\n",
      "        [[0.0095]],\n",
      "\n",
      "        [[0.6415]]], dtype=torch.float64)\n",
      "tensor([[0.8750],\n",
      "        [0.8831],\n",
      "        [0.8087],\n",
      "        [0.7437]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0967]],\n",
      "\n",
      "        [[1.2504]],\n",
      "\n",
      "        [[0.9292]],\n",
      "\n",
      "        [[0.6634]]], dtype=torch.float64)\n",
      "tensor([[0.7555],\n",
      "        [0.8013],\n",
      "        [0.7719],\n",
      "        [0.6134]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5583]],\n",
      "\n",
      "        [[0.6391]],\n",
      "\n",
      "        [[0.8182]],\n",
      "\n",
      "        [[0.4647]]], dtype=torch.float64)\n",
      "tensor([[0.3190],\n",
      "        [0.4796],\n",
      "        [0.5443],\n",
      "        [0.5372]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3722]],\n",
      "\n",
      "        [[0.2116]],\n",
      "\n",
      "        [[0.1631]],\n",
      "\n",
      "        [[0.1816]]], dtype=torch.float64)\n",
      "tensor([[0.3617],\n",
      "        [0.3663],\n",
      "        [0.5844],\n",
      "        [0.4867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2683]],\n",
      "\n",
      "        [[0.6010]],\n",
      "\n",
      "        [[0.4866]],\n",
      "\n",
      "        [[0.0892]]], dtype=torch.float64)\n",
      "tensor([[0.4427],\n",
      "        [0.5473],\n",
      "        [1.1515],\n",
      "        [1.1595]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0980]],\n",
      "\n",
      "        [[ 0.5201]],\n",
      "\n",
      "        [[ 1.4144]],\n",
      "\n",
      "        [[ 1.5288]]], dtype=torch.float64)\n",
      "tensor([[1.1858],\n",
      "        [1.0718],\n",
      "        [0.9902],\n",
      "        [1.0182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4110]],\n",
      "\n",
      "        [[0.8067]],\n",
      "\n",
      "        [[0.4346]],\n",
      "\n",
      "        [[1.1533]]], dtype=torch.float64)\n",
      "tensor([[1.4302],\n",
      "        [1.0609],\n",
      "        [1.0095],\n",
      "        [0.8819]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7957]],\n",
      "\n",
      "        [[1.4502]],\n",
      "\n",
      "        [[1.1868]],\n",
      "\n",
      "        [[0.8333]]], dtype=torch.float64)\n",
      "tensor([[0.9807],\n",
      "        [0.9206],\n",
      "        [0.8987],\n",
      "        [0.9810]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6553]],\n",
      "\n",
      "        [[0.7501]],\n",
      "\n",
      "        [[1.2400]],\n",
      "\n",
      "        [[1.5912]]], dtype=torch.float64)\n",
      "tensor([[1.0962],\n",
      "        [0.9011],\n",
      "        [0.7264],\n",
      "        [1.0376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3266]],\n",
      "\n",
      "        [[0.5490]],\n",
      "\n",
      "        [[0.2971]],\n",
      "\n",
      "        [[1.3174]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.13952:  63%|██████▎   | 1941/3067 [00:06<00:03, 305.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5067],\n",
      "        [1.7690],\n",
      "        [1.5799],\n",
      "        [1.1175]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.1989]],\n",
      "\n",
      "        [[2.4531]],\n",
      "\n",
      "        [[1.6120]],\n",
      "\n",
      "        [[0.9881]]], dtype=torch.float64)\n",
      "tensor([[1.1611],\n",
      "        [1.0976],\n",
      "        [1.3206],\n",
      "        [1.2866]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7062]],\n",
      "\n",
      "        [[1.0597]],\n",
      "\n",
      "        [[1.5381]],\n",
      "\n",
      "        [[1.6744]]], dtype=torch.float64)\n",
      "tensor([[1.2893],\n",
      "        [1.2122],\n",
      "        [1.1729],\n",
      "        [1.1203]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3405]],\n",
      "\n",
      "        [[0.8471]],\n",
      "\n",
      "        [[0.7801]],\n",
      "\n",
      "        [[0.8425]]], dtype=torch.float64)\n",
      "tensor([[1.0608],\n",
      "        [0.9041],\n",
      "        [0.8377],\n",
      "        [0.9471]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0331]],\n",
      "\n",
      "        [[1.0262]],\n",
      "\n",
      "        [[0.9095]],\n",
      "\n",
      "        [[0.7489]]], dtype=torch.float64)\n",
      "tensor([[1.0092],\n",
      "        [0.8899],\n",
      "        [0.6773],\n",
      "        [0.5884]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6334]],\n",
      "\n",
      "        [[0.5271]],\n",
      "\n",
      "        [[0.7096]],\n",
      "\n",
      "        [[0.7304]]], dtype=torch.float64)\n",
      "tensor([[0.6531],\n",
      "        [0.8567],\n",
      "        [1.0515],\n",
      "        [1.1120]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7628]],\n",
      "\n",
      "        [[0.7570]],\n",
      "\n",
      "        [[0.6958]],\n",
      "\n",
      "        [[1.1706]]], dtype=torch.float64)\n",
      "tensor([[1.0687],\n",
      "        [0.9446],\n",
      "        [0.8727],\n",
      "        [0.6759]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3879]],\n",
      "\n",
      "        [[1.4167]],\n",
      "\n",
      "        [[0.9950]],\n",
      "\n",
      "        [[0.3179]]], dtype=torch.float64)\n",
      "tensor([[0.6141],\n",
      "        [0.7972],\n",
      "        [1.0473],\n",
      "        [0.9476]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0638]],\n",
      "\n",
      "        [[1.0170]],\n",
      "\n",
      "        [[1.4526]],\n",
      "\n",
      "        [[1.4375]]], dtype=torch.float64)\n",
      "tensor([[0.9672],\n",
      "        [0.8286],\n",
      "        [0.6907],\n",
      "        [0.8200]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0574]],\n",
      "\n",
      "        [[0.4913]],\n",
      "\n",
      "        [[0.1677]],\n",
      "\n",
      "        [[1.0019]]], dtype=torch.float64)\n",
      "tensor([[1.2084],\n",
      "        [1.0572],\n",
      "        [0.7514],\n",
      "        [0.5214]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6120]],\n",
      "\n",
      "        [[1.4283]],\n",
      "\n",
      "        [[0.6345]],\n",
      "\n",
      "        [[0.3676]]], dtype=torch.float64)\n",
      "tensor([[0.6253],\n",
      "        [0.6895],\n",
      "        [0.7307],\n",
      "        [0.5725]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3907]],\n",
      "\n",
      "        [[0.6287]],\n",
      "\n",
      "        [[1.0516]],\n",
      "\n",
      "        [[1.0447]]], dtype=torch.float64)\n",
      "tensor([[0.4020],\n",
      "        [0.4336],\n",
      "        [0.5497],\n",
      "        [0.5851]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4138]],\n",
      "\n",
      "        [[0.3307]],\n",
      "\n",
      "        [[0.1296]],\n",
      "\n",
      "        [[0.4577]]], dtype=torch.float64)\n",
      "tensor([[0.4236],\n",
      "        [0.4411],\n",
      "        [0.6559],\n",
      "        [0.5459]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5906]],\n",
      "\n",
      "        [[1.0019]],\n",
      "\n",
      "        [[0.7547]],\n",
      "\n",
      "        [[0.1331]]], dtype=torch.float64)\n",
      "tensor([[0.4951],\n",
      "        [0.5892],\n",
      "        [1.0613],\n",
      "        [1.0594]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1408]],\n",
      "\n",
      "        [[ 0.6680]],\n",
      "\n",
      "        [[ 1.5438]],\n",
      "\n",
      "        [[ 1.4375]]], dtype=torch.float64)\n",
      "tensor([[1.0743],\n",
      "        [0.8844],\n",
      "        [0.9822],\n",
      "        [1.0258]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9234]],\n",
      "\n",
      "        [[0.8055]],\n",
      "\n",
      "        [[0.6068]],\n",
      "\n",
      "        [[1.1961]]], dtype=torch.float64)\n",
      "tensor([[1.3419],\n",
      "        [1.5465],\n",
      "        [1.5789],\n",
      "        [1.4555]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7195]],\n",
      "\n",
      "        [[2.0834]],\n",
      "\n",
      "        [[1.7634]],\n",
      "\n",
      "        [[1.3555]]], dtype=torch.float64)\n",
      "tensor([[1.3260],\n",
      "        [1.4351],\n",
      "        [1.9594],\n",
      "        [1.9139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8980]],\n",
      "\n",
      "        [[1.8073]],\n",
      "\n",
      "        [[2.3884]],\n",
      "\n",
      "        [[2.5409]]], dtype=torch.float64)\n",
      "tensor([[1.8444],\n",
      "        [1.7481],\n",
      "        [1.6029],\n",
      "        [1.4767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0326]],\n",
      "\n",
      "        [[1.5935]],\n",
      "\n",
      "        [[1.2157]],\n",
      "\n",
      "        [[1.5196]]], dtype=torch.float64)\n",
      "tensor([[1.7438],\n",
      "        [1.8852],\n",
      "        [1.8194],\n",
      "        [1.6891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9852]],\n",
      "\n",
      "        [[2.3353]],\n",
      "\n",
      "        [[1.9378]],\n",
      "\n",
      "        [[1.1117]]], dtype=torch.float64)\n",
      "tensor([[1.3548],\n",
      "        [1.4458],\n",
      "        [1.1395],\n",
      "        [0.9745]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0482]],\n",
      "\n",
      "        [[1.3694]],\n",
      "\n",
      "        [[1.0482]],\n",
      "\n",
      "        [[1.2885]]], dtype=torch.float64)\n",
      "tensor([[1.0467],\n",
      "        [1.0180],\n",
      "        [1.0578],\n",
      "        [0.9637]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0563]],\n",
      "\n",
      "        [[0.8171]],\n",
      "\n",
      "        [[0.7073]],\n",
      "\n",
      "        [[0.9384]]], dtype=torch.float64)\n",
      "tensor([[1.1369],\n",
      "        [0.8363],\n",
      "        [0.7273],\n",
      "        [0.8462]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2273]],\n",
      "\n",
      "        [[1.0805]],\n",
      "\n",
      "        [[0.7870]],\n",
      "\n",
      "        [[0.6773]]], dtype=torch.float64)\n",
      "tensor([[1.0109],\n",
      "        [1.0530],\n",
      "        [1.0607],\n",
      "        [1.0965]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6657]],\n",
      "\n",
      "        [[0.9188]],\n",
      "\n",
      "        [[1.1360]],\n",
      "\n",
      "        [[1.4664]]], dtype=torch.float64)\n",
      "tensor([[1.1631],\n",
      "        [1.2824],\n",
      "        [1.2045],\n",
      "        [1.2148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3035]],\n",
      "\n",
      "        [[1.0297]],\n",
      "\n",
      "        [[0.7755]],\n",
      "\n",
      "        [[1.1464]]], dtype=torch.float64)\n",
      "tensor([[1.5257],\n",
      "        [1.5050],\n",
      "        [1.5049],\n",
      "        [1.4788]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7148]],\n",
      "\n",
      "        [[1.8870]],\n",
      "\n",
      "        [[1.6236]],\n",
      "\n",
      "        [[1.1926]]], dtype=torch.float64)\n",
      "tensor([[1.3995],\n",
      "        [1.3179],\n",
      "        [1.4122],\n",
      "        [1.1701]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9973]],\n",
      "\n",
      "        [[1.1880]],\n",
      "\n",
      "        [[1.4884]],\n",
      "\n",
      "        [[1.2862]]], dtype=torch.float64)\n",
      "tensor([[1.2021],\n",
      "        [1.1672],\n",
      "        [1.1790],\n",
      "        [1.1965]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2365]],\n",
      "\n",
      "        [[0.8852]],\n",
      "\n",
      "        [[0.8356]],\n",
      "\n",
      "        [[1.2157]]], dtype=torch.float64)\n",
      "tensor([[1.4256],\n",
      "        [1.4188],\n",
      "        [1.3695],\n",
      "        [1.2970]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1059]],\n",
      "\n",
      "        [[1.8766]],\n",
      "\n",
      "        [[1.4618]],\n",
      "\n",
      "        [[1.0147]]], dtype=torch.float64)\n",
      "tensor([[1.2377],\n",
      "        [1.2474],\n",
      "        [1.0848],\n",
      "        [1.2826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9060]],\n",
      "\n",
      "        [[1.0528]],\n",
      "\n",
      "        [[1.2492]],\n",
      "\n",
      "        [[1.6351]]], dtype=torch.float64)\n",
      "tensor([[1.2832],\n",
      "        [1.2017],\n",
      "        [1.0154],\n",
      "        [1.1431]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4017]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.5999]],\n",
      "\n",
      "        [[1.4999]]], dtype=torch.float64)\n",
      "tensor([[1.4586],\n",
      "        [1.1193],\n",
      "        [1.2782],\n",
      "        [1.1291]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4329]],\n",
      "\n",
      "        [[1.6744]],\n",
      "\n",
      "        [[1.3093]],\n",
      "\n",
      "        [[0.9476]]], dtype=torch.float64)\n",
      "tensor([[0.9443],\n",
      "        [1.0334],\n",
      "        [1.1245],\n",
      "        [1.1359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5375]],\n",
      "\n",
      "        [[1.0898]],\n",
      "\n",
      "        [[1.4826]],\n",
      "\n",
      "        [[1.5473]]], dtype=torch.float64)\n",
      "tensor([[1.1057],\n",
      "        [0.9594],\n",
      "        [1.1055],\n",
      "        [1.1191]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1660]],\n",
      "\n",
      "        [[0.8448]],\n",
      "\n",
      "        [[0.7466]],\n",
      "\n",
      "        [[1.3647]]], dtype=torch.float64)\n",
      "tensor([[1.2209],\n",
      "        [1.2221],\n",
      "        [1.0424],\n",
      "        [0.9509]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5496]],\n",
      "\n",
      "        [[1.6386]],\n",
      "\n",
      "        [[1.1279]],\n",
      "\n",
      "        [[0.7720]]], dtype=torch.float64)\n",
      "tensor([[0.9356],\n",
      "        [0.9895],\n",
      "        [1.0748],\n",
      "        [0.9830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5825]],\n",
      "\n",
      "        [[1.0424]],\n",
      "\n",
      "        [[1.3128]],\n",
      "\n",
      "        [[1.3416]]], dtype=torch.float64)\n",
      "tensor([[0.8547],\n",
      "        [0.7813],\n",
      "        [0.7829],\n",
      "        [0.7586]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7616]],\n",
      "\n",
      "        [[0.6553]],\n",
      "\n",
      "        [[0.3029]],\n",
      "\n",
      "        [[0.7108]]], dtype=torch.float64)\n",
      "tensor([[0.8013],\n",
      "        [0.4117],\n",
      "        [0.5460],\n",
      "        [0.4861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0840]],\n",
      "\n",
      "        [[0.2209]],\n",
      "\n",
      "        [[0.5444]],\n",
      "\n",
      "        [[0.1088]]], dtype=torch.float64)\n",
      "tensor([[0.5138],\n",
      "        [0.5714],\n",
      "        [0.6945],\n",
      "        [0.7194]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0799]],\n",
      "\n",
      "        [[0.3919]],\n",
      "\n",
      "        [[0.7200]],\n",
      "\n",
      "        [[0.9881]]], dtype=torch.float64)\n",
      "tensor([[0.7853],\n",
      "        [0.9073],\n",
      "        [0.9221],\n",
      "        [0.9636]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8679]],\n",
      "\n",
      "        [[0.8032]],\n",
      "\n",
      "        [[0.6357]],\n",
      "\n",
      "        [[0.8760]]], dtype=torch.float64)\n",
      "tensor([[0.7788],\n",
      "        [0.6730],\n",
      "        [0.6907],\n",
      "        [0.6033]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9442]],\n",
      "\n",
      "        [[1.0170]],\n",
      "\n",
      "        [[0.6045]],\n",
      "\n",
      "        [[0.4219]]], dtype=torch.float64)\n",
      "tensor([[0.7019],\n",
      "        [0.8113],\n",
      "        [0.9078],\n",
      "        [0.7814]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3734]],\n",
      "\n",
      "        [[0.9488]],\n",
      "\n",
      "        [[1.0701]],\n",
      "\n",
      "        [[1.0597]]], dtype=torch.float64)\n",
      "tensor([[0.6881],\n",
      "        [0.7117],\n",
      "        [0.8572],\n",
      "        [0.6436]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7085]],\n",
      "\n",
      "        [[0.6126]],\n",
      "\n",
      "        [[0.5421]],\n",
      "\n",
      "        [[0.7166]]], dtype=torch.float64)\n",
      "tensor([[0.6858],\n",
      "        [0.7436],\n",
      "        [0.7473],\n",
      "        [0.7294]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8714]],\n",
      "\n",
      "        [[1.0574]],\n",
      "\n",
      "        [[0.7316]],\n",
      "\n",
      "        [[0.4820]]], dtype=torch.float64)\n",
      "tensor([[0.8317],\n",
      "        [0.8008],\n",
      "        [0.8359],\n",
      "        [0.8823]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4497]],\n",
      "\n",
      "        [[0.7142]],\n",
      "\n",
      "        [[1.0158]],\n",
      "\n",
      "        [[1.1926]]], dtype=torch.float64)\n",
      "tensor([[0.5722],\n",
      "        [0.7697],\n",
      "        [0.9166],\n",
      "        [0.9846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7073]],\n",
      "\n",
      "        [[0.6634]],\n",
      "\n",
      "        [[0.6495]],\n",
      "\n",
      "        [[0.9927]]], dtype=torch.float64)\n",
      "tensor([[0.9940],\n",
      "        [1.1827],\n",
      "        [1.2871],\n",
      "        [1.2411]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4988]],\n",
      "\n",
      "        [[1.6940]],\n",
      "\n",
      "        [[1.3439]],\n",
      "\n",
      "        [[1.1325]]], dtype=torch.float64)\n",
      "tensor([[1.2563],\n",
      "        [1.2209],\n",
      "        [1.0783],\n",
      "        [0.9221]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1325]],\n",
      "\n",
      "        [[1.2041]],\n",
      "\n",
      "        [[1.4133]],\n",
      "\n",
      "        [[1.3740]]], dtype=torch.float64)\n",
      "tensor([[0.6402],\n",
      "        [0.5696],\n",
      "        [0.8157],\n",
      "        [0.8562]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0112]],\n",
      "\n",
      "        [[0.5340]],\n",
      "\n",
      "        [[0.5109]],\n",
      "\n",
      "        [[0.8309]]], dtype=torch.float64)\n",
      "tensor([[0.8841],\n",
      "        [0.4853],\n",
      "        [0.6856],\n",
      "        [0.7376]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1857]],\n",
      "\n",
      "        [[0.8148]],\n",
      "\n",
      "        [[0.7570]],\n",
      "\n",
      "        [[0.5525]]], dtype=torch.float64)\n",
      "tensor([[0.7938],\n",
      "        [0.6268],\n",
      "        [0.5411],\n",
      "        [0.5150]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3260]],\n",
      "\n",
      "        [[0.4855]],\n",
      "\n",
      "        [[0.5121]],\n",
      "\n",
      "        [[0.8910]]], dtype=torch.float64)\n",
      "tensor([[0.4575],\n",
      "        [0.5870],\n",
      "        [0.7059],\n",
      "        [0.6494]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6010]],\n",
      "\n",
      "        [[0.2763]],\n",
      "\n",
      "        [[0.2024]],\n",
      "\n",
      "        [[0.4450]]], dtype=torch.float64)\n",
      "tensor([[0.6859],\n",
      "        [0.6028],\n",
      "        [0.6669],\n",
      "        [0.5950]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7882]],\n",
      "\n",
      "        [[1.0435]],\n",
      "\n",
      "        [[0.8125]],\n",
      "\n",
      "        [[0.1758]]], dtype=torch.float64)\n",
      "tensor([[0.4838],\n",
      "        [0.6024],\n",
      "        [1.1349],\n",
      "        [1.3095]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.1304]],\n",
      "\n",
      "        [[ 0.6900]],\n",
      "\n",
      "        [[ 1.4491]],\n",
      "\n",
      "        [[ 1.7714]]], dtype=torch.float64)\n",
      "tensor([[1.2746],\n",
      "        [1.1323],\n",
      "        [0.8440],\n",
      "        [0.9255]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4410]],\n",
      "\n",
      "        [[0.7108]],\n",
      "\n",
      "        [[0.2498]],\n",
      "\n",
      "        [[1.0447]]], dtype=torch.float64)\n",
      "tensor([[1.5977],\n",
      "        [1.6769],\n",
      "        [1.7207],\n",
      "        [1.5262]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9309]],\n",
      "\n",
      "        [[2.2660]],\n",
      "\n",
      "        [[1.8777]],\n",
      "\n",
      "        [[1.2400]]], dtype=torch.float64)\n",
      "tensor([[1.2824],\n",
      "        [1.2964],\n",
      "        [1.9995],\n",
      "        [2.0687]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7940]],\n",
      "\n",
      "        [[1.5207]],\n",
      "\n",
      "        [[2.4185]],\n",
      "\n",
      "        [[2.6669]]], dtype=torch.float64)\n",
      "tensor([[2.0651],\n",
      "        [1.8631],\n",
      "        [1.7061],\n",
      "        [1.6502]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0303]],\n",
      "\n",
      "        [[1.6582]],\n",
      "\n",
      "        [[1.1718]],\n",
      "\n",
      "        [[1.8743]]], dtype=torch.float64)\n",
      "tensor([[2.0082],\n",
      "        [1.9641],\n",
      "        [1.7990],\n",
      "        [1.6347]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3064]],\n",
      "\n",
      "        [[2.3665]],\n",
      "\n",
      "        [[1.9528]],\n",
      "\n",
      "        [[1.3740]]], dtype=torch.float64)\n",
      "tensor([[1.4552],\n",
      "        [1.3846],\n",
      "        [2.0875],\n",
      "        [2.0971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9788]],\n",
      "\n",
      "        [[1.5877]],\n",
      "\n",
      "        [[2.5513]],\n",
      "\n",
      "        [[2.6311]]], dtype=torch.float64)\n",
      "tensor([[2.1701],\n",
      "        [1.8671],\n",
      "        [1.7567],\n",
      "        [1.7065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.2833]],\n",
      "\n",
      "        [[1.6259]],\n",
      "\n",
      "        [[1.3520]],\n",
      "\n",
      "        [[1.7241]]], dtype=torch.float64)\n",
      "tensor([[1.4787],\n",
      "        [1.3969],\n",
      "        [1.4311],\n",
      "        [1.2298]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1776]],\n",
      "\n",
      "        [[1.8015]],\n",
      "\n",
      "        [[1.3058]],\n",
      "\n",
      "        [[1.1186]]], dtype=torch.float64)\n",
      "tensor([[1.3572],\n",
      "        [1.3850],\n",
      "        [1.1436],\n",
      "        [1.0826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9950]],\n",
      "\n",
      "        [[1.2688]],\n",
      "\n",
      "        [[1.3370]],\n",
      "\n",
      "        [[1.5092]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.14117:  65%|██████▌   | 2004/3067 [00:06<00:03, 307.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9409],\n",
      "        [0.8099],\n",
      "        [0.7843],\n",
      "        [0.7337]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9361]],\n",
      "\n",
      "        [[0.7223]],\n",
      "\n",
      "        [[0.2278]],\n",
      "\n",
      "        [[0.8841]]], dtype=torch.float64)\n",
      "tensor([[0.9686],\n",
      "        [0.9865],\n",
      "        [0.9321],\n",
      "        [0.8204]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1683]],\n",
      "\n",
      "        [[1.2735]],\n",
      "\n",
      "        [[1.0401]],\n",
      "\n",
      "        [[0.5201]]], dtype=torch.float64)\n",
      "tensor([[0.8039],\n",
      "        [0.7571],\n",
      "        [1.1269],\n",
      "        [1.1364]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3746]],\n",
      "\n",
      "        [[0.8309]],\n",
      "\n",
      "        [[1.3532]],\n",
      "\n",
      "        [[1.4976]]], dtype=torch.float64)\n",
      "tensor([[1.0518],\n",
      "        [1.0448],\n",
      "        [0.8817],\n",
      "        [1.0027]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2896]],\n",
      "\n",
      "        [[0.6680]],\n",
      "\n",
      "        [[0.4520]],\n",
      "\n",
      "        [[1.1163]]], dtype=torch.float64)\n",
      "tensor([[1.4149],\n",
      "        [1.6146],\n",
      "        [1.6592],\n",
      "        [1.5112]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7818]],\n",
      "\n",
      "        [[2.2013]],\n",
      "\n",
      "        [[1.8177]],\n",
      "\n",
      "        [[1.2862]]], dtype=torch.float64)\n",
      "tensor([[1.4212],\n",
      "        [1.4494],\n",
      "        [1.8823],\n",
      "        [1.8862]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0331]],\n",
      "\n",
      "        [[1.6467]],\n",
      "\n",
      "        [[2.2325]],\n",
      "\n",
      "        [[2.2833]]], dtype=torch.float64)\n",
      "tensor([[1.6483],\n",
      "        [1.5417],\n",
      "        [1.4867],\n",
      "        [1.3180]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.8234]],\n",
      "\n",
      "        [[1.2931]],\n",
      "\n",
      "        [[1.0077]],\n",
      "\n",
      "        [[1.2041]]], dtype=torch.float64)\n",
      "tensor([[1.3624],\n",
      "        [1.4436],\n",
      "        [1.3083],\n",
      "        [1.2911]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5935]],\n",
      "\n",
      "        [[1.9159]],\n",
      "\n",
      "        [[1.3855]],\n",
      "\n",
      "        [[0.9430]]], dtype=torch.float64)\n",
      "tensor([[1.1206],\n",
      "        [1.1111],\n",
      "        [1.4888],\n",
      "        [1.5176]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5606]],\n",
      "\n",
      "        [[1.1799]],\n",
      "\n",
      "        [[1.9598]],\n",
      "\n",
      "        [[2.1435]]], dtype=torch.float64)\n",
      "tensor([[1.4623],\n",
      "        [1.2426],\n",
      "        [1.1599],\n",
      "        [1.0472]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6490]],\n",
      "\n",
      "        [[0.9719]],\n",
      "\n",
      "        [[0.7212]],\n",
      "\n",
      "        [[0.7350]]], dtype=torch.float64)\n",
      "tensor([[1.0840],\n",
      "        [1.5396],\n",
      "        [1.4233],\n",
      "        [1.3839]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2619]],\n",
      "\n",
      "        [[1.8096]],\n",
      "\n",
      "        [[1.4445]],\n",
      "\n",
      "        [[1.0389]]], dtype=torch.float64)\n",
      "tensor([[1.4032],\n",
      "        [1.5325],\n",
      "        [1.4191],\n",
      "        [1.2757]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2816]],\n",
      "\n",
      "        [[1.3104]],\n",
      "\n",
      "        [[1.5820]],\n",
      "\n",
      "        [[1.5196]]], dtype=torch.float64)\n",
      "tensor([[1.1886],\n",
      "        [1.1460],\n",
      "        [1.1403],\n",
      "        [1.0845]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1937]],\n",
      "\n",
      "        [[0.8598]],\n",
      "\n",
      "        [[0.6703]],\n",
      "\n",
      "        [[0.9569]]], dtype=torch.float64)\n",
      "tensor([[1.1015],\n",
      "        [1.0274],\n",
      "        [1.0157],\n",
      "        [0.9641]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2319]],\n",
      "\n",
      "        [[1.3174]],\n",
      "\n",
      "        [[0.9569]],\n",
      "\n",
      "        [[0.7304]]], dtype=torch.float64)\n",
      "tensor([[1.0500],\n",
      "        [0.9885],\n",
      "        [0.9621],\n",
      "        [1.0101]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7015]],\n",
      "\n",
      "        [[0.9673]],\n",
      "\n",
      "        [[1.3312]],\n",
      "\n",
      "        [[1.4872]]], dtype=torch.float64)\n",
      "tensor([[1.0491],\n",
      "        [1.0425],\n",
      "        [0.8502],\n",
      "        [0.8340]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1452]],\n",
      "\n",
      "        [[0.6380]],\n",
      "\n",
      "        [[0.2532]],\n",
      "\n",
      "        [[0.9661]]], dtype=torch.float64)\n",
      "tensor([[1.2153],\n",
      "        [1.0348],\n",
      "        [0.7930],\n",
      "        [1.0234]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4144]],\n",
      "\n",
      "        [[1.3532]],\n",
      "\n",
      "        [[1.0089]],\n",
      "\n",
      "        [[0.8610]]], dtype=torch.float64)\n",
      "tensor([[1.1430],\n",
      "        [0.9973],\n",
      "        [0.9174],\n",
      "        [0.6162]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6565]],\n",
      "\n",
      "        [[0.6923]],\n",
      "\n",
      "        [[1.0170]],\n",
      "\n",
      "        [[1.0516]]], dtype=torch.float64)\n",
      "tensor([[0.5576],\n",
      "        [0.7897],\n",
      "        [0.9513],\n",
      "        [0.8534]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7766]],\n",
      "\n",
      "        [[0.6380]],\n",
      "\n",
      "        [[0.5386]],\n",
      "\n",
      "        [[0.6334]]], dtype=torch.float64)\n",
      "tensor([[0.7949],\n",
      "        [0.8691],\n",
      "        [0.7835],\n",
      "        [0.7082]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.8298]],\n",
      "\n",
      "        [[1.2608]],\n",
      "\n",
      "        [[0.8795]],\n",
      "\n",
      "        [[0.2752]]], dtype=torch.float64)\n",
      "tensor([[0.6107],\n",
      "        [0.5535],\n",
      "        [1.0293],\n",
      "        [0.9287]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0841]],\n",
      "\n",
      "        [[ 0.6160]],\n",
      "\n",
      "        [[ 1.2527]],\n",
      "\n",
      "        [[ 1.4306]]], dtype=torch.float64)\n",
      "tensor([[0.7962],\n",
      "        [0.7265],\n",
      "        [0.8341],\n",
      "        [0.6359]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0251]],\n",
      "\n",
      "        [[0.7501]],\n",
      "\n",
      "        [[0.2301]],\n",
      "\n",
      "        [[0.7293]]], dtype=torch.float64)\n",
      "tensor([[1.1687],\n",
      "        [1.0665],\n",
      "        [0.8602],\n",
      "        [0.7922]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4225]],\n",
      "\n",
      "        [[1.6166]],\n",
      "\n",
      "        [[1.1556]],\n",
      "\n",
      "        [[0.7651]]], dtype=torch.float64)\n",
      "tensor([[0.7418],\n",
      "        [0.6210],\n",
      "        [1.1775],\n",
      "        [1.2110]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1053]],\n",
      "\n",
      "        [[0.8021]],\n",
      "\n",
      "        [[1.6501]],\n",
      "\n",
      "        [[1.8154]]], dtype=torch.float64)\n",
      "tensor([[1.0449],\n",
      "        [1.0075],\n",
      "        [0.8229],\n",
      "        [0.7303]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3543]],\n",
      "\n",
      "        [[0.7004]],\n",
      "\n",
      "        [[0.3387]],\n",
      "\n",
      "        [[0.9835]]], dtype=torch.float64)\n",
      "tensor([[1.3768],\n",
      "        [1.3981],\n",
      "        [1.2782],\n",
      "        [1.1708]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7645]],\n",
      "\n",
      "        [[1.9424]],\n",
      "\n",
      "        [[1.5381]],\n",
      "\n",
      "        [[1.0620]]], dtype=torch.float64)\n",
      "tensor([[1.1464],\n",
      "        [1.1092],\n",
      "        [0.8894],\n",
      "        [0.8375]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9176]],\n",
      "\n",
      "        [[1.0170]],\n",
      "\n",
      "        [[0.8598]],\n",
      "\n",
      "        [[1.3451]]], dtype=torch.float64)\n",
      "tensor([[1.1254],\n",
      "        [0.9455],\n",
      "        [0.8904],\n",
      "        [0.7593]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9257]],\n",
      "\n",
      "        [[0.5432]],\n",
      "\n",
      "        [[0.3307]],\n",
      "\n",
      "        [[0.4520]]], dtype=torch.float64)\n",
      "tensor([[1.3241],\n",
      "        [1.3420],\n",
      "        [1.2842],\n",
      "        [1.1860]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6363]],\n",
      "\n",
      "        [[1.8523]],\n",
      "\n",
      "        [[1.4156]],\n",
      "\n",
      "        [[0.7766]]], dtype=torch.float64)\n",
      "tensor([[1.0037],\n",
      "        [0.9559],\n",
      "        [1.6079],\n",
      "        [1.7152]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3965]],\n",
      "\n",
      "        [[1.0978]],\n",
      "\n",
      "        [[2.1805]],\n",
      "\n",
      "        [[2.4104]]], dtype=torch.float64)\n",
      "tensor([[1.6897],\n",
      "        [1.4923],\n",
      "        [1.3006],\n",
      "        [1.2647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9136]],\n",
      "\n",
      "        [[1.0955]],\n",
      "\n",
      "        [[0.7662]],\n",
      "\n",
      "        [[1.4895]]], dtype=torch.float64)\n",
      "tensor([[2.1391],\n",
      "        [2.3849],\n",
      "        [2.1741],\n",
      "        [1.8418]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.7616]],\n",
      "\n",
      "        [[3.0528]],\n",
      "\n",
      "        [[2.4370]],\n",
      "\n",
      "        [[1.5196]]], dtype=torch.float64)\n",
      "tensor([[1.7526],\n",
      "        [1.7251],\n",
      "        [2.4976],\n",
      "        [2.5180]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3578]],\n",
      "\n",
      "        [[1.8743]],\n",
      "\n",
      "        [[2.9950]],\n",
      "\n",
      "        [[2.8783]]], dtype=torch.float64)\n",
      "tensor([[2.2047],\n",
      "        [1.8999],\n",
      "        [1.8886],\n",
      "        [1.6787]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.0707]],\n",
      "\n",
      "        [[1.6132]],\n",
      "\n",
      "        [[1.2896]],\n",
      "\n",
      "        [[1.5392]]], dtype=torch.float64)\n",
      "tensor([[2.0632],\n",
      "        [2.1475],\n",
      "        [2.0627],\n",
      "        [1.8568]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3110]],\n",
      "\n",
      "        [[2.5121]],\n",
      "\n",
      "        [[2.1158]],\n",
      "\n",
      "        [[1.5404]]], dtype=torch.float64)\n",
      "tensor([[1.7101],\n",
      "        [1.5933],\n",
      "        [1.5796],\n",
      "        [1.5183]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.2873]],\n",
      "\n",
      "        [[1.4387]],\n",
      "\n",
      "        [[1.7738]],\n",
      "\n",
      "        [[1.9575]]], dtype=torch.float64)\n",
      "tensor([[1.1681],\n",
      "        [1.1177],\n",
      "        [0.9679],\n",
      "        [0.8856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.3844]],\n",
      "\n",
      "        [[0.8171]],\n",
      "\n",
      "        [[0.3665]],\n",
      "\n",
      "        [[0.8841]]], dtype=torch.float64)\n",
      "tensor([[1.2774],\n",
      "        [1.2555],\n",
      "        [1.1555],\n",
      "        [1.0089]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4884]],\n",
      "\n",
      "        [[1.7507]],\n",
      "\n",
      "        [[1.3151]],\n",
      "\n",
      "        [[0.6969]]], dtype=torch.float64)\n",
      "tensor([[1.0346],\n",
      "        [0.9174],\n",
      "        [1.1252],\n",
      "        [1.3820]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5167]],\n",
      "\n",
      "        [[0.6542]],\n",
      "\n",
      "        [[1.2746]],\n",
      "\n",
      "        [[1.5496]]], dtype=torch.float64)\n",
      "tensor([[1.1987],\n",
      "        [1.2801],\n",
      "        [1.4388],\n",
      "        [1.3562]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1984]],\n",
      "\n",
      "        [[1.0066]],\n",
      "\n",
      "        [[1.0158]],\n",
      "\n",
      "        [[1.3555]]], dtype=torch.float64)\n",
      "tensor([[1.4710],\n",
      "        [1.5211],\n",
      "        [1.2404],\n",
      "        [1.2782]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.6490]],\n",
      "\n",
      "        [[1.8766]],\n",
      "\n",
      "        [[1.4294]],\n",
      "\n",
      "        [[1.1857]]], dtype=torch.float64)\n",
      "tensor([[1.0821],\n",
      "        [1.1098],\n",
      "        [1.0806],\n",
      "        [0.8937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7200]],\n",
      "\n",
      "        [[1.0274]],\n",
      "\n",
      "        [[1.1140]],\n",
      "\n",
      "        [[1.0100]]], dtype=torch.float64)\n",
      "tensor([[0.6887],\n",
      "        [0.7306],\n",
      "        [0.8918],\n",
      "        [0.8982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.6149]],\n",
      "\n",
      "        [[0.6391]],\n",
      "\n",
      "        [[0.5883]],\n",
      "\n",
      "        [[0.8055]]], dtype=torch.float64)\n",
      "tensor([[0.8359],\n",
      "        [0.9589],\n",
      "        [0.9003],\n",
      "        [0.7894]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0343]],\n",
      "\n",
      "        [[1.4502]],\n",
      "\n",
      "        [[0.8829]],\n",
      "\n",
      "        [[0.3515]]], dtype=torch.float64)\n",
      "tensor([[0.6699],\n",
      "        [0.7043],\n",
      "        [1.3432],\n",
      "        [1.3928]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1724]],\n",
      "\n",
      "        [[0.6715]],\n",
      "\n",
      "        [[1.7322]],\n",
      "\n",
      "        [[1.8673]]], dtype=torch.float64)\n",
      "tensor([[1.3021],\n",
      "        [1.3535],\n",
      "        [1.2177],\n",
      "        [1.1992]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4375]],\n",
      "\n",
      "        [[1.2111]],\n",
      "\n",
      "        [[0.7535]],\n",
      "\n",
      "        [[1.1152]]], dtype=torch.float64)\n",
      "tensor([[1.6934],\n",
      "        [1.5806],\n",
      "        [1.4095],\n",
      "        [1.4244]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.9667]],\n",
      "\n",
      "        [[2.0210]],\n",
      "\n",
      "        [[1.5311]],\n",
      "\n",
      "        [[1.1533]]], dtype=torch.float64)\n",
      "tensor([[1.4090],\n",
      "        [1.2877],\n",
      "        [1.4426],\n",
      "        [1.2171]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0435]],\n",
      "\n",
      "        [[1.0563]],\n",
      "\n",
      "        [[1.5184]],\n",
      "\n",
      "        [[1.4941]]], dtype=torch.float64)\n",
      "tensor([[0.8813],\n",
      "        [0.8648],\n",
      "        [1.0194],\n",
      "        [0.9239]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.7558]],\n",
      "\n",
      "        [[0.7073]],\n",
      "\n",
      "        [[0.6022]],\n",
      "\n",
      "        [[0.7166]]], dtype=torch.float64)\n",
      "tensor([[0.8414],\n",
      "        [0.7110],\n",
      "        [0.7316],\n",
      "        [0.6733]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9049]],\n",
      "\n",
      "        [[1.0574]],\n",
      "\n",
      "        [[0.6727]],\n",
      "\n",
      "        [[0.4913]]], dtype=torch.float64)\n",
      "tensor([[0.8184],\n",
      "        [0.7154],\n",
      "        [0.7111],\n",
      "        [0.6818]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4462]],\n",
      "\n",
      "        [[0.4497]],\n",
      "\n",
      "        [[0.9026]],\n",
      "\n",
      "        [[0.9973]]], dtype=torch.float64)\n",
      "tensor([[0.6486],\n",
      "        [0.6700],\n",
      "        [0.5088],\n",
      "        [0.3814]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7662]],\n",
      "\n",
      "        [[ 0.2532]],\n",
      "\n",
      "        [[-0.0425]],\n",
      "\n",
      "        [[ 0.1955]]], dtype=torch.float64)\n",
      "tensor([[0.8635],\n",
      "        [0.9467],\n",
      "        [0.8917],\n",
      "        [0.7551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1833]],\n",
      "\n",
      "        [[1.3890]],\n",
      "\n",
      "        [[0.9211]],\n",
      "\n",
      "        [[0.4774]]], dtype=torch.float64)\n",
      "tensor([[0.7443],\n",
      "        [0.7347],\n",
      "        [1.1724],\n",
      "        [1.1280]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2371]],\n",
      "\n",
      "        [[0.7431]],\n",
      "\n",
      "        [[1.4549]],\n",
      "\n",
      "        [[1.5277]]], dtype=torch.float64)\n",
      "tensor([[0.8595],\n",
      "        [0.8535],\n",
      "        [0.7333],\n",
      "        [0.6035]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0551]],\n",
      "\n",
      "        [[0.6657]],\n",
      "\n",
      "        [[0.2348]],\n",
      "\n",
      "        [[0.6507]]], dtype=torch.float64)\n",
      "tensor([[1.1187],\n",
      "        [1.0688],\n",
      "        [0.9152],\n",
      "        [0.7837]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.4098]],\n",
      "\n",
      "        [[1.5288]],\n",
      "\n",
      "        [[1.0424]],\n",
      "\n",
      "        [[0.4658]]], dtype=torch.float64)\n",
      "tensor([[0.7310],\n",
      "        [0.5725],\n",
      "        [0.8041],\n",
      "        [0.6850]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.1955]],\n",
      "\n",
      "        [[0.4577]],\n",
      "\n",
      "        [[0.8829]],\n",
      "\n",
      "        [[0.7951]]], dtype=torch.float64)\n",
      "tensor([[0.4741],\n",
      "        [0.6092],\n",
      "        [0.7192],\n",
      "        [0.5453]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5929]],\n",
      "\n",
      "        [[0.4728]],\n",
      "\n",
      "        [[0.3399]],\n",
      "\n",
      "        [[0.4474]]], dtype=torch.float64)\n",
      "tensor([[0.5047],\n",
      "        [0.5155],\n",
      "        [0.4557],\n",
      "        [0.4091]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.7570]],\n",
      "\n",
      "        [[ 1.0239]],\n",
      "\n",
      "        [[ 0.7015]],\n",
      "\n",
      "        [[-0.0668]]], dtype=torch.float64)\n",
      "tensor([[0.2589],\n",
      "        [0.0844],\n",
      "        [0.7090],\n",
      "        [0.8840]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.3291]],\n",
      "\n",
      "        [[ 0.0522]],\n",
      "\n",
      "        [[ 1.1868]],\n",
      "\n",
      "        [[ 1.5034]]], dtype=torch.float64)\n",
      "tensor([[0.8039],\n",
      "        [0.8305],\n",
      "        [0.9255],\n",
      "        [0.9135]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1487]],\n",
      "\n",
      "        [[0.6611]],\n",
      "\n",
      "        [[0.5733]],\n",
      "\n",
      "        [[1.0378]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2 - Loss = 0.14117:  66%|██████▋   | 2035/3067 [00:06<00:03, 315.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2007],\n",
      "        [1.1633],\n",
      "        [1.1442],\n",
      "        [0.8847]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.7171]],\n",
      "\n",
      "        [[1.8188]],\n",
      "\n",
      "        [[1.3312]],\n",
      "\n",
      "        [[0.6819]]], dtype=torch.float64)\n",
      "tensor([[0.7760],\n",
      "        [0.5946],\n",
      "        [1.4123],\n",
      "        [1.5645]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.3503]],\n",
      "\n",
      "        [[0.8980]],\n",
      "\n",
      "        [[1.9979]],\n",
      "\n",
      "        [[2.2613]]], dtype=torch.float64)\n",
      "tensor([[1.3610],\n",
      "        [1.2293],\n",
      "        [1.1152],\n",
      "        [0.9949]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.5970]],\n",
      "\n",
      "        [[1.1256]],\n",
      "\n",
      "        [[0.7801]],\n",
      "\n",
      "        [[1.0886]]], dtype=torch.float64)\n",
      "tensor([[1.5316],\n",
      "        [1.5104],\n",
      "        [1.2739],\n",
      "        [1.1013]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[2.3572]],\n",
      "\n",
      "        [[2.3168]],\n",
      "\n",
      "        [[1.6883]],\n",
      "\n",
      "        [[0.9003]]], dtype=torch.float64)\n",
      "tensor([[0.9927],\n",
      "        [0.8416],\n",
      "        [1.4511],\n",
      "        [1.3632]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.4947]],\n",
      "\n",
      "        [[0.9164]],\n",
      "\n",
      "        [[1.8084]],\n",
      "\n",
      "        [[1.7229]]], dtype=torch.float64)\n",
      "tensor([[0.9608],\n",
      "        [0.7507],\n",
      "        [0.6095],\n",
      "        [0.5793]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9268]],\n",
      "\n",
      "        [[0.3907]],\n",
      "\n",
      "        [[0.3376]],\n",
      "\n",
      "        [[0.3838]]], dtype=torch.float64)\n",
      "tensor([[0.5108],\n",
      "        [0.2215],\n",
      "        [0.0869],\n",
      "        [0.2261]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.5791]],\n",
      "\n",
      "        [[0.1562]],\n",
      "\n",
      "        [[0.1377]],\n",
      "\n",
      "        [[0.0788]]], dtype=torch.float64)\n",
      "tensor([[0.2436],\n",
      "        [0.1305],\n",
      "        [0.5035],\n",
      "        [0.3309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[-0.0899]],\n",
      "\n",
      "        [[ 0.1701]],\n",
      "\n",
      "        [[ 0.6900]],\n",
      "\n",
      "        [[ 0.8298]]], dtype=torch.float64)\n",
      "tensor([[ 0.2825],\n",
      "        [ 0.1301],\n",
      "        [-0.0832],\n",
      "        [-0.0534]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.2463]],\n",
      "\n",
      "        [[-0.2632]],\n",
      "\n",
      "        [[-0.4978]],\n",
      "\n",
      "        [[ 0.0418]]], dtype=torch.float64)\n",
      "tensor([[0.7509],\n",
      "        [0.7318],\n",
      "        [0.6633],\n",
      "        [0.6184]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.0054]],\n",
      "\n",
      "        [[1.0944]],\n",
      "\n",
      "        [[0.8760]],\n",
      "\n",
      "        [[0.4820]]], dtype=torch.float64)\n",
      "tensor([[0.6220],\n",
      "        [0.4884],\n",
      "        [0.5429],\n",
      "        [0.5266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.2625]],\n",
      "\n",
      "        [[0.4936]],\n",
      "\n",
      "        [[0.7951]],\n",
      "\n",
      "        [[0.9014]]], dtype=torch.float64)\n",
      "tensor([[0.4384],\n",
      "        [0.5855],\n",
      "        [0.4533],\n",
      "        [0.2427]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[ 0.6461]],\n",
      "\n",
      "        [[ 0.1851]],\n",
      "\n",
      "        [[-0.1581]],\n",
      "\n",
      "        [[ 0.2220]]], dtype=torch.float64)\n",
      "tensor([[0.8723],\n",
      "        [0.9979],\n",
      "        [0.8095],\n",
      "        [0.5542]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[1.1926]],\n",
      "\n",
      "        [[1.3902]],\n",
      "\n",
      "        [[0.7974]],\n",
      "\n",
      "        [[0.2036]]], dtype=torch.float64)\n",
      "tensor([[0.4708],\n",
      "        [0.4808],\n",
      "        [0.9080],\n",
      "        [1.0243]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.0418]],\n",
      "\n",
      "        [[0.3630]],\n",
      "\n",
      "        [[1.2977]],\n",
      "\n",
      "        [[1.5531]]], dtype=torch.float64)\n",
      "tensor([[0.9232],\n",
      "        [0.7760],\n",
      "        [0.6489],\n",
      "        [0.5146]], grad_fn=<AddmmBackward>)\n",
      "tensor([[[0.9222]],\n",
      "\n",
      "        [[0.4497]],\n",
      "\n",
      "        [[0.1157]],\n",
      "\n",
      "        [[0.5225]]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-59b53e311ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/batteryprobeai/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/batteryprobeai/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(multistep.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "history = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    running_loss = 0\n",
    "    pbar = tqdm(train_loader)\n",
    "    for i, (inputs, label) in enumerate(pbar):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = multistep(inputs.float())\n",
    "        print(outputs)\n",
    "        print(label)\n",
    "        loss = criterion(outputs, label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if not (i % 100):\n",
    "            pbar.set_description(\n",
    "                f\"Epoch #{epoch+1} - Loss = {running_loss / (i+1):.5f}\"\n",
    "            )\n",
    "            history.append(running_loss / (i+1))\n",
    "\n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, CONV_WIDTH):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv_1d = nn.Conv1d(19, 32, CONV_WIDTH)\n",
    "        self.dense_1 = nn.Linear(32,32)\n",
    "        self.dense_2 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv_1d(x).squeeze()\n",
    "        x = F.relu(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = F.relu(x)\n",
    "        return self.dense_2(x)[:, None]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Conv(CONV_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3816]],\n",
      "\n",
      "        [[0.4558]],\n",
      "\n",
      "        [[0.4409]],\n",
      "\n",
      "        [[0.4007]]], grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for (inputs, label) in train_loader:\n",
    "    out = conv(inputs.float())\n",
    "    print(out)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1 - Loss = 0.04731:  99%|█████████▉| 3034/3067 [00:07<00:00, 392.90it/s]/usr/local/anaconda3/envs/batteryprobeai/lib/python3.7/site-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([1, 1, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch #1 - Loss = 0.04731: 100%|██████████| 3067/3067 [00:07<00:00, 398.18it/s]\n",
      "Epoch #2 - Loss = 0.01204: 100%|██████████| 3067/3067 [00:07<00:00, 431.16it/s]\n",
      "Epoch #3 - Loss = 0.00986: 100%|██████████| 3067/3067 [00:06<00:00, 475.41it/s]\n",
      "Epoch #4 - Loss = 0.00884: 100%|██████████| 3067/3067 [00:06<00:00, 472.87it/s]\n",
      "Epoch #5 - Loss = 0.00826: 100%|██████████| 3067/3067 [00:06<00:00, 467.66it/s]\n",
      "Epoch #6 - Loss = 0.00787: 100%|██████████| 3067/3067 [00:06<00:00, 490.91it/s]\n",
      "Epoch #7 - Loss = 0.00760: 100%|██████████| 3067/3067 [00:06<00:00, 471.17it/s]\n",
      "Epoch #8 - Loss = 0.00738: 100%|██████████| 3067/3067 [00:06<00:00, 493.22it/s]\n",
      "Epoch #9 - Loss = 0.00722: 100%|██████████| 3067/3067 [00:06<00:00, 479.26it/s]\n",
      "Epoch #10 - Loss = 0.00709: 100%|██████████| 3067/3067 [00:06<00:00, 474.82it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(conv.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "history = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    running_loss = 0\n",
    "    pbar = tqdm(train_loader)\n",
    "    for i, (inputs, label) in enumerate(pbar):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = conv(inputs.float())\n",
    "        loss = criterion(outputs, label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if not (i % 100):\n",
    "            pbar.set_description(\n",
    "                f\"Epoch #{epoch+1} - Loss = {running_loss / (i+1):.5f}\"\n",
    "            )\n",
    "            history.append(running_loss / (i+1))\n",
    "\n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 0.00758: 100%|██████████| 876/876 [00:01<00:00, 628.94it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFlCAYAAADYnoD9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvPElEQVR4nO3de3yPdePH8dfHTIhUKFI2911STiOnbnexzflYTpFIZEmEIskvUhbduJGKFpLMobgj5/M2FTk1TI6VuVdCDt3OZvv8/tgsp9nYd7u+h/fz8djD9r2uXd/3rq68fa7vd5+PsdYiIiIizsnldAARERFfpzIWERFxmMpYRETEYSpjERERh6mMRUREHKYyFhERcVhup564SJEiNjAw0KmnFxERyXGbNm36w1pb9MrHHSvjwMBANm7c6NTTi4iI5DhjTPy1HtdtahEREYdlWMbGmMnGmEPGmLh0tvczxsSmfsQZY5KMMXe6PqqIiIh3yszIeArQIL2N1toR1toga20QMACIttYedU08ERER75fha8bW2hhjTGAmj9cOmHGzYRITE0lISODs2bM3ewi5Qt68ebn33nvx9/d3OoqIiKTDZW/gMsbkJ2UE3eM6+4QBYQAlS5a8antCQgIFCxYkMDAQY4yrovksay1HjhwhISGBUqVKOR1HRETS4co3cDUFvr3eLWprbYS1toq1tkrRole9s5uzZ89SuHBhFbGLGGMoXLiw7jSIiLg5V5ZxW7Jwi/oiFbFr6XyKiLg/l5SxMaYQUAuY54rjOalAgQIuP+a+ffuYPn26y48rIiLeITO/2jQDWAs8aIxJMMZ0McZ0M8Z0u2S3J4Fl1tpT2RX0WiIjIwkMDCRXrlwEBgYSGRmZk0+faSpjERG5ngzL2Frbzlpb3Frrb62911o7yVo7wVo74ZJ9plhr22Zv1MtFRkYSFhZGfHw81lri4+MJCwtzWSFHRUVRu3ZtWrVqRZkyZWjfvj3WWiBl9rD+/ftTrVo1qlWrxt69ewHo1KkTs2fPTjvGxVH266+/zpo1awgKCmL06NFs376datWqERQURIUKFdizZ49LMouISBb961+wevXlj61enfJ4NnJsOsyM9O7dm9jY2HS3r1u3jnPnzl322OnTp+nSpQuffPLJNb8nKCiIMWPGZDrDDz/8wPbt27nnnnuoWbMm3377Lf/85z8BuO2221i/fj1Tp06ld+/eLFiwIN3jDB8+nJEjR6bt07NnT3r16kX79u05f/48SUlJmc4kIiLZqGpVaNMGvvgCgoNTivji19nIY6fDvLKIM3r8ZlSrVo17772XXLlyERQUxL59+9K2tWvXLu3PtWvX3tBxH330Ud59913ee+894uPjyZcvn8syi4jIzSvWLhjzx2FMSDDGkPLnH4cp1i44W5/XbUfGGY1gAwMDiY+/er7tgIAAoqKiXJLhlltuSfvcz8+PCxcupH196buUL36eO3dukpOTgZTf8T1//vw1j/v0009TvXp1Fi5cSP369Zk4cSIhISEuySwiIjfv4MEbe9xVPHZkHB4eTv78+S97LH/+/ISHh+fI88+aNSvtz0cffRRI+QfCpk2bAJg3bx6JiYkAFCxYkBMnTqR9788//8zf/vY3Xn75ZZo1a8bWrVtzJLOIiLgntx0ZZ6R9+/YADBw4kP3791OyZEnCw8PTHs9u586do3r16iQnJzNjRsqvV3ft2pXmzZtTrVo1QkNDufXWWwGoUKECuXPnpmLFinTq1ImzZ88ybdo0/P39KVasGIMGDcqRzCIi4p7MxXcI57QqVarYK9cz3rFjBw899JAjeW7ExbWYixQp4nSUTPGU8yoi4rTrzZPkiro0xmyy1la58nGPvU0tIiLiLTz2NrWTLn1XtYiIeI+77772m7Xuvjt7n1dlLCIikur33515Xt2mFhERcZjKWERExGEqYxEREYepjC9x5MgRgoKCCAoKolixYpQoUSLt6/Rm07pZx48f56OPPnLpMUVExDN5bhlnw8oahQsXJjY2ltjYWLp160afPn3Svs6TJ0+633fpNJmZpTIWEZGLPLeML66scbGQL66sUbWqS5/mk08+oWrVqlSsWJGWLVty+vRpIGW5xFdeeYXg4GD69+/PTz/9RI0aNahatSqDBg1KWz4RYMSIEVStWpUKFSowePBgIGVZxZ9++omgoCD69evHgQMHePzxxwkKCqJcuXKsWbPGpT+HiIi4L88t4+DglCWt2rSBQYMuX/LKhVq0aMGGDRvYsmULDz30EJMmTUrbtnv3blasWMGoUaPo1asXvXr1YsOGDdxzzz1p+yxbtow9e/awfv16YmNj2bRpEzExMQwfPpy///3vxMbGMmLECKZPn079+vWJjY1ly5YtBAUFufTnEBER9+W5ZQwpxfvii/DOOyl/uriIAeLi4njssccoX748kZGRbN++PW1b69at8fPzA2Dt2rW0bt0aSFmV6aJly5axbNkyKlWqROXKldm5cyd79uy56nmqVq3Kp59+yltvvcW2bdsoWLCgy38WERFxT55dxqtXw/jx8OabKX9e+RqyC3Tq1IkPPviAbdu2MXjwYM6ePZu27eJCENdjrWXAgAFprz3v3buXLl26XLXf448/TkxMDCVKlKBDhw5MnTrVpT+HiIi4L88t44uvEX/xBbz99l+3rF1cyCdOnKB48eIkJiYSGRmZ7n41atRgzpw5AMycOTPt8fr16zN58mROnjwJwK+//sqhQ4euWlYxPj6eu+66i65du9KlSxc2b97s0p9DRETcl+dOh7lhw+WvEV98DXnDBpfern7nnXeoXr06AQEBlC9f/rICvdSYMWN45plnGDVqFI0bN6ZQoUIA1KtXjx07dqSteVygQAGmTZvG3//+d2rWrEm5cuVo2LAh5cqVY8SIEfj7+1OgQAGNjEVEfIiWUHSR06dPky9fPowxzJw5kxkzZjBv3jynYwGefV5FRLxJeksoeu7I2M1s2rSJHj16YK3l9ttvZ/LkyU5HEhERD6EydpHHHnuMLVu2OB1DREQ8kOe+gUtERMRLqIxFREQcpjIWERFxmMpYRETEYSrjK/j5+aUt1tC6deu0hSFuRqdOnZg9ezYAzz//PD/++GO6+0ZFRfHdd9+lfT1hwgT9rrGIiI/w2DIuVgyMufqjWLGsHTdfvnzExsYSFxdHnjx5mDBhwmXbk5KSbuq4EydO5OGHH053+5Vl3K1bNzp27HhTzyUiIp7FY8v44MEbe/xmPPbYY+zdu5eoqCiCg4N5+umnKV++PElJSfTr1y9tWcSPP/4YSJmHukePHjz88MM0btyYQ4cOpR2rdu3aXJzkZMmSJVSuXJmKFSsSGhrKvn37mDBhAqNHjyYoKIg1a9bw1ltvMXLkSABiY2OpUaMGFSpU4Mknn+TYsWNpx+zfvz/VqlWjdOnSWnZRRMRD6feM03HhwgUWL15MgwYNAFi/fj1xcXGUKlWKiIgIChUqxIYNGzh37hw1a9akXr16/PDDD+zatYtt27Zx8OBBHn74YTp37nzZcQ8fPkzXrl2JiYmhVKlSHD16lDvvvJNu3bpRoEAB+vbtC8DKlSvTvqdjx46MGzeOWrVqMWjQIIYMGcKYMWPScq5fv55FixYxZMgQVqxYkTMnSEREXEZlfIUzZ86krSX82GOP0aVLF7777juqVatGqVKlgJRlEbdu3Zr2evCff/7Jnj17iImJoV27dvj5+XHPPfcQEhJy1fHXrVvH448/nnasO++887p5/vzzT44fP06tWrUAePbZZ9OWaoSU9ZYBHnnkEfbt25eln11ERJyhMr7CxdeMr3TpconWWsaNG0f9+vUv22fRokUYY657fGtthvvciFtuuQVIeePZhQsXXHZcERHJOR77mrGT6tevz/jx40lMTARg9+7dnDp1iscff5yZM2eSlJTEgQMHWH2N5RwfffRRoqOj+eWXXwA4evQowFVLKl5UqFAh7rjjjrTXgz///PO0UbKIiHgHjx0Z3333td+sdffd2f/czz//PPv27aNy5cpYaylatChz587lySefZNWqVZQvX57SpUtfszSLFi1KREQELVq0IDk5mbvuuovly5fTtGlTWrVqxbx58xg3btxl3/PZZ5/RrVs3Tp8+zd/+9jc+/fTT7P8hRUQkx2gJRR+g8yoi4h7SW0JRt6lFREQclmEZG2MmG2MOGWPirrNPbWNMrDFmuzEm2rURRUREvFtmRsZTgAbpbTTG3A58BDSz1pYFWqe3r4iIiFwtwzK21sYAR6+zy9PAf6y1+1P3P3SdfTPk1GvY3krnU0TE/bniNePSwB3GmChjzCZjTLoTKhtjwowxG40xGw8fPnzV9rx583LkyBEViItYazly5Ah58+Z1OoqIiFyHK361KTfwCBAK5APWGmPWWWt3X7mjtTYCiICUd1Nfuf3ee+8lISGBaxW13Jy8efNy7733Oh1DRESuwxVlnAD8Ya09BZwyxsQAFYGryjgj/v7+adNEioiI+ApX3KaeBzxmjMltjMkPVAd2uOC4IiIiPiHDkbExZgZQGyhijEkABgP+ANbaCdbaHcaYJcBWIBmYaK1N99egRERE5HIZlrG1tl0m9hkBjHBJIhERER+jGbhEREQcpjIWERFxmMpYRETEYSpjERERh6mMRUREHKYyFhERcZjKWERExGEqYxEREYepjEVERBymMhYREXGYylhERMRhKmMRERGHqYxFREQcpjIWERFxmMpYRETEYSpjERERh6mMRUREHKYyFhERcZjKWERExGEqYxEREYepjEVERBymMhYREXGYylhERMRhKmMRERGHqYxFREQcpjIWERFxmMpYRETEYSpjERERh6mMRUREHKYyFhERcZjKWERExGEqYxEREYepjEVERBymMhYREXGYylhERMRhKmMRERGHZVjGxpjJxphDxpi4dLbXNsb8aYyJTf0Y5PqYIiIi3it3JvaZAnwATL3OPmustU1ckkhERMTHZDgyttbGAEdzIIuISI6JjIwkMDCQXLlyERgYSGRkpNORxIe56jXjR40xW4wxi40xZdPbyRgTZozZaIzZePjwYRc9tYjIjYmMjCQsLIz4+HistcTHxxMWFqZCFscYa23GOxkTCCyw1pa7xrbbgGRr7UljTCNgrLX2gYyOWaVKFbtx48abiCwikjWBgYHEx8df9XhAQAD79u3L+UDiM4wxm6y1Va58PMsjY2vt/6y1J1M/XwT4G2OKZPW4IiLZZf/+/Tf0uEh2y3IZG2OKGWNM6ufVUo95JKvHFRHJLoUKFbrm4yVLlszhJCIpMnw3tTFmBlAbKGKMSQAGA/4A1toJQCvgRWPMBeAM0NZm5t63iEgOs9by9ttvc/z4cfz8/EhKSkrblj9/fsLDwx1MJ74swzK21rbLYPsHpPzqk4iI27LW8uabbxIeHs6zzz5LaGgob775Jvv376dkyZKEh4fTvn17p2OKj8rM7xmLiHg0ay2vvfYaI0eOpGvXrkyYMIFcuXLRoUMHp6OJAJoOU0S8nLWW3r17M3LkSF566aW0IhZxJ7oiRcRrJScn0717d95//3369OnDuHHjVMTilnRViohXSkpKSrsl3b9/f0aNGkXqL36IuB2VsYh4nQsXLvDcc88xefJkBg0axLBhw1TE4tb0Bi4R8SqJiYl07NiRmTNn8s477/B///d/TkcSyZDKWES8xvnz53n66aeZM2cO7733Hq+99prTkUQyRWUsIl7h3LlztG7dmvnz5zN69Gh69+7tdCSRTFMZi4jHO3PmDC1atGDJkiV8+OGHdO/e3elIIjdEZSwiHu306dM0b96clStX8sknn/D88887HUnkhqmMRcRjnTx5kiZNmrBmzRqmTJlCx44dnY4kclNUxiLikf73v//RqFEj1q1bx7Rp02jX7rrT6Iu4NZWxiHic48ePU79+fTZv3szMmTNp1aqV05FEskRlLCIe5ejRo9StW5dt27Yxe/Zsmjdv7nQkkSxTGYuIxzh8+DB16tRh165dzJ07l0aNGjkdScQlVMYi4hF+//13QkND+fnnn5k/fz5169Z1OpKIy6iMRcTt/frrr4SGhvLf//6XRYsWERwc7HQkEZdSGYuIW9u/fz8hISEcPHiQpUuX8s9//tPpSCIupzIWEbf1yy+/EBISwrFjx1i+fDk1atRwOpJItlAZi4hb2rt3LyEhIZw8eZIVK1ZQpUoVpyOJZBuVsYi4nV27dhESEsK5c+dYtWoVQUFBTkcSyVYqYxFxK9u3byc0NBRrLVFRUZQrV87pSCLZLpfTAURELtqyZQu1a9cmV65cREdHq4jFZ6iMRcQtbN68mZCQEPLmzUt0dDRlypRxOpJIjlEZi4jjvv/+e0JCQihYsCAxMTE88MADTkcSyVEqYxFx1LfffkvdunUpXLgw0dHRlCpVyulIIjlOZSwijomOjqZ+/foUL16cmJgYAgICnI4k4giVsYg4YsWKFTRs2JCAgACioqIoUaKE05FEHKMyFpEct2TJEpo0acL999/P6tWrKV68uNORRBylMhaRHDV//nyaN2/Oww8/zOrVq7nrrrucjiTiOJWxiOSY//znP7Ro0YKKFSuycuVKChcu7HQkEbegMhaRHDFr1izatGlD1apVWb58OXfccYfTkUTchspYRLLd559/ztNPP03NmjVZunQphQoVcjqSiFtRGYtItpo8eTLPPvsstWvXZtGiRRQsWNDpSCJuR2UsItlmwoQJdOnShXr16rFgwQJuvfVWpyOJuCWVsYhki/fff58XX3yRJk2aMHfuXPLly+d0JBG3pTIWEZcbNWoUvXr14sknn2TOnDnkzZvX6Ugibi3DMjbGTDbGHDLGxGWwX1VjTJIxppXr4omIp3n33Xfp27cvbdq0YdasWeTJk8fpSCJuLzMj4ylAg+vtYIzxA94Dlrogk4h4IGstb731FgMHDqR9+/ZERkbi7+/vdCwRj5BhGVtrY4CjGezWE5gDHHJFKBHxLNZaBg4cyJAhQ+jUqROfffYZuXPndjqWiMfI8mvGxpgSwJPAhEzsG2aM2WiM2Xj48OGsPrWIuAFrLf369WPYsGGEhYUxadIk/Pz8nI4l4lFc8QauMUB/a21SRjtaayOstVWstVWKFi3qgqcWESdZa+nVqxejRo2iR48eTJgwgVy59L5QkRvlivtIVYCZxhiAIkAjY8wFa+1cFxxbRNxUcnIy3bt35+OPP+aVV15h5MiRpP49ICI3KMtlbK0tdfFzY8wUYIGKWMS7JSUl0bVrVz799FNef/113n33XRWxSBZkWMbGmBlAbaCIMSYBGAz4A1hrM3ydWES8y4ULF3juueeYNm0agwcPZvDgwSpikSzKsIytte0yezBrbacspRERt5aYmEiHDh2YNWsWQ4cOZeDAgU5HEvEK+t0DEcmU8+fP07ZtW7766itGjBhB3759nY4k4jVUxiKSoXPnztGqVSsWLFjA2LFjefnll52OJOJVVMYicl1nzpzhySefZOnSpYwfP55u3bo5HUnE66iMRSRdp06dolmzZqxevZpJkybRuXNnpyOJeCWVsYhc04kTJ2jSpAnffPMNn332GR06dHA6kojXUhmLyFX+/PNPGjZsyPr164mMjKRt27ZORxLxaipjEbnMsWPHaNCgAZs3b2bWrFm0bNnS6UgiXk9lLCJpjhw5Qt26ddm+fTtz5syhWbNmTkcS8QkqYxEB4NChQ9SpU4fdu3czd+5cGjZs6HQkEZ+hMhYRDhw4QJ06dfjll19YsGABderUcTqSiE9RGYv4uF9//ZWQkBB+/fVXFi9eTK1atZyOJOJzVMYiPmz//v2EhIRw6NAhli5dSs2aNZ2OJOKTVMYiPuqXX34hODiY48ePs3z5cqpXr+50JBGfpTIW8UF79+4lODiYU6dOsXLlSh555BGnI4n4NJWxiI/ZuXMnISEhJCYmsnr1aipWrOh0JBGfpzIW8SFxcXGEhoZijCEqKoqyZcs6HUlEgFxOBxCRnLFlyxaCg4Px8/NTEYu4GZWxiA/YtGkTwcHB5MuXj5iYGMqUKeN0JBG5hMpYxMutW7eO0NBQbrvtNqKjo7n//vudjiQiV1AZi3ixb775hnr16lGkSBFiYmIoVaqU05FE5BpUxiJeKioqigYNGlC8eHGio6MpWbKk05FEJB0qYxEvtGLFCho1akRAQADR0dGUKFHC6Ugich0qYxEvs3jxYpo0acIDDzxAVFQUxYoVczqSiGRAZSziRb7++mueeOIJypYty6pVqyhatKjTkUQkE1TGIl5izpw5tGzZkqCgIFauXEnhwoWdjiQimaQyFvECM2bM4KmnnqJatWosW7aM22+/3elIInIDVMYiHm7q1Kk888wz1KxZkyVLllCoUCGnI4nIDVIZi3iwSZMm0alTJ4KDg1m0aBEFCxZ0OpKI3ASVsYiHGj9+PM8//zz169dn/vz53HrrrU5HEpGbpDIW8UBjx46le/fuNG3alLlz55IvXz6nI4lIFqiMRTzMiBEj6N27Ny1atGD27NnccsstTkcSkSxSGYt4kPDwcF577TWeeuopZs6cSZ48eZyOJCIuoDIW8QDWWgYPHsz//d//0aFDB6ZNm4a/v7/TsUTERXI7HUBErs9ayxtvvMHw4cPp3LkzERER+Pn5OR1LRFxIZSzixqy1vPrqq4wePZoXXniBjz76iFy5dENLxNvo/2oRN5WcnEzPnj0ZPXo0PXv2ZPz48SpiES+V4f/ZxpjJxphDxpi4dLY3N8ZsNcbEGmM2GmP+6fqYIr4lOTmZF198kQ8//JBXX32VsWPHYoxxOpaIZJPM/DN7CtDgOttXAhWttUFAZ2Bi1mOJ+K6kpCS6dOlCREQEb7zxBiNGjFARi3i5DMvYWhsDHL3O9pPWWpv65a2ATW9fEbm+Cxcu0LFjR6ZMmcJbb73F0KFDVcQiPsAlb+AyxjwJDAPuAhpfZ78wIAygZMmSrnhqEa+RmJhI+/bt+fLLL3n33XcZMGCA05FEJIe45N0g1tqvrLVlgCeAd66zX4S1toq1tooWPRf5y/nz52nTpg1ffvklI0eOVBGL+BiX/mqTtTbGGPN3Y0wRa+0frjy2iLc6e/YsrVq1YuHChbz//vv07NnT6UgiksOyPDI2xtxvUl/UMsZUBvIAR7J6XBFfcObMGZo3b87ChQuZMGGCiljER2U4MjbGzABqA0WMMQnAYMAfwFo7AWgJdDTGJAJngKcueUOXiKTj1KlTNGvWjNWrVzNp0iQ6d+7sdCQRcUiGZWytbZfB9veA91yWSMQHnDhxgsaNG/Ptt98ydepUnnnmGacjiYiDNB2mSA77888/adiwIevXr2f69Ok89dRTTkcSEYepjEVy0LFjx6hfvz6xsbF88cUXtGjRwulIIuIGVMYiOeSPP/6gbt26/Pjjj8yZM4emTZs6HUlE3ITKWCQHHDp0iDp16rB7927mzZtHgwbXm2FWRHyNylgkmx04cIDQ0FD27dvHwoULCQ0NdTqSiLgZlbFINkpISCAkJITffvuNxYsXU6tWLacjiYgbUhmLZJP4+HhCQkI4fPgwS5cupWbNmk5HEhE3pTIWyQY///wzISEhHD9+nBUrVlCtWjWnI4mIG1MZi7jYnj17CAkJ4fTp06xatYrKlSs7HUlE3JzKWMSFduzYQWhoKImJiaxevZoKFSo4HUlEPIDKWMRF4uLiCA0NxRhDVFQUZcuWdTqSiHgIl6xnLOLrYmNjqV27Nrlz5yY6OlpFLCI3RGUskkUbN24kJCSE/PnzEx0dzYMPPuh0JBHxMCpjkSxYu3YtoaGhFCpUiJiYGO6//36nI4mIB1IZi9ykb775hnr16lG0aFFiYmIIDAx0OpKIeCiVschNWL16NfXr16dEiRLExMRw3333OR1JRDyYyljkBi1btoxGjRpRqlQpoqOjueeee5yOJCIeTmUscgMWLVpEs2bNKF26NKtXr+buu+92OpKIeAGVsUgmzZs3jyeeeIKyZcuyatUqihYt6nQkEfESKmORTPjyyy9p1aoVlStXZuXKlRQuXNjpSCLiRVTGIhmYPn06bdu2pXr16ixbtozbb7/d6Ugi4mVUxiLX8dlnn9GhQwcee+wxlixZwm233eZ0JBHxQipjkXRMnDiR5557jpCQEBYtWkSBAgWcjiQiXkplLHINH330EV27dqVBgwbMnz+f/PnzOx1JRLyYyljkCmPGjOGll16iadOmfPXVV+TNm9fpSCLi5VTGIpf417/+RZ8+fWjZsiWzZ8/mlltucTqSiPgAlbFIqnfeeYf+/fvTtm1bZs6cSZ48eZyOJCI+QmUsPs9ay5tvvsmgQYPo0KED06ZNI3fu3E7HEhEfojIWn2atZcCAAQwdOpQuXbrw6aef4ufn53QsEfEx+ue/+CxrLa+88gpjxozhxRdf5IMPPiBXLv37VERynv7mEZ+UnJxMjx49GDNmDL169eLDDz9UEYuIYzQyFp+TnJzMCy+8wMSJE+nbty//+te/MMY4HUtEfJiGAuJTkpKS6Ny5MxMnTmTgwIEqYhFxCxoZi8+4cOECzz77LNOnT2fIkCEMGjTI6UgiIoBGxuLlIiMjCQwMJFeuXBQqVIjp06czbNgwFbGIuBWNjMVrRUZGEhYWxunTpwE4ffo0/v7+3HfffQ4nExG5nEbG4rUGDhyYVsQXJSYmMnDgQIcSiYhcW4ZlbIyZbIw5ZIyJS2d7e2PM1tSP74wxFV0fU+TGnDt3jvj4+Gtu279/fw6nERG5vsyMjKcADa6z/ReglrW2AvAOEOGCXCI3beHChZQrVy7d7SVLlszBNCIiGcuwjK21McDR62z/zlp7LPXLdcC9LsomckP27t1L06ZNadKkCX5+fvTv3/+qdYjz589PeHi4QwlFRK7N1a8ZdwEWp7fRGBNmjNlojNl4+PBhFz+1+KpTp04xcOBAypYtS1RUFCNGjGDr1q0MHz6ciIgIAgICMMYQEBBAREQE7du3dzqyiMhljLU2452MCQQWWGvTvfdnjAkGPgL+aa09ktExq1SpYjdu3HgDUUUuZ63liy++oG/fviQkJNChQwfee+89ihcv7nQ0EZFrMsZsstZWufJxl4yMjTEVgIlA88wUsUhWbdu2jZCQENq2bUuRIkX45ptvmDp1qopYRDxSlsvYGFMS+A/QwVq7O+uRRNJ3/PhxevXqRaVKldi6dSvjx49n48aN1KxZ0+loIiI3LcNJP4wxM4DaQBFjTAIwGPAHsNZOAAYBhYGPUuf4vXCtIbhIViQnJzNlyhRef/11/vjjD1544QWGDh1K4cKFnY4mIpJlGZaxtbZdBtufB553WSKRK6xfv56ePXuyfv16atasydKlS6lUqZLTsUREXEYzcInbOnToEF26dKF69ers37+fzz//nDVr1qiIRcTrqIzF7Vy4cIH333+f0qVLM3XqVPr27cuuXbt45plntNyhiHglLRQhbiUqKoqePXsSFxdHvXr1GDt2LGXKlHE6lohIttLIWNzCf//7X5566imCg4M5efIkX331FUuWLFERi4hPUBmLo86dO8e7775LmTJl+Prrr3nrrbf48ccfeeKJJ3RLWkR8hm5Ti2MWLFhA7969+emnn2jRogWjRo0iMDDQ6VgiIjlOI2PJcXv27KFx48Y0bdoUf39/li1bxpw5c1TEIuKzVMaSY06dOsUbb7xBuXLlWLNmDSNHjmTLli3UrVvX6WgiIo7SbWrJdtZaZs2aRd++ffn111/p2LEjw4cP1zzSIiKpNDKWbLVt2zaCg4Np164dd911F99++y2fffaZilhE5BIqY8kWx44d4+WXX6ZSpUps27aNCRMmsGHDBv7xj384HU1ExO3oNrW4VHJyMpMnT2bAgAEcPXqUbt268c4773DnnXc6HU1ExG1pZCwus379emrUqEHXrl0pU6YMmzZt4sMPP1QRi4hkQGUsWXbw4EE6d+5M9erVSUhIYNq0acTExBAUFOR0NBERj6AylpuWmJjI2LFjKV26NNOmTaNfv37s2rWL9u3ba/YsEZEboNeM5aasXr2anj17sn37durXr8/YsWN58MEHnY4lIuKRNDKWG7J//37atGlDSEgIp0+fZu7cuSxevFhFLCKSBSpjyZSzZ88SHh5OmTJlmD9/PkOGDGH79u00b95ct6RFRLJIt6klQwsWLKBXr178/PPPtGzZklGjRhEQEOB0LBERr6GRsaTr0gUdbrnlFpYvX87s2bNVxCIiLqYylqucPHmSAQMGpC3oMGrUKLZs2UKdOnWcjiYi4pV0m1rSXLmgw7PPPsvw4cMpVqyY09FERLyaRsYCwNatW9MWdLj77rv57rvvmDJliopYRCQHqIx93LFjx+jZsyeVKlUiLi6Ojz/+mPXr1/Poo486HU1ExGfoNrWPunJBhxdffJG3335b80iLiDhAI2Mf9P3331O9evW0BR02b97MBx98oCIWEXGIytiHHDx4kOeee44aNWrw22+/ERkZSUxMDBUrVnQ6moiIT1MZ+4DExETGjBlD6dKliYyMpH///uzcuZOnn35as2eJiLgBvWbs5VatWkXPnj358ccfadCgAWPGjNE80iIibkYjYy+1f/9+WrduTWhoKGfOnGHevHksWrRIRSwi4oZUxl7m7NmzDB06lDJlyrBw4ULefvttfvzxR5o1a6Zb0iIibkq3qb2EtZb58+fTp08ffv75Z1q1asXIkSM1j7SIiAfQyNgL7N69m8aNG9O8eXPy5s3LihUr+PLLL1XEIiIeQmXswU6ePMnrr79OuXLl+Pbbb/n3v/9NbGwsoaGhTkcTEZEboNvUHshay4wZM+jXrx+//fYbnTp1YtiwYZpHWkTEQ2lk7GG2bt1K7dq1ad++PcWLF2ft2rV8+umnKmIREQ+WYRkbYyYbYw4ZY+LS2V7GGLPWGHPOGNPX9REF4OjRo/To0YNKlSqxfft2IiIi+P7776lRo4bT0UREJIsyMzKeAjS4zvajwMvASFcEksslJSXxySefULp0acaPH0/37t3Zs2cPXbt2xc/Pz+l4IiLiAhmWsbU2hpTCTW/7IWvtBiDRlcEE1q1bR/Xq1QkLC+Phhx9m8+bNjBs3jjvuuMPpaCIi4kJ6zdgN/f7773Tq1IlHH32UAwcOMH36dKKjo7Wgg4iIl8rRMjbGhBljNhpjNh4+fDgnn9ojJCYmMnr0aB588EGmT5/O66+/zq5du2jXrp1mzxIR8WI5WsbW2ghrbRVrbZWiRYvm5FO7vZUrVxIUFMQrr7xCzZo1iYuLY9iwYRQoUMDpaCIiks10m9phFxd0qFOnDmfPnuXrr79m4cKFlC5d2uloIiKSQzKc9MMYMwOoDRQxxiQAgwF/AGvtBGNMMWAjcBuQbIzpDTxsrf1fdoX2BmfPnmXEiBEMGzYMgKFDh/Lqq6+SN29eh5OJiEhOy7CMrbXtMtj+O3CvyxJ5OWstX3/9NX369OGXX36hdevWjBw5kpIlSzodTUREHKLb1Dlo165dNGzYkCeeeIL8+fOzcuVKvvjiCxWxiIiPUxnngBMnTtC/f3/Kly/P2rVrGT16ND/88AMhISFORxMRETeghSKykbWW6dOn89prr/Hbb7/x3HPPMWzYMO6++26no4mIiBvRyDibbNmyhVq1avHMM89wzz33sG7dOiZPnqwiFhGRq6iMXezo0aO89NJLVK5cmR07dvDJJ5/w/fffU716daejiYiIm9JtahdJSkpi0qRJvPHGGxw7doyXXnqJIUOGaB5pERHJkMrYBdauXUuPHj3YvHkzjz/+OOPGjaNChQpOxxIREQ+h29RZcHFBh3/84x8cPHiQGTNmEBUVpSIWEZEbojK+CYmJifz73/+mdOnSzJgxgwEDBrBz507atm2rBR1EROSG6Tb1DVqxYgUvv/wyO3bsoFGjRowZM4YHHnjA6VgiIuLBNDLOpPj4eFq1akXdunU5f/488+fPZ+HChSpiERHJMpVxBs6cOcPbb7/NQw89xOLFiwkPDycuLo4mTZo4HU1ERLyEblOn4+KCDr1792bfvn20adOGkSNHct999zkdTUREvIxGxtdw6YIOBQoUYNWqVcyaNUtFLCIi2UJlfIkTJ07w2muvUb58edatW8fYsWP54YcfCA4OdjqaiIh4Md2m5q8FHfr168eBAwfo3Lkzw4YN46677nI6moiI+ACfL+PY2Fh69uzJN998Q9WqVfnqq680j7SIiOQon71NffToUbp3784jjzzCrl27mDhxIuvWrVMRi4hIjvO5Mk5KSuLjjz+mdOnSRERE0KNHD3bv3k2XLl3IlcvnToeIiLgBn7pN/d1339GzZ082b95M7dq1ef/99ylfvrzTsURExMf5xFDwwIEDdOzYkZo1a3Lo0CFmzpzJqlWrVMQiIuIWvLqMExMTGTVqFA8++CCzZs3ijTfeYOfOnTz11FNa0EFERNyG196mXr58OS+//DI7d+6kcePGjBkzhvvvv9/pWCIiIlfx+JFxZGQkgYGB5MqVi8DAQMaMGUPLli2pV68eiYmJLFiwgAULFqiIRUTEbXn0yDgyMpKwsDBOnz4NpKys1KdPH/z9/QkPD+eVV14hb968DqcUERG5PmOtdeSJq1SpYjdu3JilYwQGBhIfH3/V4yVKlCAhISFLxxYREXE1Y8wma22VKx/36NvU+/fvv+bjv/32Ww4nERERuXkeXcYlS5a8ocdFRETckUeXcXh4OPnz57/ssfz58xMeHu5QIhERkRvn0WXcvn17IiIiCAgIwBhDQEAAERERtG/f3uloIiIimebRb+ASERHxJF75Bi4RERFvoDIWERFxmMpYRETEYSpjERERh6mMRUREHKYyFhERcViGZWyMmWyMOWSMiUtnuzHGvG+M2WuM2WqMqez6mCIiIt4rMyPjKUCD62xvCDyQ+hEGjM96LBEREd+RYRlba2OAo9fZpTkw1aZYB9xujCnuqoAiIiLezhWvGZcA/nvJ1wmpj13FGBNmjNlojNl4+PBhFzy1iIiI58vtgmOYazx2zTk2rbURQASAMeawMebqxYhvXhHgDxcez9PpfFxO5+MvOheX0/m4nM7HX7LjXARc60FXlHECcN8lX98LZLigsLW2qAueO40xZuO15vv0VTofl9P5+IvOxeV0Pi6n8/GXnDwXrrhN/TXQMfVd1TWAP621B1xwXBEREZ+Q4cjYGDMDqA0UMcYkAIMBfwBr7QRgEdAI2AucBp7LrrAiIiLeKMMytta2y2C7BV5yWaKbF+F0ADej83E5nY+/6FxcTufjcjoff8mxc+HYesYiIiKSQtNhioiIOMzjytgY08AYsyt1+s3Xr7Hdp6bnzMT5qG2M+dMYE5v6MciJnDlBU7deLhPnw5eujfuMMauNMTuMMduNMb2usY9PXB+ZPBe+dG3kNcasN8ZsST0fQ66xT/ZfG9Zaj/kA/ICfgL8BeYAtwMNX7NMIWEzK7z/XAL53OrfD56M2sMDprDl0Ph4HKgNx6Wz3mWsjk+fDl66N4kDl1M8LArt99e+OTJ4LX7o2DFAg9XN/4HugRk5fG542Mq4G7LXW/mytPQ/MJGU6zkv50vScmTkfPsNq6tbLZOJ8+Axr7QFr7ebUz08AO7h6pkCfuD4yeS58Rup/75OpX/qnflz5ZqpsvzY8rYwzM/Vmpqfn9AKZ/VkfTb0Fs9gYUzZnorklX7o2Msvnrg1jTCBQiZQR0KV87vq4zrkAH7o2jDF+xphY4BCw3Fqb49eGK2bgykmZmXoz09NzeoHM/KybgQBr7UljTCNgLikrbPkiX7o2MsPnrg1jTAFgDtDbWvu/Kzdf41u89vrI4Fz41LVhrU0CgowxtwNfGWPKWWsvfa9Ftl8bnjYyzszUmzc1PaeHyvBntdb+7+ItGGvtIsDfGFMk5yK6FV+6NjLka9eGMcaflPKJtNb+5xq7+Mz1kdG58LVr4yJr7XEgiquXDc72a8PTyngD8IAxppQxJg/QlpTpOC/lS9NzZng+jDHFjDEm9fNqpPw3P5LjSd2DL10bGfKlayP155wE7LDW/jud3Xzi+sjMufCxa6No6ogYY0w+oA6w84rdsv3a8Kjb1NbaC8aYHsBSUt5JPNlau90Y0y11u09Nz5nJ89EKeNEYcwE4A7S1qW8P9DZGU7deJhPnw2euDaAm0AHYlvraIMAbQEnwuesjM+fCl66N4sBnxhg/Uv7R8YW1dkFO94pm4BIREXGYp92mFhER8ToqYxEREYepjEVERBymMhYREXGYylhERMRhKmMRERGHqYxFREQcpjIWERFx2P8D5pZ/EgUnUj0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFlCAYAAAAUB7oWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA680lEQVR4nO3de5xN9f7H8dfHGPc47pJcT6WLmnLPXSKVOtINXejiKDmSI4OMYWYMIXREOCR+IkUR5ZBDBhUjdwqVkXLvglwyM9/fH7M5Q8MM9syaPfv9fDzmMbPXbb/3aj16W3uvvb7mnENEREQCSy6vA4iIiMjFU4GLiIgEIBW4iIhIAFKBi4iIBCAVuIiISABSgYuIiASg3F4HuBglSpRwFStW9DqGiIhIllizZs1B51zJtOYFVIFXrFiR+Ph4r2OIiIhkCTNLON88vYUuIiISgFTgIiIiAUgFLiIiEoAC6jNwERHJHk6dOsXu3bs5ceKE11FyhHz58lGuXDlCQ0MzvI4KXERELtru3bu54oorqFixImbmdZyA5pzj0KFD7N69m0qVKmV4Pb2FLiIiF+3EiRMUL15c5e0HZkbx4sUv+t0MFbiIiFwSlbf/XMq+VIGLiEhAKlSokN+3uXPnTt555x2/bzczqMBFRCTTTZs2jYoVK5IrVy4qVqzItGnTvI6UJhV4NhcoB5KISE4wbdo0OnXqREJCAs45EhIS6NSpk9/+37t06VIaN27Mgw8+SNWqVWnfvj3OOSDlDp69evWiVq1a1KpVix07dgDQoUMH3n///TPbOH02Hx4eTlxcHGFhYYwYMYLNmzdTq1YtwsLCuPnmm9m+fbtfMvtD0F2FfvpAOnbsGMCZAwmgffv2XkYTEQlIL774IuvWrTvv/C+++IKTJ0+eNe3YsWM8/fTTTJgwIc11wsLCGDlyZIYzrF27ls2bN1O2bFnq1avHihUrqF+/PgCFCxdm1apVTJkyhRdffJF58+addzuDBw9m2LBhZ5bp2rUr3bp1o3379vzxxx8kJSVlOFNmC7oz8L59+54p79OOHTtG3759PUokIpKznVve6U2/FLVq1aJcuXLkypWLsLAwdu7ceWZe27Ztz/z+/PPPL2q7devWZdCgQQwZMoSEhATy58/vt8yXK+jOwHft2nVR00VE5MLSO1OuWLEiCQl/HpOjQoUKLF261C8Z8ubNe+bvkJAQEhMTzzxOfYX36b9z585NcnIykPI97D/++CPN7bZr147atWszf/58WrRowb///W+aNm3ql8yXK+jOwMuXL39R00VE5PLExMRQoECBs6YVKFCAmJiYLHn+d99998zvunXrAin/qFizZg0Ac+bM4dSpUwBcccUVHDly5My63333HZUrV+Yf//gH9913Hxs2bMiSzBkRdGfgMTExZ30GDim3sMuqA0lEJNicvr6ob9++7Nq1i/LlyxMTE5Nl1x2dPHmS2rVrk5yczPTp0wF49tlnuf/++6lVqxZ33HEHBQsWBODmm28md+7c3HLLLXTo0IETJ07wf//3f4SGhlKmTBkiIiKyJHNG2Okr9QJBjRo1nD/GA582bdqZAwlS/oNd6AIMERE529atW7n++uu9jpGuihUrEh8fT4kSJbyOkq609qmZrXHO1Uhr+aB7Cx1S/jW4c+dOkpOTiY2NZf369SxbtszrWCIiIhkWlAWeWteuXSlbtiy9e/cmkN6NEBGR9O3cuTMgzr4vRdAXeIECBejfvz8rV67ko48+8jqOiIhIhgR9gQN07NiRa665hj59+mSrL+mLiIicjwocCA0NJSYmhs2bN+u2qiIiEhBU4D5t2rShevXqRERE+PXuQCIiIplBBe6TK1cuYmNjSUhI4M033/Q6joiIXMChQ4cICwsjLCyMMmXKcNVVV515fL67ql2qX3/9lTFjxvh1m/6gAk/lzjvv5I477iA6OvqsO/GIiMhlePVVWLLk7GlLlqRMv0TFixdn3bp1rFu3js6dO9O9e/czj/PkyXPe9VLfYjWjVOABIjY2loMHDzJ8+HCvo4iI5Aw1a8LDD/+vxJcsSXlcs6Zfn2bChAnUrFmTW265hTZt2py542aHDh146aWXaNKkCb169eLbb7+lTp061KxZk4iIiDNDiQIMHTqUmjVrcvPNN9O/f38gZYjRb7/9lrCwMHr27MmePXto2LAhYWFh3HTTTcTFxfn1dWSUCvwcNWvWpE2bNgwfPpz9+/d7HUdEJPA1aQIzZ6aUdkREyu+ZM1Om+9EDDzzA6tWrWb9+Pddffz0TJ048M2/btm18+umnDB8+nG7dutGtWzdWr15N2bJlzyyzcOFCtm/fzqpVq1i3bh1r1qxh2bJlDB48mCpVqrBu3TqGDh3KO++8Q4sWLVi3bh3r168nLCzMr68jo1TgaYiJieH48eMMGjTI6ygiIjlDkybw3HMQFZXy28/lDbBp0yYaNGhAtWrVmDZtGps3bz4z76GHHiIkJASAzz//nIceeghIGW3stIULF7Jw4UJuvfVWbrvtNr7++mu2b9/+p+epWbMmb731FpGRkWzcuJErrrjC768lI1Tgabjuuuvo2LEjY8eOPWtMWRERuURLlsDYsdCvX8rvcz8T94MOHTowevRoNm7cSP/+/Tlx4sSZeacHK7kQ5xy9e/c+81n6jh07ePrpp/+0XMOGDVm2bBlXXXUVjz/+OFOmTPHr68goFfh59O/fHzM78xmIiIhcotOfec+cCQMH/u/tdD+X+JEjR7jyyis5derUBe/pUadOHWbNmgXAjBkzzkxv0aIFkyZN4ujRowD8+OOP7N+//09DjCYkJFCqVCmeffZZnn76ab766iu/vo6MUoGfR7ly5ejatStTp05l06ZNXscREQlcq1ef/Zn36c/EV6/269NERUVRu3Zt7rzzTqpWrXre5UaOHMlrr71GrVq12LNnD0WKFAGgefPmtGvXjrp161KtWjUefPBBjhw5QvHixalXrx433XQTPXv2ZOnSpYSFhXHrrbcya9YsunXr5tfXkVFBOZxoRv38889UrlyZRo0aMWfOnCx7XhGR7C5QhhNNy7Fjx8ifPz9mxowZM5g+fXq2+H+8hhP1o2LFivHyyy8zd+5cVqxY4XUcERHxgzVr1hAWFsbNN9/MmDFjAvZrwzoDT8fvv//OX//6V/7617+ybNkyzCxLn19EJDsK5DPw7Epn4H5WsGBBIiIiWL58OZ988onXcURERAAVeIY888wzVKlShd69e5OcnOx1HBERERV4RoSGhhIVFcWGDRuYPn2613FERETSL3Azm2Rm+80sze9SmVkRM/vIzNab2WYz6+ibfrWZLTGzrb7p3VKtE2lmP5rZOt/P3f57SZnjkUceISwsjH79+vl9pBsREZGLlZEz8MnAXReY3wXY4py7BWgMDDezPEAi0MM5dz1QB+hiZjekWm+Ecy7M9/PxJaXPQqeHG/3+++8ZP36813FERIJeSEjImQFFHnrooTODl1yKDh068P777wMpH5tu2bLlvMsuXbqUlStXnnn85ptvenI3tnQL3Dm3DPj5QosAV1jK5dmFfMsmOuf2OOe+8m3jCLAVuOryI3unRYsWNGrUiKioqDN36hERkQsrUwbM/vxTpszlbTd//vysW7eOTZs2kSdPHt58882z5iclJV3Sdv/9739zww03nHf+uQXeuXNnnnjiiUt6rsvhj8/ARwPXAz8BG4FuzrmzrvQys4rArcCXqSa/YGYbfG/RFz3fxs2sk5nFm1n8gQMH/BD30pkZgwcPZv/+/YwcOdLTLCIigWLfvoubfikaNGjAjh07WLp0KU2aNKFdu3ZUq1aNpKQkevbseWaI0HHjxgEp9z1/4YUXuOGGG7jnnnvOGn2ycePGnP7K8oIFC7jtttu45ZZbuOOOO9i5cydvvvkmI0aMICwsjLi4OCIjIxk2bBgA69ato06dOtx88820bt2aX3755cw2e/XqRa1atbj22mv9MgSpPwq8BbAOKAuEAaPNrPDpmWZWCJgFvOicO+ybPBao4lt+D3Deb9E758Y752o452qULFnSD3EvT506dfjb3/7G0KFDOXjwoNdxRESCXmJiIp988gnVqlUDYNWqVcTExLBlyxYmTpxIkSJFWL16NatXr2bChAl8//33fPDBB3zzzTds3LiRCRMmnHVGfdqBAwd49tlnmTVrFuvXr+e9996jYsWKdO7cme7du7Nu3ToaNGhw1jpPPPEEQ4YMYcOGDVSrVo0BAwaclXPVqlWMHDnyrOmXyh8F3hGY7VLsAL4HqgKYWSgp5T3NOTf79ArOuX3OuSTfmfoEoJYfcmSZ6Ohojh49SmxsrNdRRESC1vHjxwkLC6NGjRqUL1/+zMhhtWrVolKlSkDKEKFTpkwhLCyM2rVrc+jQIbZv386yZcto27YtISEhlC1blqZNm/5p+1988QUNGzY8s61ixYpdMM9vv/3Gr7/+SqNGjQB48sknWbZs2Zn5DzzwAADVq1f3y0iXuS97C7ALuAOIM7PSwHXAd77PxCcCW51zr6VewcyudM7t8T1sDQTUaCE33ngjTzzxBG+88QbdunWjfPnyXkcSEQk6pz8DP1fqoUOdc/zrX/+iRYsWZy3z8ccfp3tnTeecX+++mTdvXiDl4rvExMTL3l5GvkY2HfgcuM7MdpvZ02bW2cw6+xaJAm43s43AYqCXc+4gUA94HGiaxtfFXjWzjWa2AWgCdL/sV5LFBgwYgHPOL2+DiIhI5mjRogVjx47l1KlTAGzbto3ff/+dhg0bMmPGDJKSktizZw9L0hjatG7dunz22Wd8//33QMoAV8Cfhhc9rUiRIhQtWvTM59tTp049czaeGdI9A3fOtU1n/k9A8zSmLwfS/KeLc+7xjAbMrsqXL0+XLl0YNWoUPXr0uOAViyIiwax06bQvWCtdOvOf+5lnnmHnzp3cdtttOOcoWbIkH374Ia1bt+a///0v1apV49prr02zaEuWLMn48eN54IEHSE5OplSpUixatIhWrVrx4IMPMmfOHP71r3+dtc7bb79N586dOXbsGJUrV+att97KtNemwUwuw8GDB6lcuTLNmjVj9uzZ6a8gIpJDaDAT/9NgJlmoRIkS9OzZkw8++IAvv/wy/RVERET8RAV+mbp3707JkiUJDw8nkN7NEBGRwKYCv0yFChWiX79+LF26lIULF3odR0REgoQK3A/+/ve/U7FiRQ03KiJBRe86+s+l7EsVuB/kyZOHqKgo1q5dy3vvved1HBGRTJcvXz4OHTqkEvcD5xyHDh0iX758F7WerkL3k6SkJG699VaOHz/Oli1bCA0N9TqSiEimOXXqFLt37+bEiRNeR8kR8uXLR7ly5f7UHRe6Ct0fd2ITUu6sExsby7333svEiRPp3Llz+iuJiASo0NDQM7cYFW/oLXQ/uvvuu6lfvz4DBgy4rHFpRURE0qMC96PTw43u3buXUaNGeR1HRERyMBW4n9WrV49WrVoxZMiQM/fNFRER8TcVeCaIiYnh8OHDDBkyxOsoIiKSQ6nAM0G1atV47LHHeP3119m9e7fXcUREJAdSgWeSAQMGkJSUxMCBA72OIiIiOZAKPJNUqlSJ5557jkmTJvHNN994HUdERHIYFXgm6tu3L/ny5eOVV17xOoqIiOQwKvBMVKpUKXr06MH777/P6tWrvY4jIiI5iAo8k/Xo0YMSJUrQp08fr6OIiEgOogLPZIULF6Zv3758+umnfPrpp17HERGRHEIFngU6d+5M+fLl6d27t0buERERv1CBZ4F8+fIxcOBA4uPjmTVrltdxREQkB9BwolkkKSmJm2++mcTERDZv3kzu3BoITkRELuxCw4nqDDyLhISEMGjQILZt28Zbb73ldRwREQlwKvAsdN9991G3bl0iIyM5fvy413FERCSAqcCz0OnhRn/66SdGjx7tdRwREQlgKvAs1rBhQ1q2bElsbCy//vqr13FERCRAqcA9MGjQIH755RdeffVVr6OIiEiAUoF7ICwsjHbt2jFy5Ej27NnjdRwREQlAKnCPDBw4kFOnTmm4URERuSQqcI9UqVKFTp06MWHCBLZv3+51HBERCTAqcA/169ePvHnzEhER4XUUEREJMCpwD5UpU4bu3bszY8YM1q5d63UcEREJICpwj/Xs2ZNixYrRu3dvr6OIiEgAUYF7rEiRIvTp04f//Oc/LFmyxOs4IiISINItcDObZGb7zWzTeeYXMbOPzGy9mW02s46p5t1lZt+Y2Q4zC081vZiZLTKz7b7fRf3zcgLT888/T7ly5TTcqIiIZFhGzsAnA3ddYH4XYItz7hagMTDczPKYWQjwBtASuAFoa2Y3+NYJBxY7564BFvseB638+fMTGRnJl19+yYcffuh1HBERCQDpFrhzbhnw84UWAa4wMwMK+ZZNBGoBO5xz3znn/gBmAPf71rkfeNv399vA3y4pfQ7y5JNPUrVqVfr27UtiYqLXcUREJJvzx2fgo4HrgZ+AjUA351wycBXwQ6rldvumAZR2zu0B8P0udb6Nm1knM4s3s/gDBw74IW72lDt3bmJiYti6dStTp071Oo6IiGTUq6/CudcwLVmSMj0T+aPAWwDrgLJAGDDazAoDlsayF/0Br3NuvHOuhnOuRsmSJS8nZ7bXunVratasSf/+/Tlx4oTXcUREJCNq1oSHH/5fiS9ZkvK4Zs1MfVp/FHhHYLZLsQP4HqhKyhn31amWK0fKWTrAPjO7EsD3e78fcgS808ON/vDDD4wZM8brOCIikhFNmsDMmSmlHRGR8nvmzJTpmcgfBb4LuAPAzEoD1wHfAauBa8yskpnlAR4F5vrWmQs86fv7SWCOH3LkCE2bNqV58+YMGjSI3377zes4IiKSEU2awHPPQVRUyu9MLm/I2NfIpgOfA9eZ2W4ze9rMOptZZ98iUcDtZraRlCvKeznnDjrnEoEXgP8AW4GZzrnNvnUGA3ea2XbgTt9j8Rk0aBCHDh1i+PDhXkcREZGMWLIExo6Ffv1SfmfBfT0skL53XKNGDRcfH+91jCzxyCOPMH/+fL799ltKly7tdRwRETmf0595n37b/NzHl8HM1jjnaqQ1T3diy6aio6M5ceIE0dHRXkcREZELWb367LI+/Zn46tWZ+rQ6A8/GOnfuzKRJk/j666+pXLmy13FERCSL6Qw8QEVERJA7d24NNyoiIn+iAs/GypYtS7du3XjnnXdYv36913FERCQbUYFncy+//DJFihShb9++XkcREZFsRAWezRUtWpTw8HDmz59PXFyc13FERCSbUIEHgK5du1K2bFnCw8M13KiIiAAq8IBQoEAB+vfvz8qVK5k3b57XcUREJBvQ18gCxKlTp7jxxhvJkycP69evJyQkxOtIIiKSyfQ1shwgNDSU6OhoNm/ezLRp07yOIyIiHtMZeABJTk6mVq1aHDx4kG+++Ya8efN6HUlERDKRzsBziFy5chEbG0tCQgLjxo3zOo6IiHhIBR5gmjVrRtOmTYmOjubIkSNexxEREY+owAOMmTF48GAOHDjAa6+95nUcERHxiAo8ANWsWZM2bdowbNgwDhw44HUcERHxgAo8QEVHR3Ps2DFiYmK8jiIiIh5QgQeoqlWr8tRTTzF27Fh27tzpdRwREcliKvAA1r9/f8yMyMhIr6OIiEgWU4EHsHLlytG1a1emTJnCpk2bvI4jIiJZSAUe4Hr37k3hwoU13KiISJBRgQe4YsWK8fLLLzN37lxWrlzpdRwREckiKvAcoFu3bpQpU0bDjYqIBBEVeA5QsGBBIiIiiIuL45NPPvE6joiIZAENZpJDnDp1iuuvv56CBQuydu1acuXSv81ERAKdBjMJAqGhoURFRbFhwwZmzJjhdRwREclkOgPPQZKTk6levTqHDx9m69at5MmTx+tIIiJyGXQGHiRODzf63XffMWHCBK/jiIhIJlKB5zAtWrSgUaNGREVFcfToUa/jiIhIJlGB5zCnhxvdt28fI0eO9DqOiIhkEhV4DlSnTh3+9re/MXToUA4ePOh1HBERyQQq8BwqOjqao0ePMnjwYK+jiIhIJlCB51A33ngjTzzxBKNHj2bXrl1exxERET9TgedgAwYMwDnHgAEDvI4iIiJ+lm6Bm9kkM9tvZmmOV2lmPc1sne9nk5klmVkxM7su1fR1ZnbYzF70rRNpZj+mmne3n1+XAOXLl6dLly5MnjyZrVu3eh1HRET8KN0buZhZQ+AoMMU5d1M6y7YCujvnmp4zPQT4EajtnEsws0jgqHNu2MWE1Y1cLt7BgwepXLkyzZo1Y/bs2V7HERGRi3BZN3Jxzi0Dfs7gc7UFpqcx/Q7gW+dcQga3I35SokQJevbsyQcffMCXX37pdRwREfETv30GbmYFgLuAWWnMfpQ/F/sLZrbB9xZ9UX/lkD/r3r07JUuW1HCjIiI5iD8vYmsFrHDOnXW2bmZ5gPuA91JNHgtUAcKAPcDw823UzDqZWbyZxR84cMCPcYNHoUKF6NevH0uXLmXRokVexxERET/wZ4GndZYN0BL4yjm37/QE59w+51yScy4ZmADUOt9GnXPjnXM1nHM1SpYs6ce4waVTp05UrFiR8PBwkpOTvY4jIiKXyS8FbmZFgEbAnDRm/+lzcTO7MtXD1kCaV7iL/+TNm5eoqCjWrl3Le++9l/4KIiKSrWXkKvTpQGOgBLAP6A+EAjjn3vQt0wG4yzn36DnrFgB+ACo7535LNX0qKW+fO2An8Hfn3J70wuoq9MuTlJTErbfeyvHjx9myZQuhoaFeRxIRkQu40FXoGg88yMybN49WrVoxduxYOnfu7HUcERG5AI0HLmfcc8891K9fnwEDBnDs2DGv44iIyCVSgQcZMyM2Npa9e/fy+uuvex1HREQukQo8CNWvX597772XwYMH8/PPGb1Hj4iIZCcq8CA1aNAgDh8+zJAhQ7yOIiIil0AFHqSqVavGY489xuuvv86PP/7odRwREblIKvAgNmDAAJKSkhg4cKDXUURE5CKpwINYpUqVeO6555g4cSLffPON13FEROQiqMCDXN++fcmXLx/9+vXzOoqIiFwEFXiQK1WqFD169OC9995DN8kREQkcKnChR48elChRgt69e3sdRSRbmzZtGhUrViRXrlxUrFiRadOmeR1JgpgKXChcuDB9+/bl008/5dNPP/U6jki2NG3aNDp16kRCQgLOORISEujUqZNKXDyje6ELACdOnOC6666jVKlSrFq1CjPzOpJItlKxYkUSEhL+NL1ChQrs3Lkz6wNJUNC90CVd+fLlY8CAAcTHxzNr1iyv44hkO7t27bqo6SKZTQUuZzz++OPccMMN9O3bl8TERK/jiGQbzjkKFy6c5rzy5ctncRqRFCpwOSMkJIRBgwaxbds2Jk+e7HUckWwhOTmZ7t2789tvvxESEnLWvAIFChATE+NRMgl2KnA5y3333UfdunWJjIzk+PHjXscR8dSpU6d48sknGTVqFN26dWPy5MlUqFABM6NChQqMHz+e9u3bex1TglRurwNI9mJmDB48mEaNGjF69Gh69uzpdSQRTxw7doyHHnqIjz/+mJiYGHr37o2Z8dhjj3kdTQTQGbikoWHDhrRs2ZLY2Fh+/fVXr+OIZLmff/6ZO++8kwULFjBu3Dj69Omjb2ZItqMClzQNGjSIX375haFDh3odRSRL/fjjjzRq1Ij4+HhmzpxJp06dvI4kkiYVuKQpLCyMdu3aMWLECPbs2eN1HJEssW3bNurVq8fOnTv55JNPaNOmjdeRRM5LBS7nNXDgQE6dOkVUVJTXUUQy3Zo1a6hfvz6///47S5YsoWnTpl5HErkgFbicV5UqVejUqRMTJkxgx44dXscRyTRLliyhSZMm5M+fnxUrVlCjRpo3vhLJVlTgckH9+vUjT548Gm5UcqzZs2dz1113cfXVV7Ny5UquvfZaryOJZIgKXC6oTJkydO/enRkzZrB27Vqv44j41YQJE3jooYeoXr06cXFxXHXVVV5HEskwFbikq2fPnhQrVow+ffp4HUXEL5xzxMbG0qlTJ1q0aMGiRYsoVqyY17FELooKXNJVpEgRevfuzYIFC1i6dKnXcUQuS3JyMj169KBPnz60a9eOOXPmULBgQa9jiVw0FbhkSJcuXShXrhzh4eEE0hC0IqmdOnWKDh06MGLECP7xj38wdepUQkNDvY4lcklU4JIh+fPnJzIyki+//JI5c+Z4HUfkoh07dozWrVszdepUoqKiGDlyJLly6X+BErgskM6matSo4eLj472OEbQSExOpVq0aZsaGDRvInVu30pfA8Msvv9CqVStWrlzJmDFj6Ny5s9eRRDLEzNY459L8XqP++SkZljt3bmJiYti6dStTp071Oo5Ihvz00080bNiQVatW8e6776q8JcfQGbhcFOcctWvXZu/evWzbto18+fJ5HUnkvLZv307z5s05cOAAH374Ic2aNfM6kshF0Rm4+M3p4UZ/+OEHxo4d63UckfNau3Yt9evX5+jRoyxZskTlLTmOClwuWtOmTWnevDkxMTH89ttvXscR+ZOlS5fSqFEj8uXLR1xcHDVr1vQ6kojfqcDlkgwaNIhDhw4xfPhwr6OInOXDDz88c2vUFStWULVqVa8jiWSKdAvczCaZ2X4z23Se+T3NbJ3vZ5OZJZlZMd+8nWa20TcvPtU6xcxskZlt9/0u6r+XJFmhevXqPPzww7z22mvs27fP6zgiAEycOJE2bdpw6623smzZMsqVK+d1JJFMk5Ez8MnAXeeb6Zwb6pwLc86FAb2Bz5xzP6dapIlvfuoP4cOBxc65a4DFvscSYKKjozlx4gTR0dFeR5Eg55xjyJAhPPPMM9x55518+umnFC9e3OtYIpkq3QJ3zi0Dfk5vOZ+2wPQMLHc/8Lbv77eBv2Vw+5KNXHPNNTzzzDOMGzeO7777zus4EqSSk5Pp2bMn4eHhtG3blrlz5+rWqBIU/PYZuJkVIOVMfVaqyQ5YaGZrzKxTqumlnXN7AHy/S11gu53MLN7M4g8cOOCvuOInERERhISE0L9/f6+jSBA6deoUTz31FMOHD+eFF17g//7v/8iTJ4/XsUSyhD8vYmsFrDjn7fN6zrnbgJZAFzNreLEbdc6Nd87VcM7VKFmypL+yip+ULVuWbt26MW3aNDZs2OB1HAkix44d44EHHuDtt99mwIABvP7667o1qgQVfx7tj3LO2+fOuZ98v/cDHwC1fLP2mdmVAL7f+/2YQ7JYr169KFKkiIYblSzz66+/0qJFC+bPn8+YMWOIiIjAzLyOJZKl/FLgZlYEaATMSTWtoJldcfpvoDlw+kr2ucCTvr+fTL2eBJ6iRYsSHh7O/PnziYuL8zqO5HB79uyhYcOGfPnll8yYMYPnnnvO60ginkj3VqpmNh1oDJQA9gH9gVAA59ybvmU6AHc55x5NtV5lUs66AXID7zjnYnzzigMzgfLALuChc956T5NupZp9HTt2jGuuuYZKlSoRFxensyHJFDt27KB58+bs379ft0aVoHChW6nqXujiN+PHj+fvf/87c+fOpVWrVl7HkRxm3bp13HXXXSQmJvLJJ5/o7moSFHQvdMkSHTt25JprrqFPnz4kJSV5HUdykM8++4xGjRqRJ08eli9frvIWQQUufhQaGkp0dDSbNm3inXfe8TqO5BBz5syhRYsWXHXVVbo1qkgqKnDxqwcffJDq1avTr18/Tp486XUcCXBvvfUWDzzwALfccgtxcXFcffXVXkcSyTZU4OJXuXLlIjY2loSEBMaNG+d1HAlgr776Kk899RTNmjVj8eLFujWqyDlU4OJ3zZo1o2nTpkRHR3PkyBGv40iAcc7Rs2dPevXqxSOPPMJHH31EoUKFvI4lku2owMXvzIzBgwdz4MABXnvtNa/jSABJTEykY8eODBs2jOeff55p06bp1qgi56ECl0xRs2ZN2rRpw7Bhw9A97CUjjh8/fubWqJGRkYwePZqQkBCvY4lkWypwyTTR0dEcO3aMQYMGeR1FsrnTt0adN28eb7zxBv3799fNgETSoQKXTFO1alU6duzImDFjSEhI8DqOZFN79+6lcePGfPHFF0yfPp3nn3/e60giAUEFLpkqMjISM9Nwo5Kmb7/9lnr16rFjxw7mzZvHI4884nUkkYChApdMVa5cObp27cqUKVPYtGlT+itI0Fi/fj316tXj119/ZfHixTRv3tzrSCIBRQUumS48PJwrrriCV155xesokk3ExcXRqFEjQkNDWb58ObVr1/Y6kkjAUYFLpitevDi9evVizpw5rFy50us44rG5c+fSvHlzypQpw4oVK7j++uu9jiQSkFTgkiW6detG6dKlCQ8PJ5BGwBP/mjx5Mg888ADVqlVj+fLllC9f3utIIgFLBS5ZomDBgkRERBAXF8eCBQu8jiMeGDp0KB07dqRp06b897//pUSJEl5HEgloKnDJMs8++yxVqlShd+/eJCcnex1HsohzjpdffpmXX36Zhx9+WLdGFfETFbhkmdDQUKKioli/fj0zZszwOo5kgcTERJ5++mmGDh3Kc889xzvvvEPevHm9jiWSI1ggfR5Zo0YNFx8f73UMuQzJyclUr16dw4cPs3XrVt3nOgc7fvw4bdu2Zc6cOfTv3193VxO5BGa2xjlXI615OgOXLHV6uNHvvvuOCRMmeB1HMslvv/3GXXfdxdy5c/nXv/515oY+IuI/KnDJci1atKBRo0ZERUVx9OhRr+OIn+3bt4/GjRuzcuVKpk2bxgsvvOB1JJEcSQUuWc7MiI2NZd++fYwaNcrrOOJH3333HfXq1WPbtm3MmzePtm3beh1JJMdSgYsn6taty/3338+rr77KoUOHvI4jfrBhwwbq1avHL7/8wuLFi2nRooXXkURyNBW4eCYmJoajR48SGxvrdRS5THFxcTRs2JCQkBDi4uKoU6eO15FEcjwVuHjmxhtv5IknnmD06NH88MMPXseRS/TRRx+duTXqypUrueGGG7yOJBIUVODiqcjISJxzDBgwwOsocgnefvttWrduzU033URcXJxujSqShVTg4qkKFSrQpUsX3nrrLbZu3ep1HLkIw4cPp0OHDjRu3Jj//ve/lCxZ0utIIkFFBS6e6927NwULFtRwowHCOUd4eDj//Oc/efDBB5k/fz5XXHGF17FEgo4KXDxXsmRJ/vnPfzJ79mxWrVrldRy5gMTERJ599lmGDBlC586dmTFjhm6NKuIRFbhkCy+99BIlS5bUcKPZ2IkTJ3jooYeYOHEi/fr1Y8yYMYSEhHgdSyRoqcAlWyhUqBD9+vVjyZIlLFq0yOs4co7Dhw/TsmVLPvzwQ0aNGsXAgQN1a1QRj2kwE8k2Tp48SdWqVSlWrBirV68mVy79+zI72LdvHy1btmTjxo28/fbbtGvXzutIIkFDg5lIQMibNy9RUVF89dVXvPfee17HEeD777+nfv36fPPNN3z00Ucqb5FsRGfgkq0kJSVx6623cvz4cbZs2UJoaKjXkYLWxo0badGiBSdOnGD+/PnUrVvX60giQeeyzsDNbJKZ7TezTeeZ39PM1vl+NplZkpkVM7OrzWyJmW01s81m1i3VOpFm9mOq9e6+9JcnOUlISAiDBg1ix44dTJo0yes4QWv58uU0bNiQXLlyERcXp/IWyYbSPQM3s4bAUWCKc+6mdJZtBXR3zjU1syuBK51zX5nZFcAa4G/OuS1mFgkcdc4Nu5iwOgMPDs45GjZsyLfffsuOHTsoUKCA15GCyvz583nwwQcpX748CxcupEKFCl5HEglal3UG7pxbBvycwedqC0z3rbfHOfeV7+8jwFbgqgxuR4LY6eFG9+zZw+uvv+51nKAydepU7r//fm688UaWL1+u8hbJxvx2EZuZFQDuAmalMa8icCvwZarJL5jZBt9b9EX9lUNyhvr163PvvfcyZMgQfvnlF6/jBIURI0bwxBNP0KhRI5YsWaJbo4pkc/68Cr0VsMI5d9bZupkVIqXUX3TOHfZNHgtUAcKAPcDw823UzDqZWbyZxR84cMCPcSW7GzRoEL/99htDhgzxOkqO5pyjT58+vPTSS7Rp04aPP/5Yt0YVCQD+LPBH8b19fpqZhZJS3tOcc7NPT3fO7XPOJTnnkoEJQK3zbdQ5N945V8M5V0NnBMGlWrVqPPbYY4waNYoff/zR6zg5UlJSEn//+9+JjY2lU6dOvPvuu7o1qkiA8EuBm1kRoBEwJ9U0AyYCW51zr52z/JWpHrYG0rzCXWTAgAEkJSUxcOBAr6PkOCdOnODhhx9mwoQJvPLKK7z55pu6NapIAMnI18imA58D15nZbjN72sw6m1nnVIu1BhY6535PNa0e8DjQNI2vi71qZhvNbAPQBOjun5cjOU2lSpXo3LkzEydOZNu2bV7HyTEOHz7M3XffzezZsxk1ahRRUVG6NapIgNGNXCTb279/P5UrV+buu+9m5syZXscJePv376dly5Zs2LCByZMn0759e68jich56FaqEtBKlSpFjx49eO+999A/4C7Pzp07qVevHlu3bmXu3Lkqb5EApgKXgNCjRw9KlChBnz59vI4SsDZt2sTtt9/OwYMH+fTTT2nZsqXXkUTkMqjAJSAULlyYvn37smjRIhYvXux1nICzcuVKGjRogJkRFxfH7bff7nUkEblMKnAJGJ07d6Z8+fKEh4cTSNdueO3jjz+mWbNmlCxZkhUrVnDTTRe8I7KIBAgVuASMfPnyMWDAAOLj45k9e3b6KwjTpk3j/vvv5/rrr2f58uVUrFjR60gi4icqcAkojz/+ODfccAN9+/YlMTHR6zjZ2qhRo3jsscdo0KABS5YsoVSpUl5HEhE/UoFLQDk93Og333zD5MmTvY6TLTnneOWVV3jxxRd54IEH+PjjjylcuLDXsUTEz/Q9cAk4zjluv/12fvjhB7Zv307+/Pm9jpRtJCUl8fzzzzN+/HieffZZxo4dq7uriQQwfQ9cchQzY/Dgwfz444+88cYbXsfJNk6ePMkjjzzC+PHj6dOnD+PGjVN5i+RgKnAJSI0aNaJly5YMGjSIX3/91es4njty5Ah33303s2bNYsSIEcTExOjWqCI5nApcAtagQYP45ZdfGDp0qNdRPLV//36aNGnCZ599xpQpU3jxxRe9jiQiWUAFLgErLCyMtm3bMnLkSPbs2eN1HE8kJCTQoEEDtmzZwpw5c3j88ce9jiQiWUQFLgEtKiqKP/74g6ioKK+jZLnNmzdz++23s3//fhYtWsQ999zjdSQRyUIqcAloVapUoVOnTkyYMIEdO3Z4HSfLfP755zRo0ADnHMuWLaNevXpeRxKRLKYCl4DXr18/8uTJQ0REhNdRssSCBQto1qwZxYsXZ8WKFVSrVs3rSCLiARW4BLwyZcrQvXt3pk+fztq1a72Ok6neeecdWrVqxXXXXceKFSuoVKmS15FExCMqcMkRevbsSbFixXL0cKOvv/467du3p379+ixdulS3RhUJcipwyRGKFClC7969WbBgAUuXLvU6jl855+jXrx/dunWjdevWfPLJJ7o1qoiowCXn6NKlC+XKlaN37945ZrjRpKQknnvuOaKjo3n66aeZOXMm+fLl8zqWiGQDKnDJMfLnz09kZCRffPEFc+bM8TrOZTt58iSPPvoo48aNIzw8nAkTJpA7d26vY4lINqHBTCRHSUxM5KabbiJXrlxs3LgxYO8FfuTIEVq3bs3ixYsZPnw4L730kteRRMQDGsxEgkbu3LmJiYlh69atTJ061es4l+TAgQM0bdqUpUuX8vbbb6u8RSRNOgOXHMc5R+3atdm7dy/btm0LqM+Md+3aRfPmzUlISGDmzJm0atXK60gi4iGdgUtQOT3c6A8//MDYsWO9jpNhW7Zs4fbbb2fv3r0sWrRI5S0iF6QClxypadOm3HnnncTExHD48GGv46Triy++oEGDBiQnJ7Ns2TLq16/vdSQRyeZU4JJjxcbGcujQIYYNG+Z1lAtasGABd9xxB0WLFmXFihXcfPPNXkcSkQCgApccq3r16jz88MO89tpr7Nu3z+s4aZo+fTqtWrXi2muv1a1RReSiqMAlR4uKiuLEiRPExMR4HeVPRo8eTfv27alXrx5Lly6ldOnSXkcSkQCiApcc7dprr+WZZ57hzTff5Pvvv/c6DpBylXz//v3p2rUr9913HwsWLKBIkSJexxKRAKMClxwvIiKCkJCQbDHcaFJSEl26dGHgwIE89dRTvP/++wH1NTcRyT5U4JLjlS1blm7dujFt2jQ2bNjgWY6TJ0/Srl07xo4dy8svv8y///1v3RpVRC6ZClyCQq9evShSpAh9+/b15PmPHj3Kvffey8yZMxk6dChDhgzBzDzJIiI5gwpcgkLRokUJDw9n3rx5LF++PEuf++DBgzRt2pQlS5YwefJk/vnPf2bp84tIzqQCl6DRtWtXypYtS3h4eJYNN7pr1y7q16/Pxo0b+eCDD3jyySez5HlFJOdLt8DNbJKZ7TezTeeZ39PM1vl+NplZkpkV8827y8y+MbMdZhaeap1iZrbIzLb7fhf130sSSVuBAgXo378/K1asYP78+Zn+fFu3bqVevXrs3buXhQsX6taoIuJX6Q5mYmYNgaPAFOfcTeks2wro7pxramYhwDbgTmA3sBpo65zbYmavAj875wb7ir2oc65XemE1mIlcrlOnTnHjjTeSN29e1q1bl2nDjX755Zfcfffd5MmThwULFnDLLbdkyvOISM52WYOZOOeWAT9n8LnaAtN9f9cCdjjnvnPO/QHMAO73zbsfeNv399vA3zK4fZHLEhoaSnR0NJs2beKdd97JlOdYuHAhd9xxB3/5y19YsWKFyltEMoXfPgM3swLAXcAs36SrgB9SLbLbNw2gtHNuD4Dvd6kLbLeTmcWbWfyBAwf8FVeC2IMPPshtt91GREQEJ0+e9Ou23333Xe69917++te/smLFCipXruzX7YuInObPi9haASucc6fP1tP6jsxFXznknBvvnKvhnKtRsmTJywooApArVy4GDx7Mzp07GTdunN+2O2bMGNq2bUudOnVYunQpZcqU8du2RUTO5c8Cf5T/vX0OKWfcV6d6XA74yff3PjO7EsD3e78fc4ikq1mzZjRt2pTo6GiOHDlyWdtyzhEZGUmXLl1o1aoV//nPf/jLX/7in6AiIufhlwI3syJAI2BOqsmrgWvMrJKZ5SGl4Of65s0FTn+f5slz1hPJdGZGbGwsBw4cYMSIEZe8neTkZLp27cqAAQPo0KEDs2bNIn/+/H5MKiKStox8jWw68DlwnZntNrOnzayzmXVOtVhrYKFz7vfTE5xzicALwH+ArcBM59xm3+zBwJ1mtp2Uq9QH++fliGRcrVq1aNOmDcOGDeNSrq/4448/aNeuHW+88QY9e/Zk0qRJujWqiGSZdL9Glp3oa2Tib19//TU33ngj//jHPy7qTPzo0aO0adOGhQsX8uqrr9KzZ89MTCkiweqyvkYmkpNVrVqVjh07MmbMGBISEjK0zsGDB7njjjtYvHgxkyZNUnmLiCdU4BL0IiMjMTMiIyPTXfaHH36gQYMGrF+/ntmzZ9OxY8fMDygikgYVuAS9cuXK0bVrV6ZMmcLmzZvPu9zXX39NvXr1+Omnn1i4cCH33XdfFqYUETmbClwECA8Pp1ChQucdbnTVqlXUr1+fP/74g88++4yGDRtmcUIRkbOpwEWA4sWL06tXL+bMmcPnn39+1rxFixbRtGlTChcuzIoVKwgLC/MmpIhIKipwEZ9u3bpRunTps4YbnTlzJvfccw9VqlRhxYoVVKlSxeOUIiIp9KVVEZ+CBQsSERFBly5dKFOmDPv3p9wg8LrrruOzzz7T3dVEJFvRGbhIKgULFsTMzpQ3wK5du7Jk/HARkYuhAhdJpX///px7c6Pjx4+f9+I2ERGvqMBFUtm1a9dFTRcR8YoKXCSV8uXLX9R0ERGvqMBFUomJiaFAgQJnTStQoAAxMTEeJRIRSZsKXCSV9u3bM378eCpUqICZUaFCBcaPH0/79u29jiYichaNRiYiIpJNaTQyERGRHEYFLiIiEoBU4CIiIgFIBS4iIhKAVOAiIiIBSAUuIiISgFTgIiIiAUgFLiIiEoBU4CIiIgFIBS4iIhKAVOAiIiIBSAUuIiISgFTgIiIiAUgFLiIiEoBU4CIiIgFIBS4iIhKAVOAiIiIBSAUuIiISgFTgIiIiAUgFLiIiEoDSLXAzm2Rm+81s0wWWaWxm68xss5l95pt2nW/a6Z/DZvaib16kmf2Yat7dfntFIiIiQSB3BpaZDIwGpqQ108z+AowB7nLO7TKzUgDOuW+AMN8yIcCPwAepVh3hnBt2qcFFRESCWbpn4M65ZcDPF1ikHTDbObfLt/z+NJa5A/jWOZdwSSlFRETkLP74DPxaoKiZLTWzNWb2RBrLPApMP2faC2a2wfcWfdHzbdzMOplZvJnFHzhwwA9xRUREAp8/Cjw3UB24B2gB9DOza0/PNLM8wH3Ae6nWGQtUIeUt9j3A8PNt3Dk33jlXwzlXo2TJkn6IKyIiEvgy8hl4enYDB51zvwO/m9ky4BZgm29+S+Ar59y+0yuk/tvMJgDz/JBDREQkaPjjDHwO0MDMcptZAaA2sDXV/Lac8/a5mV2Z6mFr4LxXuIuIiMifpXsGbmbTgcZACTPbDfQHQgGcc28657aa2QJgA5AM/Ns5t8m3bgHgTuDv52z2VTMLAxywM435IiIicgHmnPM6Q4bVqFHDxcfHex1DREQkS5jZGudcjbTm6U5sIiIiAUgFLiIiEoBU4CIiIgFIBS4iIhKAVOAiIiIBSAUuIiJyGcqUAbM//5Qpk7nPqwIXERG5DPv2Xdx0f1GBi4iIBCAVuIiISABSgYuIiAQgFbiIiEgAUoGLiIhchtKlL266v/hjPHAREZGgtXevN8+rM3AREZEApAIXEREJQCpwERGRAKQCFxERCUAqcBERkQCkAhcREQlAKnAREZEApAIXEREJQCpwERGRAKQCFxERCUDmnPM6Q4aZ2QEgwY+bLAEc9OP2Ap32x9m0P/5H++Js2h//o31xNn/vjwrOuZJpzQioAvc3M4t3ztXwOkd2of1xNu2P/9G+OJv2x/9oX5wtK/eH3kIXEREJQCpwERGRABTsBT7e6wDZjPbH2bQ//kf74mzaH/+jfXG2LNsfQf0ZuIiISKAK9jNwERGRgBQUBW5md5nZN2a2w8zC05hvZva6b/4GM7vNi5xZJQP7o7GZ/WZm63w/EV7kzApmNsnM9pvZpvPMD5pjIwP7ImiOCwAzu9rMlpjZVjPbbGbd0lgmKI6PDO6LoDk+zCyfma0ys/W+/TEgjWUy/9hwzuXoHyAE+BaoDOQB1gM3nLPM3cAngAF1gC+9zu3x/mgMzPM6axbtj4bAbcCm88wPpmMjvX0RNMeF7/VeCdzm+/sKYFuw/r8jg/siaI4P33/vQr6/Q4EvgTpZfWwEwxl4LWCHc+4759wfwAzg/nOWuR+Y4lJ8AfzFzK7M6qBZJCP7I2g455YBP19gkaA5NjKwL4KKc26Pc+4r399HgK3AVecsFhTHRwb3RdDw/fc+6nsY6vs594KyTD82gqHArwJ+SPV4N38+8DKyTE6R0dda1/f20CdmdmPWRMuWgunYyIigPC7MrCJwKylnWqkF3fFxgX0BQXR8mFmIma0D9gOLnHNZfmzk9ufGsilLY9q5/1LKyDI5RUZe61ek3L7vqJndDXwIXJPZwbKpYDo20hOUx4WZFQJmAS865w6fOzuNVXLs8ZHOvgiq48M5lwSEmdlfgA/M7CbnXOrrRzL92AiGM/DdwNWpHpcDfrqEZXKKdF+rc+7w6beHnHMfA6FmViLrImYrwXRsXFAwHhdmFkpKYU1zzs1OY5GgOT7S2xfBeHwAOOd+BZYCd50zK9OPjWAo8NXANWZWyczyAI8Cc89ZZi7whO+qwTrAb865PVkdNIukuz/MrIyZme/vWqQcJ4eyPGn2EEzHxgUF23Hhe60Tga3OudfOs1hQHB8Z2RfBdHyYWUnfmTdmlh9oBnx9zmKZfmzk+LfQnXOJZvYC8B9SrsCe5JzbbGadffPfBD4m5YrBHcAxoKNXeTNbBvfHg8BzZpYIHAcedb7LKnMaM5tOytWzJcxsN9CflAtSgu7YyMC+CJrjwqce8Diw0fdZJ0AfoDwE3fGRkX0RTMfHlcDbZhZCyj9UZjrn5mV1r+hObCIiIgEoGN5CFxERyXFU4CIiIgFIBS4iIhKAVOAiIiIBSAUuIiISgFTgIiIiAUgFLiIiEoBU4CIiIgHo/wE7QXSgNd3LVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFpCAYAAACvXECGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvjUlEQVR4nO3de3yP9eP/8cdrG4akQqnEqk+lkr3taOQwKnRwKIQVkqQSSuUrP6eijz5KpOIzImpO4UORQg4jY6c20lFlPkofh04OldPr98dmRWZj7+21997P++222/a+rmvX9Xxfrpvnrvf7er8uY61FRERE3AlwHUBERMTfqYxFREQcUxmLiIg4pjIWERFxTGUsIiLimMpYRETEsXzL2Bgz1RizyxjzSR7zKxtj3jXGZBpjthhj7vN+TBERkdKrIGfGbwAtTzP/EeBTa20o0BR40RhTtvDRRERE/EO+ZWytTQR+PN0iQCVjjAHOyVn2iHfiiYiIlH5BXljHK8A7wPdAJeBua+0xL6xXRETEL3ijjFsAGUAz4EpguTFmrbX215MXNMb0AnoBVKxYMbx27dpe2LyIiIhvSEtL22OtrXbydG+U8X3AaJs9yPVWY8y3QG0g+eQFrbXxQDxARESETU1N9cLmRUREfIMxJutU073x0abtQPOcjVwEXAN844X1ioiI+IV8z4yNMbPIvkq6qjFmBzAMKANgrZ0EPAu8YYzZDBhgoLV2T5ElFhERKWXyLWNrbed85n8P3OK1RCIiIn7GG+8Zi4iIDzt8+DA7duzg999/dx2l1AgODqZGjRqUKVOmQMurjEVE/NyOHTuoVKkSISEhZA8ZIYVhrWXv3r3s2LGDyy+/vEC/o7GpRUT83O+//06VKlVUxF5ijKFKlSpn9EqDylhERFTEXnam+1NlLCIizp1zzjleX+e2bduYOXOm19dbFFTGIiJyRhISEggJCSEgIICQkBASEhJcRzollXEx8pWDQkSkNEhISKBXr15kZWVhrSUrK4tevXp57f/e1atX07RpU9q3b0/t2rWJi4sje4BHCAkJYeDAgURFRREVFcXWrVsB6N69O/Pmzctdx/Gz7P/7v/9j7dq1eDweXnrpJbZs2UJUVBQej4e6devy1VdfeSWzN/j01dTHD4qDBw8C5B4UAHFxcS6jiYj4pP79+5ORkZHn/A0bNvDHH3+cMO3gwYPcf//9TJ48+ZS/4/F4GDduXIEzfPzxx2zZsoVLLrmEhg0b8tFHH3HjjTcCcO6555KcnMyMGTPo378/ixcvznM9o0eP5oUXXshd5tFHH6Vfv37ExcVx6NAhjh49WuBMRc2nz4wHDx6cW8THHTx4kMGDBztKJCJSup1cxPlNPxtRUVHUqFGDgIAAPB4P27Zty53XuXPn3O9JSUlntN6YmBiee+45nn/+ebKysihfvrzXMheWT58Zb9++/Yymi4jI6eV3BhsSEkJW1t/vdVCrVi1Wr17tlQzlypXL/TkwMJAjR47kPv7rVcrHfw4KCuLYsew791prOXTo0CnX26VLF6Kjo1myZAktWrRgypQpNGvWzCuZC8unz4xr1qx5yunVq1cv5iQiIv5h1KhRVKhQ4YRpFSpUYNSoUcWy/Tlz5uR+j4mJAbL/QEhLSwNg0aJFHD58GIBKlSqxb9++3N/95ptvuOKKK+jbty+tW7dm06ZNxZK5IHy6jE91UADs2bOHWbNmOUgkIlK6xcXFER8fT61atTDGUKtWLeLj44vtOp0//viD6Ohoxo8fz0svvQTAAw88wJo1a4iKimLjxo1UrFgRgLp16xIUFERoaCgvvfQSc+bMoU6dOng8Hj7//HO6du1aLJkLwhy/Sq24eet+xgkJCQwePJjt27dTs2ZNnnzySebMmcPatWvp27cvL7zwQoHHBhUR8UefffYZ1157resY+QoJCSE1NZWqVau6jlIgp9qvxpg0a23Eycv69JkxZP+Vtm3bNo4dO8a2bdt45JFH+PDDD+nfvz8vv/wysbGx7Ny503VMERGRPPl8GZ9KmTJleOmll5g1axYff/wxYWFhrF271nUsEREphG3btvnMWfGZKpVlfFynTp3YuHEjlSpVolmzZowfPx5XL8uLiIjkpVSXMUCdOnVISUnhtttuo3///sTFxXHgwAHXsURERHKV+jIGqFy5MgsWLOC5555jzpw51K9fv0QNgyYiIv7NL8oYICAggEGDBvH++++zc+dOIiIiWLRoketYIiIi/lPGx918882kpaVx9dVX07ZtWwYPHlyixicVEfE3e/fuxePx4PF4qF69Opdeemnu47xG0zpbP//8M6+99ppX1+kNflfGkD1s29q1a+nZsyfPPfccrVq1Ys+ePa5jiYiUfP/6F6xadeK0Vauyp5+lKlWqkJGRQUZGBr179+axxx7LfVy2bNk8f++vw2QWlMq4hAkODmby5MlMnjyZxMREIiIicodTExGRPERGQseOfxbyqlXZjyMjvbqZyZMnExkZSWhoKHfddVfuTYG6d+/O448/TmxsLAMHDuTrr7+mfv36REZGMnTo0NzbJwKMGTOGyMhI6taty7Bhw4Ds2yp+/fXXeDwennzySXbu3Enjxo3xeDzUqVPH2cdg/baMj+vZsyfr1q3DWkvDhg15/fXXXUcSESm5YmNh7tzsAh46NPv73LnZ073ozjvvJCUlhczMTK699toT/m/+8ssvWbFiBS+++CL9+vWjX79+pKSkcMkll+Qus2zZMr766iuSk5PJyMggLS2NxMRERo8ezZVXXklGRgZjxoxh5syZtGjRgoyMDDIzM/F4PF59HgXl92UM5J4VN27cmJ49e9KrVy9+//1317FEREqm2Fh46CF49tns714uYoBPPvmERo0accMNN5CQkMCWLVty53Xo0IHAwEAAkpKS6NChA5B9V6bjli1bxrJly6hXrx5hYWF8/vnnp/wUTWRkJNOmTWP48OFs3ryZSpUqef25FITKOEfVqlVZunQpTz/9NJMnT6ZRo0a6FaOIyKmsWgUTJ8KQIdnfT34P2Qu6d+/OK6+8wubNmxk2bNgJJ0jHbwRxOtZaBg0alPve89atW7n//vv/tlzjxo1JTEzk0ksv5d5772XGjBlefR4FpTL+i8DAQEaNGsXChQv58ssvCQsLY8WKFa5jiYiUHMffI547F5555s+XrL1cyPv27ePiiy/m8OHDJCQk5Llc/fr1mT9/PgCzZ8/Ond6iRQumTp3K/v37Afjuu+/YtWvX326rmJWVxYUXXsgDDzzA/fffT3p6ulefR0GpjE+hTZs2pKSkUL16dVq0aMHo0aM1jKaICEBKyonvER9/DzklxaubefbZZ4mOjubmm2+mdu3aeS43btw4xo4dS1RUFDt37qRy5coA3HLLLXTp0oWYmBhuuOEG2rdvz759+6hSpQoNGzakTp06PPnkk6xevRqPx0O9evWYP38+/fr18+rzKCifv4ViUTpw4AA9e/Zk9uzZtG3bljfeeCP3H1pEpLTwlVsonsrBgwcpX748xhhmz57NrFmzSsyATmdyC8WgYkvlgypWrMjMmTOpX78+TzzxBFFRUSxYsIDrr7/edTQREQHS0tLo06cP1lrOO+88pk6d6jrSWdHL1PkwxtCvXz9WrlzJL7/8QlRUFHPmzHEdS0REgEaNGpGZmcmmTZtITEzkH//4h+tIZ0VlXECNGjUiPT2devXq0alTJx5//HEOHz7sOpaIiJQCKuMzcMkll7By5Ur69u3LSy+9RPPmzfnhhx9cxxIRER+nMj5DZcuWZfz48bz11lukpqYSFhbGRx995DqWiIj4MJXxWYqLi2PDhg1UqFCBpk2bMmHCBH38SUREzorKuBDq1q1LamoqrVq1om/fvtx7770cOHDAdSwREZ8TGBiYe7OGDh065N4Y4mx0796defPmAdn3H/j000/zXHb16tWsX78+9/GkSZOcjMKlMi6k8847j4ULFzJy5EhmzpxJTEwMW7dudR1LRKRIVK8Oxvz9q3r1wq23fPnyZGRk8Mknn1C2bFkmTZp0wvyzve/8lClTuO666/Kcf3IZ9+7dm65du57VtgpDZewFAQEBDB48mKVLl/Ldd98RERHBu+++6zqWiIjX/e9/Zzb9bDRq1IitW7eyevVqYmNj6dKlCzfccANHjx7lySefzL0t4r///W8gexzqPn36cN1113Hbbbexa9eu3HU1bdqU4wNMvf/++4SFhREaGkrz5s3Ztm0bkyZN4qWXXsLj8bB27VqGDx/OCy+8AEBGRgb169enbt26tGvXjp9++il3nQMHDiQqKoqrr77aK7ddVBl7UYsWLUhLS+PKK6+kdevWDBky5Kz/mhMR8UdHjhxh6dKl3HDDDQAkJyczatQoPv30U15//XUqV65MSkoKKSkpTJ48mW+//Zb//Oc/fPHFF2zevJnJkyefcKZ73O7du3nggQeYP38+mZmZvP3224SEhNC7d28ee+wxMjIyaNSo0Qm/07VrV55//nk2bdrEDTfcwIgRI07ImZyczLhx406YfrZUxl4WEhLCunXruO+++xg5ciS33XYbe/fudR1LRKRE++233/B4PERERFCzZs3cOyxFRUVx+eWXA9m3RZwxYwYej4fo6Gj27t3LV199RWJiIp07dyYwMJBLLrmEZs2a/W39GzZsoHHjxrnruuCCC06b55dffuHnn3+mSZMmAHTr1o3ExMTc+XfeeScA4eHhbNu2rdDPX8NhFoHy5cvz+uuvExMTQ58+fYiIiGD+/PmEhYW5jiYiUiIdf8/4ZH+9XaK1lgkTJtCiRYsTlnnvvfcwxpx2/dbafJc5E+XKlQOyLzw7cuRIodenM+MiYozhgQceYO3atRw9epQGDRowbdo017FERHxWixYtmDhxYu7oh19++SUHDhygcePGzJ49m6NHj7Jz505WneJ2jjExMaxZs4Zvv/0WgB9//BHgb7dUPK5y5cqcf/75ue8Hv/nmm7lnyUVBZ8ZFLCoqirS0NDp37kyPHj3YuHEj48ePz/2rSkTEl1x00akv1rrooqLfds+ePdm2bRthYWFYa6lWrRoLFy6kXbt2rFy5khtuuIGrr776lKVZrVo14uPjufPOOzl27BgXXnghy5cv54477qB9+/YsWrSICRMmnPA706dPp3fv3hw8eJArrriiSE+odAvFYnLkyBGGDBnC6NGjiYqKYt68eVx22WWuY4mI+PQtFEuyM7mFol6mLiZBQUH885//ZMGCBXz22WeEhYWxcuVK17FERKQEUBkXs3bt2pGSksKFF17IzTffzL/+9S8Noyki4ufyLWNjzFRjzC5jzCd5zH/SGJOR8/WJMeaoMeb014z7uWuuuYaNGzfSvn17Bg4cSPv27fn1119dxxIREUcKcmb8BtAyr5nW2jHWWo+11gMMAtZYa3/0TrzS65xzzmH27NmMHTuWRYsWERUVddrxU0VEipJeofOuM92f+ZaxtTYRKGi5dgZmnVECP2aM4bHHHuPDDz/kp59+Iioqirffftt1LBHxM8HBwezdu1eF7CXWWvbu3UtwcHCBf6dAV1MbY0KAxdbaOqdZpgKwA/hHXmfGxpheQC+AmjVrhmdlZRU4aGn33Xff0aFDB5KSkhgwYACjR48mKEifPBORonf48GF27NjB77//7jpKqREcHEyNGjUoU6bMCdPzupram2V8N3CPtfaOggT1t482FcShQ4cYMGAAr7zyCk2aNGHOnDlcVBwf3hMRkWJRHB9t6oReoi6UsmXLMmHCBN58802Sk5MJCwsjKSnJdSwRESliXiljY0xloAmwyBvr83f33HMPSUlJBAcH06RJE1577TW9lyMiUooV5KNNs4Ak4BpjzA5jzP3GmN7GmN5/WawdsMxae6Cogvqb0NBQUlNTadGiBY888gjdunXj4MGDrmOJiEgR0HCYJdyxY8cYOXIkw4cPp27dusyfP58rr7zSdSwRETkLGg7TRwUEBDB06FCWLFnC9u3biYiIYMmSJa5jiYiIF6mMfUSrVq1ITU0lJCSE22+/neHDh3Ps2DHXsURExAtUxj7kiiuuYP369XTr1o0RI0Zw++23596TU0REfJfK2MeUL1+eadOmMXHiRFasWEFERAQff/yx61giIlIIKmMfZIyhd+/erF27lkOHDtGgQQOmT5/uOpaIiJwllbEPi46OJj09nZiYGLp3787DDz/MH3/84TqWiIicIZWxj7vwwgtZtmwZTz31FBMnTqRJkybs2LHDdSwRETkDKuNSICgoiOeff5558+axZcsWwsPDWb16tetYIiJSQCrjUuSuu+4iJSWFCy64gJtuuokXXnhBw2iKiPgAlXEpU7t2bZKTk2nXrh1PPvkkHTt2ZN++fa5jiYjIaaiMS6FKlSoxd+5cxowZw4IFC4iKiuLzzz93HUtERPKgMi6ljDE88cQTrFixgr179xIZGcn8+fNdxxIRkVNQGZdysbGxpKenU6dOHdq3b89TTz3FkSNHXMcSEZG/UBn7gRo1arB69WoefvhhxowZwy233MKuXbtcxxIRkRwqYz9Rrlw5Xn31VaZPn05SUhLh4eFs3LjRdSwREUFl7He6du1KUlISZcqUoVGjRkyaNEkffxIRcUxl7Ic8Hg9paWncfPPNPPTQQ9x333389ttvrmOJiPgtlbGfOv/883n33XcZPnw4M2bMoEGDBnz77beuY4mI+CWVsR8LCAhg2LBhLF68mG3bthEeHs7SpUtdxxIR8TsqY+HWW28lLS2NmjVrctttt/HMM89w7Ngx17FERPyGylgAuOKKK1i/fj333HMPw4YNo3Xr1vz000+uY4mI+AWVseSqUKEC06dP57XXXmPZsmVERESQmZnpOpaISKmnMpYTGGN46KGHWLNmDb///jsxMTG89dZbrmOJiJRqKmM5pZiYGNLT04mKiuLee++lT58+HDp0yHUsEZFSSWUsebroootYsWIFAwYM4NVXX6Vp06Z89913rmOJiJQ6KmM5raCgIF544QXmzp3Lpk2bCAsLY82aNa5jiYiUKipjKZAOHTqQnJzM+eefT/PmzRk7dqyG0RQR8RKVsRTYddddR3JyMm3atGHAgAF06tSJ/fv3u44lIuLzVMZyRs4991zmzZvH888/z7x584iOjuaLL75wHUtExKepjOWMGWN46qmnWL58Obt27SIyMpL//Oc/rmOJiPgslbGctWbNmpGens61117LnXfeyaBBgzhy5IjrWCIiPkdlLIVy2WWXkZiYyIMPPsjo0aNp2bIlu3fvdh1LRMSnqIyl0MqVK8ekSZOYOnUq69atIzw8nOTkZNexRER8hspYvOa+++5j/fr1BAYG0qhRI+Lj4/XxJxGRAlAZi1eFhYWRmppKbGwsDz74ID179uS3335zHUtEpERTGYvXValShSVLljBkyBCmTp3KjTfeyLZt21zHEhEpsVTGUiQCAwN55plnePfdd/n6668JDw/ngw8+cB1LRKREUhlLkbr99ttJTU2lRo0atGrVipEjR3Ls2DHXsUREShSVsRS5f/zjHyQlJdGlSxeGDBlC27Zt+fnnn13HEhEpMVTGUiwqVKjAm2++yYQJE1i6dCmRkZFs3rzZdSwRkRJBZSzFxhhDnz59WLNmDQcOHCA6OpqZM2e6jiUi4pzKWIpdgwYNSE9PJzIykri4OPr27cuhQ4dcxxIRcUZlLE5Ur16dFStW8PjjjzNhwgSaNWvG999/7zqWiIgTKmNxpkyZMrz44ovMnj2bjIwMwsPDWbt2retYIiLFLt8yNsZMNcbsMsZ8cpplmhpjMowxW4wxa7wbUUq7u+++m40bN3LuuecSGxvLuHHjNIymiPiVgpwZvwG0zGumMeY84DWgtbX2eqCDV5KJX7n++utJTk7mjjvu4LHHHqNLly4cOHDAdSwRkWKRbxlbaxOBH0+zSBdggbV2e87yu7yUTfxM5cqVWbBgAaNHj2bu3LnUr1+fr776ynUsEZEi5433jK8GzjfGrDbGpBljunphneKnjDEMHDiQDz74gJ07dxIREcGiRYtcxxIRKVLeKOMgIBy4DWgBDDHGXH2qBY0xvYwxqcaYVN2AXk7npptuIj09nauvvpq2bdsyePBgjh496jqWiEiR8EYZ7wDet9YesNbuARKB0FMtaK2Nt9ZGWGsjqlWr5oVNS2lWs2ZN1q5dywMPPMBzzz1Hq1at2LNnj+tYIiJe540yXgQ0MsYEGWMqANHAZ15YrwjBwcHEx8czZcoUEhMTCQ8PJzU11XUsERGvKshHm2YBScA1xpgdxpj7jTG9jTG9Aay1nwHvA5uAZGCKtTbPj0GJnI3777+fdevWAXDjjTfy+uuvO04kIuI9xtXnOSMiIqzOcORM7dmzhy5durB8+XJ69uzJhAkTCA4Odh1LRKRAjDFp1tqIk6drBC7xKVWrVmXp0qUMHjyYKVOm0KhRI7KyslzHEhEpFJWx+JzAwEBGjhzJokWL+PLLLwkPD2f58uWuY4mInDWVsfis1q1bk5qaysUXX0zLli355z//ybFjx1zHEhE5Yypj8WlXXXUVGzZs4O677+bpp5/mzjvv5JdffnEdS0TkjKiMxedVrFiRhIQExo8fz5IlS4iMjOSTT3RBv4j4DpWxlArGGPr27cuqVavYt28f0dHRzJ49m4SEBEJCQggICCAkJISEhATXUUVE/ibIdQARb7rxxhtJT0+nY8eOdO7cmaCgII4cOQJAVlYWvXr1AiAuLs5lTBGRE+jMWEqdiy++mJUrV1KpUqXcIj7u4MGDDB482FEyEZFTUxlLqVSmTBn2799/ynnbt28v5jQiIqenMpZSq2bNmqecftlllxVzEhGR01MZS6k1atQoKlSo8LfpgYGBfPPNNw4SiYicmspYSq24uDji4+OpVasWxhhq1apFv379+Omnn/B4PMyePdt1RBERQDeKED+UlZVFly5dWL9+PT169ODll1+mYsWKrmOJiB/QjSJEctSqVYs1a9YwePBgpk2bRkREBJs2bXIdS0T8mMpY/FJQUBAjR45kxYoV/PLLL0RFRfHaa6/h6pUiEfFvKmPxa82aNSMzM5NmzZrxyCOPcNddd/Hjjz+6jiUifkZlLH6vWrVqLF68mBdffJHFixfj8XhYt26d61gi4kdUxiJAQEAAjz/+OOvXr6ds2bI0adKEkSNHcvToUdfRRMQPqIxF/iIiIoL09HQ6derEkCFDuPnmm/n+++9dxxKRUk5lLHKSc889l7feeotp06axceNGQkNDWbJkietYIlKKqYxFTsEYQ/fu3UlLS+PSSy/l9ttvZ8CAARw6dMh1NBEphVTGIqdRu3ZtNmzYQJ8+fRg7diwNGjRg69atrmOJSCmjMhbJR3BwMBMmTGDhwoV888031KtXj4SEBNexRKQUURmLFFCbNm3IzMykXr163HPPPXTv3j3P2zSKiJwJlbHIGbjssstYuXIlQ4cOZcaMGYSHh5ORkeE6loj4OJWxyBkKCgpixIgRrFy5kv379xMdHc2ECRM0lKaInDWVschZatq0KZmZmdxyyy307duXtm3bsnfvXtexRMQHqYxFCqFq1aq88847jBs3jqVLl+LxeEhMTHQdS0R8jMpYpJCMMfTr148NGzZQvnx5YmNjGTFihIbSFJECUxmLeElYWBhpaWnExcUxfPhwmjdvzo4dO1zHEhEfoDIW8aJKlSoxY8YMpk+fTmpqKh6Ph3fffdd1LBEp4VTGIkWga9eupKenU7NmTVq3bk3//v35448/XMcSkRJKZSxSRK6++mqSkpLo168f48ePJyYmhi+//NJ1LBEpgVTGIkWoXLlyjBs3jnfeeYft27cTFhbGjBkzXMcSkRJGZSxSDO644w4yMjIIDw+nW7dudO3alX379rmOJSIlhMpYpJjUqFGDlStXMmLECBISEggPDyc9Pd11LBEpAVTGIsUoMDCQoUOHsmrVKn777Tfq16/P+PHjNZSmiJ9TGYs40LhxYzIyMmjVqhX9+/endevW7Nmzx3UsEXFEZSziSJUqVVi4cCETJkxg2bJlhIaGsnr1atexRMQBlbGIQ8YY+vTpw8aNG6lUqRLNmjVj6NChHDlyxHU0ESlGKmOREsDj8ZCamkq3bt149tlniY2N5b///a/rWCJSTFTGIiXEOeecw7Rp03jrrbfIyMggNDSURYsWuY4lIsVAZSxSwsTFxZGens4VV1xB27ZtefTRR/n9999dxxKRIqQyFimBrrrqKtavX8/jjz/OK6+8Qv369fn8889dxxKRIqIyFimhypYty4svvsiSJUv47rvvCA8PZ9q0afpMskgplG8ZG2OmGmN2GWM+yWN+U2PML8aYjJyvod6PKeK/br31VjIzM4mOjqZHjx7cc889/Prrr65jiYgXFeTM+A2gZT7LrLXWenK+nil8LBH5q0suuYTly5czcuRI5syZQ1hYGKmpqa5jiYiX5FvG1tpE4MdiyCIipxEYGMjgwYNZs2YNhw4dokGDBowdO5Zjx465jiYiheSt94xjjDGZxpilxpjrvbROETmFhg0bkpGRwe23386AAQO4/fbb2bVrl+tYIlII3ijjdKCWtTYUmAAszGtBY0wvY0yqMSZ19+7dXti0iH+64IILmD9/Pq+++iorV67E4/GwcuVK17FE5CwVuoyttb9aa/fn/PweUMYYUzWPZeOttRHW2ohq1aoVdtMifs0Yw8MPP0xycjKVK1fmpptuYvDgwRpKU8QHFbqMjTHVjTEm5+eonHXuLex6RaRg6tatS2pqKj169OC5556jSZMmZGVluY4lImegIB9tmgUkAdcYY3YYY+43xvQ2xvTOWaQ98IkxJhN4Gehk9UFIkWJVsWJFpkyZwqxZs9i8eTMej4cFCxa4jiUiBWRc9WZERITVRzNEvO/rr7+mc+fOpKSk8NBDD/Hiiy9Svnx517FEBDDGpFlrI06erhG4REqZK6+8knXr1vHEE08wceJEoqOj+eyzz1zHEpHTUBmLlEJly5ZlzJgxLF26lB9++IHw8HCmTJmioTRFSiiVsUgp1rJlSzIzM2nQoAEPPPAAnTt35pdffnEdS0ROojIWKeUuvvhili1bxnPPPce8efOoV68eycnJrmOJyF+ojEX8QEBAAIMGDSIxMZFjx47RsGFDxowZo6E0RUoIlbGIH2nQoAEZGRm0adOGp556iltvvZX//e9/rmOJ+D2VsYifOe+883j77beZNGkSa9asITQ0lOXLl7uOJeLXVMYifsgYw4MPPkhKSgpVqlShRYsWDBo0iMOHD7uOJuKXVMYifqxOnTqkpKTQs2dPRo8eTePGjdm2bZvrWCJ+R2Us4ucqVKhAfHw8c+bM4dNPP8Xj8fD222+7jiXiV1TGIgJAx44dycjIoHbt2nTs2JEHH3yQgwcPuo4l4hdUxiKS6/LLL2ft2rUMHDiQ+Ph4oqKi2LJli+tYIqWeylhETlCmTBlGjx7NBx98wO7du4mIiODf//63htIUKUIqYxE5pVtuuYXMzEwaNWpE79696dixIz///LPrWCKlkspYRPJUvXp13n//fZ5//nkWLlyIx+Nhw4YNrmOJlDoqYxE5rYCAAJ566inWrVuHMYYbb7yR0aNHayhNES9SGYtIgURHR/Pxxx9z1113MWjQIFq0aMEPP/zgOpZIqaAyFpECO++885g9ezaTJ0/mo48+IjQ0lA8++MB1LBGfpzIWkTNijKFnz56kpqZy4YUX0rJlS5566ikOHTrkOpqIz1IZi8hZue6660hOTqZ3796MGTOGRo0a8c0337iOJeKTVMYictbKly/PxIkTmTdvHl988QX16tVjzpw5rmOJ+ByVsYgU2l133UVGRgbXX389nTp1omfPnhw4cMB1LBGfoTIWEa8ICQlhzZo1PP3000ydOpXIyEg2b97sOpaIT1AZi4jXlClThlGjRrF8+XJ++uknIiMjmThxoobSFMmHylhEvK558+ZkZmYSGxvLww8/TPv27fnpp59cxxIpsVTGIlIkLrzwQpYsWcILL7zAO++8g8fj4aOPPnIdS6REUhmLSJEJCAhgwIABrF+/nqCgIJo0acKoUaM4evSo62giJYrKWESKXGRkJB9//DEdOnTg//2//8ctt9zC999/7zqWSImhMhaRYnHuuecyc+ZMXn/9dTZs2EBoaCjvvfee61giJYLKWESKjTGGHj16kJqayiWXXMJtt93GgAEDNJSm+D2VsYgUu2uvvZaNGzfyyCOPMHbsWBo2bMjWrVtdxxJxRmUsIk4EBwfzyiuvsGDBAr7++mvq1avHzJkzXccScUJlLCJOtWvXjoyMDEJDQ4mLi6NHjx4aSlP8jspYRJyrWbMmq1evZsiQIbzxxhuEh4eTkZHhOpZIsVEZi0iJEBQUxDPPPMOHH37Ir7/+Sv369XnllVc0lKb4BZWxiJQosbGxZGZm0rx5cx599FHatWvHjz/+6DqWSJFSGYtIiVOtWjUWL17M2LFjee+99wgNDWXt2rWuY4kUGZWxiJRIxhgee+wxkpKSCA4OpmnTpjzzzDMaSlNKJZWxiJRo4eHhpKen07lzZ4YNG0bz5s357rvvXMcS8SqVsYiUeJUqVeLNN9/kjTfeIDU1ldDQUBYvXuw6lojXqIxFxCcYY+jWrRtpaWlcdtll3HHHHfTv358//vjDdTSRQlMZi4hPueaaa0hKSuLRRx9l/PjxxMTE8NVXX7mOJVIoKmMR8TnBwcG8/PLLLFy4kKysLMLCwnjzzTddxxI5aypjEfFZbdq0ITMzk3r16tG1a1e6devG/v37XccSOWMqYxHxaTVq1GDlypUMGzaMt956i7CwMNLT013HEjkj+ZaxMWaqMWaXMeaTfJaLNMYcNca09148EZH8BQUFMXz4cFauXMnBgweJiYlh/PjxGkpTfEZBzozfAFqebgFjTCDwPPCBFzKJiJyVJk2akJGRQYsWLejfvz9t2rRhz549rmOJ5CvfMrbWJgL5DQz7KDAf2OWNUCIiZ6tq1aosWrSI8ePH88EHHxAaGsqaNWtcxxI5rUK/Z2yMuRRoB0wqwLK9jDGpxpjU3bt3F3bTIiKnZIyhb9++bNiwgYoVK9KsWTOGDx/OkSNHXEcTOSVvXMA1Dhhorc13wFhrbby1NsJaG1GtWjUvbFpEJG/16tUjLS2Ne+65hxEjRtCsWTP++9//uo4l8jfeKOMIYLYxZhvQHnjNGNPWC+sVESm0SpUqMX36dGbMmEF6ejoej4d33nmHhIQEQkJCCAgIICQkhISEBNdRxY8FFXYF1trLj/9sjHkDWGytXVjY9YqIeNO9995L/fr16dSpE23atCEoKCj3ZeusrCx69eoFQFxcnMuY4qcK8tGmWUAScI0xZocx5n5jTG9jTO+ijyci4j1XXXUV69evp1KlSn97//jgwYMMHjzYUTLxd/meGVtrOxd0Zdba7oVKIyJSxMqVK5fnKF3bt28v5jQi2TQCl4j4nZo1a57RdJGipjIWEb8zatQoKlSocMK0ChUqMGrUKEeJxN+pjEXE78TFxREfH0+tWrUwxlCrVi3i4+N18ZY4Y1yN3RoREWFTU1OdbFtERMQFY0yatTbi5Ok6MxYREXFMZSwiIuKYylhERMQxlbGIiIhjKmMRERHHVMYiIiKOqYxFREQcUxmLiIg4pjIWERFxTGUsIiLimMpYRETEMZWxiIiIYypjERERx1TGIiIijqmMRUREHFMZi4iIOKYyFhERcUxlLCIi4pjKWERExDGVsYiIiGMqYxEREcdUxiIiIo6pjEVERBxTGYuIiDimMhYREXFMZSwiIuKYylhERMQxlbGIiIhjKmMRERHHVMYiIiKOqYxFREQcUxmLiIg4pjIWERFxTGUsIiLimMpYRETEMZWxiIiIYypjERERx1TGIiIijqmMRUREHFMZi4iIOJZvGRtjphpjdhljPsljfhtjzCZjTIYxJtUYc6P3Y4qIiJReBTkzfgNoeZr5HwKh1loP0AOYUvhYIiIi/iPfMrbWJgI/nmb+fmutzXlYEbB5LSsiIiJ/55X3jI0x7YwxnwNLyD47FhERkQLyShlba/9jra0NtAWezWs5Y0yvnPeVU3fv3u2NTYuIiPg8r15NnfOS9pXGmKp5zI+31kZYayOqVavmzU2LiIj4rEKXsTHmH8YYk/NzGFAW2FvY9YqIiPiLoPwWMMbMApoCVY0xO4BhQBkAa+0k4C6gqzHmMPAbcPdfLugSERGRfORbxtbazvnMfx543muJRERE/IxG4BIREXFMZSwiIuKYylhERMQxlbGIiIhjKmMRERHHVMYiIiKOqYxFREQcUxmLiIg4pjIWERFxTGUsIiJy3L/+BatWnTht1ars6UVIZSwiInJcZCR07PhnIa9alf04MrJIN5vv2NQiIiJ+IzYW5s7NLuCHHoKJE7Mfx8YW6WZ1ZiwiIvJXsbHZRfzss9nfi7iIQWUsIiJyolWrss+IhwzJ/n7ye8hFQGUsIiJy3PH3iOfOhWee+fMl6yIuZJWxiIjIcSkpJ75HfPw95JSUIt2ssdYW6QbyEhERYVNTU51sW0RExAVjTJq1NuLk6TozFhERcUxlLCIi4pjKWERExDGVsYiIiGMqYxEREcdUxiIiIo6pjEVERBxTGYuIiDimMhYREXFMZSwiIuKYylhERMQxlbGIiIhjKmMRERHHVMYiIiKOqYxFREQcUxmLiIg4pjIWERFxTGUsIiLimMpYREQkR/XqYMzfv6pXL9rtqoxFRERy/O9/ZzbdW1TGIiIijqmMRUREHFMZi4iIOKYyFhERcUxlLCIikuOii85surcEFe3qRUREfMcPP7jZrs6MRUREHFMZi4iIOJZvGRtjphpjdhljPsljfpwxZlPO13pjTKj3Y4qIiJReBTkzfgNoeZr53wJNrLV1gWeBeC/kEhER8Rv5XsBlrU00xoScZv76vzzcANTwQi4RERG/4e33jO8HluY10xjTyxiTaoxJ3b17t5c3LSIi4pu8VsbGmFiyy3hgXstYa+OttRHW2ohq1ap5a9MiIiI+zSufMzbG1AWmAK2stXu9sU4RERF/UegzY2NMTWABcK+19svCRxIREfEv+Z4ZG2NmAU2BqsaYHcAwoAyAtXYSMBSoArxmjAE4Yq2NKKrAIiIipY2x1rrZsDG7gSwvrrIqsMeL6/N12h8n0v74k/bFibQ/TqT98aei2Be1rLV/u2jKWRl7mzEmVWfkf9L+OJH2x5+0L06k/XEi7Y8/Fee+0HCYIiIijqmMRUREHCtNZaxhOE+k/XEi7Y8/aV+cSPvjRNoffyq2fVFq3jMWERHxVaXpzFhERMQn+VwZG2NaGmO+MMZsNcb83ynmG2PMyznzNxljwlzkLC4F2B9NjTG/GGMycr6GushZHApwu09/Ozby2x/+dGxcZoxZZYz5zBizxRjT7xTL+MXxUcB94U/HRrAxJtkYk5mzP0acYpmiPzastT7zBQQCXwNXAGWBTOC6k5a5leybVRigPrDRdW7H+6MpsNh11mLaH42BMOCTPOb7zbFRwP3hT8fGxUBYzs+VgC/99f+OAu4Lfzo2DHBOzs9lgI1A/eI+NnztzDgK2Gqt/cZaewiYDbQ5aZk2wAybbQNwnjHm4uIOWkwKsj/8hrU2EfjxNIv407FRkP3hN6y1O6216Tk/7wM+Ay49aTG/OD4KuC/8Rs6/9/6ch2Vyvk6+mKrIjw1fK+NLgf/+5fEO/n4QFWSZ0qKgzzUm5yWYpcaY64snWonkT8dGQfndsZFzf/Z6ZJ8B/ZXfHR+n2RfgR8eGMSbQGJMB7AKWW2uL/djwyl2bipE5xbST/4IpyDKlRUGeazrZw6/tN8bcCiwErirqYCWUPx0bBeF3x4Yx5hxgPtDfWvvrybNP8Sul9vjIZ1/41bFhrT0KeIwx5wH/McbUsdb+9VqLIj82fO3MeAdw2V8e1wC+P4tlSot8n6u19tfjL8FYa98DyhhjqhZfxBLFn46NfPnbsWGMKUN2+SRYaxecYhG/OT7y2xf+dmwcZ639GVgNtDxpVpEfG75WxinAVcaYy40xZYFOwDsnLfMO0DXn6rf6wC/W2p3FHbSY5Ls/jDHVjcm+nZYxJorsf3N/vee0Px0b+fKnYyPneb4OfGatHZvHYn5xfBRkX/jZsVEt54wYY0x54Cbg85MWK/Jjw6deprbWHjHG9AE+IPtK4qnW2i3GmN458ycB75F95dtW4CBwn6u8Ra2A+6M98JAx5gjwG9DJ5lweWNqY/G/36TfHBhRof/jNsQE0BO4FNue8NwjwNFAT/O74KMi+8Kdj42JgujEmkOw/OuZaaxcXd69oBC4RERHHfO1lahERkVJHZSwiIuKYylhERMQxlbGIiIhjKmMRERHHVMYiIiKOqYxFREQcUxmLiIg49v8BA+JN/PfSn5YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "running_loss = 0\n",
    "pbar = tqdm(val_loader)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, label) in enumerate(pbar):\n",
    "        out = conv(inputs.float())\n",
    "        running_loss += loss(out, label.float())  # MSE per batch\n",
    "        if not (i % 100):\n",
    "            pbar.set_description(f\"Loss {running_loss / (i+1):.5f}\")\n",
    "\n",
    "for i in range(25, 29):\n",
    "    out = conv(torch.Tensor(val_ds[i][0])[None, :]).detach().numpy().squeeze()\n",
    "    plt.plot(np.arange(0, CONV_WIDTH, 1), val_ds[i][0][:, 1], \"ko-\", label=\"Inputs\")\n",
    "    plt.plot(CONV_WIDTH, val_ds[i][1], \"rx\", label=\"Targets\")\n",
    "    plt.plot(CONV_WIDTH, out, \"bs\", label=\"Prediction\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
